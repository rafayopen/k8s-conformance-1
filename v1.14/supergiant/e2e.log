I0514 09:04:49.080484      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-862630419
I0514 09:04:49.080890      16 e2e.go:240] Starting e2e run "5254e0e2-7627-11e9-8d5d-c6eb97da6be3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1557824686 - Will randomize all specs
Will run 204 of 3584 specs

May 14 09:04:49.431: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:04:49.435: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 14 09:04:49.456: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 14 09:04:49.523: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 14 09:04:49.523: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
May 14 09:04:49.523: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 14 09:04:49.542: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 14 09:04:49.542: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'prometheus-operator-prometheus-node-exporter' (0 seconds elapsed)
May 14 09:04:49.542: INFO: e2e test version: v1.14.0
May 14 09:04:49.543: INFO: kube-apiserver version: v1.14.0
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:04:49.544: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
May 14 09:04:49.625: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 14 09:04:49.652: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6970
May 14 09:04:51.794: INFO: Started pod liveness-http in namespace container-probe-6970
STEP: checking the pod's current state and verifying that restartCount is present
May 14 09:04:51.796: INFO: Initial restart count of pod liveness-http is 0
May 14 09:05:09.824: INFO: Restart count of pod container-probe-6970/liveness-http is now 1 (18.027925896s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:05:09.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6970" for this suite.
May 14 09:05:19.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:05:19.907: INFO: namespace container-probe-6970 deletion completed in 10.071878686s

• [SLOW TEST:30.363 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:05:19.907: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0514 09:06:00.054117      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 09:06:00.054: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:06:00.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1434" for this suite.
May 14 09:06:06.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:06:06.134: INFO: namespace gc-1434 deletion completed in 6.07840838s

• [SLOW TEST:46.227 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:06:06.135: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4802
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9299
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3799
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:06:32.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4802" for this suite.
May 14 09:06:38.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:06:38.616: INFO: namespace namespaces-4802 deletion completed in 6.075363459s
STEP: Destroying namespace "nsdeletetest-9299" for this suite.
May 14 09:06:38.617: INFO: Namespace nsdeletetest-9299 was already deleted
STEP: Destroying namespace "nsdeletetest-3799" for this suite.
May 14 09:06:44.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:06:44.691: INFO: namespace nsdeletetest-3799 deletion completed in 6.073669271s

• [SLOW TEST:38.556 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:06:44.692: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6430
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6430
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 09:06:44.820: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 09:07:04.863: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.1.182:8080/dial?request=hostName&protocol=http&host=10.100.1.181&port=8080&tries=1'] Namespace:pod-network-test-6430 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:07:04.863: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:07:05.002: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:07:05.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6430" for this suite.
May 14 09:07:27.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:07:27.081: INFO: namespace pod-network-test-6430 deletion completed in 22.075879925s

• [SLOW TEST:42.389 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:07:27.082: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 14 09:07:29.733: INFO: Successfully updated pod "pod-update-b1e88769-7627-11e9-8d5d-c6eb97da6be3"
STEP: verifying the updated pod is in kubernetes
May 14 09:07:29.737: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:07:29.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7622" for this suite.
May 14 09:07:51.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:07:51.813: INFO: namespace pods-7622 deletion completed in 22.074237927s

• [SLOW TEST:24.731 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:07:51.813: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9245
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:07:51.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3" in namespace "projected-9245" to be "success or failure"
May 14 09:07:51.950: INFO: Pod "downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.945096ms
May 14 09:07:53.954: INFO: Pod "downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006736186s
STEP: Saw pod success
May 14 09:07:53.954: INFO: Pod "downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:07:53.956: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:07:53.987: INFO: Waiting for pod downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:07:53.989: INFO: Pod downwardapi-volume-c0a5f1aa-7627-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:07:53.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9245" for this suite.
May 14 09:07:59.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:00.067: INFO: namespace projected-9245 deletion completed in 6.075654763s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:00.067: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c5915539-7627-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:08:00.204: INFO: Waiting up to 5m0s for pod "pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3" in namespace "secrets-7301" to be "success or failure"
May 14 09:08:00.208: INFO: Pod "pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.541144ms
May 14 09:08:02.211: INFO: Pod "pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007351057s
STEP: Saw pod success
May 14 09:08:02.211: INFO: Pod "pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:08:02.213: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 09:08:02.226: INFO: Waiting for pod pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:08:02.228: INFO: Pod pod-secrets-c591be27-7627-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:02.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7301" for this suite.
May 14 09:08:08.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:08.305: INFO: namespace secrets-7301 deletion completed in 6.075147319s

• [SLOW TEST:8.238 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:08.306: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
May 14 09:08:08.540: INFO: Waiting up to 5m0s for pod "client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3" in namespace "containers-6362" to be "success or failure"
May 14 09:08:08.542: INFO: Pod "client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.698219ms
May 14 09:08:10.545: INFO: Pod "client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00514847s
STEP: Saw pod success
May 14 09:08:10.545: INFO: Pod "client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:08:10.547: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:08:10.558: INFO: Waiting for pod client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:08:10.560: INFO: Pod client-containers-ca88b964-7627-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:10.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6362" for this suite.
May 14 09:08:16.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:16.636: INFO: namespace containers-6362 deletion completed in 6.073853822s

• [SLOW TEST:8.330 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:16.636: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2013
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:16.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2013" for this suite.
May 14 09:08:22.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:22.843: INFO: namespace services-2013 deletion completed in 6.074936363s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.207 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:22.844: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:08:22.975: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-7041" to be "success or failure"
May 14 09:08:22.978: INFO: Pod "downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716451ms
May 14 09:08:24.980: INFO: Pod "downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004900683s
STEP: Saw pod success
May 14 09:08:24.980: INFO: Pod "downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:08:24.982: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:08:24.994: INFO: Waiting for pod downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:08:24.996: INFO: Pod downwardapi-volume-d324c2f6-7627-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:24.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7041" for this suite.
May 14 09:08:31.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:31.093: INFO: namespace downward-api-7041 deletion completed in 6.093021357s

• [SLOW TEST:8.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:31.094: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:08:31.228: INFO: (0) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.839263ms)
May 14 09:08:31.231: INFO: (1) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.467524ms)
May 14 09:08:31.233: INFO: (2) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.352561ms)
May 14 09:08:31.236: INFO: (3) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.489304ms)
May 14 09:08:31.238: INFO: (4) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.41356ms)
May 14 09:08:31.241: INFO: (5) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.446083ms)
May 14 09:08:31.243: INFO: (6) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.417262ms)
May 14 09:08:31.245: INFO: (7) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.358894ms)
May 14 09:08:31.248: INFO: (8) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.383582ms)
May 14 09:08:31.250: INFO: (9) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.440288ms)
May 14 09:08:31.253: INFO: (10) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.394112ms)
May 14 09:08:31.255: INFO: (11) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.297431ms)
May 14 09:08:31.257: INFO: (12) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.354423ms)
May 14 09:08:31.260: INFO: (13) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.194492ms)
May 14 09:08:31.262: INFO: (14) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.379878ms)
May 14 09:08:31.265: INFO: (15) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.061494ms)
May 14 09:08:31.267: INFO: (16) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.300362ms)
May 14 09:08:31.270: INFO: (17) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.413448ms)
May 14 09:08:31.272: INFO: (18) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.20611ms)
May 14 09:08:31.275: INFO: (19) /api/v1/nodes/ip-10-2-82-233.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.634404ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:31.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4367" for this suite.
May 14 09:08:37.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:37.362: INFO: namespace proxy-4367 deletion completed in 6.084739032s

• [SLOW TEST:6.268 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:37.363: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:37.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9422" for this suite.
May 14 09:08:59.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:08:59.608: INFO: namespace pods-9422 deletion completed in 22.09389859s

• [SLOW TEST:22.246 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:08:59.609: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
May 14 09:08:59.737: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-862630419 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:08:59.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-200" for this suite.
May 14 09:09:05.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:09:05.874: INFO: namespace kubectl-200 deletion completed in 6.073313918s

• [SLOW TEST:6.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:09:05.874: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 14 09:09:06.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-6382'
May 14 09:09:06.400: INFO: stderr: ""
May 14 09:09:06.400: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 14 09:09:07.402: INFO: Selector matched 1 pods for map[app:redis]
May 14 09:09:07.403: INFO: Found 1 / 1
May 14 09:09:07.403: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 14 09:09:07.404: INFO: Selector matched 1 pods for map[app:redis]
May 14 09:09:07.404: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 14 09:09:07.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 patch pod redis-master-xmcg4 --namespace=kubectl-6382 -p {"metadata":{"annotations":{"x":"y"}}}'
May 14 09:09:07.520: INFO: stderr: ""
May 14 09:09:07.520: INFO: stdout: "pod/redis-master-xmcg4 patched\n"
STEP: checking annotations
May 14 09:09:07.523: INFO: Selector matched 1 pods for map[app:redis]
May 14 09:09:07.523: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:09:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6382" for this suite.
May 14 09:09:29.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:09:29.612: INFO: namespace kubectl-6382 deletion completed in 22.084680299s

• [SLOW TEST:23.738 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:09:29.612: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6825
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 14 09:09:29.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126863,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 09:09:29.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126863,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 14 09:09:39.753: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126877,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 14 09:09:39.754: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126877,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 14 09:09:49.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126891,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 09:09:49.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126891,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 14 09:09:59.764: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126905,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 09:09:59.764: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-a,UID:faf1bea6-7627-11e9-a442-02538a874012,ResourceVersion:126905,Generation:0,CreationTimestamp:2019-05-14 09:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 14 09:10:09.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-b,UID:12cc5718-7628-11e9-a442-02538a874012,ResourceVersion:126920,Generation:0,CreationTimestamp:2019-05-14 09:10:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 09:10:09.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-b,UID:12cc5718-7628-11e9-a442-02538a874012,ResourceVersion:126920,Generation:0,CreationTimestamp:2019-05-14 09:10:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 14 09:10:19.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-b,UID:12cc5718-7628-11e9-a442-02538a874012,ResourceVersion:126934,Generation:0,CreationTimestamp:2019-05-14 09:10:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 09:10:19.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6825,SelfLink:/api/v1/namespaces/watch-6825/configmaps/e2e-watch-test-configmap-b,UID:12cc5718-7628-11e9-a442-02538a874012,ResourceVersion:126934,Generation:0,CreationTimestamp:2019-05-14 09:10:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:10:29.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6825" for this suite.
May 14 09:10:35.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:10:35.851: INFO: namespace watch-6825 deletion completed in 6.072486429s

• [SLOW TEST:66.239 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:10:35.852: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:10:38.012: INFO: Waiting up to 5m0s for pod "client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3" in namespace "pods-4522" to be "success or failure"
May 14 09:10:38.019: INFO: Pod "client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.680077ms
May 14 09:10:40.022: INFO: Pod "client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00952806s
STEP: Saw pod success
May 14 09:10:40.022: INFO: Pod "client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:10:40.024: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3 container env3cont: <nil>
STEP: delete the pod
May 14 09:10:40.038: INFO: Waiting for pod client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:10:40.041: INFO: Pod client-envvars-23a113db-7628-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:10:40.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4522" for this suite.
May 14 09:11:18.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:11:18.116: INFO: namespace pods-4522 deletion completed in 38.073255331s

• [SLOW TEST:42.265 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:11:18.117: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:11:20.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8578" for this suite.
May 14 09:12:06.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:12:06.351: INFO: namespace kubelet-test-8578 deletion completed in 46.074406228s

• [SLOW TEST:48.234 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:12:06.352: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 14 09:12:06.484: INFO: Waiting up to 5m0s for pod "pod-585d7153-7628-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-8602" to be "success or failure"
May 14 09:12:06.488: INFO: Pod "pod-585d7153-7628-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.645861ms
May 14 09:12:08.490: INFO: Pod "pod-585d7153-7628-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006203264s
STEP: Saw pod success
May 14 09:12:08.490: INFO: Pod "pod-585d7153-7628-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:12:08.492: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-585d7153-7628-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:12:08.518: INFO: Waiting for pod pod-585d7153-7628-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:12:08.520: INFO: Pod pod-585d7153-7628-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:12:08.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8602" for this suite.
May 14 09:12:14.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:12:14.593: INFO: namespace emptydir-8602 deletion completed in 6.071027696s

• [SLOW TEST:8.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:12:14.593: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5d4701ef-7628-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:12:14.728: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3" in namespace "configmap-6572" to be "success or failure"
May 14 09:12:14.734: INFO: Pod "pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.631628ms
May 14 09:12:16.737: INFO: Pod "pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008275745s
STEP: Saw pod success
May 14 09:12:16.737: INFO: Pod "pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:12:16.745: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:12:16.762: INFO: Waiting for pod pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:12:16.764: INFO: Pod pod-configmaps-5d4761b2-7628-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:12:16.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6572" for this suite.
May 14 09:12:22.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:12:22.844: INFO: namespace configmap-6572 deletion completed in 6.077785383s

• [SLOW TEST:8.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:12:22.844: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 14 09:12:22.989: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:22.995: INFO: Number of nodes with available pods: 0
May 14 09:12:22.995: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:23.998: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:24.000: INFO: Number of nodes with available pods: 0
May 14 09:12:24.000: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:24.998: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:25.000: INFO: Number of nodes with available pods: 0
May 14 09:12:25.000: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:25.998: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:26.000: INFO: Number of nodes with available pods: 1
May 14 09:12:26.000: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 14 09:12:26.011: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:26.013: INFO: Number of nodes with available pods: 0
May 14 09:12:26.013: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:27.016: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:27.018: INFO: Number of nodes with available pods: 0
May 14 09:12:27.018: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:28.018: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:28.020: INFO: Number of nodes with available pods: 0
May 14 09:12:28.020: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:29.016: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:29.017: INFO: Number of nodes with available pods: 0
May 14 09:12:29.017: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:30.016: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:30.018: INFO: Number of nodes with available pods: 0
May 14 09:12:30.018: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:31.016: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:31.018: INFO: Number of nodes with available pods: 0
May 14 09:12:31.018: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:12:32.016: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:12:32.018: INFO: Number of nodes with available pods: 1
May 14 09:12:32.018: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2051, will wait for the garbage collector to delete the pods
May 14 09:12:32.077: INFO: Deleting DaemonSet.extensions daemon-set took: 5.201763ms
May 14 09:12:32.577: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.205681ms
May 14 09:12:35.379: INFO: Number of nodes with available pods: 0
May 14 09:12:35.379: INFO: Number of running nodes: 0, number of available pods: 0
May 14 09:12:35.382: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2051/daemonsets","resourceVersion":"127293"},"items":null}

May 14 09:12:35.384: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2051/pods","resourceVersion":"127293"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:12:35.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2051" for this suite.
May 14 09:12:41.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:12:41.465: INFO: namespace daemonsets-2051 deletion completed in 6.074636636s

• [SLOW TEST:18.621 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:12:41.465: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 14 09:12:41.599: INFO: Waiting up to 5m0s for pod "pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-9251" to be "success or failure"
May 14 09:12:41.604: INFO: Pod "pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.901028ms
May 14 09:12:43.606: INFO: Pod "pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007003419s
STEP: Saw pod success
May 14 09:12:43.606: INFO: Pod "pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:12:43.608: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:12:43.620: INFO: Waiting for pod pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:12:43.622: INFO: Pod pod-6d4b9a87-7628-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:12:43.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9251" for this suite.
May 14 09:12:49.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:12:49.700: INFO: namespace emptydir-9251 deletion completed in 6.075760245s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:12:49.701: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 14 09:12:52.384: INFO: Successfully updated pod "annotationupdate72342978-7628-11e9-8d5d-c6eb97da6be3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:12:56.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5102" for this suite.
May 14 09:13:18.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:13:18.479: INFO: namespace downward-api-5102 deletion completed in 22.07397971s

• [SLOW TEST:28.778 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:13:18.479: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9099
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-835bce6a-7628-11e9-8d5d-c6eb97da6be3
STEP: Creating configMap with name cm-test-opt-upd-835bcea6-7628-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-835bce6a-7628-11e9-8d5d-c6eb97da6be3
STEP: Updating configmap cm-test-opt-upd-835bcea6-7628-11e9-8d5d-c6eb97da6be3
STEP: Creating configMap with name cm-test-opt-create-835bcec1-7628-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:13:22.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9099" for this suite.
May 14 09:13:44.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:13:44.772: INFO: namespace configmap-9099 deletion completed in 22.094122571s

• [SLOW TEST:26.293 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:13:44.772: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
May 14 09:13:44.905: INFO: Waiting up to 5m0s for pod "client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3" in namespace "containers-5103" to be "success or failure"
May 14 09:13:44.909: INFO: Pod "client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.265741ms
May 14 09:13:46.911: INFO: Pod "client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005941144s
STEP: Saw pod success
May 14 09:13:46.911: INFO: Pod "client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:13:46.913: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:13:46.926: INFO: Waiting for pod client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:13:46.928: INFO: Pod client-containers-930741a7-7628-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:13:46.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5103" for this suite.
May 14 09:13:52.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:13:53.002: INFO: namespace containers-5103 deletion completed in 6.072171256s

• [SLOW TEST:8.230 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:13:53.002: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:13:53.143: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 14 09:13:53.153: INFO: Number of nodes with available pods: 0
May 14 09:13:53.153: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 14 09:13:53.172: INFO: Number of nodes with available pods: 0
May 14 09:13:53.172: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:13:54.174: INFO: Number of nodes with available pods: 0
May 14 09:13:54.174: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:13:55.174: INFO: Number of nodes with available pods: 1
May 14 09:13:55.174: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 14 09:13:55.187: INFO: Number of nodes with available pods: 1
May 14 09:13:55.187: INFO: Number of running nodes: 0, number of available pods: 1
May 14 09:13:56.189: INFO: Number of nodes with available pods: 0
May 14 09:13:56.189: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 14 09:13:56.197: INFO: Number of nodes with available pods: 0
May 14 09:13:56.198: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:13:57.200: INFO: Number of nodes with available pods: 0
May 14 09:13:57.200: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:13:58.200: INFO: Number of nodes with available pods: 0
May 14 09:13:58.200: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:13:59.205: INFO: Number of nodes with available pods: 0
May 14 09:13:59.205: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:14:00.200: INFO: Number of nodes with available pods: 1
May 14 09:14:00.200: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9383, will wait for the garbage collector to delete the pods
May 14 09:14:00.262: INFO: Deleting DaemonSet.extensions daemon-set took: 5.76188ms
May 14 09:14:00.562: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.221578ms
May 14 09:14:12.564: INFO: Number of nodes with available pods: 0
May 14 09:14:12.564: INFO: Number of running nodes: 0, number of available pods: 0
May 14 09:14:12.565: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9383/daemonsets","resourceVersion":"127621"},"items":null}

May 14 09:14:12.567: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9383/pods","resourceVersion":"127621"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:14:12.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9383" for this suite.
May 14 09:14:18.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:14:18.653: INFO: namespace daemonsets-9383 deletion completed in 6.07328681s

• [SLOW TEST:25.651 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:14:18.654: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
May 14 09:14:18.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 --namespace=kubectl-7155 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 14 09:14:20.353: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 14 09:14:20.353: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:14:22.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7155" for this suite.
May 14 09:14:36.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:14:36.435: INFO: namespace kubectl-7155 deletion completed in 14.075070459s

• [SLOW TEST:17.781 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:14:36.435: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 14 09:14:40.595: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:40.598: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:42.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:42.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:44.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:44.600: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:46.599: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:46.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:48.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:48.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:50.599: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:50.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:52.599: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:52.613: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:54.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:54.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:56.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:56.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:14:58.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:14:58.601: INFO: Pod pod-with-poststart-exec-hook still exists
May 14 09:15:00.598: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 14 09:15:00.601: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:15:00.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3867" for this suite.
May 14 09:15:22.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:15:22.678: INFO: namespace container-lifecycle-hook-3867 deletion completed in 22.075176203s

• [SLOW TEST:46.243 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:15:22.679: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2609
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 14 09:15:22.827: INFO: Found 0 stateful pods, waiting for 3
May 14 09:15:32.830: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:15:32.830: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:15:32.830: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 14 09:15:32.852: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 14 09:15:42.881: INFO: Updating stateful set ss2
May 14 09:15:42.894: INFO: Waiting for Pod statefulset-2609/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 14 09:15:52.954: INFO: Found 2 stateful pods, waiting for 3
May 14 09:16:02.956: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:16:02.956: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:16:02.956: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 14 09:16:02.974: INFO: Updating stateful set ss2
May 14 09:16:02.986: INFO: Waiting for Pod statefulset-2609/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 14 09:16:13.007: INFO: Updating stateful set ss2
May 14 09:16:13.049: INFO: Waiting for StatefulSet statefulset-2609/ss2 to complete update
May 14 09:16:13.050: INFO: Waiting for Pod statefulset-2609/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 14 09:16:23.055: INFO: Deleting all statefulset in ns statefulset-2609
May 14 09:16:23.057: INFO: Scaling statefulset ss2 to 0
May 14 09:16:33.069: INFO: Waiting for statefulset status.replicas updated to 0
May 14 09:16:33.071: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:16:33.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2609" for this suite.
May 14 09:16:39.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:16:39.157: INFO: namespace statefulset-2609 deletion completed in 6.074813603s

• [SLOW TEST:76.479 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:16:39.158: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 09:16:39.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4297'
May 14 09:16:39.369: INFO: stderr: ""
May 14 09:16:39.370: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 14 09:16:44.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pod e2e-test-nginx-pod --namespace=kubectl-4297 -o json'
May 14 09:16:44.487: INFO: stderr: ""
May 14 09:16:44.487: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-14T09:16:39Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4297\",\n        \"resourceVersion\": \"128178\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4297/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fb02936f-7628-11e9-a442-02538a874012\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mdch8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-2-82-233.ec2.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mdch8\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mdch8\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T09:16:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T09:16:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T09:16:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T09:16:39Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b1c8cf4883d85805017352a0e1d387ed8fb59c9b4c0094baf4c26632d7ebbb93\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-14T09:16:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.2.82.233\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.100.1.214\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-14T09:16:39Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 14 09:16:44.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 replace -f - --namespace=kubectl-4297'
May 14 09:16:44.633: INFO: stderr: ""
May 14 09:16:44.633: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
May 14 09:16:44.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete pods e2e-test-nginx-pod --namespace=kubectl-4297'
May 14 09:16:46.582: INFO: stderr: ""
May 14 09:16:46.582: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:16:46.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4297" for this suite.
May 14 09:16:52.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:16:52.671: INFO: namespace kubectl-4297 deletion completed in 6.086586579s

• [SLOW TEST:13.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:16:52.672: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:16:52.804: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3" in namespace "projected-3551" to be "success or failure"
May 14 09:16:52.811: INFO: Pod "downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.722772ms
May 14 09:16:54.813: INFO: Pod "downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008704273s
STEP: Saw pod success
May 14 09:16:54.813: INFO: Pod "downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:16:54.815: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:16:54.832: INFO: Waiting for pod downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:16:54.835: INFO: Pod downwardapi-volume-03067649-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:16:54.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3551" for this suite.
May 14 09:17:00.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:17:00.920: INFO: namespace projected-3551 deletion completed in 6.082382867s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:17:00.920: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
May 14 09:17:01.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-6468'
May 14 09:17:01.200: INFO: stderr: ""
May 14 09:17:01.200: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:17:01.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6468'
May 14 09:17:01.307: INFO: stderr: ""
May 14 09:17:01.307: INFO: stdout: "update-demo-nautilus-2d94h update-demo-nautilus-n69wv "
May 14 09:17:01.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-2d94h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:01.374: INFO: stderr: ""
May 14 09:17:01.374: INFO: stdout: ""
May 14 09:17:01.374: INFO: update-demo-nautilus-2d94h is created but not running
May 14 09:17:06.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6468'
May 14 09:17:06.446: INFO: stderr: ""
May 14 09:17:06.446: INFO: stdout: "update-demo-nautilus-2d94h update-demo-nautilus-n69wv "
May 14 09:17:06.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-2d94h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:06.520: INFO: stderr: ""
May 14 09:17:06.520: INFO: stdout: "true"
May 14 09:17:06.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-2d94h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:06.587: INFO: stderr: ""
May 14 09:17:06.587: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:17:06.587: INFO: validating pod update-demo-nautilus-2d94h
May 14 09:17:06.590: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:17:06.591: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:17:06.591: INFO: update-demo-nautilus-2d94h is verified up and running
May 14 09:17:06.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-n69wv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:06.658: INFO: stderr: ""
May 14 09:17:06.658: INFO: stdout: "true"
May 14 09:17:06.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-n69wv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:06.726: INFO: stderr: ""
May 14 09:17:06.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:17:06.726: INFO: validating pod update-demo-nautilus-n69wv
May 14 09:17:06.729: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:17:06.729: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:17:06.729: INFO: update-demo-nautilus-n69wv is verified up and running
STEP: rolling-update to new replication controller
May 14 09:17:06.730: INFO: scanned /root for discovery docs: <nil>
May 14 09:17:06.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6468'
May 14 09:17:29.092: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 14 09:17:29.092: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:17:29.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6468'
May 14 09:17:29.170: INFO: stderr: ""
May 14 09:17:29.170: INFO: stdout: "update-demo-kitten-bxxb2 update-demo-kitten-r6hgl "
May 14 09:17:29.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-kitten-bxxb2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:29.238: INFO: stderr: ""
May 14 09:17:29.238: INFO: stdout: "true"
May 14 09:17:29.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-kitten-bxxb2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:29.305: INFO: stderr: ""
May 14 09:17:29.305: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 14 09:17:29.305: INFO: validating pod update-demo-kitten-bxxb2
May 14 09:17:29.308: INFO: got data: {
  "image": "kitten.jpg"
}

May 14 09:17:29.308: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 14 09:17:29.308: INFO: update-demo-kitten-bxxb2 is verified up and running
May 14 09:17:29.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-kitten-r6hgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:29.374: INFO: stderr: ""
May 14 09:17:29.374: INFO: stdout: "true"
May 14 09:17:29.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-kitten-r6hgl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6468'
May 14 09:17:29.442: INFO: stderr: ""
May 14 09:17:29.442: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 14 09:17:29.442: INFO: validating pod update-demo-kitten-r6hgl
May 14 09:17:29.446: INFO: got data: {
  "image": "kitten.jpg"
}

May 14 09:17:29.446: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 14 09:17:29.446: INFO: update-demo-kitten-r6hgl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:17:29.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6468" for this suite.
May 14 09:17:51.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:17:51.521: INFO: namespace kubectl-6468 deletion completed in 22.073423164s

• [SLOW TEST:50.601 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:17:51.521: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-261a3f5c-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:17:51.658: INFO: Waiting up to 5m0s for pod "pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3" in namespace "secrets-9099" to be "success or failure"
May 14 09:17:51.660: INFO: Pod "pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.95243ms
May 14 09:17:53.663: INFO: Pod "pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00509496s
STEP: Saw pod success
May 14 09:17:53.663: INFO: Pod "pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:17:53.665: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3 container secret-env-test: <nil>
STEP: delete the pod
May 14 09:17:53.681: INFO: Waiting for pod pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:17:53.684: INFO: Pod pod-secrets-261a9c51-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:17:53.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9099" for this suite.
May 14 09:17:59.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:17:59.761: INFO: namespace secrets-9099 deletion completed in 6.075142433s

• [SLOW TEST:8.240 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:17:59.762: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4413
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-4413/secret-test-2b03a888-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:17:59.898: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3" in namespace "secrets-4413" to be "success or failure"
May 14 09:17:59.902: INFO: Pod "pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.75653ms
May 14 09:18:01.904: INFO: Pod "pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006362156s
STEP: Saw pod success
May 14 09:18:01.904: INFO: Pod "pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:18:01.906: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3 container env-test: <nil>
STEP: delete the pod
May 14 09:18:01.921: INFO: Waiting for pod pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:18:01.923: INFO: Pod pod-configmaps-2b040957-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:18:01.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4413" for this suite.
May 14 09:18:07.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:18:07.999: INFO: namespace secrets-4413 deletion completed in 6.073634712s

• [SLOW TEST:8.238 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:18:08.000: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2fed8960-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:18:08.141: INFO: Waiting up to 5m0s for pod "pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3" in namespace "configmap-6775" to be "success or failure"
May 14 09:18:08.147: INFO: Pod "pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.6561ms
May 14 09:18:10.149: INFO: Pod "pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007916518s
STEP: Saw pod success
May 14 09:18:10.149: INFO: Pod "pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:18:10.151: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:18:10.164: INFO: Waiting for pod pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:18:10.166: INFO: Pod pod-configmaps-2fedfa45-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:18:10.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6775" for this suite.
May 14 09:18:16.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:18:16.245: INFO: namespace configmap-6775 deletion completed in 6.077194874s

• [SLOW TEST:8.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:18:16.246: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9491
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-34d7428f-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating secret with name s-test-opt-upd-34d742eb-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-34d7428f-7629-11e9-8d5d-c6eb97da6be3
STEP: Updating secret s-test-opt-upd-34d742eb-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating secret with name s-test-opt-create-34d74316-7629-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:18:20.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9491" for this suite.
May 14 09:18:42.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:18:42.533: INFO: namespace projected-9491 deletion completed in 22.078109151s

• [SLOW TEST:26.287 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:18:42.533: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 14 09:18:42.664: INFO: Waiting up to 5m0s for pod "pod-4481d026-7629-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-7487" to be "success or failure"
May 14 09:18:42.668: INFO: Pod "pod-4481d026-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.049968ms
May 14 09:18:44.670: INFO: Pod "pod-4481d026-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005191615s
STEP: Saw pod success
May 14 09:18:44.670: INFO: Pod "pod-4481d026-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:18:44.671: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-4481d026-7629-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:18:44.685: INFO: Waiting for pod pod-4481d026-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:18:44.687: INFO: Pod pod-4481d026-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:18:44.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7487" for this suite.
May 14 09:18:50.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:18:50.788: INFO: namespace emptydir-7487 deletion completed in 6.098822575s

• [SLOW TEST:8.255 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:18:50.789: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-496dcfad-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:18:50.927: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3" in namespace "projected-8746" to be "success or failure"
May 14 09:18:50.930: INFO: Pod "pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.921014ms
May 14 09:18:52.939: INFO: Pod "pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011544052s
STEP: Saw pod success
May 14 09:18:52.939: INFO: Pod "pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:18:52.949: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:18:52.963: INFO: Waiting for pod pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:18:52.966: INFO: Pod pod-projected-configmaps-496e309c-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:18:52.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8746" for this suite.
May 14 09:18:58.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:18:59.042: INFO: namespace projected-8746 deletion completed in 6.074490583s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:18:59.044: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-ppvz
STEP: Creating a pod to test atomic-volume-subpath
May 14 09:18:59.181: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppvz" in namespace "subpath-4626" to be "success or failure"
May 14 09:18:59.184: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.722883ms
May 14 09:19:01.186: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 2.005045987s
May 14 09:19:03.189: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 4.007493s
May 14 09:19:05.192: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 6.010197894s
May 14 09:19:07.194: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 8.012798108s
May 14 09:19:09.197: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 10.01567877s
May 14 09:19:11.200: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 12.018605944s
May 14 09:19:13.203: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 14.021284495s
May 14 09:19:15.205: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 16.023586435s
May 14 09:19:17.208: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 18.026292607s
May 14 09:19:19.211: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Running", Reason="", readiness=true. Elapsed: 20.029188598s
May 14 09:19:21.213: INFO: Pod "pod-subpath-test-configmap-ppvz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031687571s
STEP: Saw pod success
May 14 09:19:21.213: INFO: Pod "pod-subpath-test-configmap-ppvz" satisfied condition "success or failure"
May 14 09:19:21.215: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-subpath-test-configmap-ppvz container test-container-subpath-configmap-ppvz: <nil>
STEP: delete the pod
May 14 09:19:21.228: INFO: Waiting for pod pod-subpath-test-configmap-ppvz to disappear
May 14 09:19:21.232: INFO: Pod pod-subpath-test-configmap-ppvz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ppvz
May 14 09:19:21.232: INFO: Deleting pod "pod-subpath-test-configmap-ppvz" in namespace "subpath-4626"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:19:21.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4626" for this suite.
May 14 09:19:27.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:19:27.309: INFO: namespace subpath-4626 deletion completed in 6.073545551s

• [SLOW TEST:28.265 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:19:27.309: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:19:27.458: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-8616" to be "success or failure"
May 14 09:19:27.473: INFO: Pod "downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.298057ms
May 14 09:19:29.475: INFO: Pod "downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016413802s
STEP: Saw pod success
May 14 09:19:29.475: INFO: Pod "downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:19:29.477: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:19:29.492: INFO: Waiting for pod downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:19:29.496: INFO: Pod downwardapi-volume-5f32c146-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:19:29.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8616" for this suite.
May 14 09:19:35.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:19:35.579: INFO: namespace downward-api-8616 deletion completed in 6.079435693s

• [SLOW TEST:8.270 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:19:35.580: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:19:35.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-6584" to be "success or failure"
May 14 09:19:35.716: INFO: Pod "downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.787754ms
May 14 09:19:37.718: INFO: Pod "downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007079101s
May 14 09:19:39.720: INFO: Pod "downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009277457s
STEP: Saw pod success
May 14 09:19:39.720: INFO: Pod "downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:19:39.722: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:19:39.735: INFO: Waiting for pod downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:19:39.737: INFO: Pod downwardapi-volume-642013ef-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:19:39.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6584" for this suite.
May 14 09:19:45.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:19:45.813: INFO: namespace downward-api-6584 deletion completed in 6.074098548s

• [SLOW TEST:10.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:19:45.813: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
May 14 09:19:45.942: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-862630419 proxy --unix-socket=/tmp/kubectl-proxy-unix215495254/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:19:45.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3055" for this suite.
May 14 09:19:52.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:19:52.067: INFO: namespace kubectl-3055 deletion completed in 6.071301901s

• [SLOW TEST:6.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:19:52.068: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3132
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 09:19:52.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3132'
May 14 09:19:52.445: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 14 09:19:52.445: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 14 09:19:52.452: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
May 14 09:19:52.453: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 14 09:19:52.469: INFO: scanned /root for discovery docs: <nil>
May 14 09:19:52.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3132'
May 14 09:20:08.228: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 14 09:20:08.228: INFO: stdout: "Created e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d\nScaling up e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 14 09:20:08.228: INFO: stdout: "Created e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d\nScaling up e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 14 09:20:08.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3132'
May 14 09:20:08.301: INFO: stderr: ""
May 14 09:20:08.301: INFO: stdout: "e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d-bgxmv "
May 14 09:20:08.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d-bgxmv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3132'
May 14 09:20:08.369: INFO: stderr: ""
May 14 09:20:08.370: INFO: stdout: "true"
May 14 09:20:08.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d-bgxmv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3132'
May 14 09:20:08.436: INFO: stderr: ""
May 14 09:20:08.436: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 14 09:20:08.436: INFO: e2e-test-nginx-rc-d024ebf7707d912e0ef9b9c02d24949d-bgxmv is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
May 14 09:20:08.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete rc e2e-test-nginx-rc --namespace=kubectl-3132'
May 14 09:20:08.526: INFO: stderr: ""
May 14 09:20:08.526: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:20:08.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3132" for this suite.
May 14 09:20:14.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:20:14.605: INFO: namespace kubectl-3132 deletion completed in 6.074665809s

• [SLOW TEST:22.537 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:20:14.605: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:20:14.734: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 14 09:20:14.739: INFO: Pod name sample-pod: Found 0 pods out of 1
May 14 09:20:19.742: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 14 09:20:19.742: INFO: Creating deployment "test-rolling-update-deployment"
May 14 09:20:19.746: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 14 09:20:19.754: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 14 09:20:21.759: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 14 09:20:21.761: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 14 09:20:21.766: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1406,SelfLink:/apis/apps/v1/namespaces/deployment-1406/deployments/test-rolling-update-deployment,UID:7e5f6a9c-7629-11e9-a442-02538a874012,ResourceVersion:129058,Generation:1,CreationTimestamp:2019-05-14 09:20:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-14 09:20:19 +0000 UTC 2019-05-14 09:20:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-14 09:20:21 +0000 UTC 2019-05-14 09:20:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 14 09:20:21.770: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-1406,SelfLink:/apis/apps/v1/namespaces/deployment-1406/replicasets/test-rolling-update-deployment-67599b4d9,UID:7e6118a3-7629-11e9-a442-02538a874012,ResourceVersion:129048,Generation:1,CreationTimestamp:2019-05-14 09:20:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7e5f6a9c-7629-11e9-a442-02538a874012 0xc00261e5a0 0xc00261e5a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 14 09:20:21.770: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 14 09:20:21.770: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1406,SelfLink:/apis/apps/v1/namespaces/deployment-1406/replicasets/test-rolling-update-controller,UID:7b634380-7629-11e9-a442-02538a874012,ResourceVersion:129057,Generation:2,CreationTimestamp:2019-05-14 09:20:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7e5f6a9c-7629-11e9-a442-02538a874012 0xc00261e4c7 0xc00261e4c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 09:20:21.773: INFO: Pod "test-rolling-update-deployment-67599b4d9-f77zn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-f77zn,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-1406,SelfLink:/api/v1/namespaces/deployment-1406/pods/test-rolling-update-deployment-67599b4d9-f77zn,UID:7e61bd89-7629-11e9-a442-02538a874012,ResourceVersion:129047,Generation:0,CreationTimestamp:2019-05-14 09:20:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 7e6118a3-7629-11e9-a442-02538a874012 0xc002547130 0xc002547131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6xvbg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xvbg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6xvbg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025471a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025471c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:20:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:20:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:20:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:20:19 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.232,StartTime:2019-05-14 09:20:19 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-14 09:20:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d9c929e577793bee7e21e1433ec88e80433c6dfee428d1d937e34151be250d3a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:20:21.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1406" for this suite.
May 14 09:20:27.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:20:27.849: INFO: namespace deployment-1406 deletion completed in 6.074101708s

• [SLOW TEST:13.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:20:27.849: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2070
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2257
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:20:34.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2815" for this suite.
May 14 09:20:40.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:20:40.524: INFO: namespace namespaces-2815 deletion completed in 6.075418012s
STEP: Destroying namespace "nsdeletetest-2070" for this suite.
May 14 09:20:40.526: INFO: Namespace nsdeletetest-2070 was already deleted
STEP: Destroying namespace "nsdeletetest-2257" for this suite.
May 14 09:20:46.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:20:46.611: INFO: namespace nsdeletetest-2257 deletion completed in 6.085300061s

• [SLOW TEST:18.762 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:20:46.612: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:20:46.750: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3" in namespace "projected-7311" to be "success or failure"
May 14 09:20:46.757: INFO: Pod "downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.413199ms
May 14 09:20:48.760: INFO: Pod "downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00980927s
STEP: Saw pod success
May 14 09:20:48.760: INFO: Pod "downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:20:48.761: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:20:48.774: INFO: Waiting for pod downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:20:48.777: INFO: Pod downwardapi-volume-8e76f6e0-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:20:48.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7311" for this suite.
May 14 09:20:54.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:20:54.856: INFO: namespace projected-7311 deletion completed in 6.076452909s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:20:54.857: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:20:54.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3" in namespace "projected-7450" to be "success or failure"
May 14 09:20:54.993: INFO: Pod "downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.272091ms
May 14 09:20:56.996: INFO: Pod "downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00674581s
STEP: Saw pod success
May 14 09:20:56.996: INFO: Pod "downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:20:56.998: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:20:57.010: INFO: Waiting for pod downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:20:57.012: INFO: Pod downwardapi-volume-9360cbca-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:20:57.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7450" for this suite.
May 14 09:21:03.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:21:03.087: INFO: namespace projected-7450 deletion completed in 6.072698147s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:21:03.088: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-9848c443-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:21:03.222: INFO: Waiting up to 5m0s for pod "pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3" in namespace "secrets-7003" to be "success or failure"
May 14 09:21:03.225: INFO: Pod "pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.625878ms
May 14 09:21:05.228: INFO: Pod "pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006198757s
STEP: Saw pod success
May 14 09:21:05.228: INFO: Pod "pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:21:05.229: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 09:21:05.242: INFO: Waiting for pod pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:21:05.244: INFO: Pod pod-secrets-98493862-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:21:05.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7003" for this suite.
May 14 09:21:11.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:21:11.324: INFO: namespace secrets-7003 deletion completed in 6.077799533s

• [SLOW TEST:8.236 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:21:11.324: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6183
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-9d31e26d-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating secret with name secret-projected-all-test-volume-9d31e252-7629-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test Check all projections for projected volume plugin
May 14 09:21:11.464: INFO: Waiting up to 5m0s for pod "projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3" in namespace "projected-6183" to be "success or failure"
May 14 09:21:11.466: INFO: Pod "projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.770149ms
May 14 09:21:13.469: INFO: Pod "projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004970688s
STEP: Saw pod success
May 14 09:21:13.469: INFO: Pod "projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:21:13.471: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3 container projected-all-volume-test: <nil>
STEP: delete the pod
May 14 09:21:13.483: INFO: Waiting for pod projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:21:13.485: INFO: Pod projected-volume-9d31e20f-7629-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:21:13.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6183" for this suite.
May 14 09:21:19.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:21:19.562: INFO: namespace projected-6183 deletion completed in 6.075421815s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:21:19.563: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 14 09:21:22.217: INFO: Successfully updated pod "labelsupdatea21af3ce-7629-11e9-8d5d-c6eb97da6be3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:21:26.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7378" for this suite.
May 14 09:21:48.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:21:48.313: INFO: namespace downward-api-7378 deletion completed in 22.076019098s

• [SLOW TEST:28.749 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:21:48.314: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 14 09:21:48.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-974'
May 14 09:21:48.611: INFO: stderr: ""
May 14 09:21:48.611: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:21:48.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-974'
May 14 09:21:48.709: INFO: stderr: ""
May 14 09:21:48.709: INFO: stdout: "update-demo-nautilus-nccj9 update-demo-nautilus-x6429 "
May 14 09:21:48.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-nccj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-974'
May 14 09:21:48.793: INFO: stderr: ""
May 14 09:21:48.793: INFO: stdout: ""
May 14 09:21:48.793: INFO: update-demo-nautilus-nccj9 is created but not running
May 14 09:21:53.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-974'
May 14 09:21:53.999: INFO: stderr: ""
May 14 09:21:53.999: INFO: stdout: "update-demo-nautilus-nccj9 update-demo-nautilus-x6429 "
May 14 09:21:53.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-nccj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-974'
May 14 09:21:54.081: INFO: stderr: ""
May 14 09:21:54.081: INFO: stdout: "true"
May 14 09:21:54.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-nccj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-974'
May 14 09:21:54.149: INFO: stderr: ""
May 14 09:21:54.149: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:21:54.149: INFO: validating pod update-demo-nautilus-nccj9
May 14 09:21:54.152: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:21:54.152: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:21:54.152: INFO: update-demo-nautilus-nccj9 is verified up and running
May 14 09:21:54.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-x6429 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-974'
May 14 09:21:54.218: INFO: stderr: ""
May 14 09:21:54.218: INFO: stdout: "true"
May 14 09:21:54.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-x6429 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-974'
May 14 09:21:54.284: INFO: stderr: ""
May 14 09:21:54.284: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:21:54.284: INFO: validating pod update-demo-nautilus-x6429
May 14 09:21:54.287: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:21:54.287: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:21:54.287: INFO: update-demo-nautilus-x6429 is verified up and running
STEP: using delete to clean up resources
May 14 09:21:54.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-974'
May 14 09:21:54.355: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 09:21:54.355: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 14 09:21:54.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-974'
May 14 09:21:54.449: INFO: stderr: "No resources found.\n"
May 14 09:21:54.449: INFO: stdout: ""
May 14 09:21:54.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=update-demo --namespace=kubectl-974 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 09:21:54.518: INFO: stderr: ""
May 14 09:21:54.518: INFO: stdout: "update-demo-nautilus-nccj9\nupdate-demo-nautilus-x6429\n"
May 14 09:21:55.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-974'
May 14 09:21:55.094: INFO: stderr: "No resources found.\n"
May 14 09:21:55.094: INFO: stdout: ""
May 14 09:21:55.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=update-demo --namespace=kubectl-974 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 09:21:55.172: INFO: stderr: ""
May 14 09:21:55.172: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:21:55.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-974" for this suite.
May 14 09:22:17.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:22:17.253: INFO: namespace kubectl-974 deletion completed in 22.078659266s

• [SLOW TEST:28.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:22:17.253: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 14 09:22:17.381: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:22:21.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9085" for this suite.
May 14 09:22:27.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:22:27.471: INFO: namespace init-container-9085 deletion completed in 6.089172958s

• [SLOW TEST:10.218 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:22:27.472: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1077
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1077
May 14 09:22:29.625: INFO: Started pod liveness-exec in namespace container-probe-1077
STEP: checking the pod's current state and verifying that restartCount is present
May 14 09:22:29.627: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:26:30.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1077" for this suite.
May 14 09:26:36.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:26:36.108: INFO: namespace container-probe-1077 deletion completed in 6.075294358s

• [SLOW TEST:248.637 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:26:36.109: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-5ec7eb5a-762a-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:26:36.244: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3" in namespace "projected-1587" to be "success or failure"
May 14 09:26:36.248: INFO: Pod "pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.331912ms
May 14 09:26:38.250: INFO: Pod "pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005791781s
STEP: Saw pod success
May 14 09:26:38.250: INFO: Pod "pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:26:38.252: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 09:26:38.267: INFO: Waiting for pod pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:26:38.269: INFO: Pod pod-projected-secrets-5ec83a66-762a-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:26:38.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1587" for this suite.
May 14 09:26:44.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:26:44.345: INFO: namespace projected-1587 deletion completed in 6.074509307s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:26:44.346: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
May 14 09:26:46.496: INFO: Pod pod-hostip-63b0db23-762a-11e9-8d5d-c6eb97da6be3 has hostIP: 10.2.82.233
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:26:46.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-705" for this suite.
May 14 09:27:08.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:27:08.579: INFO: namespace pods-705 deletion completed in 22.074267702s

• [SLOW TEST:24.233 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:27:08.580: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-72228fcd-762a-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:27:08.714: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3" in namespace "projected-2770" to be "success or failure"
May 14 09:27:08.717: INFO: Pod "pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438133ms
May 14 09:27:10.720: INFO: Pod "pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005299667s
STEP: Saw pod success
May 14 09:27:10.720: INFO: Pod "pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:27:10.721: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:27:10.734: INFO: Waiting for pod pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:27:10.736: INFO: Pod pod-projected-configmaps-7222e3da-762a-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:27:10.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2770" for this suite.
May 14 09:27:16.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:27:16.833: INFO: namespace projected-2770 deletion completed in 6.091739494s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:27:16.834: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-1827
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1827 to expose endpoints map[]
May 14 09:27:16.976: INFO: successfully validated that service endpoint-test2 in namespace services-1827 exposes endpoints map[] (6.915458ms elapsed)
STEP: Creating pod pod1 in namespace services-1827
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1827 to expose endpoints map[pod1:[80]]
May 14 09:27:19.003: INFO: successfully validated that service endpoint-test2 in namespace services-1827 exposes endpoints map[pod1:[80]] (2.019485442s elapsed)
STEP: Creating pod pod2 in namespace services-1827
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1827 to expose endpoints map[pod1:[80] pod2:[80]]
May 14 09:27:21.028: INFO: successfully validated that service endpoint-test2 in namespace services-1827 exposes endpoints map[pod1:[80] pod2:[80]] (2.020135823s elapsed)
STEP: Deleting pod pod1 in namespace services-1827
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1827 to expose endpoints map[pod2:[80]]
May 14 09:27:21.045: INFO: successfully validated that service endpoint-test2 in namespace services-1827 exposes endpoints map[pod2:[80]] (13.500013ms elapsed)
STEP: Deleting pod pod2 in namespace services-1827
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1827 to expose endpoints map[]
May 14 09:27:21.058: INFO: successfully validated that service endpoint-test2 in namespace services-1827 exposes endpoints map[] (6.320299ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:27:21.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1827" for this suite.
May 14 09:27:27.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:27:27.162: INFO: namespace services-1827 deletion completed in 6.081186674s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:10.329 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:27:27.163: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6607
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May 14 09:27:27.311: INFO: Found 0 stateful pods, waiting for 3
May 14 09:27:37.314: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:27:37.314: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:27:37.314: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:27:37.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-6607 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:27:37.501: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:27:37.501: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:27:37.501: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 14 09:27:47.547: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 14 09:27:57.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-6607 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:27:57.745: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:27:57.745: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:27:57.745: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
May 14 09:28:17.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-6607 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:28:17.953: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:28:17.953: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:28:17.953: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 09:28:27.976: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 14 09:28:37.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-6607 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:28:38.158: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:28:38.158: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:28:38.158: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 09:28:58.170: INFO: Waiting for StatefulSet statefulset-6607/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 14 09:29:08.174: INFO: Deleting all statefulset in ns statefulset-6607
May 14 09:29:08.176: INFO: Scaling statefulset ss2 to 0
May 14 09:29:38.187: INFO: Waiting for statefulset status.replicas updated to 0
May 14 09:29:38.189: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:29:38.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6607" for this suite.
May 14 09:29:44.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:29:44.277: INFO: namespace statefulset-6607 deletion completed in 6.072596735s

• [SLOW TEST:137.114 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:29:44.278: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May 14 09:29:44.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8116'
May 14 09:29:44.559: INFO: stderr: ""
May 14 09:29:44.559: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:29:44.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:29:44.667: INFO: stderr: ""
May 14 09:29:44.667: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-t8h7h "
May 14 09:29:44.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:29:44.755: INFO: stderr: ""
May 14 09:29:44.755: INFO: stdout: ""
May 14 09:29:44.755: INFO: update-demo-nautilus-66q6f is created but not running
May 14 09:29:49.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:29:49.825: INFO: stderr: ""
May 14 09:29:49.825: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-t8h7h "
May 14 09:29:49.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:29:49.892: INFO: stderr: ""
May 14 09:29:49.892: INFO: stdout: "true"
May 14 09:29:49.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:29:49.958: INFO: stderr: ""
May 14 09:29:49.958: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:29:49.958: INFO: validating pod update-demo-nautilus-66q6f
May 14 09:29:49.962: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:29:49.962: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:29:49.962: INFO: update-demo-nautilus-66q6f is verified up and running
May 14 09:29:49.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-t8h7h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:29:50.033: INFO: stderr: ""
May 14 09:29:50.033: INFO: stdout: "true"
May 14 09:29:50.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-t8h7h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:29:50.100: INFO: stderr: ""
May 14 09:29:50.101: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:29:50.101: INFO: validating pod update-demo-nautilus-t8h7h
May 14 09:29:50.104: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:29:50.104: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:29:50.104: INFO: update-demo-nautilus-t8h7h is verified up and running
STEP: scaling down the replication controller
May 14 09:29:50.105: INFO: scanned /root for discovery docs: <nil>
May 14 09:29:50.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8116'
May 14 09:29:51.214: INFO: stderr: ""
May 14 09:29:51.215: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:29:51.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:29:51.287: INFO: stderr: ""
May 14 09:29:51.287: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-t8h7h "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 14 09:29:56.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:29:56.524: INFO: stderr: ""
May 14 09:29:56.524: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-t8h7h "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 14 09:30:01.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:30:01.596: INFO: stderr: ""
May 14 09:30:01.596: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-t8h7h "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 14 09:30:06.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:30:06.665: INFO: stderr: ""
May 14 09:30:06.665: INFO: stdout: "update-demo-nautilus-66q6f "
May 14 09:30:06.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:06.736: INFO: stderr: ""
May 14 09:30:06.736: INFO: stdout: "true"
May 14 09:30:06.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:06.819: INFO: stderr: ""
May 14 09:30:06.819: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:30:06.819: INFO: validating pod update-demo-nautilus-66q6f
May 14 09:30:06.821: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:30:06.821: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:30:06.821: INFO: update-demo-nautilus-66q6f is verified up and running
STEP: scaling up the replication controller
May 14 09:30:06.823: INFO: scanned /root for discovery docs: <nil>
May 14 09:30:06.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8116'
May 14 09:30:07.921: INFO: stderr: ""
May 14 09:30:07.921: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 09:30:07.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8116'
May 14 09:30:07.992: INFO: stderr: ""
May 14 09:30:07.992: INFO: stdout: "update-demo-nautilus-66q6f update-demo-nautilus-brlvl "
May 14 09:30:07.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:08.074: INFO: stderr: ""
May 14 09:30:08.074: INFO: stdout: "true"
May 14 09:30:08.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-66q6f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:08.144: INFO: stderr: ""
May 14 09:30:08.144: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:30:08.144: INFO: validating pod update-demo-nautilus-66q6f
May 14 09:30:08.147: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:30:08.147: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:30:08.147: INFO: update-demo-nautilus-66q6f is verified up and running
May 14 09:30:08.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-brlvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:08.220: INFO: stderr: ""
May 14 09:30:08.220: INFO: stdout: "true"
May 14 09:30:08.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods update-demo-nautilus-brlvl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8116'
May 14 09:30:08.289: INFO: stderr: ""
May 14 09:30:08.289: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 14 09:30:08.289: INFO: validating pod update-demo-nautilus-brlvl
May 14 09:30:08.292: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 09:30:08.292: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 09:30:08.292: INFO: update-demo-nautilus-brlvl is verified up and running
STEP: using delete to clean up resources
May 14 09:30:08.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8116'
May 14 09:30:08.368: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 09:30:08.368: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 14 09:30:08.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8116'
May 14 09:30:08.459: INFO: stderr: "No resources found.\n"
May 14 09:30:08.459: INFO: stdout: ""
May 14 09:30:08.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=update-demo --namespace=kubectl-8116 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 09:30:08.529: INFO: stderr: ""
May 14 09:30:08.529: INFO: stdout: "update-demo-nautilus-66q6f\nupdate-demo-nautilus-brlvl\n"
May 14 09:30:09.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8116'
May 14 09:30:09.115: INFO: stderr: "No resources found.\n"
May 14 09:30:09.115: INFO: stdout: ""
May 14 09:30:09.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=update-demo --namespace=kubectl-8116 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 09:30:09.185: INFO: stderr: ""
May 14 09:30:09.185: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:30:09.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8116" for this suite.
May 14 09:30:31.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:30:31.261: INFO: namespace kubectl-8116 deletion completed in 22.073557435s

• [SLOW TEST:46.983 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:30:31.261: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:30:31.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-725" to be "success or failure"
May 14 09:30:31.399: INFO: Pod "downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.453292ms
May 14 09:30:33.402: INFO: Pod "downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008204814s
STEP: Saw pod success
May 14 09:30:33.402: INFO: Pod "downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:30:33.404: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:30:33.416: INFO: Waiting for pod downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:30:33.419: INFO: Pod downwardapi-volume-eaf1414b-762a-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:30:33.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-725" for this suite.
May 14 09:30:39.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:30:39.495: INFO: namespace downward-api-725 deletion completed in 6.07441252s

• [SLOW TEST:8.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:30:39.495: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:30:41.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-176" for this suite.
May 14 09:30:47.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:30:47.744: INFO: namespace emptydir-wrapper-176 deletion completed in 6.086447087s

• [SLOW TEST:8.249 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:30:47.746: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:30:47.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-3340" to be "success or failure"
May 14 09:30:47.883: INFO: Pod "downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.770013ms
May 14 09:30:49.885: INFO: Pod "downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004778306s
STEP: Saw pod success
May 14 09:30:49.885: INFO: Pod "downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:30:49.886: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:30:49.904: INFO: Waiting for pod downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:30:49.906: INFO: Pod downwardapi-volume-f4c4cc33-762a-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:30:49.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3340" for this suite.
May 14 09:30:55.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:30:55.983: INFO: namespace downward-api-3340 deletion completed in 6.074511472s

• [SLOW TEST:8.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:30:55.984: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4430
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f9adc154-762a-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:30:56.121: INFO: Waiting up to 5m0s for pod "pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3" in namespace "secrets-4430" to be "success or failure"
May 14 09:30:56.126: INFO: Pod "pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.121819ms
May 14 09:30:58.134: INFO: Pod "pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01332888s
STEP: Saw pod success
May 14 09:30:58.134: INFO: Pod "pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:30:58.138: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 09:30:58.156: INFO: Waiting for pod pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:30:58.158: INFO: Pod pod-secrets-f9ae37c8-762a-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:30:58.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4430" for this suite.
May 14 09:31:04.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:31:04.256: INFO: namespace secrets-4430 deletion completed in 6.095940788s

• [SLOW TEST:8.273 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:31:04.257: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0514 09:31:10.409050      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 09:31:10.409: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:31:10.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-644" for this suite.
May 14 09:31:16.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:31:16.488: INFO: namespace gc-644 deletion completed in 6.077211057s

• [SLOW TEST:12.231 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:31:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0514 09:31:47.139389      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 09:31:47.139: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:31:47.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3929" for this suite.
May 14 09:31:53.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:31:53.224: INFO: namespace gc-3929 deletion completed in 6.082710926s

• [SLOW TEST:36.735 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:31:53.224: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 14 09:31:57.398: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:31:57.400: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:31:59.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:31:59.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:01.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:01.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:03.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:03.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:05.401: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:05.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:07.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:07.404: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:09.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:09.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:11.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:11.402: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:13.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:13.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:15.401: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:15.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:17.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:17.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:19.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:19.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:21.401: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:21.403: INFO: Pod pod-with-prestop-exec-hook still exists
May 14 09:32:23.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 14 09:32:23.405: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:32:23.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3609" for this suite.
May 14 09:32:45.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:32:45.493: INFO: namespace container-lifecycle-hook-3609 deletion completed in 22.07738538s

• [SLOW TEST:52.269 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:32:45.494: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 14 09:32:45.627: INFO: Waiting up to 5m0s for pod "pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-343" to be "success or failure"
May 14 09:32:45.631: INFO: Pod "pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176996ms
May 14 09:32:47.633: INFO: Pod "pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006871734s
STEP: Saw pod success
May 14 09:32:47.633: INFO: Pod "pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:32:47.635: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:32:47.648: INFO: Waiting for pod pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:32:47.651: INFO: Pod pod-3af3b470-762b-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:32:47.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-343" for this suite.
May 14 09:32:53.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:32:53.728: INFO: namespace emptydir-343 deletion completed in 6.073542822s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:32:53.729: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5117
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5117
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5117
May 14 09:32:53.931: INFO: Found 0 stateful pods, waiting for 1
May 14 09:33:03.934: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 14 09:33:03.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:33:04.142: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:33:04.142: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:33:04.142: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 09:33:04.144: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 14 09:33:14.146: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 09:33:14.147: INFO: Waiting for statefulset status.replicas updated to 0
May 14 09:33:14.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998947s
May 14 09:33:15.159: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996214198s
May 14 09:33:16.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993811798s
May 14 09:33:17.165: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990929114s
May 14 09:33:18.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988170983s
May 14 09:33:19.170: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985276933s
May 14 09:33:20.173: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982999149s
May 14 09:33:21.176: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979979276s
May 14 09:33:22.178: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977324245s
May 14 09:33:23.180: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.998433ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5117
May 14 09:33:24.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:33:24.405: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:33:24.405: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:33:24.405: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 09:33:24.407: INFO: Found 1 stateful pods, waiting for 3
May 14 09:33:34.410: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:33:34.410: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 09:33:34.410: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 14 09:33:34.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:33:34.625: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:33:34.625: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:33:34.625: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 09:33:34.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:33:34.807: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:33:34.807: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:33:34.807: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 09:33:34.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 09:33:35.018: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 09:33:35.018: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 09:33:35.018: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 09:33:35.018: INFO: Waiting for statefulset status.replicas updated to 0
May 14 09:33:35.020: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 14 09:33:45.024: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 09:33:45.024: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 14 09:33:45.024: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 14 09:33:45.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998955s
May 14 09:33:46.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99338271s
May 14 09:33:47.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990212624s
May 14 09:33:48.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987749626s
May 14 09:33:49.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985122256s
May 14 09:33:50.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982597436s
May 14 09:33:51.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979794133s
May 14 09:33:52.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977440766s
May 14 09:33:53.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.974960973s
May 14 09:33:54.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.219965ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5117
May 14 09:33:55.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:33:55.229: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:33:55.229: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:33:55.229: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 09:33:55.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:33:55.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:33:55.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:33:55.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 09:33:55.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-5117 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 09:33:55.569: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 09:33:55.569: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 09:33:55.569: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 09:33:55.569: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 14 09:34:15.579: INFO: Deleting all statefulset in ns statefulset-5117
May 14 09:34:15.581: INFO: Scaling statefulset ss to 0
May 14 09:34:15.587: INFO: Waiting for statefulset status.replicas updated to 0
May 14 09:34:15.589: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:34:15.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5117" for this suite.
May 14 09:34:21.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:34:21.676: INFO: namespace statefulset-5117 deletion completed in 6.075837129s

• [SLOW TEST:87.947 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:34:21.676: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 14 09:34:23.825: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-74485cb9-762b-11e9-8d5d-c6eb97da6be3,GenerateName:,Namespace:events-1943,SelfLink:/api/v1/namespaces/events-1943/pods/send-events-74485cb9-762b-11e9-8d5d-c6eb97da6be3,UID:7448b2dd-762b-11e9-a442-02538a874012,ResourceVersion:131707,Generation:0,CreationTimestamp:2019-05-14 09:34:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 808154983,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9g5dj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9g5dj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9g5dj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c92090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c920b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:34:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:34:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:34:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:34:21 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.36,StartTime:2019-05-14 09:34:21 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-14 09:34:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://bf04de26e0645c5e93e2d35e54ea591a292a99009b2f2a32dac56f1eff33db31}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 14 09:34:25.828: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 14 09:34:27.830: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:34:27.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1943" for this suite.
May 14 09:35:13.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:35:13.914: INFO: namespace events-1943 deletion completed in 46.077356177s

• [SLOW TEST:52.238 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:35:13.914: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 14 09:35:14.050: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1881,SelfLink:/api/v1/namespaces/watch-1881/configmaps/e2e-watch-test-watch-closed,UID:936b0fa1-762b-11e9-a442-02538a874012,ResourceVersion:131796,Generation:0,CreationTimestamp:2019-05-14 09:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 09:35:14.051: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1881,SelfLink:/api/v1/namespaces/watch-1881/configmaps/e2e-watch-test-watch-closed,UID:936b0fa1-762b-11e9-a442-02538a874012,ResourceVersion:131797,Generation:0,CreationTimestamp:2019-05-14 09:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 14 09:35:14.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1881,SelfLink:/api/v1/namespaces/watch-1881/configmaps/e2e-watch-test-watch-closed,UID:936b0fa1-762b-11e9-a442-02538a874012,ResourceVersion:131798,Generation:0,CreationTimestamp:2019-05-14 09:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 09:35:14.059: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1881,SelfLink:/api/v1/namespaces/watch-1881/configmaps/e2e-watch-test-watch-closed,UID:936b0fa1-762b-11e9-a442-02538a874012,ResourceVersion:131799,Generation:0,CreationTimestamp:2019-05-14 09:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:35:14.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1881" for this suite.
May 14 09:35:20.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:35:20.141: INFO: namespace watch-1881 deletion completed in 6.079852003s

• [SLOW TEST:6.227 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:35:20.142: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-kg6d
STEP: Creating a pod to test atomic-volume-subpath
May 14 09:35:20.279: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-kg6d" in namespace "subpath-5649" to be "success or failure"
May 14 09:35:20.283: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.329069ms
May 14 09:35:22.286: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006933605s
May 14 09:35:24.289: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 4.009537614s
May 14 09:35:26.292: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 6.012112145s
May 14 09:35:28.294: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 8.014758953s
May 14 09:35:30.297: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 10.017472068s
May 14 09:35:32.300: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 12.020273696s
May 14 09:35:34.302: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 14.02249493s
May 14 09:35:36.304: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 16.024819651s
May 14 09:35:38.307: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 18.027624569s
May 14 09:35:40.310: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Running", Reason="", readiness=true. Elapsed: 20.030159117s
May 14 09:35:42.312: INFO: Pod "pod-subpath-test-downwardapi-kg6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.032746042s
STEP: Saw pod success
May 14 09:35:42.312: INFO: Pod "pod-subpath-test-downwardapi-kg6d" satisfied condition "success or failure"
May 14 09:35:42.314: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-subpath-test-downwardapi-kg6d container test-container-subpath-downwardapi-kg6d: <nil>
STEP: delete the pod
May 14 09:35:42.326: INFO: Waiting for pod pod-subpath-test-downwardapi-kg6d to disappear
May 14 09:35:42.330: INFO: Pod pod-subpath-test-downwardapi-kg6d no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-kg6d
May 14 09:35:42.330: INFO: Deleting pod "pod-subpath-test-downwardapi-kg6d" in namespace "subpath-5649"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:35:42.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5649" for this suite.
May 14 09:35:48.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:35:48.409: INFO: namespace subpath-5649 deletion completed in 6.075401434s

• [SLOW TEST:28.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:35:48.410: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
May 14 09:35:49.420: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 14 09:35:51.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423349, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423349, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423349, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423349, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 09:35:54.629: INFO: Waited 1.119073522s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:35:55.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9362" for this suite.
May 14 09:36:01.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:36:01.329: INFO: namespace aggregator-9362 deletion completed in 6.212781403s

• [SLOW TEST:12.919 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:36:01.329: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
May 14 09:36:01.464: INFO: Waiting up to 5m0s for pod "var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3" in namespace "var-expansion-7686" to be "success or failure"
May 14 09:36:01.466: INFO: Pod "var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0894ms
May 14 09:36:03.468: INFO: Pod "var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004111786s
STEP: Saw pod success
May 14 09:36:03.468: INFO: Pod "var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:36:03.470: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:36:03.483: INFO: Waiting for pod var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:36:03.485: INFO: Pod var-expansion-afadeb62-762b-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:36:03.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7686" for this suite.
May 14 09:36:09.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:36:09.572: INFO: namespace var-expansion-7686 deletion completed in 6.084082416s

• [SLOW TEST:8.243 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:36:09.572: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 14 09:36:09.704: INFO: Waiting up to 5m0s for pod "pod-b4975550-762b-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-7508" to be "success or failure"
May 14 09:36:09.708: INFO: Pod "pod-b4975550-762b-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.722332ms
May 14 09:36:11.710: INFO: Pod "pod-b4975550-762b-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005705781s
STEP: Saw pod success
May 14 09:36:11.710: INFO: Pod "pod-b4975550-762b-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:36:11.712: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-b4975550-762b-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:36:11.725: INFO: Waiting for pod pod-b4975550-762b-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:36:11.727: INFO: Pod pod-b4975550-762b-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:36:11.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7508" for this suite.
May 14 09:36:17.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:36:17.801: INFO: namespace emptydir-7508 deletion completed in 6.072631758s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:36:17.802: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 14 09:36:23.976: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:23.976: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.109: INFO: Exec stderr: ""
May 14 09:36:24.109: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.109: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.212: INFO: Exec stderr: ""
May 14 09:36:24.212: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.212: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.310: INFO: Exec stderr: ""
May 14 09:36:24.310: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.310: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.422: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 14 09:36:24.422: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.422: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.526: INFO: Exec stderr: ""
May 14 09:36:24.526: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.526: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.653: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 14 09:36:24.654: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.654: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.764: INFO: Exec stderr: ""
May 14 09:36:24.764: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.764: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.881: INFO: Exec stderr: ""
May 14 09:36:24.881: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.881: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:24.981: INFO: Exec stderr: ""
May 14 09:36:24.981: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5959 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:36:24.981: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:36:25.091: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:36:25.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5959" for this suite.
May 14 09:37:03.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:37:03.169: INFO: namespace e2e-kubelet-etc-hosts-5959 deletion completed in 38.075567617s

• [SLOW TEST:45.367 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:37:03.170: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-d489e36b-762b-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:37:03.305: INFO: Waiting up to 5m0s for pod "pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3" in namespace "secrets-6590" to be "success or failure"
May 14 09:37:03.308: INFO: Pod "pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.021009ms
May 14 09:37:05.311: INFO: Pod "pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005502942s
STEP: Saw pod success
May 14 09:37:05.311: INFO: Pod "pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:37:05.312: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 09:37:05.324: INFO: Waiting for pod pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:37:05.327: INFO: Pod pod-secrets-d48a5c21-762b-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:37:05.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6590" for this suite.
May 14 09:37:11.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:37:11.403: INFO: namespace secrets-6590 deletion completed in 6.073590609s

• [SLOW TEST:8.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:37:11.403: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:37:11.537: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3" in namespace "projected-9032" to be "success or failure"
May 14 09:37:11.541: INFO: Pod "downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057523ms
May 14 09:37:13.544: INFO: Pod "downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006519559s
STEP: Saw pod success
May 14 09:37:13.544: INFO: Pod "downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:37:13.546: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:37:13.559: INFO: Waiting for pod downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:37:13.562: INFO: Pod downwardapi-volume-d9722916-762b-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:37:13.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9032" for this suite.
May 14 09:37:19.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:37:19.640: INFO: namespace projected-9032 deletion completed in 6.075208562s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:37:19.640: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-294
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-de5bb636-762b-11e9-8d5d-c6eb97da6be3
STEP: Creating configMap with name cm-test-opt-upd-de5bb67d-762b-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-de5bb636-762b-11e9-8d5d-c6eb97da6be3
STEP: Updating configmap cm-test-opt-upd-de5bb67d-762b-11e9-8d5d-c6eb97da6be3
STEP: Creating configMap with name cm-test-opt-create-de5bb697-762b-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:38:42.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-294" for this suite.
May 14 09:39:04.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:39:04.235: INFO: namespace projected-294 deletion completed in 22.087882913s

• [SLOW TEST:104.595 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:39:04.235: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4563.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4563.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 14 09:39:08.393: INFO: DNS probes using dns-4563/dns-test-1cb2ff9d-762c-11e9-8d5d-c6eb97da6be3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:39:08.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4563" for this suite.
May 14 09:39:14.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:39:14.482: INFO: namespace dns-4563 deletion completed in 6.077013712s

• [SLOW TEST:10.247 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:39:14.482: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2508
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:39:14.612: INFO: Creating deployment "test-recreate-deployment"
May 14 09:39:14.618: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 14 09:39:14.635: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 14 09:39:16.639: INFO: Waiting deployment "test-recreate-deployment" to complete
May 14 09:39:16.641: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 14 09:39:16.646: INFO: Updating deployment test-recreate-deployment
May 14 09:39:16.648: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 14 09:39:16.770: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2508,SelfLink:/apis/apps/v1/namespaces/deployment-2508/deployments/test-recreate-deployment,UID:22cefdab-762c-11e9-a442-02538a874012,ResourceVersion:132542,Generation:2,CreationTimestamp:2019-05-14 09:39:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-14 09:39:16 +0000 UTC 2019-05-14 09:39:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-14 09:39:16 +0000 UTC 2019-05-14 09:39:14 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 14 09:39:16.773: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-2508,SelfLink:/apis/apps/v1/namespaces/deployment-2508/replicasets/test-recreate-deployment-c9cbd8684,UID:240db066-762c-11e9-a442-02538a874012,ResourceVersion:132541,Generation:1,CreationTimestamp:2019-05-14 09:39:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 22cefdab-762c-11e9-a442-02538a874012 0xc0018ba070 0xc0018ba071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 09:39:16.773: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 14 09:39:16.773: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-2508,SelfLink:/apis/apps/v1/namespaces/deployment-2508/replicasets/test-recreate-deployment-7d57d5ff7c,UID:22cfb903-762c-11e9-a442-02538a874012,ResourceVersion:132531,Generation:2,CreationTimestamp:2019-05-14 09:39:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 22cefdab-762c-11e9-a442-02538a874012 0xc002717fa7 0xc002717fa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 09:39:16.775: INFO: Pod "test-recreate-deployment-c9cbd8684-5g8l6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-5g8l6,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-2508,SelfLink:/api/v1/namespaces/deployment-2508/pods/test-recreate-deployment-c9cbd8684-5g8l6,UID:240e57eb-762c-11e9-a442-02538a874012,ResourceVersion:132543,Generation:0,CreationTimestamp:2019-05-14 09:39:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 240db066-762c-11e9-a442-02538a874012 0xc0018baab0 0xc0018baab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rfscr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rfscr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rfscr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018bab10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018bab30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:39:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:39:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:39:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:39:16 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:39:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:39:16.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2508" for this suite.
May 14 09:39:22.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:39:22.852: INFO: namespace deployment-2508 deletion completed in 6.075029325s

• [SLOW TEST:8.370 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:39:22.853: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:39:26.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-572" for this suite.
May 14 09:40:13.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:40:13.074: INFO: namespace kubelet-test-572 deletion completed in 46.073162932s

• [SLOW TEST:50.221 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:40:13.074: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
May 14 09:40:13.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 api-versions'
May 14 09:40:13.270: INFO: stderr: ""
May 14 09:40:13.270: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:40:13.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4619" for this suite.
May 14 09:40:19.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:40:19.351: INFO: namespace kubectl-4619 deletion completed in 6.07829546s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:40:19.351: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 09:40:19.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-360'
May 14 09:40:19.848: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 14 09:40:19.848: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
May 14 09:40:19.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete jobs e2e-test-nginx-job --namespace=kubectl-360'
May 14 09:40:19.931: INFO: stderr: ""
May 14 09:40:19.931: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:40:19.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-360" for this suite.
May 14 09:40:25.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:40:26.009: INFO: namespace kubectl-360 deletion completed in 6.074928521s

• [SLOW TEST:6.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:40:26.010: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-2612
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2612
STEP: Deleting pre-stop pod
May 14 09:40:35.166: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:40:35.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2612" for this suite.
May 14 09:41:13.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:41:13.251: INFO: namespace prestop-2612 deletion completed in 38.074789514s

• [SLOW TEST:47.241 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:41:13.251: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
May 14 09:41:13.388: INFO: Waiting up to 5m0s for pod "client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3" in namespace "containers-5157" to be "success or failure"
May 14 09:41:13.390: INFO: Pod "client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.306587ms
May 14 09:41:15.393: INFO: Pod "client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004933854s
STEP: Saw pod success
May 14 09:41:15.393: INFO: Pod "client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:41:15.394: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:41:15.406: INFO: Waiting for pod client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:41:15.408: INFO: Pod client-containers-6999de86-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:41:15.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5157" for this suite.
May 14 09:41:21.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:41:21.489: INFO: namespace containers-5157 deletion completed in 6.077499394s

• [SLOW TEST:8.238 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:41:21.489: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
May 14 09:41:21.622: INFO: Waiting up to 5m0s for pod "client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3" in namespace "containers-3225" to be "success or failure"
May 14 09:41:21.624: INFO: Pod "client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186208ms
May 14 09:41:23.687: INFO: Pod "client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.064459679s
STEP: Saw pod success
May 14 09:41:23.687: INFO: Pod "client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:41:23.689: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:41:23.707: INFO: Waiting for pod client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:41:23.713: INFO: Pod client-containers-6e823eaf-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:41:23.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3225" for this suite.
May 14 09:41:29.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:41:29.794: INFO: namespace containers-3225 deletion completed in 6.076849865s

• [SLOW TEST:8.305 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:41:29.794: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:41:29.929: INFO: (0) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.461053ms)
May 14 09:41:29.931: INFO: (1) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.098523ms)
May 14 09:41:29.933: INFO: (2) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.400842ms)
May 14 09:41:29.936: INFO: (3) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.300675ms)
May 14 09:41:29.938: INFO: (4) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.432609ms)
May 14 09:41:29.940: INFO: (5) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.288118ms)
May 14 09:41:29.943: INFO: (6) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.416756ms)
May 14 09:41:29.945: INFO: (7) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.493381ms)
May 14 09:41:29.948: INFO: (8) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.333103ms)
May 14 09:41:29.950: INFO: (9) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.543079ms)
May 14 09:41:29.953: INFO: (10) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.518847ms)
May 14 09:41:29.955: INFO: (11) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.283135ms)
May 14 09:41:29.957: INFO: (12) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.162326ms)
May 14 09:41:29.960: INFO: (13) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.317297ms)
May 14 09:41:29.962: INFO: (14) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.275176ms)
May 14 09:41:29.964: INFO: (15) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.150776ms)
May 14 09:41:29.967: INFO: (16) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.147451ms)
May 14 09:41:29.969: INFO: (17) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.3636ms)
May 14 09:41:29.971: INFO: (18) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.348318ms)
May 14 09:41:29.974: INFO: (19) /api/v1/nodes/ip-10-2-82-233.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.343307ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:41:29.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2904" for this suite.
May 14 09:41:35.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:41:36.050: INFO: namespace proxy-2904 deletion completed in 6.074105976s

• [SLOW TEST:6.256 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:41:36.050: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:41:36.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3" in namespace "projected-4866" to be "success or failure"
May 14 09:41:36.189: INFO: Pod "downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547382ms
May 14 09:41:38.191: INFO: Pod "downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005823973s
STEP: Saw pod success
May 14 09:41:38.191: INFO: Pod "downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:41:38.193: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:41:38.208: INFO: Waiting for pod downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:41:38.209: INFO: Pod downwardapi-volume-77300dfd-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:41:38.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4866" for this suite.
May 14 09:41:44.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:41:44.286: INFO: namespace projected-4866 deletion completed in 6.07409988s

• [SLOW TEST:8.235 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:41:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 14 09:41:44.436: INFO: PodSpec: initContainers in spec.initContainers
May 14 09:42:33.263: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7c1c2749-762c-11e9-8d5d-c6eb97da6be3", GenerateName:"", Namespace:"init-container-1147", SelfLink:"/api/v1/namespaces/init-container-1147/pods/pod-init-7c1c2749-762c-11e9-8d5d-c6eb97da6be3", UID:"7c1c9fa2-762c-11e9-a442-02538a874012", ResourceVersion:"133064", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693423704, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"436930273"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-576fb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002ed2000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-576fb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-576fb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-576fb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00275e088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-2-82-233.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003296000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00275e100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00275e120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00275e128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00275e12c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423704, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423704, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423704, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693423704, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.2.82.233", PodIP:"10.100.1.55", StartTime:(*v1.Time)(0xc0028f6080), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002da690)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002da700)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://1debc1c7f8793c0334bae0e85e2316a2f7c52431cf146578d16c80b3ad96c83c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028f60c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0028f60a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:42:33.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1147" for this suite.
May 14 09:42:55.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:42:55.341: INFO: namespace init-container-1147 deletion completed in 22.07446685s

• [SLOW TEST:71.055 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:42:55.341: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-15
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 14 09:42:55.484: INFO: Waiting up to 5m0s for pod "downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-15" to be "success or failure"
May 14 09:42:55.486: INFO: Pod "downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204496ms
May 14 09:42:57.492: INFO: Pod "downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007726437s
STEP: Saw pod success
May 14 09:42:57.492: INFO: Pod "downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:42:57.496: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:42:57.514: INFO: Waiting for pod downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:42:57.521: INFO: Pod downward-api-a67465c3-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:42:57.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-15" for this suite.
May 14 09:43:03.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:43:03.603: INFO: namespace downward-api-15 deletion completed in 6.078632368s

• [SLOW TEST:8.262 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:43:03.604: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:43:03.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3" in namespace "projected-2005" to be "success or failure"
May 14 09:43:03.741: INFO: Pod "downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.232254ms
May 14 09:43:05.744: INFO: Pod "downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004861173s
STEP: Saw pod success
May 14 09:43:05.744: INFO: Pod "downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:43:05.746: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:43:05.759: INFO: Waiting for pod downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:43:05.761: INFO: Pod downwardapi-volume-ab5febab-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:43:05.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2005" for this suite.
May 14 09:43:11.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:43:11.841: INFO: namespace projected-2005 deletion completed in 6.078045335s

• [SLOW TEST:8.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:43:11.842: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-b048c135-762c-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:43:11.978: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3" in namespace "projected-4386" to be "success or failure"
May 14 09:43:11.980: INFO: Pod "pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.673241ms
May 14 09:43:13.983: INFO: Pod "pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004828112s
STEP: Saw pod success
May 14 09:43:13.983: INFO: Pod "pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:43:13.985: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:43:13.995: INFO: Waiting for pod pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:43:13.997: INFO: Pod pod-projected-configmaps-b0491f08-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:43:13.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4386" for this suite.
May 14 09:43:20.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:43:20.072: INFO: namespace projected-4386 deletion completed in 6.073341761s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:43:20.072: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 14 09:43:20.204: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 14 09:43:20.208: INFO: Waiting for terminating namespaces to be deleted...
May 14 09:43:20.209: INFO: 
Logging pods the kubelet thinks is on node ip-10-2-82-233.ec2.internal before test
May 14 09:43:20.215: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-14 09:04:33 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 14 09:43:20.215: INFO: sonobuoy-systemd-logs-daemon-set-9584be86564342a8-cgp7q from heptio-sonobuoy started at 2019-05-14 09:04:37 +0000 UTC (2 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 14 09:43:20.215: INFO: 	Container systemd-logs ready: true, restart count 0
May 14 09:43:20.215: INFO: prometheus-operator-kube-state-metrics-5d7558d7cc-jm7r4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 14 09:43:20.215: INFO: prometheus-operator-prometheus-node-exporter-frpgv from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container node-exporter ready: true, restart count 0
May 14 09:43:20.215: INFO: liveness-http from container-probe-8911 started at 2019-05-13 13:25:40 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container liveness ready: true, restart count 0
May 14 09:43:20.215: INFO: prometheus-operator-operator-55445689db-bqr4b from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container prometheus-operator ready: true, restart count 0
May 14 09:43:20.215: INFO: kube-flannel-ds-amd64-kr6f4 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container kube-flannel ready: true, restart count 1
May 14 09:43:20.215: INFO: prometheus-prometheus-operator-prometheus-0 from kube-system started at 2019-05-13 13:23:15 +0000 UTC (3 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container prometheus ready: true, restart count 1
May 14 09:43:20.215: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
May 14 09:43:20.215: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
May 14 09:43:20.215: INFO: alertmanager-prometheus-operator-alertmanager-0 from kube-system started at 2019-05-13 13:23:08 +0000 UTC (2 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container alertmanager ready: true, restart count 0
May 14 09:43:20.215: INFO: 	Container config-reloader ready: true, restart count 0
May 14 09:43:20.215: INFO: prometheus-operator-grafana-5d74ccd7bd-4rch4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (2 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container grafana ready: true, restart count 0
May 14 09:43:20.215: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
May 14 09:43:20.215: INFO: tiller-deploy-65949f8696-22447 from kube-system started at 2019-05-13 13:22:15 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container tiller ready: true, restart count 0
May 14 09:43:20.215: INFO: kube-proxy-f4nj2 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 09:43:20.215: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b666d36e-762c-11e9-8d5d-c6eb97da6be3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b666d36e-762c-11e9-8d5d-c6eb97da6be3 off the node ip-10-2-82-233.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b666d36e-762c-11e9-8d5d-c6eb97da6be3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:43:24.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2529" for this suite.
May 14 09:43:32.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:43:32.344: INFO: namespace sched-pred-2529 deletion completed in 8.075468568s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.272 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:43:32.344: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 14 09:43:34.998: INFO: Successfully updated pod "annotationupdatebc814d78-762c-11e9-8d5d-c6eb97da6be3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:43:39.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7286" for this suite.
May 14 09:44:01.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:44:01.093: INFO: namespace projected-7286 deletion completed in 22.073834622s

• [SLOW TEST:28.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:44:01.093: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 14 09:44:01.237: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-116,SelfLink:/api/v1/namespaces/watch-116/configmaps/e2e-watch-test-resource-version,UID:cda4043c-762c-11e9-a442-02538a874012,ResourceVersion:133364,Generation:0,CreationTimestamp:2019-05-14 09:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 09:44:01.238: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-116,SelfLink:/api/v1/namespaces/watch-116/configmaps/e2e-watch-test-resource-version,UID:cda4043c-762c-11e9-a442-02538a874012,ResourceVersion:133365,Generation:0,CreationTimestamp:2019-05-14 09:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:44:01.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-116" for this suite.
May 14 09:44:07.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:44:07.318: INFO: namespace watch-116 deletion completed in 6.078270983s

• [SLOW TEST:6.225 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:44:07.319: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0514 09:44:17.468908      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 09:44:17.469: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:44:17.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2871" for this suite.
May 14 09:44:23.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:44:23.588: INFO: namespace gc-2871 deletion completed in 6.115958564s

• [SLOW TEST:16.269 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:44:23.590: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:44:23.745: INFO: Conformance test suite needs a cluster with at least 2 nodes.
May 14 09:44:23.745: INFO: Create a RollingUpdate DaemonSet
May 14 09:44:23.748: INFO: Check that daemon pods launch on every node of the cluster
May 14 09:44:23.753: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:23.755: INFO: Number of nodes with available pods: 0
May 14 09:44:23.755: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:44:24.760: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:24.768: INFO: Number of nodes with available pods: 0
May 14 09:44:24.768: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:44:25.757: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:25.759: INFO: Number of nodes with available pods: 1
May 14 09:44:25.759: INFO: Number of running nodes: 1, number of available pods: 1
May 14 09:44:25.759: INFO: Update the DaemonSet to trigger a rollout
May 14 09:44:25.765: INFO: Updating DaemonSet daemon-set
May 14 09:44:32.774: INFO: Roll back the DaemonSet before rollout is complete
May 14 09:44:32.778: INFO: Updating DaemonSet daemon-set
May 14 09:44:32.779: INFO: Make sure DaemonSet rollback is complete
May 14 09:44:32.783: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:32.783: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:32.786: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:33.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:33.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:33.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:34.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:34.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:34.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:35.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:35.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:35.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:36.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:36.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:36.791: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:37.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:37.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:37.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:38.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:38.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:38.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:39.793: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:39.794: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:39.799: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:40.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:40.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:40.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:41.788: INFO: Wrong image for pod: daemon-set-mc52j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 14 09:44:41.788: INFO: Pod daemon-set-mc52j is not available
May 14 09:44:41.792: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:44:42.788: INFO: Pod daemon-set-qdq5v is not available
May 14 09:44:42.790: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9185, will wait for the garbage collector to delete the pods
May 14 09:44:42.850: INFO: Deleting DaemonSet.extensions daemon-set took: 3.922036ms
May 14 09:44:43.153: INFO: Terminating DaemonSet.extensions daemon-set pods took: 302.949358ms
May 14 09:44:46.054: INFO: Number of nodes with available pods: 0
May 14 09:44:46.055: INFO: Number of running nodes: 0, number of available pods: 0
May 14 09:44:46.056: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9185/daemonsets","resourceVersion":"133550"},"items":null}

May 14 09:44:46.058: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9185/pods","resourceVersion":"133550"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:44:46.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9185" for this suite.
May 14 09:44:52.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:44:52.136: INFO: namespace daemonsets-9185 deletion completed in 6.072057302s

• [SLOW TEST:28.547 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:44:52.137: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1340
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
May 14 09:44:52.268: INFO: Waiting up to 5m0s for pod "var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3" in namespace "var-expansion-1340" to be "success or failure"
May 14 09:44:52.274: INFO: Pod "var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.782655ms
May 14 09:44:54.276: INFO: Pod "var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007841403s
STEP: Saw pod success
May 14 09:44:54.276: INFO: Pod "var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:44:54.278: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:44:54.291: INFO: Waiting for pod var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:44:54.293: INFO: Pod var-expansion-ec106915-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:44:54.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1340" for this suite.
May 14 09:45:00.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:00.378: INFO: namespace var-expansion-1340 deletion completed in 6.08260095s

• [SLOW TEST:8.241 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:00.378: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:45:00.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 version'
May 14 09:45:00.570: INFO: stderr: ""
May 14 09:45:00.570: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:00.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3234" for this suite.
May 14 09:45:06.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:06.649: INFO: namespace kubectl-3234 deletion completed in 6.075522957s

• [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:06.649: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-f4b70e36-762c-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:45:06.785: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3" in namespace "projected-5513" to be "success or failure"
May 14 09:45:06.790: INFO: Pod "pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.792293ms
May 14 09:45:08.792: INFO: Pod "pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007381037s
STEP: Saw pod success
May 14 09:45:08.792: INFO: Pod "pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:45:08.794: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 09:45:08.807: INFO: Waiting for pod pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:45:08.809: INFO: Pod pod-projected-secrets-f4b77cf3-762c-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:08.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5513" for this suite.
May 14 09:45:14.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:14.886: INFO: namespace projected-5513 deletion completed in 6.074818879s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:14.887: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8439
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-f9a01412-762c-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8439" for this suite.
May 14 09:45:39.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:39.122: INFO: namespace configmap-8439 deletion completed in 22.07289093s

• [SLOW TEST:24.236 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:39.123: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8195
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
May 14 09:45:39.257: INFO: Waiting up to 5m0s for pod "var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3" in namespace "var-expansion-8195" to be "success or failure"
May 14 09:45:39.262: INFO: Pod "var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.711404ms
May 14 09:45:41.264: INFO: Pod "var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006698189s
STEP: Saw pod success
May 14 09:45:41.264: INFO: Pod "var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:45:41.267: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:45:41.279: INFO: Waiting for pod var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:45:41.281: INFO: Pod var-expansion-08122c55-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:41.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8195" for this suite.
May 14 09:45:47.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:47.370: INFO: namespace var-expansion-8195 deletion completed in 6.087019186s

• [SLOW TEST:8.247 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:47.371: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
May 14 09:45:50.027: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6372 pod-service-account-0d4b8562-762d-11e9-8d5d-c6eb97da6be3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 14 09:45:50.211: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6372 pod-service-account-0d4b8562-762d-11e9-8d5d-c6eb97da6be3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 14 09:45:50.397: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6372 pod-service-account-0d4b8562-762d-11e9-8d5d-c6eb97da6be3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:50.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6372" for this suite.
May 14 09:45:56.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:45:56.686: INFO: namespace svcaccounts-6372 deletion completed in 6.072891167s

• [SLOW TEST:9.315 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:45:56.687: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-1289fed3-762d-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 09:45:56.822: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3" in namespace "projected-4828" to be "success or failure"
May 14 09:45:56.826: INFO: Pod "pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.439905ms
May 14 09:45:58.829: INFO: Pod "pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007069176s
STEP: Saw pod success
May 14 09:45:58.829: INFO: Pod "pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:45:58.831: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 09:45:58.844: INFO: Waiting for pod pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:45:58.845: INFO: Pod pod-projected-secrets-128a6a17-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:45:58.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4828" for this suite.
May 14 09:46:04.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:46:04.929: INFO: namespace projected-4828 deletion completed in 6.08096921s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:46:04.929: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9761
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:46:29.077: INFO: Container started at 2019-05-14 09:46:05 +0000 UTC, pod became ready at 2019-05-14 09:46:27 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:46:29.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9761" for this suite.
May 14 09:46:51.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:46:51.153: INFO: namespace container-probe-9761 deletion completed in 22.073681295s

• [SLOW TEST:46.224 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:46:51.155: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6300/configmap-test-33011fa3-762d-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:46:51.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3" in namespace "configmap-6300" to be "success or failure"
May 14 09:46:51.323: INFO: Pod "pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.480118ms
May 14 09:46:53.325: INFO: Pod "pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012839513s
May 14 09:46:55.331: INFO: Pod "pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018496227s
STEP: Saw pod success
May 14 09:46:55.331: INFO: Pod "pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:46:55.333: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3 container env-test: <nil>
STEP: delete the pod
May 14 09:46:55.346: INFO: Waiting for pod pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:46:55.348: INFO: Pod pod-configmaps-33019c9b-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:46:55.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6300" for this suite.
May 14 09:47:01.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:47:01.431: INFO: namespace configmap-6300 deletion completed in 6.080398156s

• [SLOW TEST:10.276 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:47:01.432: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 14 09:47:01.571: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:133997,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 09:47:01.572: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:133998,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 14 09:47:01.572: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:133999,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 14 09:47:11.593: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:134015,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 09:47:11.593: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:134016,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 14 09:47:11.593: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3576,SelfLink:/api/v1/namespaces/watch-3576/configmaps/e2e-watch-test-label-changed,UID:392177d8-762d-11e9-a442-02538a874012,ResourceVersion:134017,Generation:0,CreationTimestamp:2019-05-14 09:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:47:11.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3576" for this suite.
May 14 09:47:17.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:47:17.675: INFO: namespace watch-3576 deletion completed in 6.078867051s

• [SLOW TEST:16.243 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:47:17.676: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May 14 09:47:17.810: INFO: Waiting up to 5m0s for pod "pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-3448" to be "success or failure"
May 14 09:47:17.814: INFO: Pod "pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.753706ms
May 14 09:47:19.816: INFO: Pod "pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006254972s
STEP: Saw pod success
May 14 09:47:19.816: INFO: Pod "pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:47:19.818: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:47:19.831: INFO: Waiting for pod pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:47:19.833: INFO: Pod pod-42d01c20-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:47:19.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3448" for this suite.
May 14 09:47:25.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:47:25.909: INFO: namespace emptydir-3448 deletion completed in 6.074452838s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:47:25.910: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 09:47:26.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-3371'
May 14 09:47:26.129: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 14 09:47:26.129: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
May 14 09:47:28.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3371'
May 14 09:47:28.225: INFO: stderr: ""
May 14 09:47:28.225: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:47:28.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3371" for this suite.
May 14 09:47:50.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:47:50.307: INFO: namespace kubectl-3371 deletion completed in 22.078915577s

• [SLOW TEST:24.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:47:50.307: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 14 09:47:50.462: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:47:50.465: INFO: Number of nodes with available pods: 0
May 14 09:47:50.465: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 09:47:51.468: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:47:51.470: INFO: Number of nodes with available pods: 1
May 14 09:47:51.470: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 14 09:47:51.481: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 09:47:51.483: INFO: Number of nodes with available pods: 1
May 14 09:47:51.484: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9140, will wait for the garbage collector to delete the pods
May 14 09:47:52.549: INFO: Deleting DaemonSet.extensions daemon-set took: 4.203413ms
May 14 09:47:52.849: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.262327ms
May 14 09:49:01.452: INFO: Number of nodes with available pods: 0
May 14 09:49:01.452: INFO: Number of running nodes: 0, number of available pods: 0
May 14 09:49:01.453: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9140/daemonsets","resourceVersion":"134287"},"items":null}

May 14 09:49:01.455: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9140/pods","resourceVersion":"134287"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:49:01.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9140" for this suite.
May 14 09:49:07.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:49:07.597: INFO: namespace daemonsets-9140 deletion completed in 6.135343271s

• [SLOW TEST:77.290 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:49:07.597: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-8454b03a-762d-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:49:07.733: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3" in namespace "projected-5545" to be "success or failure"
May 14 09:49:07.738: INFO: Pod "pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444758ms
May 14 09:49:09.741: INFO: Pod "pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007648967s
STEP: Saw pod success
May 14 09:49:09.741: INFO: Pod "pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:49:09.743: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:49:09.759: INFO: Waiting for pod pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:49:09.761: INFO: Pod pod-projected-configmaps-84552075-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:49:09.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5545" for this suite.
May 14 09:49:15.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:49:15.835: INFO: namespace projected-5545 deletion completed in 6.072006748s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:49:15.835: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May 14 09:49:15.968: INFO: Waiting up to 5m0s for pod "pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-604" to be "success or failure"
May 14 09:49:15.970: INFO: Pod "pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.159423ms
May 14 09:49:17.973: INFO: Pod "pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00484064s
STEP: Saw pod success
May 14 09:49:17.973: INFO: Pod "pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:49:17.974: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:49:17.987: INFO: Waiting for pod pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:49:17.989: INFO: Pod pod-893da8f4-762d-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:49:17.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-604" for this suite.
May 14 09:49:23.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:49:24.066: INFO: namespace emptydir-604 deletion completed in 6.074398352s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:49:24.066: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8746
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:49:24.195: INFO: Creating deployment "nginx-deployment"
May 14 09:49:24.199: INFO: Waiting for observed generation 1
May 14 09:49:26.206: INFO: Waiting for all required pods to come up
May 14 09:49:26.210: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 14 09:49:32.223: INFO: Waiting for deployment "nginx-deployment" to complete
May 14 09:49:32.227: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 14 09:49:32.231: INFO: Updating deployment nginx-deployment
May 14 09:49:32.231: INFO: Waiting for observed generation 2
May 14 09:49:34.237: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 14 09:49:34.238: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 14 09:49:34.240: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 14 09:49:34.245: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 14 09:49:34.245: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 14 09:49:34.247: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 14 09:49:34.250: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 14 09:49:34.250: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 14 09:49:34.255: INFO: Updating deployment nginx-deployment
May 14 09:49:34.256: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 14 09:49:34.285: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 14 09:49:36.292: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 14 09:49:36.296: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8746,SelfLink:/apis/apps/v1/namespaces/deployment-8746/deployments/nginx-deployment,UID:8e25cef5-762d-11e9-a442-02538a874012,ResourceVersion:134660,Generation:3,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-14 09:49:34 +0000 UTC 2019-05-14 09:49:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-14 09:49:34 +0000 UTC 2019-05-14 09:49:24 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 14 09:49:36.298: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8746,SelfLink:/apis/apps/v1/namespaces/deployment-8746/replicasets/nginx-deployment-5f9595f595,UID:92f04be8-762d-11e9-a442-02538a874012,ResourceVersion:134658,Generation:3,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8e25cef5-762d-11e9-a442-02538a874012 0xc00275f487 0xc00275f488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 09:49:36.298: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 14 09:49:36.298: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-8746,SelfLink:/apis/apps/v1/namespaces/deployment-8746/replicasets/nginx-deployment-6f478d8d8,UID:8e265557-762d-11e9-a442-02538a874012,ResourceVersion:134644,Generation:3,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8e25cef5-762d-11e9-a442-02538a874012 0xc00275f557 0xc00275f558}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 14 09:49:36.302: INFO: Pod "nginx-deployment-5f9595f595-5dhgg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5dhgg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-5dhgg,UID:942f3aad-762d-11e9-a442-02538a874012,ResourceVersion:134640,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc00275fe47 0xc00275fe48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00275feb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00275fed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.303: INFO: Pod "nginx-deployment-5f9595f595-6nqkz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6nqkz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-6nqkz,UID:92fc3620-762d-11e9-a442-02538a874012,ResourceVersion:134581,Generation:0,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc00275ff50 0xc00275ff51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00275ffc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00275ffe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.303: INFO: Pod "nginx-deployment-5f9595f595-8pd7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8pd7x,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-8pd7x,UID:942f4c4c-762d-11e9-a442-02538a874012,ResourceVersion:134649,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a80b0 0xc0023a80b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.303: INFO: Pod "nginx-deployment-5f9595f595-dpr7z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dpr7z,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-dpr7z,UID:942b886f-762d-11e9-a442-02538a874012,ResourceVersion:134698,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a81c0 0xc0023a81c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.303: INFO: Pod "nginx-deployment-5f9595f595-mtf7q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mtf7q,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-mtf7q,UID:92fa63fb-762d-11e9-a442-02538a874012,ResourceVersion:134579,Generation:0,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8320 0xc0023a8321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a83b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.304: INFO: Pod "nginx-deployment-5f9595f595-nf9rp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nf9rp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-nf9rp,UID:942f764a-762d-11e9-a442-02538a874012,ResourceVersion:134657,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8480 0xc0023a8481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a84f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.304: INFO: Pod "nginx-deployment-5f9595f595-qbnr4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qbnr4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-qbnr4,UID:942bdc74-762d-11e9-a442-02538a874012,ResourceVersion:134626,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8590 0xc0023a8591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.304: INFO: Pod "nginx-deployment-5f9595f595-rjszl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rjszl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-rjszl,UID:92f22cc0-762d-11e9-a442-02538a874012,ResourceVersion:134563,Generation:0,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a86a0 0xc0023a86a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.304: INFO: Pod "nginx-deployment-5f9595f595-t24xt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-t24xt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-t24xt,UID:92f2571d-762d-11e9-a442-02538a874012,ResourceVersion:134573,Generation:0,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8800 0xc0023a8801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.305: INFO: Pod "nginx-deployment-5f9595f595-vhrlb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vhrlb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-vhrlb,UID:94340d3b-762d-11e9-a442-02538a874012,ResourceVersion:134650,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8960 0xc0023a8961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a89d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a89f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.305: INFO: Pod "nginx-deployment-5f9595f595-wzbq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wzbq7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-wzbq7,UID:942f720d-762d-11e9-a442-02538a874012,ResourceVersion:134656,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8a70 0xc0023a8a71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.305: INFO: Pod "nginx-deployment-5f9595f595-xstk9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xstk9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-xstk9,UID:92f11291-762d-11e9-a442-02538a874012,ResourceVersion:134552,Generation:0,CreationTimestamp:2019-05-14 09:49:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8b80 0xc0023a8b81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:32 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.305: INFO: Pod "nginx-deployment-5f9595f595-zrm4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zrm4n,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-5f9595f595-zrm4n,UID:94283f62-762d-11e9-a442-02538a874012,ResourceVersion:134653,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 92f04be8-762d-11e9-a442-02538a874012 0xc0023a8ce0 0xc0023a8ce1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.305: INFO: Pod "nginx-deployment-6f478d8d8-2gd9l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2gd9l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-2gd9l,UID:942bb44d-762d-11e9-a442-02538a874012,ResourceVersion:134699,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a8e40 0xc0023a8e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a8ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.306: INFO: Pod "nginx-deployment-6f478d8d8-2kxpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2kxpj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-2kxpj,UID:9428bdb2-762d-11e9-a442-02538a874012,ResourceVersion:134692,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a8f80 0xc0023a8f81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a8fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.306: INFO: Pod "nginx-deployment-6f478d8d8-6hrvz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6hrvz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-6hrvz,UID:9425c4b3-762d-11e9-a442-02538a874012,ResourceVersion:134638,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a90c0 0xc0023a90c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.306: INFO: Pod "nginx-deployment-6f478d8d8-6j9hc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6j9hc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-6j9hc,UID:8e292138-762d-11e9-a442-02538a874012,ResourceVersion:134484,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9200 0xc0023a9201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.84,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://cdb519d3db429898f24af319e5eb6ed16840c21d0b2247254f5451628665d7cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.306: INFO: Pod "nginx-deployment-6f478d8d8-78j2c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-78j2c,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-78j2c,UID:8e2d5f72-762d-11e9-a442-02538a874012,ResourceVersion:134510,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9350 0xc0023a9351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a93b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a93d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.88,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d40a62ef1e9b680082e937822053eee5a76739a728f8c113dc86068444758d70}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-985vs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-985vs,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-985vs,UID:942b9c99-762d-11e9-a442-02538a874012,ResourceVersion:134627,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a94b0 0xc0023a94b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-997pz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-997pz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-997pz,UID:942ba36b-762d-11e9-a442-02538a874012,ResourceVersion:134636,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a95b0 0xc0023a95b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-bnpgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bnpgn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-bnpgn,UID:942f82cd-762d-11e9-a442-02538a874012,ResourceVersion:134655,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a96b0 0xc0023a96b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-dqqnw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dqqnw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-dqqnw,UID:8e27bb89-762d-11e9-a442-02538a874012,ResourceVersion:134493,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a97b0 0xc0023a97b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.82,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://91085ee3bc58a4eaf01138bb5108d902aeb6d8ede0fdd4b06e33ecddd357a36b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-f7fgk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-f7fgk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-f7fgk,UID:8e2b9578-762d-11e9-a442-02538a874012,ResourceVersion:134481,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9900 0xc0023a9901}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.85,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1b24698a9abf781c5f0c4b9235264ade53572f676731bdc878f4b697e86d6065}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.307: INFO: Pod "nginx-deployment-6f478d8d8-ffnl4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ffnl4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-ffnl4,UID:942f64ed-762d-11e9-a442-02538a874012,ResourceVersion:134654,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9a50 0xc0023a9a51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-hnnb8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hnnb8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-hnnb8,UID:942bca07-762d-11e9-a442-02538a874012,ResourceVersion:134700,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9b50 0xc0023a9b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-kv8m8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kv8m8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-kv8m8,UID:942f9504-762d-11e9-a442-02538a874012,ResourceVersion:134651,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9c90 0xc0023a9c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-p9kll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-p9kll,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-p9kll,UID:94282ca6-762d-11e9-a442-02538a874012,ResourceVersion:134672,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9d90 0xc0023a9d91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:,StartTime:2019-05-14 09:49:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-qqcxq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qqcxq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-qqcxq,UID:8e2b6e74-762d-11e9-a442-02538a874012,ResourceVersion:134498,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0023a9ed0 0xc0023a9ed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023a9f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023a9f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.90,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d1519a0001f441965f289a8301eb14a14cadf054d8ae9f55ecea2538b14b10de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-v5cxt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v5cxt,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-v5cxt,UID:8e2b0372-762d-11e9-a442-02538a874012,ResourceVersion:134503,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc002526020 0xc002526021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025260a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.86,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://985271e770a778c8ff31a887c3ed4aed609f848809ea585fdb53dc8d2d85008d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.308: INFO: Pod "nginx-deployment-6f478d8d8-v8wc4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v8wc4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-v8wc4,UID:942fa9a3-762d-11e9-a442-02538a874012,ResourceVersion:134637,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc002526170 0xc002526171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025261d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025261f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.309: INFO: Pod "nginx-deployment-6f478d8d8-vn9m7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vn9m7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-vn9m7,UID:942f99cb-762d-11e9-a442-02538a874012,ResourceVersion:134652,Generation:0,CreationTimestamp:2019-05-14 09:49:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc002526270 0xc002526271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025262d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025262f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.309: INFO: Pod "nginx-deployment-6f478d8d8-vpb7z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vpb7z,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-vpb7z,UID:8e2da0b9-762d-11e9-a442-02538a874012,ResourceVersion:134488,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc002526370 0xc002526371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025263d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025263f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.87,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://970378c1a3dc76642ba42730437f8aeb2af33eaec64e142a902bce1cbd6668c6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 14 09:49:36.309: INFO: Pod "nginx-deployment-6f478d8d8-vvj9m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vvj9m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8746,SelfLink:/api/v1/namespaces/deployment-8746/pods/nginx-deployment-6f478d8d8-vvj9m,UID:8e2e19f8-762d-11e9-a442-02538a874012,ResourceVersion:134515,Generation:0,CreationTimestamp:2019-05-14 09:49:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 8e265557-762d-11e9-a442-02538a874012 0xc0025264d0 0xc0025264d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sj9mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj9mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj9mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:49:24 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.91,StartTime:2019-05-14 09:49:24 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:49:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://12cc1bdec6b6348f3dead744f117b076539a542cfde68cbf5f523f7bb4bb2958}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:49:36.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8746" for this suite.
May 14 09:49:42.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:49:42.388: INFO: namespace deployment-8746 deletion completed in 6.077030055s

• [SLOW TEST:18.322 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:49:42.388: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:49:42.557: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9915456f-762d-11e9-a442-02538a874012", Controller:(*bool)(0xc0019da16a), BlockOwnerDeletion:(*bool)(0xc0019da16b)}}
May 14 09:49:42.562: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"99142b6d-762d-11e9-a442-02538a874012", Controller:(*bool)(0xc0018ba12a), BlockOwnerDeletion:(*bool)(0xc0018ba12b)}}
May 14 09:49:42.566: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9914abb3-762d-11e9-a442-02538a874012", Controller:(*bool)(0xc0019da31a), BlockOwnerDeletion:(*bool)(0xc0019da31b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:49:47.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1022" for this suite.
May 14 09:49:53.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:49:53.671: INFO: namespace gc-1022 deletion completed in 6.096476818s

• [SLOW TEST:11.283 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:49:53.676: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:50:18.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7756" for this suite.
May 14 09:50:24.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:50:25.028: INFO: namespace container-runtime-7756 deletion completed in 6.075342427s

• [SLOW TEST:31.352 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:50:25.028: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9740
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 09:50:25.156: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 09:50:45.194: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.1.120:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9740 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 09:50:45.194: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 09:50:45.303: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:50:45.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9740" for this suite.
May 14 09:51:07.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:51:07.384: INFO: namespace pod-network-test-9740 deletion completed in 22.077254111s

• [SLOW TEST:42.355 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:51:07.385: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 14 09:51:10.050: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3"
May 14 09:51:10.050: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3" in namespace "pods-1316" to be "terminated due to deadline exceeded"
May 14 09:51:10.052: INFO: Pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3": Phase="Running", Reason="", readiness=true. Elapsed: 1.707439ms
May 14 09:51:12.054: INFO: Pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3": Phase="Running", Reason="", readiness=true. Elapsed: 2.004226528s
May 14 09:51:14.057: INFO: Pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.006726011s
May 14 09:51:14.057: INFO: Pod "pod-update-activedeadlineseconds-cbbb628b-762d-11e9-8d5d-c6eb97da6be3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:51:14.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1316" for this suite.
May 14 09:51:20.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:51:20.132: INFO: namespace pods-1316 deletion completed in 6.072946122s

• [SLOW TEST:12.747 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:51:20.132: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:52:20.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9604" for this suite.
May 14 09:52:42.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:52:42.369: INFO: namespace container-probe-9604 deletion completed in 22.096553373s

• [SLOW TEST:82.236 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:52:42.370: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
May 14 09:52:42.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-6371'
May 14 09:52:42.920: INFO: stderr: ""
May 14 09:52:42.920: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
May 14 09:52:43.923: INFO: Selector matched 1 pods for map[app:redis]
May 14 09:52:43.923: INFO: Found 1 / 1
May 14 09:52:43.923: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 14 09:52:43.925: INFO: Selector matched 1 pods for map[app:redis]
May 14 09:52:43.925: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 14 09:52:43.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 logs redis-master-pxbps redis-master --namespace=kubectl-6371'
May 14 09:52:44.002: INFO: stderr: ""
May 14 09:52:44.002: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 09:52:43.762 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 09:52:43.762 # Server started, Redis version 3.2.12\n1:M 14 May 09:52:43.762 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 09:52:43.762 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 14 09:52:44.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 log redis-master-pxbps redis-master --namespace=kubectl-6371 --tail=1'
May 14 09:52:44.077: INFO: stderr: ""
May 14 09:52:44.077: INFO: stdout: "1:M 14 May 09:52:43.762 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 14 09:52:44.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 log redis-master-pxbps redis-master --namespace=kubectl-6371 --limit-bytes=1'
May 14 09:52:44.151: INFO: stderr: ""
May 14 09:52:44.151: INFO: stdout: " "
STEP: exposing timestamps
May 14 09:52:44.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 log redis-master-pxbps redis-master --namespace=kubectl-6371 --tail=1 --timestamps'
May 14 09:52:44.229: INFO: stderr: ""
May 14 09:52:44.229: INFO: stdout: "2019-05-14T09:52:43.765103693Z 1:M 14 May 09:52:43.762 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 14 09:52:46.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 log redis-master-pxbps redis-master --namespace=kubectl-6371 --since=1s'
May 14 09:52:46.853: INFO: stderr: ""
May 14 09:52:46.853: INFO: stdout: ""
May 14 09:52:46.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 log redis-master-pxbps redis-master --namespace=kubectl-6371 --since=24h'
May 14 09:52:46.933: INFO: stderr: ""
May 14 09:52:46.933: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 09:52:43.762 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 09:52:43.762 # Server started, Redis version 3.2.12\n1:M 14 May 09:52:43.762 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 09:52:43.762 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
May 14 09:52:46.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-6371'
May 14 09:52:47.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 09:52:47.002: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 14 09:52:47.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6371'
May 14 09:52:47.095: INFO: stderr: "No resources found.\n"
May 14 09:52:47.095: INFO: stdout: ""
May 14 09:52:47.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=nginx --namespace=kubectl-6371 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 09:52:47.163: INFO: stderr: ""
May 14 09:52:47.163: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:52:47.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6371" for this suite.
May 14 09:52:53.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:52:53.240: INFO: namespace kubectl-6371 deletion completed in 6.074827767s

• [SLOW TEST:10.870 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:52:53.240: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5770
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
May 14 09:52:53.377: INFO: Waiting up to 5m0s for pod "pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-5770" to be "success or failure"
May 14 09:52:53.380: INFO: Pod "pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047316ms
May 14 09:52:55.383: INFO: Pod "pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005825336s
STEP: Saw pod success
May 14 09:52:55.383: INFO: Pod "pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:52:55.384: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:52:55.396: INFO: Waiting for pod pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:52:55.399: INFO: Pod pod-0ad3486b-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:52:55.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5770" for this suite.
May 14 09:53:01.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:01.489: INFO: namespace emptydir-5770 deletion completed in 6.088205839s

• [SLOW TEST:8.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:01.490: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 14 09:53:01.625: INFO: Waiting up to 5m0s for pod "downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-8936" to be "success or failure"
May 14 09:53:01.633: INFO: Pod "downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.204066ms
May 14 09:53:03.635: INFO: Pod "downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009739354s
STEP: Saw pod success
May 14 09:53:03.635: INFO: Pod "downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:53:03.637: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:53:03.650: INFO: Waiting for pod downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:53:03.653: INFO: Pod downward-api-0fbdfe02-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:03.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8936" for this suite.
May 14 09:53:09.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:09.728: INFO: namespace downward-api-8936 deletion completed in 6.072423146s

• [SLOW TEST:8.238 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:09.728: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7957
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
May 14 09:53:09.860: INFO: Waiting up to 5m0s for pod "pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-7957" to be "success or failure"
May 14 09:53:09.863: INFO: Pod "pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.480392ms
May 14 09:53:11.865: INFO: Pod "pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005166035s
STEP: Saw pod success
May 14 09:53:11.865: INFO: Pod "pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:53:11.867: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 09:53:11.881: INFO: Waiting for pod pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:53:11.883: INFO: Pod pod-14a6e897-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:11.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7957" for this suite.
May 14 09:53:17.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:17.959: INFO: namespace emptydir-7957 deletion completed in 6.07338231s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:17.960: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:18.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9021" for this suite.
May 14 09:53:24.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:24.353: INFO: namespace kubelet-test-9021 deletion completed in 6.246369729s

• [SLOW TEST:6.393 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:24.353: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 14 09:53:24.486: INFO: Waiting up to 5m0s for pod "downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-2551" to be "success or failure"
May 14 09:53:24.489: INFO: Pod "downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.02259ms
May 14 09:53:26.492: INFO: Pod "downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005767488s
STEP: Saw pod success
May 14 09:53:26.492: INFO: Pod "downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:53:26.493: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 09:53:26.506: INFO: Waiting for pod downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:53:26.508: INFO: Pod downward-api-1d5e6663-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:26.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2551" for this suite.
May 14 09:53:32.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:32.583: INFO: namespace downward-api-2551 deletion completed in 6.073588328s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:32.584: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
May 14 09:53:32.717: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3984" to be "success or failure"
May 14 09:53:32.721: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.131557ms
May 14 09:53:34.724: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006004707s
STEP: Saw pod success
May 14 09:53:34.724: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 14 09:53:34.725: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 14 09:53:34.741: INFO: Waiting for pod pod-host-path-test to disappear
May 14 09:53:34.747: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:34.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3984" for this suite.
May 14 09:53:40.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:40.830: INFO: namespace hostpath-3984 deletion completed in 6.077637533s

• [SLOW TEST:8.246 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:40.831: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5077
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 09:53:40.966: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 14 09:53:45.969: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 14 09:53:45.969: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 14 09:53:45.982: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5077,SelfLink:/apis/apps/v1/namespaces/deployment-5077/deployments/test-cleanup-deployment,UID:2a2db929-762e-11e9-a442-02538a874012,ResourceVersion:135678,Generation:1,CreationTimestamp:2019-05-14 09:53:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 14 09:53:45.986: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
May 14 09:53:45.986: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 14 09:53:45.986: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5077,SelfLink:/apis/apps/v1/namespaces/deployment-5077/replicasets/test-cleanup-controller,UID:2730e06e-762e-11e9-a442-02538a874012,ResourceVersion:135679,Generation:1,CreationTimestamp:2019-05-14 09:53:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 2a2db929-762e-11e9-a442-02538a874012 0xc00233b6d7 0xc00233b6d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 14 09:53:45.991: INFO: Pod "test-cleanup-controller-mc8fk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-mc8fk,GenerateName:test-cleanup-controller-,Namespace:deployment-5077,SelfLink:/api/v1/namespaces/deployment-5077/pods/test-cleanup-controller-mc8fk,UID:2731c6bc-762e-11e9-a442-02538a874012,ResourceVersion:135671,Generation:0,CreationTimestamp:2019-05-14 09:53:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 2730e06e-762e-11e9-a442-02538a874012 0xc00233bc47 0xc00233bc48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4sc9d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4sc9d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4sc9d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00233bcb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00233bcd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:53:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:53:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:53:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 09:53:40 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.131,StartTime:2019-05-14 09:53:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-14 09:53:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://32c7a20f8e905c939cf6ac7fa1b291f4d34b3f8afd711d1fe536a9c711fc3b05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:53:45.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5077" for this suite.
May 14 09:53:52.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:53:52.093: INFO: namespace deployment-5077 deletion completed in 6.086053462s

• [SLOW TEST:11.263 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:53:52.094: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1714
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-2de7af47-762e-11e9-8d5d-c6eb97da6be3
STEP: Creating secret with name s-test-opt-upd-2de7af84-762e-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2de7af47-762e-11e9-8d5d-c6eb97da6be3
STEP: Updating secret s-test-opt-upd-2de7af84-762e-11e9-8d5d-c6eb97da6be3
STEP: Creating secret with name s-test-opt-create-2de7af9b-762e-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:55:26.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1714" for this suite.
May 14 09:55:48.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:55:48.727: INFO: namespace secrets-1714 deletion completed in 22.074144023s

• [SLOW TEST:116.634 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:55:48.728: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:55:48.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-8718" to be "success or failure"
May 14 09:55:48.887: INFO: Pod "downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.846473ms
May 14 09:55:50.890: INFO: Pod "downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006691698s
STEP: Saw pod success
May 14 09:55:50.890: INFO: Pod "downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:55:50.892: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:55:50.904: INFO: Waiting for pod downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:55:50.905: INFO: Pod downwardapi-volume-736fc682-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:55:50.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8718" for this suite.
May 14 09:55:56.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:55:56.989: INFO: namespace downward-api-8718 deletion completed in 6.081347963s

• [SLOW TEST:8.261 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:55:56.989: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-7858e758-762e-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:55:57.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3" in namespace "projected-1126" to be "success or failure"
May 14 09:55:57.132: INFO: Pod "pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.520442ms
May 14 09:55:59.134: INFO: Pod "pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008442873s
STEP: Saw pod success
May 14 09:55:59.135: INFO: Pod "pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:55:59.136: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:55:59.150: INFO: Waiting for pod pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:55:59.151: INFO: Pod pod-projected-configmaps-78594a40-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:55:59.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1126" for this suite.
May 14 09:56:05.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:56:05.230: INFO: namespace projected-1126 deletion completed in 6.075954645s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:56:05.230: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-962 to expose endpoints map[]
May 14 09:56:05.371: INFO: Get endpoints failed (3.657705ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 14 09:56:06.373: INFO: successfully validated that service multi-endpoint-test in namespace services-962 exposes endpoints map[] (1.006198505s elapsed)
STEP: Creating pod pod1 in namespace services-962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-962 to expose endpoints map[pod1:[100]]
May 14 09:56:08.393: INFO: successfully validated that service multi-endpoint-test in namespace services-962 exposes endpoints map[pod1:[100]] (2.015108068s elapsed)
STEP: Creating pod pod2 in namespace services-962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-962 to expose endpoints map[pod1:[100] pod2:[101]]
May 14 09:56:10.418: INFO: successfully validated that service multi-endpoint-test in namespace services-962 exposes endpoints map[pod1:[100] pod2:[101]] (2.022115103s elapsed)
STEP: Deleting pod pod1 in namespace services-962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-962 to expose endpoints map[pod2:[101]]
May 14 09:56:11.436: INFO: successfully validated that service multi-endpoint-test in namespace services-962 exposes endpoints map[pod2:[101]] (1.014391857s elapsed)
STEP: Deleting pod pod2 in namespace services-962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-962 to expose endpoints map[]
May 14 09:56:12.444: INFO: successfully validated that service multi-endpoint-test in namespace services-962 exposes endpoints map[] (1.003666692s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:56:12.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-962" for this suite.
May 14 09:56:34.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:56:34.543: INFO: namespace services-962 deletion completed in 22.07878241s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.313 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:56:34.544: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3524
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8ebb5a6d-762e-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 09:56:34.679: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3" in namespace "configmap-3524" to be "success or failure"
May 14 09:56:34.683: INFO: Pod "pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.165965ms
May 14 09:56:36.686: INFO: Pod "pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007592357s
STEP: Saw pod success
May 14 09:56:36.686: INFO: Pod "pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:56:36.688: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 09:56:36.702: INFO: Waiting for pod pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:56:36.704: INFO: Pod pod-configmaps-8ebbbbcf-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:56:36.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3524" for this suite.
May 14 09:56:42.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:56:42.790: INFO: namespace configmap-3524 deletion completed in 6.08396878s

• [SLOW TEST:8.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:56:42.790: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 09:56:42.924: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3" in namespace "projected-7090" to be "success or failure"
May 14 09:56:42.928: INFO: Pod "downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672347ms
May 14 09:56:44.930: INFO: Pod "downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006304224s
STEP: Saw pod success
May 14 09:56:44.930: INFO: Pod "downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 09:56:44.932: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 09:56:44.945: INFO: Waiting for pod downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3 to disappear
May 14 09:56:44.948: INFO: Pod downwardapi-volume-93a5ab5c-762e-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:56:44.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7090" for this suite.
May 14 09:56:50.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:56:51.038: INFO: namespace projected-7090 deletion completed in 6.087972224s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:56:51.039: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3946
May 14 09:56:53.178: INFO: Started pod liveness-exec in namespace container-probe-3946
STEP: checking the pod's current state and verifying that restartCount is present
May 14 09:56:53.180: INFO: Initial restart count of pod liveness-exec is 0
May 14 09:57:41.235: INFO: Restart count of pod container-probe-3946/liveness-exec is now 1 (48.055364371s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:57:41.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3946" for this suite.
May 14 09:57:47.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:57:47.326: INFO: namespace container-probe-3946 deletion completed in 6.080102233s

• [SLOW TEST:56.287 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:57:47.327: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 14 09:57:51.511: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:57:51.513: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:57:53.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:57:53.516: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:57:55.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:57:55.516: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:57:57.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:57:57.521: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:57:59.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:57:59.516: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:58:01.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:58:01.516: INFO: Pod pod-with-poststart-http-hook still exists
May 14 09:58:03.513: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 14 09:58:03.516: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:58:03.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1886" for this suite.
May 14 09:58:25.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:58:25.595: INFO: namespace container-lifecycle-hook-1886 deletion completed in 22.077090256s

• [SLOW TEST:38.269 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:58:25.596: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:58:27.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5274" for this suite.
May 14 09:59:17.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:59:17.825: INFO: namespace kubelet-test-5274 deletion completed in 50.081870242s

• [SLOW TEST:52.229 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:59:17.825: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3
May 14 09:59:17.958: INFO: Pod name my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3: Found 0 pods out of 1
May 14 09:59:22.961: INFO: Pod name my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3: Found 1 pods out of 1
May 14 09:59:22.961: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3" are running
May 14 09:59:22.963: INFO: Pod "my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3-2nb2s" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 09:59:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 09:59:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 09:59:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 09:59:17 +0000 UTC Reason: Message:}])
May 14 09:59:22.963: INFO: Trying to dial the pod
May 14 09:59:27.970: INFO: Controller my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3: Got expected result from replica 1 [my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3-2nb2s]: "my-hostname-basic-f00ded7e-762e-11e9-8d5d-c6eb97da6be3-2nb2s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:59:27.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4484" for this suite.
May 14 09:59:33.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:59:34.057: INFO: namespace replication-controller-4484 deletion completed in 6.085190514s

• [SLOW TEST:16.232 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:59:34.058: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0514 09:59:44.242247      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 09:59:44.242: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:59:44.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8121" for this suite.
May 14 09:59:50.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 09:59:50.319: INFO: namespace gc-8121 deletion completed in 6.07472506s

• [SLOW TEST:16.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 09:59:50.320: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 14 09:59:50.449: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 09:59:54.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-972" for this suite.
May 14 10:00:16.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:00:16.222: INFO: namespace init-container-972 deletion completed in 22.085388947s

• [SLOW TEST:25.902 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:00:16.222: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 10:00:16.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9996'
May 14 10:00:16.442: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 14 10:00:16.442: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 14 10:00:16.446: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-r4x69]
May 14 10:00:16.446: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-r4x69" in namespace "kubectl-9996" to be "running and ready"
May 14 10:00:16.448: INFO: Pod "e2e-test-nginx-rc-r4x69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006621ms
May 14 10:00:18.450: INFO: Pod "e2e-test-nginx-rc-r4x69": Phase="Running", Reason="", readiness=true. Elapsed: 2.004298312s
May 14 10:00:18.450: INFO: Pod "e2e-test-nginx-rc-r4x69" satisfied condition "running and ready"
May 14 10:00:18.450: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-r4x69]
May 14 10:00:18.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 logs rc/e2e-test-nginx-rc --namespace=kubectl-9996'
May 14 10:00:18.538: INFO: stderr: ""
May 14 10:00:18.538: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
May 14 10:00:18.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete rc e2e-test-nginx-rc --namespace=kubectl-9996'
May 14 10:00:18.610: INFO: stderr: ""
May 14 10:00:18.610: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:00:18.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9996" for this suite.
May 14 10:00:40.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:00:40.693: INFO: namespace kubectl-9996 deletion completed in 22.080004408s

• [SLOW TEST:24.471 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:00:40.693: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 14 10:00:40.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 14 10:00:40.829: INFO: Waiting for terminating namespaces to be deleted...
May 14 10:00:40.830: INFO: 
Logging pods the kubelet thinks is on node ip-10-2-82-233.ec2.internal before test
May 14 10:00:40.836: INFO: kube-flannel-ds-amd64-kr6f4 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container kube-flannel ready: true, restart count 1
May 14 10:00:40.836: INFO: alertmanager-prometheus-operator-alertmanager-0 from kube-system started at 2019-05-13 13:23:08 +0000 UTC (2 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container alertmanager ready: true, restart count 0
May 14 10:00:40.836: INFO: 	Container config-reloader ready: true, restart count 0
May 14 10:00:40.836: INFO: prometheus-prometheus-operator-prometheus-0 from kube-system started at 2019-05-13 13:23:15 +0000 UTC (3 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container prometheus ready: true, restart count 1
May 14 10:00:40.836: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
May 14 10:00:40.836: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
May 14 10:00:40.836: INFO: prometheus-operator-grafana-5d74ccd7bd-4rch4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (2 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container grafana ready: true, restart count 0
May 14 10:00:40.836: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
May 14 10:00:40.836: INFO: kube-proxy-f4nj2 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container kube-proxy ready: true, restart count 0
May 14 10:00:40.836: INFO: tiller-deploy-65949f8696-22447 from kube-system started at 2019-05-13 13:22:15 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container tiller ready: true, restart count 0
May 14 10:00:40.836: INFO: prometheus-operator-kube-state-metrics-5d7558d7cc-jm7r4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 14 10:00:40.836: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-14 09:04:33 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 14 10:00:40.836: INFO: sonobuoy-systemd-logs-daemon-set-9584be86564342a8-cgp7q from heptio-sonobuoy started at 2019-05-14 09:04:37 +0000 UTC (2 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 14 10:00:40.836: INFO: 	Container systemd-logs ready: true, restart count 0
May 14 10:00:40.836: INFO: prometheus-operator-prometheus-node-exporter-frpgv from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container node-exporter ready: true, restart count 0
May 14 10:00:40.836: INFO: prometheus-operator-operator-55445689db-bqr4b from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container prometheus-operator ready: true, restart count 0
May 14 10:00:40.836: INFO: liveness-http from container-probe-8911 started at 2019-05-13 13:25:40 +0000 UTC (1 container statuses recorded)
May 14 10:00:40.836: INFO: 	Container liveness ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod liveness-http requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod sonobuoy-systemd-logs-daemon-set-9584be86564342a8-cgp7q requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod alertmanager-prometheus-operator-alertmanager-0 requesting resource cpu=100m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod kube-flannel-ds-amd64-kr6f4 requesting resource cpu=100m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod kube-proxy-f4nj2 requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod prometheus-operator-grafana-5d74ccd7bd-4rch4 requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod prometheus-operator-kube-state-metrics-5d7558d7cc-jm7r4 requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod prometheus-operator-operator-55445689db-bqr4b requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod prometheus-operator-prometheus-node-exporter-frpgv requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod prometheus-prometheus-operator-prometheus-0 requesting resource cpu=150m on Node ip-10-2-82-233.ec2.internal
May 14 10:00:40.855: INFO: Pod tiller-deploy-65949f8696-22447 requesting resource cpu=0m on Node ip-10-2-82-233.ec2.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3.159e845974d5002c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-397/filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3 to ip-10-2-82-233.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3.159e84599d72659f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3.159e8459a0028598], Reason = [Created], Message = [Created container filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3.159e8459adb2e0e6], Reason = [Started], Message = [Started container filler-pod-2177e21c-762f-11e9-8d5d-c6eb97da6be3]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159e8459ecb3a93a], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-10-2-82-233.ec2.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:00:43.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-397" for this suite.
May 14 10:00:49.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:00:49.967: INFO: namespace sched-pred-397 deletion completed in 6.075061753s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.274 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:00:49.969: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:00:50.116: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:00:52.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6197" for this suite.
May 14 10:01:34.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:01:34.220: INFO: namespace pods-6197 deletion completed in 42.079419124s

• [SLOW TEST:44.251 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:01:34.221: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 14 10:01:34.356: INFO: Pod name pod-release: Found 0 pods out of 1
May 14 10:01:39.358: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:01:39.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9933" for this suite.
May 14 10:01:45.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:01:45.487: INFO: namespace replication-controller-9933 deletion completed in 6.092908218s

• [SLOW TEST:11.266 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:01:45.487: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1253
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4811b82c-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:01:45.626: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3" in namespace "projected-1253" to be "success or failure"
May 14 10:01:45.631: INFO: Pod "pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.971235ms
May 14 10:01:47.633: INFO: Pod "pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007910437s
STEP: Saw pod success
May 14 10:01:47.634: INFO: Pod "pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:01:47.635: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:01:47.648: INFO: Waiting for pod pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:01:47.650: INFO: Pod pod-projected-configmaps-481231b0-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:01:47.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1253" for this suite.
May 14 10:01:53.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:01:53.742: INFO: namespace projected-1253 deletion completed in 6.089240418s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:01:53.743: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:01:53.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 version --client'
May 14 10:01:54.016: INFO: stderr: ""
May 14 10:01:54.016: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 14 10:01:54.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-2885'
May 14 10:01:54.176: INFO: stderr: ""
May 14 10:01:54.176: INFO: stdout: "replicationcontroller/redis-master created\n"
May 14 10:01:54.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-2885'
May 14 10:01:54.361: INFO: stderr: ""
May 14 10:01:54.361: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 14 10:01:55.364: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:01:55.364: INFO: Found 0 / 1
May 14 10:01:56.364: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:01:56.364: INFO: Found 1 / 1
May 14 10:01:56.364: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 14 10:01:56.366: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:01:56.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 14 10:01:56.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 describe pod redis-master-c769c --namespace=kubectl-2885'
May 14 10:01:56.446: INFO: stderr: ""
May 14 10:01:56.446: INFO: stdout: "Name:               redis-master-c769c\nNamespace:          kubectl-2885\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-2-82-233.ec2.internal/10.2.82.233\nStart Time:         Tue, 14 May 2019 10:01:54 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.100.1.166\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://445c964d45f66a3bfbcc820b45a5864847c4c80ad14b2505dbb7129dad247e71\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 14 May 2019 10:01:55 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-j7kbk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-j7kbk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-j7kbk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                  Message\n  ----    ------     ----  ----                                  -------\n  Normal  Scheduled  2s    default-scheduler                     Successfully assigned kubectl-2885/redis-master-c769c to ip-10-2-82-233.ec2.internal\n  Normal  Pulled     2s    kubelet, ip-10-2-82-233.ec2.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-2-82-233.ec2.internal  Created container redis-master\n  Normal  Started    1s    kubelet, ip-10-2-82-233.ec2.internal  Started container redis-master\n"
May 14 10:01:56.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 describe rc redis-master --namespace=kubectl-2885'
May 14 10:01:56.533: INFO: stderr: ""
May 14 10:01:56.533: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2885\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-c769c\n"
May 14 10:01:56.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 describe service redis-master --namespace=kubectl-2885'
May 14 10:01:56.608: INFO: stderr: ""
May 14 10:01:56.608: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2885\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.84.5\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.100.1.166:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 14 10:01:56.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 describe node ip-10-2-82-233.ec2.internal'
May 14 10:01:56.704: INFO: stderr: ""
May 14 10:01:56.704: INFO: stdout: "Name:               ip-10-2-82-233.ec2.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-1\n                    failure-domain.beta.kubernetes.io/zone=us-east-1a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-2-82-233.ec2.internal\n                    kubernetes.io/os=linux\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"26:48:4f:7f:dd:33\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.2.82.233\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 May 2019 13:21:59 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 13 May 2019 13:22:01 +0000   Mon, 13 May 2019 13:22:01 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 14 May 2019 10:01:06 +0000   Mon, 13 May 2019 13:21:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 14 May 2019 10:01:06 +0000   Mon, 13 May 2019 13:21:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 14 May 2019 10:01:06 +0000   Mon, 13 May 2019 13:21:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 14 May 2019 10:01:06 +0000   Mon, 13 May 2019 13:22:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.2.82.233\n  ExternalIP:   34.205.39.210\n  InternalDNS:  ip-10-2-82-233.ec2.internal\n  ExternalDNS:  ec2-34-205-39-210.compute-1.amazonaws.com\n  Hostname:     ip-10-2-82-233.ec2.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           81254044Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8173760Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           74883726827\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8071360Ki\n pods:                        110\nSystem Info:\n Machine ID:                 2fc4fffbae2649d6b9f2517a2bd25b6f\n System UUID:                EC2C62A6-3CD4-0086-CBE9-DC438AE0571F\n Boot ID:                    2374a597-b152-4213-b003-39a1b6f4d5fe\n Kernel Version:             4.4.0-1075-aws\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nPodCIDR:                     10.100.1.0/24\nProviderID:                  aws:///us-east-1a/i-06120930a7f979262\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  container-probe-8911       liveness-http                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-9584be86564342a8-cgp7q    0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  kube-system                alertmanager-prometheus-operator-alertmanager-0            100m (5%)     100m (5%)   225Mi (2%)       25Mi (0%)      20h\n  kube-system                kube-flannel-ds-amd64-kr6f4                                100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      20h\n  kube-system                kube-proxy-f4nj2                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                prometheus-operator-grafana-5d74ccd7bd-4rch4               0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                prometheus-operator-kube-state-metrics-5d7558d7cc-jm7r4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                prometheus-operator-operator-55445689db-bqr4b              0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                prometheus-operator-prometheus-node-exporter-frpgv         0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                prometheus-prometheus-operator-prometheus-0                150m (7%)     150m (7%)   75Mi (0%)        75Mi (0%)      20h\n  kube-system                tiller-deploy-65949f8696-22447                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h\n  kubectl-2885               redis-master-c769c                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         350m (17%)  350m (17%)\n  memory                      350Mi (4%)  150Mi (1%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
May 14 10:01:56.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 describe namespace kubectl-2885'
May 14 10:01:56.798: INFO: stderr: ""
May 14 10:01:56.798: INFO: stdout: "Name:         kubectl-2885\nLabels:       e2e-framework=kubectl\n              e2e-run=5254e0e2-7627-11e9-8d5d-c6eb97da6be3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:01:56.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2885" for this suite.
May 14 10:02:18.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:02:18.875: INFO: namespace kubectl-2885 deletion completed in 22.075213695s

• [SLOW TEST:25.132 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:02:18.875: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4004
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5bf87d95-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5bf87d95-762f-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:02:23.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4004" for this suite.
May 14 10:02:45.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:02:45.119: INFO: namespace projected-4004 deletion completed in 22.07581162s

• [SLOW TEST:26.244 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:02:45.120: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-z5n2
STEP: Creating a pod to test atomic-volume-subpath
May 14 10:02:45.257: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-z5n2" in namespace "subpath-5909" to be "success or failure"
May 14 10:02:45.260: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.904921ms
May 14 10:02:47.262: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005159794s
May 14 10:02:49.266: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 4.008719982s
May 14 10:02:51.268: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 6.011396312s
May 14 10:02:53.271: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 8.013704767s
May 14 10:02:55.273: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 10.016356975s
May 14 10:02:57.276: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 12.018736491s
May 14 10:02:59.279: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 14.021588222s
May 14 10:03:01.281: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 16.024237374s
May 14 10:03:03.283: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 18.026479391s
May 14 10:03:05.286: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Running", Reason="", readiness=true. Elapsed: 20.028881087s
May 14 10:03:07.288: INFO: Pod "pod-subpath-test-projected-z5n2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031439988s
STEP: Saw pod success
May 14 10:03:07.288: INFO: Pod "pod-subpath-test-projected-z5n2" satisfied condition "success or failure"
May 14 10:03:07.290: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-subpath-test-projected-z5n2 container test-container-subpath-projected-z5n2: <nil>
STEP: delete the pod
May 14 10:03:07.306: INFO: Waiting for pod pod-subpath-test-projected-z5n2 to disappear
May 14 10:03:07.308: INFO: Pod pod-subpath-test-projected-z5n2 no longer exists
STEP: Deleting pod pod-subpath-test-projected-z5n2
May 14 10:03:07.308: INFO: Deleting pod "pod-subpath-test-projected-z5n2" in namespace "subpath-5909"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:03:07.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5909" for this suite.
May 14 10:03:13.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:03:13.386: INFO: namespace subpath-5909 deletion completed in 6.074397332s

• [SLOW TEST:28.267 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:03:13.387: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 14 10:03:13.523: INFO: Waiting up to 5m0s for pod "downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-3626" to be "success or failure"
May 14 10:03:13.527: INFO: Pod "downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401845ms
May 14 10:03:15.530: INFO: Pod "downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007126271s
May 14 10:03:17.533: INFO: Pod "downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01021038s
STEP: Saw pod success
May 14 10:03:17.533: INFO: Pod "downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:03:17.535: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 10:03:17.551: INFO: Waiting for pod downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:03:17.553: INFO: Pod downward-api-7c76344d-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:03:17.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3626" for this suite.
May 14 10:03:23.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:03:23.761: INFO: namespace downward-api-3626 deletion completed in 6.205997559s

• [SLOW TEST:10.375 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:03:23.765: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-82b38d05-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:03:24.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3" in namespace "configmap-9230" to be "success or failure"
May 14 10:03:24.026: INFO: Pod "pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.99861ms
May 14 10:03:26.034: INFO: Pod "pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017831603s
STEP: Saw pod success
May 14 10:03:26.034: INFO: Pod "pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:03:26.035: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:03:26.048: INFO: Waiting for pod pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:03:26.051: INFO: Pod pod-configmaps-82b66c86-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:03:26.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9230" for this suite.
May 14 10:03:32.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:03:32.126: INFO: namespace configmap-9230 deletion completed in 6.072700379s

• [SLOW TEST:8.361 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:03:32.126: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7379
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:03:32.265: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:03:33.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7379" for this suite.
May 14 10:03:39.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:03:39.439: INFO: namespace custom-resource-definition-7379 deletion completed in 6.075677424s

• [SLOW TEST:7.313 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:03:39.440: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-kk55
STEP: Creating a pod to test atomic-volume-subpath
May 14 10:03:39.579: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kk55" in namespace "subpath-5858" to be "success or failure"
May 14 10:03:39.583: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16165ms
May 14 10:03:41.586: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 2.006674414s
May 14 10:03:43.588: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 4.009271037s
May 14 10:03:45.591: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 6.011994066s
May 14 10:03:47.593: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 8.014466951s
May 14 10:03:49.596: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 10.016878565s
May 14 10:03:51.599: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 12.019825871s
May 14 10:03:53.601: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 14.022557108s
May 14 10:03:55.605: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 16.025634843s
May 14 10:03:57.607: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 18.028247494s
May 14 10:03:59.610: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Running", Reason="", readiness=true. Elapsed: 20.030745429s
May 14 10:04:01.612: INFO: Pod "pod-subpath-test-configmap-kk55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033255588s
STEP: Saw pod success
May 14 10:04:01.612: INFO: Pod "pod-subpath-test-configmap-kk55" satisfied condition "success or failure"
May 14 10:04:01.615: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-subpath-test-configmap-kk55 container test-container-subpath-configmap-kk55: <nil>
STEP: delete the pod
May 14 10:04:01.627: INFO: Waiting for pod pod-subpath-test-configmap-kk55 to disappear
May 14 10:04:01.629: INFO: Pod pod-subpath-test-configmap-kk55 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kk55
May 14 10:04:01.629: INFO: Deleting pod "pod-subpath-test-configmap-kk55" in namespace "subpath-5858"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:04:01.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5858" for this suite.
May 14 10:04:07.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:04:07.715: INFO: namespace subpath-5858 deletion completed in 6.082311407s

• [SLOW TEST:28.276 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:04:07.716: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 14 10:04:07.849: INFO: Waiting up to 5m0s for pod "pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-241" to be "success or failure"
May 14 10:04:07.852: INFO: Pod "pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.212866ms
May 14 10:04:09.856: INFO: Pod "pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006635698s
STEP: Saw pod success
May 14 10:04:09.856: INFO: Pod "pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:04:09.857: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 10:04:09.872: INFO: Waiting for pod pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:04:09.874: INFO: Pod pod-9cd7d00f-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:04:09.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-241" for this suite.
May 14 10:04:15.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:04:15.951: INFO: namespace emptydir-241 deletion completed in 6.074771324s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:04:15.952: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 10:04:16.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3" in namespace "projected-1959" to be "success or failure"
May 14 10:04:16.132: INFO: Pod "downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.260659ms
May 14 10:04:18.135: INFO: Pod "downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005617261s
STEP: Saw pod success
May 14 10:04:18.135: INFO: Pod "downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:04:18.137: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 10:04:18.149: INFO: Waiting for pod downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:04:18.152: INFO: Pod downwardapi-volume-a1c70da5-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:04:18.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1959" for this suite.
May 14 10:04:24.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:04:24.230: INFO: namespace projected-1959 deletion completed in 6.075346066s

• [SLOW TEST:8.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:04:24.230: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:04:28.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-562" for this suite.
May 14 10:04:34.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:04:34.448: INFO: namespace kubelet-test-562 deletion completed in 6.07514489s

• [SLOW TEST:10.217 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:04:34.450: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5725
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5725.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5725.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5725.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5725.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5725.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5725.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 14 10:04:36.722: INFO: DNS probes using dns-5725/dns-test-acc74806-762f-11e9-8d5d-c6eb97da6be3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:04:36.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5725" for this suite.
May 14 10:04:42.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:04:42.836: INFO: namespace dns-5725 deletion completed in 6.103029554s

• [SLOW TEST:8.386 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:04:42.836: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7350
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 10:04:42.965: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 10:05:07.016: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.1.178:8080/dial?request=hostName&protocol=udp&host=10.100.1.177&port=8081&tries=1'] Namespace:pod-network-test-7350 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 10:05:07.016: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 10:05:07.134: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:05:07.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7350" for this suite.
May 14 10:05:29.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:05:29.214: INFO: namespace pod-network-test-7350 deletion completed in 22.076673718s

• [SLOW TEST:46.378 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:05:29.214: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
May 14 10:05:29.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-5091'
May 14 10:05:29.662: INFO: stderr: ""
May 14 10:05:29.662: INFO: stdout: "pod/pause created\n"
May 14 10:05:29.662: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 14 10:05:29.663: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5091" to be "running and ready"
May 14 10:05:29.666: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.125835ms
May 14 10:05:31.669: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005670654s
May 14 10:05:31.669: INFO: Pod "pause" satisfied condition "running and ready"
May 14 10:05:31.669: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
May 14 10:05:31.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 label pods pause testing-label=testing-label-value --namespace=kubectl-5091'
May 14 10:05:31.741: INFO: stderr: ""
May 14 10:05:31.741: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 14 10:05:31.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pod pause -L testing-label --namespace=kubectl-5091'
May 14 10:05:31.812: INFO: stderr: ""
May 14 10:05:31.812: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 14 10:05:31.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 label pods pause testing-label- --namespace=kubectl-5091'
May 14 10:05:31.883: INFO: stderr: ""
May 14 10:05:31.883: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 14 10:05:31.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pod pause -L testing-label --namespace=kubectl-5091'
May 14 10:05:31.947: INFO: stderr: ""
May 14 10:05:31.947: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
May 14 10:05:31.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-5091'
May 14 10:05:32.017: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:05:32.017: INFO: stdout: "pod \"pause\" force deleted\n"
May 14 10:05:32.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get rc,svc -l name=pause --no-headers --namespace=kubectl-5091'
May 14 10:05:32.088: INFO: stderr: "No resources found.\n"
May 14 10:05:32.088: INFO: stdout: ""
May 14 10:05:32.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 get pods -l name=pause --namespace=kubectl-5091 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 10:05:32.162: INFO: stderr: ""
May 14 10:05:32.162: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:05:32.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5091" for this suite.
May 14 10:05:38.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:05:38.238: INFO: namespace kubectl-5091 deletion completed in 6.073483961s

• [SLOW TEST:9.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:05:38.238: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-d2ccb10f-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:05:38.375: INFO: Waiting up to 5m0s for pod "pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3" in namespace "secrets-6808" to be "success or failure"
May 14 10:05:38.379: INFO: Pod "pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.460755ms
May 14 10:05:40.381: INFO: Pod "pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006090418s
STEP: Saw pod success
May 14 10:05:40.381: INFO: Pod "pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:05:40.383: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 10:05:40.406: INFO: Waiting for pod pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:05:40.408: INFO: Pod pod-secrets-d2cd13d0-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:05:40.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6808" for this suite.
May 14 10:05:46.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:05:46.484: INFO: namespace secrets-6808 deletion completed in 6.074306853s

• [SLOW TEST:8.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:05:46.485: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May 14 10:05:46.620: INFO: Waiting up to 5m0s for pod "downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-5226" to be "success or failure"
May 14 10:05:46.626: INFO: Pod "downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.893325ms
May 14 10:05:48.629: INFO: Pod "downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008813373s
STEP: Saw pod success
May 14 10:05:48.629: INFO: Pod "downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:05:48.630: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3 container dapi-container: <nil>
STEP: delete the pod
May 14 10:05:48.644: INFO: Waiting for pod downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:05:48.646: INFO: Pod downward-api-d7b6e79b-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:05:48.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5226" for this suite.
May 14 10:05:54.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:05:54.725: INFO: namespace downward-api-5226 deletion completed in 6.076902416s

• [SLOW TEST:8.241 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:05:54.726: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-dca26d18-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:05:54.880: INFO: Waiting up to 5m0s for pod "pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3" in namespace "configmap-9561" to be "success or failure"
May 14 10:05:54.890: INFO: Pod "pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.26496ms
May 14 10:05:56.892: INFO: Pod "pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012800804s
STEP: Saw pod success
May 14 10:05:56.893: INFO: Pod "pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:05:56.894: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:05:56.906: INFO: Waiting for pod pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:05:56.908: INFO: Pod pod-configmaps-dca2dbec-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:05:56.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9561" for this suite.
May 14 10:06:02.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:06:02.983: INFO: namespace configmap-9561 deletion completed in 6.073368537s

• [SLOW TEST:8.257 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:06:02.984: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7521.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7521.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7521.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7521.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 201.4.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.4.201_udp@PTR;check="$$(dig +tcp +noall +answer +search 201.4.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.4.201_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7521.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7521.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7521.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7521.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7521.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7521.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 201.4.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.4.201_udp@PTR;check="$$(dig +tcp +noall +answer +search 201.4.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.4.201_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 14 10:06:05.162: INFO: Unable to read wheezy_udp@dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.164: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.166: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.169: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.182: INFO: Unable to read jessie_udp@dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.185: INFO: Unable to read jessie_tcp@dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.188: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.190: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local from pod dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3: the server could not find the requested resource (get pods dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3)
May 14 10:06:05.212: INFO: Lookups using dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3 failed for: [wheezy_udp@dns-test-service.dns-7521.svc.cluster.local wheezy_tcp@dns-test-service.dns-7521.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local jessie_udp@dns-test-service.dns-7521.svc.cluster.local jessie_tcp@dns-test-service.dns-7521.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7521.svc.cluster.local]

May 14 10:06:10.255: INFO: DNS probes using dns-7521/dns-test-e18f0a70-762f-11e9-8d5d-c6eb97da6be3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:06:10.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7521" for this suite.
May 14 10:06:16.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:06:16.401: INFO: namespace dns-7521 deletion completed in 6.076110294s

• [SLOW TEST:13.417 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:06:16.401: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 14 10:06:16.540: INFO: Waiting up to 5m0s for pod "pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-3948" to be "success or failure"
May 14 10:06:16.543: INFO: Pod "pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.483721ms
May 14 10:06:18.547: INFO: Pod "pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007795898s
STEP: Saw pod success
May 14 10:06:18.547: INFO: Pod "pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:06:18.553: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 10:06:18.588: INFO: Waiting for pod pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:06:18.590: INFO: Pod pod-e98c5377-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:06:18.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3948" for this suite.
May 14 10:06:24.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:06:24.673: INFO: namespace emptydir-3948 deletion completed in 6.08056243s

• [SLOW TEST:8.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:06:24.674: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9915
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-ee7a6220-762f-11e9-8d5d-c6eb97da6be3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ee7a6220-762f-11e9-8d5d-c6eb97da6be3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:06:28.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9915" for this suite.
May 14 10:06:50.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:06:50.921: INFO: namespace configmap-9915 deletion completed in 22.079894088s

• [SLOW TEST:26.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:06:50.922: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 10:06:51.057: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-1312" to be "success or failure"
May 14 10:06:51.061: INFO: Pod "downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.976359ms
May 14 10:06:53.064: INFO: Pod "downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007049556s
STEP: Saw pod success
May 14 10:06:53.064: INFO: Pod "downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:06:53.066: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 10:06:53.079: INFO: Waiting for pod downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:06:53.081: INFO: Pod downwardapi-volume-fe1f7cb4-762f-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:06:53.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1312" for this suite.
May 14 10:06:59.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:06:59.159: INFO: namespace downward-api-1312 deletion completed in 6.07627401s

• [SLOW TEST:8.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:06:59.160: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:06:59.288: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:07:01.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9511" for this suite.
May 14 10:07:39.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:07:39.478: INFO: namespace pods-9511 deletion completed in 38.072337646s

• [SLOW TEST:40.318 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:07:39.478: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8840
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 14 10:07:39.612: INFO: Waiting up to 5m0s for pod "pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-8840" to be "success or failure"
May 14 10:07:39.615: INFO: Pod "pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.53969ms
May 14 10:07:41.617: INFO: Pod "pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005004212s
STEP: Saw pod success
May 14 10:07:41.617: INFO: Pod "pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:07:41.619: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 10:07:41.632: INFO: Waiting for pod pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:07:41.634: INFO: Pod pod-1b10595f-7630-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:07:41.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8840" for this suite.
May 14 10:07:47.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:07:47.709: INFO: namespace emptydir-8840 deletion completed in 6.072887231s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:07:47.710: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:07:50.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4606" for this suite.
May 14 10:08:12.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:08:12.937: INFO: namespace replication-controller-4606 deletion completed in 22.075370167s

• [SLOW TEST:25.227 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:08:12.938: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3472
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-2f20f5aa-7630-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:08:13.278: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3" in namespace "configmap-3472" to be "success or failure"
May 14 10:08:13.280: INFO: Pod "pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.866927ms
May 14 10:08:15.282: INFO: Pod "pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003935012s
STEP: Saw pod success
May 14 10:08:15.282: INFO: Pod "pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:08:15.284: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:08:15.298: INFO: Waiting for pod pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:08:15.301: INFO: Pod pod-configmaps-2f2179c4-7630-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:08:15.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3472" for this suite.
May 14 10:08:21.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:08:21.376: INFO: namespace configmap-3472 deletion completed in 6.072969847s

• [SLOW TEST:8.438 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:08:21.377: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3572
I0514 10:08:21.557547      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3572, replica count: 1
I0514 10:08:22.608036      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 10:08:23.608290      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 10:08:24.608604      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 14 10:08:24.720: INFO: Created: latency-svc-7q9j6
May 14 10:08:24.721: INFO: Got endpoints: latency-svc-7q9j6 [12.687775ms]
May 14 10:08:24.748: INFO: Created: latency-svc-l2vbm
May 14 10:08:24.773: INFO: Got endpoints: latency-svc-l2vbm [51.644515ms]
May 14 10:08:24.786: INFO: Created: latency-svc-x289g
May 14 10:08:24.786: INFO: Got endpoints: latency-svc-x289g [63.127275ms]
May 14 10:08:24.790: INFO: Created: latency-svc-llkrz
May 14 10:08:24.792: INFO: Got endpoints: latency-svc-llkrz [68.34645ms]
May 14 10:08:24.797: INFO: Created: latency-svc-nh4x6
May 14 10:08:24.803: INFO: Got endpoints: latency-svc-nh4x6 [77.390949ms]
May 14 10:08:24.819: INFO: Created: latency-svc-pbb9k
May 14 10:08:24.819: INFO: Created: latency-svc-rkdq5
May 14 10:08:24.827: INFO: Got endpoints: latency-svc-pbb9k [99.29315ms]
May 14 10:08:24.831: INFO: Got endpoints: latency-svc-rkdq5 [101.597996ms]
May 14 10:08:24.836: INFO: Created: latency-svc-5xrzs
May 14 10:08:24.844: INFO: Created: latency-svc-pflhb
May 14 10:08:24.845: INFO: Got endpoints: latency-svc-5xrzs [114.314491ms]
May 14 10:08:24.847: INFO: Got endpoints: latency-svc-pflhb [113.955987ms]
May 14 10:08:24.858: INFO: Created: latency-svc-dzxjb
May 14 10:08:24.865: INFO: Got endpoints: latency-svc-dzxjb [130.995885ms]
May 14 10:08:24.866: INFO: Created: latency-svc-dfpm4
May 14 10:08:24.876: INFO: Got endpoints: latency-svc-dfpm4 [141.227446ms]
May 14 10:08:24.881: INFO: Created: latency-svc-pd5hp
May 14 10:08:24.883: INFO: Got endpoints: latency-svc-pd5hp [143.33246ms]
May 14 10:08:24.889: INFO: Created: latency-svc-fftpm
May 14 10:08:24.894: INFO: Got endpoints: latency-svc-fftpm [151.905557ms]
May 14 10:08:24.899: INFO: Created: latency-svc-b2p8b
May 14 10:08:24.914: INFO: Created: latency-svc-b527h
May 14 10:08:24.914: INFO: Got endpoints: latency-svc-b2p8b [169.260544ms]
May 14 10:08:24.920: INFO: Got endpoints: latency-svc-b527h [173.282843ms]
May 14 10:08:24.922: INFO: Created: latency-svc-bhk9m
May 14 10:08:24.926: INFO: Got endpoints: latency-svc-bhk9m [177.322718ms]
May 14 10:08:24.930: INFO: Created: latency-svc-22g7d
May 14 10:08:24.937: INFO: Created: latency-svc-bvz85
May 14 10:08:24.941: INFO: Got endpoints: latency-svc-22g7d [167.739867ms]
May 14 10:08:24.943: INFO: Got endpoints: latency-svc-bvz85 [157.338992ms]
May 14 10:08:24.947: INFO: Created: latency-svc-n2zq5
May 14 10:08:24.955: INFO: Got endpoints: latency-svc-n2zq5 [162.970998ms]
May 14 10:08:24.965: INFO: Created: latency-svc-f4dwn
May 14 10:08:24.965: INFO: Got endpoints: latency-svc-f4dwn [162.193838ms]
May 14 10:08:24.972: INFO: Created: latency-svc-7ntfm
May 14 10:08:24.974: INFO: Got endpoints: latency-svc-7ntfm [143.641236ms]
May 14 10:08:24.981: INFO: Created: latency-svc-sgw6n
May 14 10:08:24.997: INFO: Got endpoints: latency-svc-sgw6n [169.261689ms]
May 14 10:08:24.997: INFO: Created: latency-svc-lpl7g
May 14 10:08:24.997: INFO: Got endpoints: latency-svc-lpl7g [152.136969ms]
May 14 10:08:25.019: INFO: Created: latency-svc-r5wns
May 14 10:08:25.022: INFO: Got endpoints: latency-svc-r5wns [175.269763ms]
May 14 10:08:25.034: INFO: Created: latency-svc-slmks
May 14 10:08:25.044: INFO: Created: latency-svc-k6tx4
May 14 10:08:25.044: INFO: Got endpoints: latency-svc-slmks [179.112735ms]
May 14 10:08:25.048: INFO: Got endpoints: latency-svc-k6tx4 [168.736065ms]
May 14 10:08:25.055: INFO: Created: latency-svc-4hjqw
May 14 10:08:25.058: INFO: Got endpoints: latency-svc-4hjqw [174.625337ms]
May 14 10:08:25.064: INFO: Created: latency-svc-7mvqp
May 14 10:08:25.070: INFO: Got endpoints: latency-svc-7mvqp [174.428895ms]
May 14 10:08:25.077: INFO: Created: latency-svc-8fldq
May 14 10:08:25.086: INFO: Created: latency-svc-bbm46
May 14 10:08:25.086: INFO: Got endpoints: latency-svc-8fldq [172.556202ms]
May 14 10:08:25.094: INFO: Got endpoints: latency-svc-bbm46 [174.325073ms]
May 14 10:08:25.107: INFO: Created: latency-svc-78z9s
May 14 10:08:25.112: INFO: Got endpoints: latency-svc-78z9s [185.94809ms]
May 14 10:08:25.121: INFO: Created: latency-svc-mvz5w
May 14 10:08:25.121: INFO: Got endpoints: latency-svc-mvz5w [180.199844ms]
May 14 10:08:25.137: INFO: Created: latency-svc-sdkgt
May 14 10:08:25.144: INFO: Created: latency-svc-442zg
May 14 10:08:25.152: INFO: Got endpoints: latency-svc-sdkgt [208.838641ms]
May 14 10:08:25.156: INFO: Got endpoints: latency-svc-442zg [200.022844ms]
May 14 10:08:25.159: INFO: Created: latency-svc-f2gn5
May 14 10:08:25.166: INFO: Got endpoints: latency-svc-f2gn5 [200.764857ms]
May 14 10:08:25.168: INFO: Created: latency-svc-tmrrr
May 14 10:08:25.173: INFO: Created: latency-svc-x6kn6
May 14 10:08:25.176: INFO: Got endpoints: latency-svc-tmrrr [201.91823ms]
May 14 10:08:25.179: INFO: Got endpoints: latency-svc-x6kn6 [182.152413ms]
May 14 10:08:25.189: INFO: Created: latency-svc-spdgt
May 14 10:08:25.194: INFO: Got endpoints: latency-svc-spdgt [197.753798ms]
May 14 10:08:25.200: INFO: Created: latency-svc-wmxv9
May 14 10:08:25.206: INFO: Created: latency-svc-2dnwv
May 14 10:08:25.206: INFO: Got endpoints: latency-svc-wmxv9 [183.372896ms]
May 14 10:08:25.211: INFO: Created: latency-svc-dspp7
May 14 10:08:25.220: INFO: Created: latency-svc-6s5bw
May 14 10:08:25.224: INFO: Created: latency-svc-d8ktg
May 14 10:08:25.224: INFO: Got endpoints: latency-svc-2dnwv [176.573337ms]
May 14 10:08:25.230: INFO: Created: latency-svc-5dzhl
May 14 10:08:25.236: INFO: Created: latency-svc-jl8hv
May 14 10:08:25.239: INFO: Created: latency-svc-jzpmx
May 14 10:08:25.244: INFO: Created: latency-svc-lqr6k
May 14 10:08:25.250: INFO: Created: latency-svc-7h586
May 14 10:08:25.256: INFO: Created: latency-svc-bskkf
May 14 10:08:25.262: INFO: Created: latency-svc-tsr4b
May 14 10:08:25.270: INFO: Got endpoints: latency-svc-dspp7 [225.427471ms]
May 14 10:08:25.274: INFO: Created: latency-svc-67sxd
May 14 10:08:25.275: INFO: Created: latency-svc-4fqm7
May 14 10:08:25.281: INFO: Created: latency-svc-6wt29
May 14 10:08:25.286: INFO: Created: latency-svc-ccmc9
May 14 10:08:25.296: INFO: Created: latency-svc-d9ftv
May 14 10:08:25.298: INFO: Created: latency-svc-f92w6
May 14 10:08:25.317: INFO: Got endpoints: latency-svc-6s5bw [259.246174ms]
May 14 10:08:25.325: INFO: Created: latency-svc-tcpt6
May 14 10:08:25.368: INFO: Got endpoints: latency-svc-d8ktg [297.50435ms]
May 14 10:08:25.376: INFO: Created: latency-svc-fksmb
May 14 10:08:25.418: INFO: Got endpoints: latency-svc-5dzhl [331.06133ms]
May 14 10:08:25.425: INFO: Created: latency-svc-f58s5
May 14 10:08:25.468: INFO: Got endpoints: latency-svc-jl8hv [373.997356ms]
May 14 10:08:25.474: INFO: Created: latency-svc-bgk8r
May 14 10:08:25.517: INFO: Got endpoints: latency-svc-jzpmx [404.930099ms]
May 14 10:08:25.523: INFO: Created: latency-svc-9ccbx
May 14 10:08:25.567: INFO: Got endpoints: latency-svc-lqr6k [446.004132ms]
May 14 10:08:25.576: INFO: Created: latency-svc-rzmt7
May 14 10:08:25.618: INFO: Got endpoints: latency-svc-7h586 [465.733276ms]
May 14 10:08:25.625: INFO: Created: latency-svc-q4xhs
May 14 10:08:25.668: INFO: Got endpoints: latency-svc-bskkf [511.884305ms]
May 14 10:08:25.676: INFO: Created: latency-svc-ktt95
May 14 10:08:25.721: INFO: Got endpoints: latency-svc-tsr4b [554.430652ms]
May 14 10:08:25.728: INFO: Created: latency-svc-t898m
May 14 10:08:25.768: INFO: Got endpoints: latency-svc-67sxd [591.257729ms]
May 14 10:08:25.776: INFO: Created: latency-svc-dwvrp
May 14 10:08:25.819: INFO: Got endpoints: latency-svc-4fqm7 [639.705658ms]
May 14 10:08:25.825: INFO: Created: latency-svc-9xcbg
May 14 10:08:25.869: INFO: Got endpoints: latency-svc-6wt29 [599.051354ms]
May 14 10:08:25.877: INFO: Created: latency-svc-jchw5
May 14 10:08:25.917: INFO: Got endpoints: latency-svc-ccmc9 [722.440091ms]
May 14 10:08:25.925: INFO: Created: latency-svc-bj9wv
May 14 10:08:25.968: INFO: Got endpoints: latency-svc-d9ftv [761.773976ms]
May 14 10:08:25.975: INFO: Created: latency-svc-c2mtk
May 14 10:08:26.018: INFO: Got endpoints: latency-svc-f92w6 [794.178675ms]
May 14 10:08:26.025: INFO: Created: latency-svc-nddjg
May 14 10:08:26.071: INFO: Got endpoints: latency-svc-tcpt6 [753.178594ms]
May 14 10:08:26.078: INFO: Created: latency-svc-rdkws
May 14 10:08:26.118: INFO: Got endpoints: latency-svc-fksmb [750.232684ms]
May 14 10:08:26.128: INFO: Created: latency-svc-vjfs2
May 14 10:08:26.169: INFO: Got endpoints: latency-svc-f58s5 [750.93126ms]
May 14 10:08:26.175: INFO: Created: latency-svc-b22mm
May 14 10:08:26.218: INFO: Got endpoints: latency-svc-bgk8r [750.464687ms]
May 14 10:08:26.230: INFO: Created: latency-svc-w64nn
May 14 10:08:26.275: INFO: Got endpoints: latency-svc-9ccbx [757.849505ms]
May 14 10:08:26.283: INFO: Created: latency-svc-xkfmp
May 14 10:08:26.324: INFO: Got endpoints: latency-svc-rzmt7 [757.446715ms]
May 14 10:08:26.336: INFO: Created: latency-svc-fwrxn
May 14 10:08:26.391: INFO: Got endpoints: latency-svc-q4xhs [771.991564ms]
May 14 10:08:26.410: INFO: Created: latency-svc-fpwmt
May 14 10:08:26.421: INFO: Got endpoints: latency-svc-ktt95 [752.203287ms]
May 14 10:08:26.433: INFO: Created: latency-svc-nwsm4
May 14 10:08:26.470: INFO: Got endpoints: latency-svc-t898m [749.185471ms]
May 14 10:08:26.485: INFO: Created: latency-svc-q2jdj
May 14 10:08:26.521: INFO: Got endpoints: latency-svc-dwvrp [753.044923ms]
May 14 10:08:26.534: INFO: Created: latency-svc-jnpqw
May 14 10:08:26.575: INFO: Got endpoints: latency-svc-9xcbg [756.404567ms]
May 14 10:08:26.584: INFO: Created: latency-svc-xvqxs
May 14 10:08:26.619: INFO: Got endpoints: latency-svc-jchw5 [749.653319ms]
May 14 10:08:26.633: INFO: Created: latency-svc-2cpwc
May 14 10:08:26.668: INFO: Got endpoints: latency-svc-bj9wv [751.172463ms]
May 14 10:08:26.679: INFO: Created: latency-svc-6f2pq
May 14 10:08:26.724: INFO: Got endpoints: latency-svc-c2mtk [756.154603ms]
May 14 10:08:26.736: INFO: Created: latency-svc-9x8gg
May 14 10:08:26.769: INFO: Got endpoints: latency-svc-nddjg [750.525761ms]
May 14 10:08:26.777: INFO: Created: latency-svc-db5sj
May 14 10:08:26.818: INFO: Got endpoints: latency-svc-rdkws [747.120995ms]
May 14 10:08:26.827: INFO: Created: latency-svc-vf4rp
May 14 10:08:26.869: INFO: Got endpoints: latency-svc-vjfs2 [750.590125ms]
May 14 10:08:26.878: INFO: Created: latency-svc-vkk8j
May 14 10:08:26.918: INFO: Got endpoints: latency-svc-b22mm [749.15931ms]
May 14 10:08:26.926: INFO: Created: latency-svc-zfb26
May 14 10:08:26.968: INFO: Got endpoints: latency-svc-w64nn [749.643403ms]
May 14 10:08:26.977: INFO: Created: latency-svc-85fsf
May 14 10:08:27.023: INFO: Got endpoints: latency-svc-xkfmp [747.420329ms]
May 14 10:08:27.031: INFO: Created: latency-svc-cjx6k
May 14 10:08:27.068: INFO: Got endpoints: latency-svc-fwrxn [743.741892ms]
May 14 10:08:27.077: INFO: Created: latency-svc-7l55m
May 14 10:08:27.120: INFO: Got endpoints: latency-svc-fpwmt [728.950021ms]
May 14 10:08:27.134: INFO: Created: latency-svc-fjrrw
May 14 10:08:27.173: INFO: Got endpoints: latency-svc-nwsm4 [752.430498ms]
May 14 10:08:27.188: INFO: Created: latency-svc-jcrs5
May 14 10:08:27.223: INFO: Got endpoints: latency-svc-q2jdj [753.37864ms]
May 14 10:08:27.237: INFO: Created: latency-svc-xn2gs
May 14 10:08:27.271: INFO: Got endpoints: latency-svc-jnpqw [750.139167ms]
May 14 10:08:27.279: INFO: Created: latency-svc-2w54j
May 14 10:08:27.325: INFO: Got endpoints: latency-svc-xvqxs [749.913238ms]
May 14 10:08:27.348: INFO: Created: latency-svc-7vrmj
May 14 10:08:27.371: INFO: Got endpoints: latency-svc-2cpwc [752.063886ms]
May 14 10:08:27.379: INFO: Created: latency-svc-fbvkp
May 14 10:08:27.421: INFO: Got endpoints: latency-svc-6f2pq [752.686745ms]
May 14 10:08:27.436: INFO: Created: latency-svc-psvxf
May 14 10:08:27.473: INFO: Got endpoints: latency-svc-9x8gg [748.709598ms]
May 14 10:08:27.485: INFO: Created: latency-svc-v5j2g
May 14 10:08:27.525: INFO: Got endpoints: latency-svc-db5sj [755.741407ms]
May 14 10:08:27.542: INFO: Created: latency-svc-kck48
May 14 10:08:27.572: INFO: Got endpoints: latency-svc-vf4rp [753.971089ms]
May 14 10:08:27.590: INFO: Created: latency-svc-f8jdb
May 14 10:08:27.621: INFO: Got endpoints: latency-svc-vkk8j [751.548298ms]
May 14 10:08:27.631: INFO: Created: latency-svc-x6zt6
May 14 10:08:27.671: INFO: Got endpoints: latency-svc-zfb26 [752.827442ms]
May 14 10:08:27.684: INFO: Created: latency-svc-svbkx
May 14 10:08:27.721: INFO: Got endpoints: latency-svc-85fsf [751.892746ms]
May 14 10:08:27.733: INFO: Created: latency-svc-lcvwn
May 14 10:08:27.770: INFO: Got endpoints: latency-svc-cjx6k [747.327201ms]
May 14 10:08:27.781: INFO: Created: latency-svc-4ph4v
May 14 10:08:27.818: INFO: Got endpoints: latency-svc-7l55m [749.595587ms]
May 14 10:08:27.831: INFO: Created: latency-svc-7n9bx
May 14 10:08:27.873: INFO: Got endpoints: latency-svc-fjrrw [752.280304ms]
May 14 10:08:27.885: INFO: Created: latency-svc-m96r6
May 14 10:08:27.918: INFO: Got endpoints: latency-svc-jcrs5 [745.199822ms]
May 14 10:08:27.931: INFO: Created: latency-svc-t2txf
May 14 10:08:27.970: INFO: Got endpoints: latency-svc-xn2gs [746.790967ms]
May 14 10:08:27.980: INFO: Created: latency-svc-mkjvj
May 14 10:08:28.020: INFO: Got endpoints: latency-svc-2w54j [748.927436ms]
May 14 10:08:28.031: INFO: Created: latency-svc-9dvjz
May 14 10:08:28.070: INFO: Got endpoints: latency-svc-7vrmj [744.700744ms]
May 14 10:08:28.083: INFO: Created: latency-svc-72bf8
May 14 10:08:28.121: INFO: Got endpoints: latency-svc-fbvkp [750.107975ms]
May 14 10:08:28.138: INFO: Created: latency-svc-njt89
May 14 10:08:28.171: INFO: Got endpoints: latency-svc-psvxf [749.814692ms]
May 14 10:08:28.181: INFO: Created: latency-svc-pg6t9
May 14 10:08:28.219: INFO: Got endpoints: latency-svc-v5j2g [746.156607ms]
May 14 10:08:28.230: INFO: Created: latency-svc-54plb
May 14 10:08:28.269: INFO: Got endpoints: latency-svc-kck48 [744.513743ms]
May 14 10:08:28.285: INFO: Created: latency-svc-cv8sh
May 14 10:08:28.319: INFO: Got endpoints: latency-svc-f8jdb [746.612618ms]
May 14 10:08:28.333: INFO: Created: latency-svc-psgll
May 14 10:08:28.369: INFO: Got endpoints: latency-svc-x6zt6 [748.578369ms]
May 14 10:08:28.392: INFO: Created: latency-svc-hjnml
May 14 10:08:28.422: INFO: Got endpoints: latency-svc-svbkx [751.29228ms]
May 14 10:08:28.435: INFO: Created: latency-svc-fkwxg
May 14 10:08:28.472: INFO: Got endpoints: latency-svc-lcvwn [751.087833ms]
May 14 10:08:28.486: INFO: Created: latency-svc-wtcdl
May 14 10:08:28.521: INFO: Got endpoints: latency-svc-4ph4v [750.080096ms]
May 14 10:08:28.529: INFO: Created: latency-svc-5xczp
May 14 10:08:28.569: INFO: Got endpoints: latency-svc-7n9bx [750.654312ms]
May 14 10:08:28.579: INFO: Created: latency-svc-pvh5t
May 14 10:08:28.620: INFO: Got endpoints: latency-svc-m96r6 [747.086616ms]
May 14 10:08:28.632: INFO: Created: latency-svc-8q8rw
May 14 10:08:28.670: INFO: Got endpoints: latency-svc-t2txf [751.801571ms]
May 14 10:08:28.682: INFO: Created: latency-svc-b7ccq
May 14 10:08:28.719: INFO: Got endpoints: latency-svc-mkjvj [748.557312ms]
May 14 10:08:28.729: INFO: Created: latency-svc-x5jcl
May 14 10:08:28.781: INFO: Got endpoints: latency-svc-9dvjz [761.270909ms]
May 14 10:08:28.792: INFO: Created: latency-svc-r4f46
May 14 10:08:28.820: INFO: Got endpoints: latency-svc-72bf8 [749.710146ms]
May 14 10:08:28.832: INFO: Created: latency-svc-8djmx
May 14 10:08:28.870: INFO: Got endpoints: latency-svc-njt89 [748.931561ms]
May 14 10:08:28.878: INFO: Created: latency-svc-28rqn
May 14 10:08:28.919: INFO: Got endpoints: latency-svc-pg6t9 [748.157388ms]
May 14 10:08:28.933: INFO: Created: latency-svc-s4vfc
May 14 10:08:28.973: INFO: Got endpoints: latency-svc-54plb [753.326913ms]
May 14 10:08:28.990: INFO: Created: latency-svc-w56h9
May 14 10:08:29.019: INFO: Got endpoints: latency-svc-cv8sh [749.750394ms]
May 14 10:08:29.033: INFO: Created: latency-svc-xr625
May 14 10:08:29.071: INFO: Got endpoints: latency-svc-psgll [751.569948ms]
May 14 10:08:29.084: INFO: Created: latency-svc-rq4bt
May 14 10:08:29.120: INFO: Got endpoints: latency-svc-hjnml [750.783408ms]
May 14 10:08:29.128: INFO: Created: latency-svc-txjjt
May 14 10:08:29.169: INFO: Got endpoints: latency-svc-fkwxg [746.808839ms]
May 14 10:08:29.178: INFO: Created: latency-svc-lrbrg
May 14 10:08:29.219: INFO: Got endpoints: latency-svc-wtcdl [747.0603ms]
May 14 10:08:29.233: INFO: Created: latency-svc-xn2px
May 14 10:08:29.271: INFO: Got endpoints: latency-svc-5xczp [750.119233ms]
May 14 10:08:29.289: INFO: Created: latency-svc-wm2sz
May 14 10:08:29.320: INFO: Got endpoints: latency-svc-pvh5t [750.458912ms]
May 14 10:08:29.337: INFO: Created: latency-svc-pdcgj
May 14 10:08:29.369: INFO: Got endpoints: latency-svc-8q8rw [748.669406ms]
May 14 10:08:29.389: INFO: Created: latency-svc-xrhhd
May 14 10:08:29.419: INFO: Got endpoints: latency-svc-b7ccq [746.92323ms]
May 14 10:08:29.433: INFO: Created: latency-svc-lvxdc
May 14 10:08:29.473: INFO: Got endpoints: latency-svc-x5jcl [753.350205ms]
May 14 10:08:29.487: INFO: Created: latency-svc-fddrv
May 14 10:08:29.523: INFO: Got endpoints: latency-svc-r4f46 [741.226147ms]
May 14 10:08:29.534: INFO: Created: latency-svc-42ktf
May 14 10:08:29.569: INFO: Got endpoints: latency-svc-8djmx [748.495343ms]
May 14 10:08:29.578: INFO: Created: latency-svc-qvwcb
May 14 10:08:29.623: INFO: Got endpoints: latency-svc-28rqn [752.882784ms]
May 14 10:08:29.632: INFO: Created: latency-svc-j2k6q
May 14 10:08:29.670: INFO: Got endpoints: latency-svc-s4vfc [750.542131ms]
May 14 10:08:29.678: INFO: Created: latency-svc-6g6dl
May 14 10:08:29.719: INFO: Got endpoints: latency-svc-w56h9 [745.489101ms]
May 14 10:08:29.730: INFO: Created: latency-svc-j2g6p
May 14 10:08:29.770: INFO: Got endpoints: latency-svc-xr625 [750.511808ms]
May 14 10:08:29.780: INFO: Created: latency-svc-mptws
May 14 10:08:29.819: INFO: Got endpoints: latency-svc-rq4bt [747.492716ms]
May 14 10:08:29.827: INFO: Created: latency-svc-rr7cg
May 14 10:08:29.870: INFO: Got endpoints: latency-svc-txjjt [749.967971ms]
May 14 10:08:29.878: INFO: Created: latency-svc-qpwzt
May 14 10:08:29.919: INFO: Got endpoints: latency-svc-lrbrg [749.904819ms]
May 14 10:08:29.931: INFO: Created: latency-svc-fv4mg
May 14 10:08:29.969: INFO: Got endpoints: latency-svc-xn2px [750.240197ms]
May 14 10:08:29.979: INFO: Created: latency-svc-2hfr9
May 14 10:08:30.020: INFO: Got endpoints: latency-svc-wm2sz [748.805263ms]
May 14 10:08:30.028: INFO: Created: latency-svc-tzm9g
May 14 10:08:30.069: INFO: Got endpoints: latency-svc-pdcgj [749.281312ms]
May 14 10:08:30.078: INFO: Created: latency-svc-8zkt5
May 14 10:08:30.117: INFO: Got endpoints: latency-svc-xrhhd [748.135416ms]
May 14 10:08:30.128: INFO: Created: latency-svc-tzx8w
May 14 10:08:30.167: INFO: Got endpoints: latency-svc-lvxdc [748.237614ms]
May 14 10:08:30.178: INFO: Created: latency-svc-rkhd5
May 14 10:08:30.221: INFO: Got endpoints: latency-svc-fddrv [748.431648ms]
May 14 10:08:30.231: INFO: Created: latency-svc-7hdsb
May 14 10:08:30.270: INFO: Got endpoints: latency-svc-42ktf [747.514102ms]
May 14 10:08:30.280: INFO: Created: latency-svc-fslrg
May 14 10:08:30.320: INFO: Got endpoints: latency-svc-qvwcb [751.210741ms]
May 14 10:08:30.331: INFO: Created: latency-svc-khkxv
May 14 10:08:30.370: INFO: Got endpoints: latency-svc-j2k6q [747.095174ms]
May 14 10:08:30.381: INFO: Created: latency-svc-bq9vn
May 14 10:08:30.420: INFO: Got endpoints: latency-svc-6g6dl [749.773785ms]
May 14 10:08:30.429: INFO: Created: latency-svc-mjfl4
May 14 10:08:30.468: INFO: Got endpoints: latency-svc-j2g6p [749.290204ms]
May 14 10:08:30.479: INFO: Created: latency-svc-q4zlg
May 14 10:08:30.519: INFO: Got endpoints: latency-svc-mptws [749.594496ms]
May 14 10:08:30.531: INFO: Created: latency-svc-d8pqg
May 14 10:08:30.568: INFO: Got endpoints: latency-svc-rr7cg [748.747904ms]
May 14 10:08:30.579: INFO: Created: latency-svc-t8jzw
May 14 10:08:30.621: INFO: Got endpoints: latency-svc-qpwzt [750.14014ms]
May 14 10:08:30.630: INFO: Created: latency-svc-rpg9f
May 14 10:08:30.669: INFO: Got endpoints: latency-svc-fv4mg [749.423418ms]
May 14 10:08:30.681: INFO: Created: latency-svc-cdd9s
May 14 10:08:30.720: INFO: Got endpoints: latency-svc-2hfr9 [750.041976ms]
May 14 10:08:30.727: INFO: Created: latency-svc-zccgq
May 14 10:08:30.772: INFO: Got endpoints: latency-svc-tzm9g [752.344962ms]
May 14 10:08:30.791: INFO: Created: latency-svc-ds5s9
May 14 10:08:30.825: INFO: Got endpoints: latency-svc-8zkt5 [755.366753ms]
May 14 10:08:30.848: INFO: Created: latency-svc-7scfb
May 14 10:08:30.877: INFO: Got endpoints: latency-svc-tzx8w [759.900475ms]
May 14 10:08:30.892: INFO: Created: latency-svc-g4b6r
May 14 10:08:30.919: INFO: Got endpoints: latency-svc-rkhd5 [751.747563ms]
May 14 10:08:30.931: INFO: Created: latency-svc-tdt7p
May 14 10:08:30.968: INFO: Got endpoints: latency-svc-7hdsb [747.234455ms]
May 14 10:08:30.981: INFO: Created: latency-svc-5rl82
May 14 10:08:31.019: INFO: Got endpoints: latency-svc-fslrg [748.707401ms]
May 14 10:08:31.028: INFO: Created: latency-svc-v825h
May 14 10:08:31.069: INFO: Got endpoints: latency-svc-khkxv [749.150838ms]
May 14 10:08:31.083: INFO: Created: latency-svc-c58xf
May 14 10:08:31.119: INFO: Got endpoints: latency-svc-bq9vn [748.519615ms]
May 14 10:08:31.128: INFO: Created: latency-svc-lwhfz
May 14 10:08:31.169: INFO: Got endpoints: latency-svc-mjfl4 [749.520126ms]
May 14 10:08:31.180: INFO: Created: latency-svc-cclb7
May 14 10:08:31.218: INFO: Got endpoints: latency-svc-q4zlg [750.098942ms]
May 14 10:08:31.229: INFO: Created: latency-svc-cxvpd
May 14 10:08:31.269: INFO: Got endpoints: latency-svc-d8pqg [749.020172ms]
May 14 10:08:31.280: INFO: Created: latency-svc-ntrf7
May 14 10:08:31.322: INFO: Got endpoints: latency-svc-t8jzw [754.672274ms]
May 14 10:08:31.335: INFO: Created: latency-svc-nk6xt
May 14 10:08:31.369: INFO: Got endpoints: latency-svc-rpg9f [748.747353ms]
May 14 10:08:31.382: INFO: Created: latency-svc-rbrhq
May 14 10:08:31.419: INFO: Got endpoints: latency-svc-cdd9s [750.019895ms]
May 14 10:08:31.430: INFO: Created: latency-svc-s5s58
May 14 10:08:31.469: INFO: Got endpoints: latency-svc-zccgq [749.063421ms]
May 14 10:08:31.481: INFO: Created: latency-svc-xclq4
May 14 10:08:31.524: INFO: Got endpoints: latency-svc-ds5s9 [751.539073ms]
May 14 10:08:31.534: INFO: Created: latency-svc-qqvrk
May 14 10:08:31.572: INFO: Got endpoints: latency-svc-7scfb [746.842145ms]
May 14 10:08:31.589: INFO: Created: latency-svc-mhjrz
May 14 10:08:31.618: INFO: Got endpoints: latency-svc-g4b6r [740.742828ms]
May 14 10:08:31.632: INFO: Created: latency-svc-rwhgp
May 14 10:08:31.669: INFO: Got endpoints: latency-svc-tdt7p [750.021584ms]
May 14 10:08:31.682: INFO: Created: latency-svc-h7pww
May 14 10:08:31.721: INFO: Got endpoints: latency-svc-5rl82 [752.631377ms]
May 14 10:08:31.737: INFO: Created: latency-svc-zm2b5
May 14 10:08:31.769: INFO: Got endpoints: latency-svc-v825h [750.085228ms]
May 14 10:08:31.781: INFO: Created: latency-svc-zjbst
May 14 10:08:31.818: INFO: Got endpoints: latency-svc-c58xf [748.810322ms]
May 14 10:08:31.829: INFO: Created: latency-svc-rfbcz
May 14 10:08:31.869: INFO: Got endpoints: latency-svc-lwhfz [749.849522ms]
May 14 10:08:31.879: INFO: Created: latency-svc-25f2t
May 14 10:08:31.924: INFO: Got endpoints: latency-svc-cclb7 [754.593083ms]
May 14 10:08:31.933: INFO: Created: latency-svc-74k69
May 14 10:08:31.971: INFO: Got endpoints: latency-svc-cxvpd [753.120308ms]
May 14 10:08:31.985: INFO: Created: latency-svc-qg9pv
May 14 10:08:32.019: INFO: Got endpoints: latency-svc-ntrf7 [749.757576ms]
May 14 10:08:32.033: INFO: Created: latency-svc-ck6p7
May 14 10:08:32.068: INFO: Got endpoints: latency-svc-nk6xt [745.321838ms]
May 14 10:08:32.082: INFO: Created: latency-svc-7c57k
May 14 10:08:32.121: INFO: Got endpoints: latency-svc-rbrhq [751.15128ms]
May 14 10:08:32.131: INFO: Created: latency-svc-bgxl7
May 14 10:08:32.168: INFO: Got endpoints: latency-svc-s5s58 [749.490925ms]
May 14 10:08:32.179: INFO: Created: latency-svc-smfjq
May 14 10:08:32.220: INFO: Got endpoints: latency-svc-xclq4 [751.012713ms]
May 14 10:08:32.243: INFO: Created: latency-svc-nlvpb
May 14 10:08:32.270: INFO: Got endpoints: latency-svc-qqvrk [745.936735ms]
May 14 10:08:32.285: INFO: Created: latency-svc-6fdl9
May 14 10:08:32.322: INFO: Got endpoints: latency-svc-mhjrz [749.907564ms]
May 14 10:08:32.335: INFO: Created: latency-svc-tpths
May 14 10:08:32.370: INFO: Got endpoints: latency-svc-rwhgp [751.972904ms]
May 14 10:08:32.380: INFO: Created: latency-svc-fw28f
May 14 10:08:32.418: INFO: Got endpoints: latency-svc-h7pww [749.014989ms]
May 14 10:08:32.424: INFO: Created: latency-svc-46x4f
May 14 10:08:32.467: INFO: Got endpoints: latency-svc-zm2b5 [745.919345ms]
May 14 10:08:32.476: INFO: Created: latency-svc-k92cn
May 14 10:08:32.518: INFO: Got endpoints: latency-svc-zjbst [749.119156ms]
May 14 10:08:32.524: INFO: Created: latency-svc-j9x2x
May 14 10:08:32.567: INFO: Got endpoints: latency-svc-rfbcz [748.565557ms]
May 14 10:08:32.617: INFO: Got endpoints: latency-svc-25f2t [747.999084ms]
May 14 10:08:32.668: INFO: Got endpoints: latency-svc-74k69 [744.368895ms]
May 14 10:08:32.718: INFO: Got endpoints: latency-svc-qg9pv [747.028699ms]
May 14 10:08:32.768: INFO: Got endpoints: latency-svc-ck6p7 [748.99001ms]
May 14 10:08:32.820: INFO: Got endpoints: latency-svc-7c57k [752.417577ms]
May 14 10:08:32.868: INFO: Got endpoints: latency-svc-bgxl7 [746.945463ms]
May 14 10:08:32.918: INFO: Got endpoints: latency-svc-smfjq [749.293758ms]
May 14 10:08:32.968: INFO: Got endpoints: latency-svc-nlvpb [747.829169ms]
May 14 10:08:33.018: INFO: Got endpoints: latency-svc-6fdl9 [748.159214ms]
May 14 10:08:33.068: INFO: Got endpoints: latency-svc-tpths [746.485729ms]
May 14 10:08:33.118: INFO: Got endpoints: latency-svc-fw28f [747.246695ms]
May 14 10:08:33.168: INFO: Got endpoints: latency-svc-46x4f [750.116206ms]
May 14 10:08:33.218: INFO: Got endpoints: latency-svc-k92cn [750.711873ms]
May 14 10:08:33.269: INFO: Got endpoints: latency-svc-j9x2x [750.444979ms]
May 14 10:08:33.269: INFO: Latencies: [51.644515ms 63.127275ms 68.34645ms 77.390949ms 99.29315ms 101.597996ms 113.955987ms 114.314491ms 130.995885ms 141.227446ms 143.33246ms 143.641236ms 151.905557ms 152.136969ms 157.338992ms 162.193838ms 162.970998ms 167.739867ms 168.736065ms 169.260544ms 169.261689ms 172.556202ms 173.282843ms 174.325073ms 174.428895ms 174.625337ms 175.269763ms 176.573337ms 177.322718ms 179.112735ms 180.199844ms 182.152413ms 183.372896ms 185.94809ms 197.753798ms 200.022844ms 200.764857ms 201.91823ms 208.838641ms 225.427471ms 259.246174ms 297.50435ms 331.06133ms 373.997356ms 404.930099ms 446.004132ms 465.733276ms 511.884305ms 554.430652ms 591.257729ms 599.051354ms 639.705658ms 722.440091ms 728.950021ms 740.742828ms 741.226147ms 743.741892ms 744.368895ms 744.513743ms 744.700744ms 745.199822ms 745.321838ms 745.489101ms 745.919345ms 745.936735ms 746.156607ms 746.485729ms 746.612618ms 746.790967ms 746.808839ms 746.842145ms 746.92323ms 746.945463ms 747.028699ms 747.0603ms 747.086616ms 747.095174ms 747.120995ms 747.234455ms 747.246695ms 747.327201ms 747.420329ms 747.492716ms 747.514102ms 747.829169ms 747.999084ms 748.135416ms 748.157388ms 748.159214ms 748.237614ms 748.431648ms 748.495343ms 748.519615ms 748.557312ms 748.565557ms 748.578369ms 748.669406ms 748.707401ms 748.709598ms 748.747353ms 748.747904ms 748.805263ms 748.810322ms 748.927436ms 748.931561ms 748.99001ms 749.014989ms 749.020172ms 749.063421ms 749.119156ms 749.150838ms 749.15931ms 749.185471ms 749.281312ms 749.290204ms 749.293758ms 749.423418ms 749.490925ms 749.520126ms 749.594496ms 749.595587ms 749.643403ms 749.653319ms 749.710146ms 749.750394ms 749.757576ms 749.773785ms 749.814692ms 749.849522ms 749.904819ms 749.907564ms 749.913238ms 749.967971ms 750.019895ms 750.021584ms 750.041976ms 750.080096ms 750.085228ms 750.098942ms 750.107975ms 750.116206ms 750.119233ms 750.139167ms 750.14014ms 750.232684ms 750.240197ms 750.444979ms 750.458912ms 750.464687ms 750.511808ms 750.525761ms 750.542131ms 750.590125ms 750.654312ms 750.711873ms 750.783408ms 750.93126ms 751.012713ms 751.087833ms 751.15128ms 751.172463ms 751.210741ms 751.29228ms 751.539073ms 751.548298ms 751.569948ms 751.747563ms 751.801571ms 751.892746ms 751.972904ms 752.063886ms 752.203287ms 752.280304ms 752.344962ms 752.417577ms 752.430498ms 752.631377ms 752.686745ms 752.827442ms 752.882784ms 753.044923ms 753.120308ms 753.178594ms 753.326913ms 753.350205ms 753.37864ms 753.971089ms 754.593083ms 754.672274ms 755.366753ms 755.741407ms 756.154603ms 756.404567ms 757.446715ms 757.849505ms 759.900475ms 761.270909ms 761.773976ms 771.991564ms 794.178675ms]
May 14 10:08:33.269: INFO: 50 %ile: 748.747904ms
May 14 10:08:33.269: INFO: 90 %ile: 753.044923ms
May 14 10:08:33.269: INFO: 99 %ile: 771.991564ms
May 14 10:08:33.270: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:08:33.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3572" for this suite.
May 14 10:08:57.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:08:57.344: INFO: namespace svc-latency-3572 deletion completed in 24.072459548s

• [SLOW TEST:35.968 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:08:57.345: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4688
STEP: Creating secret with name secret-test-4979eb0e-7630-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:08:57.627: INFO: Waiting up to 5m0s for pod "pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3" in namespace "secrets-7052" to be "success or failure"
May 14 10:08:57.631: INFO: Pod "pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.99463ms
May 14 10:08:59.634: INFO: Pod "pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006687399s
STEP: Saw pod success
May 14 10:08:59.634: INFO: Pod "pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:08:59.636: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 10:08:59.647: INFO: Waiting for pod pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:08:59.650: INFO: Pod pod-secrets-49902452-7630-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:08:59.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7052" for this suite.
May 14 10:09:05.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:09:05.728: INFO: namespace secrets-7052 deletion completed in 6.075481733s
STEP: Destroying namespace "secret-namespace-4688" for this suite.
May 14 10:09:11.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:09:11.813: INFO: namespace secret-namespace-4688 deletion completed in 6.085030305s

• [SLOW TEST:14.468 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:09:11.813: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4484
May 14 10:09:13.954: INFO: Started pod liveness-http in namespace container-probe-4484
STEP: checking the pod's current state and verifying that restartCount is present
May 14 10:09:13.956: INFO: Initial restart count of pod liveness-http is 0
May 14 10:09:29.977: INFO: Restart count of pod container-probe-4484/liveness-http is now 1 (16.02150957s elapsed)
May 14 10:09:50.004: INFO: Restart count of pod container-probe-4484/liveness-http is now 2 (36.048394315s elapsed)
May 14 10:10:10.030: INFO: Restart count of pod container-probe-4484/liveness-http is now 3 (56.074430374s elapsed)
May 14 10:10:30.055: INFO: Restart count of pod container-probe-4484/liveness-http is now 4 (1m16.099522793s elapsed)
May 14 10:11:38.145: INFO: Restart count of pod container-probe-4484/liveness-http is now 5 (2m24.189147946s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:11:38.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4484" for this suite.
May 14 10:11:44.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:11:44.228: INFO: namespace container-probe-4484 deletion completed in 6.073815381s

• [SLOW TEST:152.415 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:11:44.229: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May 14 10:11:44.356: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:11:47.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8440" for this suite.
May 14 10:11:53.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:11:53.317: INFO: namespace init-container-8440 deletion completed in 6.073163182s

• [SLOW TEST:9.088 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:11:53.317: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
May 14 10:11:53.985: INFO: created pod pod-service-account-defaultsa
May 14 10:11:53.985: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 14 10:11:53.993: INFO: created pod pod-service-account-mountsa
May 14 10:11:53.993: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 14 10:11:53.999: INFO: created pod pod-service-account-nomountsa
May 14 10:11:53.999: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 14 10:11:54.008: INFO: created pod pod-service-account-defaultsa-mountspec
May 14 10:11:54.008: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 14 10:11:54.015: INFO: created pod pod-service-account-mountsa-mountspec
May 14 10:11:54.015: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 14 10:11:54.025: INFO: created pod pod-service-account-nomountsa-mountspec
May 14 10:11:54.026: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 14 10:11:54.032: INFO: created pod pod-service-account-defaultsa-nomountspec
May 14 10:11:54.032: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 14 10:11:54.037: INFO: created pod pod-service-account-mountsa-nomountspec
May 14 10:11:54.037: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 14 10:11:54.046: INFO: created pod pod-service-account-nomountsa-nomountspec
May 14 10:11:54.046: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:11:54.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1448" for this suite.
May 14 10:12:16.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:12:16.142: INFO: namespace svcaccounts-1448 deletion completed in 22.085732813s

• [SLOW TEST:22.826 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:12:16.142: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 14 10:12:16.274: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 14 10:12:23.311: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:12:23.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1178" for this suite.
May 14 10:12:29.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:12:29.389: INFO: namespace pods-1178 deletion completed in 6.073215412s

• [SLOW TEST:13.246 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:12:29.390: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-6f6t
STEP: Creating a pod to test atomic-volume-subpath
May 14 10:12:29.528: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6f6t" in namespace "subpath-9849" to be "success or failure"
May 14 10:12:29.532: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Pending", Reason="", readiness=false. Elapsed: 3.928737ms
May 14 10:12:31.534: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 2.006793297s
May 14 10:12:33.542: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 4.013953156s
May 14 10:12:35.544: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 6.016801461s
May 14 10:12:37.547: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 8.01961403s
May 14 10:12:39.549: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 10.021810587s
May 14 10:12:41.552: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 12.024520016s
May 14 10:12:43.555: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 14.026920134s
May 14 10:12:45.557: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 16.02971502s
May 14 10:12:47.560: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 18.032407725s
May 14 10:12:49.562: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Running", Reason="", readiness=true. Elapsed: 20.034720227s
May 14 10:12:51.565: INFO: Pod "pod-subpath-test-secret-6f6t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037336572s
STEP: Saw pod success
May 14 10:12:51.565: INFO: Pod "pod-subpath-test-secret-6f6t" satisfied condition "success or failure"
May 14 10:12:51.567: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-subpath-test-secret-6f6t container test-container-subpath-secret-6f6t: <nil>
STEP: delete the pod
May 14 10:12:51.580: INFO: Waiting for pod pod-subpath-test-secret-6f6t to disappear
May 14 10:12:51.582: INFO: Pod pod-subpath-test-secret-6f6t no longer exists
STEP: Deleting pod pod-subpath-test-secret-6f6t
May 14 10:12:51.582: INFO: Deleting pod "pod-subpath-test-secret-6f6t" in namespace "subpath-9849"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:12:51.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9849" for this suite.
May 14 10:12:57.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:12:57.661: INFO: namespace subpath-9849 deletion completed in 6.075077041s

• [SLOW TEST:28.272 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:12:57.662: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May 14 10:13:00.331: INFO: Successfully updated pod "labelsupdated8b747e7-7630-11e9-8d5d-c6eb97da6be3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:13:04.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3796" for this suite.
May 14 10:13:26.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:13:26.427: INFO: namespace projected-3796 deletion completed in 22.074188032s

• [SLOW TEST:28.765 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:13:26.427: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5970
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-e9dc717c-7630-11e9-8d5d-c6eb97da6be3
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:13:26.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5970" for this suite.
May 14 10:13:32.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:13:32.639: INFO: namespace configmap-5970 deletion completed in 6.079816744s

• [SLOW TEST:6.211 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:13:32.639: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7850
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-7850
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7850
May 14 10:13:32.786: INFO: Found 0 stateful pods, waiting for 1
May 14 10:13:42.789: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 14 10:13:42.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 10:13:42.971: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 10:13:42.971: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 10:13:42.971: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 10:13:42.973: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 14 10:13:52.975: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 10:13:52.975: INFO: Waiting for statefulset status.replicas updated to 0
May 14 10:13:52.986: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:13:52.986: INFO: ss-0  ip-10-2-82-233.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:13:52.986: INFO: 
May 14 10:13:52.986: INFO: StatefulSet ss has not reached scale 3, at 1
May 14 10:13:53.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996294749s
May 14 10:13:54.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993509282s
May 14 10:13:55.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989388709s
May 14 10:13:56.999: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986076851s
May 14 10:13:58.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983541784s
May 14 10:13:59.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980612632s
May 14 10:14:00.008: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977958002s
May 14 10:14:01.011: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975136135s
May 14 10:14:02.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.218984ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7850
May 14 10:14:03.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 10:14:03.178: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 14 10:14:03.178: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 10:14:03.178: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 10:14:03.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 10:14:03.346: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 14 10:14:03.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 10:14:03.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 10:14:03.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 10:14:03.517: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 14 10:14:03.517: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 10:14:03.517: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 10:14:03.520: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 14 10:14:13.523: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 10:14:13.523: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 10:14:13.523: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 14 10:14:13.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 10:14:13.706: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 10:14:13.706: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 10:14:13.706: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 10:14:13.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 10:14:13.875: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 10:14:13.875: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 10:14:13.875: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 10:14:13.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 exec --namespace=statefulset-7850 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 10:14:14.062: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 14 10:14:14.062: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 10:14:14.062: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 10:14:14.062: INFO: Waiting for statefulset status.replicas updated to 0
May 14 10:14:14.064: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 14 10:14:24.069: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 10:14:24.069: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 14 10:14:24.069: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 14 10:14:24.078: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:24.078: INFO: ss-0  ip-10-2-82-233.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:24.078: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:24.078: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:24.078: INFO: 
May 14 10:14:24.078: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:25.081: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:25.081: INFO: ss-0  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:25.081: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:25.081: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:25.081: INFO: 
May 14 10:14:25.081: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:26.085: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:26.085: INFO: ss-0  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:26.085: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:26.085: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:26.085: INFO: 
May 14 10:14:26.085: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:27.088: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:27.088: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:27.088: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:27.088: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:27.088: INFO: 
May 14 10:14:27.088: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:28.091: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:28.091: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:28.091: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:28.091: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:28.091: INFO: 
May 14 10:14:28.091: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:29.094: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:29.094: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:29.094: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:29.094: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:29.094: INFO: 
May 14 10:14:29.094: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:30.097: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:30.097: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:30.097: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:30.097: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:30.097: INFO: 
May 14 10:14:30.097: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:31.102: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:31.102: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:31.103: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:31.103: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:31.103: INFO: 
May 14 10:14:31.103: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:32.108: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
May 14 10:14:32.108: INFO: ss-0  ip-10-2-82-233.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:32 +0000 UTC  }]
May 14 10:14:32.108: INFO: ss-1  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:32.109: INFO: ss-2  ip-10-2-82-233.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:14:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:13:52 +0000 UTC  }]
May 14 10:14:32.109: INFO: 
May 14 10:14:32.109: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 10:14:33.111: INFO: Verifying statefulset ss doesn't scale past 0 for another 966.250026ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7850
May 14 10:14:34.125: INFO: Scaling statefulset ss to 0
May 14 10:14:34.143: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 14 10:14:34.146: INFO: Deleting all statefulset in ns statefulset-7850
May 14 10:14:34.148: INFO: Scaling statefulset ss to 0
May 14 10:14:34.154: INFO: Waiting for statefulset status.replicas updated to 0
May 14 10:14:34.156: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:14:34.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7850" for this suite.
May 14 10:14:40.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:14:40.252: INFO: namespace statefulset-7850 deletion completed in 6.083616278s

• [SLOW TEST:67.613 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:14:40.252: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 14 10:14:43.404: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:14:44.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9874" for this suite.
May 14 10:15:12.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:15:12.492: INFO: namespace replicaset-9874 deletion completed in 28.074383568s

• [SLOW TEST:32.239 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:15:12.492: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-291606e3-7631-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:15:12.637: INFO: Waiting up to 5m0s for pod "pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3" in namespace "secrets-7138" to be "success or failure"
May 14 10:15:12.640: INFO: Pod "pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.674407ms
May 14 10:15:14.643: INFO: Pod "pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006148746s
STEP: Saw pod success
May 14 10:15:14.643: INFO: Pod "pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:15:14.645: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3 container secret-volume-test: <nil>
STEP: delete the pod
May 14 10:15:14.657: INFO: Waiting for pod pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:15:14.659: INFO: Pod pod-secrets-29167184-7631-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:15:14.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7138" for this suite.
May 14 10:15:20.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:15:20.735: INFO: namespace secrets-7138 deletion completed in 6.072923861s

• [SLOW TEST:8.243 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:15:20.735: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:15:20.881: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 14 10:15:25.884: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 14 10:15:25.884: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 14 10:15:27.886: INFO: Creating deployment "test-rollover-deployment"
May 14 10:15:27.898: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 14 10:15:29.906: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 14 10:15:29.910: INFO: Ensure that both replica sets have 1 created replica
May 14 10:15:29.913: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 14 10:15:29.919: INFO: Updating deployment test-rollover-deployment
May 14 10:15:29.919: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 14 10:15:31.934: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 14 10:15:31.947: INFO: Make sure deployment "test-rollover-deployment" is complete
May 14 10:15:31.951: INFO: all replica sets need to contain the pod-template-hash label
May 14 10:15:31.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425731, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 10:15:33.955: INFO: all replica sets need to contain the pod-template-hash label
May 14 10:15:33.955: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425731, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 10:15:35.956: INFO: all replica sets need to contain the pod-template-hash label
May 14 10:15:35.956: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425731, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 10:15:37.955: INFO: all replica sets need to contain the pod-template-hash label
May 14 10:15:37.956: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425731, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 10:15:39.955: INFO: all replica sets need to contain the pod-template-hash label
May 14 10:15:39.955: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425731, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693425727, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 14 10:15:41.955: INFO: 
May 14 10:15:41.955: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 14 10:15:41.961: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6563,SelfLink:/apis/apps/v1/namespaces/deployment-6563/deployments/test-rollover-deployment,UID:322e24d1-7631-11e9-a442-02538a874012,ResourceVersion:140949,Generation:2,CreationTimestamp:2019-05-14 10:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-14 10:15:27 +0000 UTC 2019-05-14 10:15:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-14 10:15:41 +0000 UTC 2019-05-14 10:15:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 14 10:15:41.964: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-6563,SelfLink:/apis/apps/v1/namespaces/deployment-6563/replicasets/test-rollover-deployment-766b4d6c9d,UID:33647f07-7631-11e9-a442-02538a874012,ResourceVersion:140939,Generation:2,CreationTimestamp:2019-05-14 10:15:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 322e24d1-7631-11e9-a442-02538a874012 0xc0015fc497 0xc0015fc498}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 14 10:15:41.964: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 14 10:15:41.964: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6563,SelfLink:/apis/apps/v1/namespaces/deployment-6563/replicasets/test-rollover-controller,UID:2e007e26-7631-11e9-a442-02538a874012,ResourceVersion:140948,Generation:2,CreationTimestamp:2019-05-14 10:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 322e24d1-7631-11e9-a442-02538a874012 0xc0015fc2a7 0xc0015fc2a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 10:15:41.964: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-6563,SelfLink:/apis/apps/v1/namespaces/deployment-6563/replicasets/test-rollover-deployment-6455657675,UID:322ff858-7631-11e9-a442-02538a874012,ResourceVersion:140913,Generation:2,CreationTimestamp:2019-05-14 10:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 322e24d1-7631-11e9-a442-02538a874012 0xc0015fc387 0xc0015fc388}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 14 10:15:41.966: INFO: Pod "test-rollover-deployment-766b4d6c9d-lxh75" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-lxh75,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-6563,SelfLink:/api/v1/namespaces/deployment-6563/pods/test-rollover-deployment-766b4d6c9d-lxh75,UID:33679acc-7631-11e9-a442-02538a874012,ResourceVersion:140923,Generation:0,CreationTimestamp:2019-05-14 10:15:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 33647f07-7631-11e9-a442-02538a874012 0xc0015fd217 0xc0015fd218}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7d8gq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7d8gq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7d8gq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-2-82-233.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015fd280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015fd2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:15:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:15:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:15:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 10:15:29 +0000 UTC  }],Message:,Reason:,HostIP:10.2.82.233,PodIP:10.100.1.216,StartTime:2019-05-14 10:15:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-14 10:15:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://49b9819c0205b784aab5b6de7998331a84d6b2158d4000a6f8310250b28f8636}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:15:41.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6563" for this suite.
May 14 10:15:47.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:15:48.059: INFO: namespace deployment-6563 deletion completed in 6.090000377s

• [SLOW TEST:27.324 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:15:48.060: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tw2gd in namespace proxy-9959
I0514 10:15:48.203725      16 runners.go:184] Created replication controller with name: proxy-service-tw2gd, namespace: proxy-9959, replica count: 1
I0514 10:15:49.254208      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 10:15:50.254476      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 10:15:51.254704      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 10:15:52.254977      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 10:15:53.255309      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 10:15:54.255544      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 10:15:55.255787      16 runners.go:184] proxy-service-tw2gd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 14 10:15:55.258: INFO: setup took 7.071110461s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 14 10:15:55.270: INFO: (0) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 10.896291ms)
May 14 10:15:55.270: INFO: (0) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.908497ms)
May 14 10:15:55.270: INFO: (0) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 11.30123ms)
May 14 10:15:55.270: INFO: (0) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.226184ms)
May 14 10:15:55.271: INFO: (0) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 12.343509ms)
May 14 10:15:55.274: INFO: (0) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 14.537021ms)
May 14 10:15:55.274: INFO: (0) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 16.255211ms)
May 14 10:15:55.274: INFO: (0) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.019098ms)
May 14 10:15:55.274: INFO: (0) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 15.270517ms)
May 14 10:15:55.275: INFO: (0) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 16.267023ms)
May 14 10:15:55.276: INFO: (0) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 17.33449ms)
May 14 10:15:55.282: INFO: (0) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 22.114173ms)
May 14 10:15:55.282: INFO: (0) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 24.026472ms)
May 14 10:15:55.283: INFO: (0) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 23.973453ms)
May 14 10:15:55.283: INFO: (0) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 23.761663ms)
May 14 10:15:55.286: INFO: (0) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 27.850565ms)
May 14 10:15:55.300: INFO: (1) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 13.679772ms)
May 14 10:15:55.300: INFO: (1) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 13.617286ms)
May 14 10:15:55.300: INFO: (1) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 13.445658ms)
May 14 10:15:55.300: INFO: (1) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 12.987842ms)
May 14 10:15:55.300: INFO: (1) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 13.577767ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 13.181322ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.647814ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 13.062683ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 13.556644ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 12.743526ms)
May 14 10:15:55.301: INFO: (1) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 14.350609ms)
May 14 10:15:55.302: INFO: (1) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 14.477264ms)
May 14 10:15:55.303: INFO: (1) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 15.792525ms)
May 14 10:15:55.303: INFO: (1) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.363489ms)
May 14 10:15:55.304: INFO: (1) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 16.793325ms)
May 14 10:15:55.304: INFO: (1) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.754938ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 8.733551ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 9.581673ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 9.367696ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 10.179468ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 10.197235ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 10.190331ms)
May 14 10:15:55.314: INFO: (2) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 10.047893ms)
May 14 10:15:55.317: INFO: (2) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 11.384564ms)
May 14 10:15:55.317: INFO: (2) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 10.840885ms)
May 14 10:15:55.317: INFO: (2) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 10.83586ms)
May 14 10:15:55.320: INFO: (2) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 15.592962ms)
May 14 10:15:55.321: INFO: (2) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.98297ms)
May 14 10:15:55.321: INFO: (2) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.964913ms)
May 14 10:15:55.321: INFO: (2) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.500966ms)
May 14 10:15:55.322: INFO: (2) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 17.952319ms)
May 14 10:15:55.322: INFO: (2) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 17.838364ms)
May 14 10:15:55.332: INFO: (3) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 8.885649ms)
May 14 10:15:55.334: INFO: (3) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 11.57569ms)
May 14 10:15:55.334: INFO: (3) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.24462ms)
May 14 10:15:55.334: INFO: (3) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 10.987806ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.261902ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 11.420185ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.41824ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.5559ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 11.727563ms)
May 14 10:15:55.335: INFO: (3) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 11.568934ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 15.758232ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 14.837147ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 15.110233ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 14.805508ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.115107ms)
May 14 10:15:55.338: INFO: (3) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.7778ms)
May 14 10:15:55.343: INFO: (4) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 4.99055ms)
May 14 10:15:55.351: INFO: (4) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 11.783098ms)
May 14 10:15:55.351: INFO: (4) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 12.681791ms)
May 14 10:15:55.351: INFO: (4) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 12.839212ms)
May 14 10:15:55.351: INFO: (4) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 12.180893ms)
May 14 10:15:55.355: INFO: (4) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.387688ms)
May 14 10:15:55.355: INFO: (4) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 14.195704ms)
May 14 10:15:55.356: INFO: (4) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.131532ms)
May 14 10:15:55.355: INFO: (4) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 15.882456ms)
May 14 10:15:55.356: INFO: (4) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 17.112916ms)
May 14 10:15:55.356: INFO: (4) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 17.34202ms)
May 14 10:15:55.357: INFO: (4) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 17.569398ms)
May 14 10:15:55.357: INFO: (4) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 17.207468ms)
May 14 10:15:55.357: INFO: (4) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 17.938217ms)
May 14 10:15:55.357: INFO: (4) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 18.379399ms)
May 14 10:15:55.357: INFO: (4) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 18.73788ms)
May 14 10:15:55.365: INFO: (5) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 7.759503ms)
May 14 10:15:55.370: INFO: (5) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.899132ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.841542ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 11.094725ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 12.765075ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 10.849462ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 6.581049ms)
May 14 10:15:55.371: INFO: (5) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 7.704064ms)
May 14 10:15:55.372: INFO: (5) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 13.698291ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 9.001748ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 15.0944ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 15.651722ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 15.9041ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 13.141513ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.592935ms)
May 14 10:15:55.373: INFO: (5) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 14.968253ms)
May 14 10:15:55.380: INFO: (6) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 6.284835ms)
May 14 10:15:55.385: INFO: (6) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 10.923388ms)
May 14 10:15:55.385: INFO: (6) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 10.530996ms)
May 14 10:15:55.385: INFO: (6) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 10.762487ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 26.430425ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 27.290695ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 26.347451ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 26.667709ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 25.852805ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 26.206618ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 26.018081ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 27.101727ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 26.40747ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 26.19732ms)
May 14 10:15:55.401: INFO: (6) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 25.9151ms)
May 14 10:15:55.405: INFO: (6) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 30.522705ms)
May 14 10:15:55.414: INFO: (7) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 8.444614ms)
May 14 10:15:55.414: INFO: (7) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 8.564302ms)
May 14 10:15:55.414: INFO: (7) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 8.718617ms)
May 14 10:15:55.414: INFO: (7) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 8.996848ms)
May 14 10:15:55.417: INFO: (7) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.28143ms)
May 14 10:15:55.417: INFO: (7) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 11.58447ms)
May 14 10:15:55.417: INFO: (7) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.530955ms)
May 14 10:15:55.418: INFO: (7) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 12.388814ms)
May 14 10:15:55.419: INFO: (7) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 13.46303ms)
May 14 10:15:55.422: INFO: (7) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 16.628381ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 17.843907ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 17.506352ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 17.49009ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 17.510898ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 17.094802ms)
May 14 10:15:55.423: INFO: (7) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 18.486571ms)
May 14 10:15:55.439: INFO: (8) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 15.083347ms)
May 14 10:15:55.439: INFO: (8) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 15.906152ms)
May 14 10:15:55.439: INFO: (8) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.272787ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 15.315195ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 15.338723ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.969472ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.407989ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 15.476115ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 16.360408ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 15.38358ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 16.982969ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 16.743165ms)
May 14 10:15:55.440: INFO: (8) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 16.561156ms)
May 14 10:15:55.441: INFO: (8) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 16.608103ms)
May 14 10:15:55.441: INFO: (8) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 16.370735ms)
May 14 10:15:55.441: INFO: (8) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 16.418522ms)
May 14 10:15:55.450: INFO: (9) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 7.212977ms)
May 14 10:15:55.451: INFO: (9) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 9.884236ms)
May 14 10:15:55.451: INFO: (9) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 9.681482ms)
May 14 10:15:55.452: INFO: (9) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 9.785324ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 15.635195ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 16.193038ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 16.53286ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 15.08792ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 15.638239ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 14.99681ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.543643ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.766059ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.339995ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 15.214258ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 16.533154ms)
May 14 10:15:55.458: INFO: (9) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.256577ms)
May 14 10:15:55.467: INFO: (10) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 8.098649ms)
May 14 10:15:55.467: INFO: (10) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 8.396057ms)
May 14 10:15:55.467: INFO: (10) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 8.460498ms)
May 14 10:15:55.467: INFO: (10) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 8.133809ms)
May 14 10:15:55.468: INFO: (10) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 8.944923ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 14.32716ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 14.611159ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 14.68107ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 15.129613ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 14.956096ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 15.119647ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.857536ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 15.305177ms)
May 14 10:15:55.474: INFO: (10) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 15.227605ms)
May 14 10:15:55.476: INFO: (10) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 16.672331ms)
May 14 10:15:55.476: INFO: (10) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.734927ms)
May 14 10:15:55.480: INFO: (11) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 4.516949ms)
May 14 10:15:55.481: INFO: (11) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 4.98737ms)
May 14 10:15:55.481: INFO: (11) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 4.590217ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 13.332863ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 12.264303ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 12.194433ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.694076ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.608028ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 13.791212ms)
May 14 10:15:55.490: INFO: (11) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 13.62397ms)
May 14 10:15:55.495: INFO: (11) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 18.907635ms)
May 14 10:15:55.496: INFO: (11) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 19.314079ms)
May 14 10:15:55.496: INFO: (11) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 18.562456ms)
May 14 10:15:55.496: INFO: (11) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 18.129313ms)
May 14 10:15:55.497: INFO: (11) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 21.054411ms)
May 14 10:15:55.497: INFO: (11) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 20.977734ms)
May 14 10:15:55.503: INFO: (12) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 5.552959ms)
May 14 10:15:55.503: INFO: (12) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 5.129188ms)
May 14 10:15:55.504: INFO: (12) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 5.796322ms)
May 14 10:15:55.504: INFO: (12) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 6.006393ms)
May 14 10:15:55.506: INFO: (12) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 7.545884ms)
May 14 10:15:55.510: INFO: (12) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 11.392156ms)
May 14 10:15:55.511: INFO: (12) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 13.030404ms)
May 14 10:15:55.512: INFO: (12) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.247474ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 15.278092ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 15.600077ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 16.160159ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 15.453305ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.398863ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 15.667009ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.662249ms)
May 14 10:15:55.514: INFO: (12) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 15.406928ms)
May 14 10:15:55.525: INFO: (13) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 10.390905ms)
May 14 10:15:55.531: INFO: (13) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 16.344624ms)
May 14 10:15:55.531: INFO: (13) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 16.505714ms)
May 14 10:15:55.531: INFO: (13) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 16.228598ms)
May 14 10:15:55.531: INFO: (13) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 16.401436ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 16.452548ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 16.683687ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 16.671641ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 17.058312ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 17.088629ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.987582ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 16.839743ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 17.161844ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 17.490296ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 17.373097ms)
May 14 10:15:55.532: INFO: (13) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 17.625145ms)
May 14 10:15:55.544: INFO: (14) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 12.064667ms)
May 14 10:15:55.545: INFO: (14) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 12.105436ms)
May 14 10:15:55.545: INFO: (14) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 12.064796ms)
May 14 10:15:55.545: INFO: (14) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 12.114208ms)
May 14 10:15:55.545: INFO: (14) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 12.083664ms)
May 14 10:15:55.546: INFO: (14) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 13.198584ms)
May 14 10:15:55.546: INFO: (14) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.359944ms)
May 14 10:15:55.547: INFO: (14) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 14.482588ms)
May 14 10:15:55.547: INFO: (14) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.775586ms)
May 14 10:15:55.548: INFO: (14) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 15.742135ms)
May 14 10:15:55.549: INFO: (14) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.051401ms)
May 14 10:15:55.549: INFO: (14) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 16.369929ms)
May 14 10:15:55.550: INFO: (14) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 16.838799ms)
May 14 10:15:55.550: INFO: (14) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 17.262067ms)
May 14 10:15:55.551: INFO: (14) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 18.038117ms)
May 14 10:15:55.551: INFO: (14) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 18.374894ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 13.91326ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 13.660185ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 12.822323ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 14.023383ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 14.952776ms)
May 14 10:15:55.566: INFO: (15) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 14.186144ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 12.945156ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 14.504914ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 15.472319ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 14.895852ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 14.761397ms)
May 14 10:15:55.567: INFO: (15) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 15.694914ms)
May 14 10:15:55.569: INFO: (15) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 16.484577ms)
May 14 10:15:55.569: INFO: (15) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 16.557487ms)
May 14 10:15:55.569: INFO: (15) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.543843ms)
May 14 10:15:55.569: INFO: (15) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 16.820002ms)
May 14 10:15:55.577: INFO: (16) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 7.845228ms)
May 14 10:15:55.577: INFO: (16) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 7.910203ms)
May 14 10:15:55.580: INFO: (16) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 10.078143ms)
May 14 10:15:55.580: INFO: (16) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 10.586649ms)
May 14 10:15:55.580: INFO: (16) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 10.640247ms)
May 14 10:15:55.583: INFO: (16) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.779676ms)
May 14 10:15:55.584: INFO: (16) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 14.791448ms)
May 14 10:15:55.584: INFO: (16) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 14.775971ms)
May 14 10:15:55.585: INFO: (16) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.765299ms)
May 14 10:15:55.585: INFO: (16) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 15.523464ms)
May 14 10:15:55.586: INFO: (16) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 15.942247ms)
May 14 10:15:55.586: INFO: (16) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 16.992954ms)
May 14 10:15:55.587: INFO: (16) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 17.21085ms)
May 14 10:15:55.587: INFO: (16) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 17.63509ms)
May 14 10:15:55.588: INFO: (16) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 17.435944ms)
May 14 10:15:55.588: INFO: (16) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 18.410825ms)
May 14 10:15:55.595: INFO: (17) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 7.331799ms)
May 14 10:15:55.599: INFO: (17) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 8.961083ms)
May 14 10:15:55.599: INFO: (17) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 9.959172ms)
May 14 10:15:55.599: INFO: (17) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 9.448816ms)
May 14 10:15:55.600: INFO: (17) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 10.290016ms)
May 14 10:15:55.600: INFO: (17) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.17271ms)
May 14 10:15:55.600: INFO: (17) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 11.69675ms)
May 14 10:15:55.600: INFO: (17) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 11.215984ms)
May 14 10:15:55.601: INFO: (17) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 12.533028ms)
May 14 10:15:55.602: INFO: (17) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 12.439033ms)
May 14 10:15:55.602: INFO: (17) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 12.845934ms)
May 14 10:15:55.604: INFO: (17) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 14.174137ms)
May 14 10:15:55.604: INFO: (17) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.116468ms)
May 14 10:15:55.605: INFO: (17) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 15.350273ms)
May 14 10:15:55.605: INFO: (17) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 16.265917ms)
May 14 10:15:55.605: INFO: (17) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 16.074809ms)
May 14 10:15:55.617: INFO: (18) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 9.962782ms)
May 14 10:15:55.618: INFO: (18) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 11.041884ms)
May 14 10:15:55.618: INFO: (18) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 10.631332ms)
May 14 10:15:55.618: INFO: (18) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 10.862882ms)
May 14 10:15:55.618: INFO: (18) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 12.300086ms)
May 14 10:15:55.620: INFO: (18) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 13.58193ms)
May 14 10:15:55.620: INFO: (18) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.625715ms)
May 14 10:15:55.620: INFO: (18) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 14.495933ms)
May 14 10:15:55.620: INFO: (18) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 13.884755ms)
May 14 10:15:55.620: INFO: (18) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 14.819695ms)
May 14 10:15:55.621: INFO: (18) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 15.062164ms)
May 14 10:15:55.621: INFO: (18) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 15.094323ms)
May 14 10:15:55.622: INFO: (18) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 14.691133ms)
May 14 10:15:55.622: INFO: (18) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 14.687829ms)
May 14 10:15:55.622: INFO: (18) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 15.995258ms)
May 14 10:15:55.623: INFO: (18) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 16.735204ms)
May 14 10:15:55.626: INFO: (19) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">test<... (200; 3.043043ms)
May 14 10:15:55.630: INFO: (19) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 7.272495ms)
May 14 10:15:55.636: INFO: (19) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 12.911919ms)
May 14 10:15:55.636: INFO: (19) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:460/proxy/: tls baz (200; 12.690222ms)
May 14 10:15:55.636: INFO: (19) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:160/proxy/: foo (200; 13.255228ms)
May 14 10:15:55.636: INFO: (19) /api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/http:proxy-service-tw2gd-kvds7:1080/proxy/rewriteme">... (200; 13.211818ms)
May 14 10:15:55.637: INFO: (19) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:443/proxy/tlsrewritem... (200; 13.717539ms)
May 14 10:15:55.637: INFO: (19) /api/v1/namespaces/proxy-9959/pods/https:proxy-service-tw2gd-kvds7:462/proxy/: tls qux (200; 13.53752ms)
May 14 10:15:55.637: INFO: (19) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7:162/proxy/: bar (200; 13.762609ms)
May 14 10:15:55.637: INFO: (19) /api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/: <a href="/api/v1/namespaces/proxy-9959/pods/proxy-service-tw2gd-kvds7/proxy/rewriteme">test</a> (200; 13.894631ms)
May 14 10:15:55.640: INFO: (19) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname1/proxy/: foo (200; 16.801997ms)
May 14 10:15:55.641: INFO: (19) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname2/proxy/: bar (200; 18.120218ms)
May 14 10:15:55.641: INFO: (19) /api/v1/namespaces/proxy-9959/services/proxy-service-tw2gd:portname1/proxy/: foo (200; 18.227887ms)
May 14 10:15:55.642: INFO: (19) /api/v1/namespaces/proxy-9959/services/http:proxy-service-tw2gd:portname2/proxy/: bar (200; 18.377885ms)
May 14 10:15:55.642: INFO: (19) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname1/proxy/: tls baz (200; 19.005085ms)
May 14 10:15:55.642: INFO: (19) /api/v1/namespaces/proxy-9959/services/https:proxy-service-tw2gd:tlsportname2/proxy/: tls qux (200; 18.885116ms)
STEP: deleting ReplicationController proxy-service-tw2gd in namespace proxy-9959, will wait for the garbage collector to delete the pods
May 14 10:15:55.700: INFO: Deleting ReplicationController proxy-service-tw2gd took: 5.262253ms
May 14 10:15:56.000: INFO: Terminating ReplicationController proxy-service-tw2gd pods took: 300.243978ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:16:02.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9959" for this suite.
May 14 10:16:08.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:16:08.679: INFO: namespace proxy-9959 deletion completed in 6.075947236s

• [SLOW TEST:20.619 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:16:08.679: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
May 14 10:16:08.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 cluster-info'
May 14 10:16:09.043: INFO: stderr: ""
May 14 10:16:09.043: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:16:09.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5530" for this suite.
May 14 10:16:15.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:16:15.141: INFO: namespace kubectl-5530 deletion completed in 6.095302358s

• [SLOW TEST:6.462 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:16:15.141: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 14 10:16:15.514: INFO: Pod name wrapped-volume-race-4e834184-7631-11e9-8d5d-c6eb97da6be3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4e834184-7631-11e9-8d5d-c6eb97da6be3 in namespace emptydir-wrapper-5808, will wait for the garbage collector to delete the pods
May 14 10:16:31.623: INFO: Deleting ReplicationController wrapped-volume-race-4e834184-7631-11e9-8d5d-c6eb97da6be3 took: 6.034252ms
May 14 10:16:31.923: INFO: Terminating ReplicationController wrapped-volume-race-4e834184-7631-11e9-8d5d-c6eb97da6be3 pods took: 300.405029ms
STEP: Creating RC which spawns configmap-volume pods
May 14 10:17:12.636: INFO: Pod name wrapped-volume-race-709bbed8-7631-11e9-8d5d-c6eb97da6be3: Found 0 pods out of 5
May 14 10:17:17.640: INFO: Pod name wrapped-volume-race-709bbed8-7631-11e9-8d5d-c6eb97da6be3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-709bbed8-7631-11e9-8d5d-c6eb97da6be3 in namespace emptydir-wrapper-5808, will wait for the garbage collector to delete the pods
May 14 10:17:27.716: INFO: Deleting ReplicationController wrapped-volume-race-709bbed8-7631-11e9-8d5d-c6eb97da6be3 took: 6.234446ms
May 14 10:17:28.018: INFO: Terminating ReplicationController wrapped-volume-race-709bbed8-7631-11e9-8d5d-c6eb97da6be3 pods took: 301.845776ms
STEP: Creating RC which spawns configmap-volume pods
May 14 10:18:12.630: INFO: Pod name wrapped-volume-race-945e2d10-7631-11e9-8d5d-c6eb97da6be3: Found 0 pods out of 5
May 14 10:18:17.635: INFO: Pod name wrapped-volume-race-945e2d10-7631-11e9-8d5d-c6eb97da6be3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-945e2d10-7631-11e9-8d5d-c6eb97da6be3 in namespace emptydir-wrapper-5808, will wait for the garbage collector to delete the pods
May 14 10:18:27.709: INFO: Deleting ReplicationController wrapped-volume-race-945e2d10-7631-11e9-8d5d-c6eb97da6be3 took: 4.411101ms
May 14 10:18:28.009: INFO: Terminating ReplicationController wrapped-volume-race-945e2d10-7631-11e9-8d5d-c6eb97da6be3 pods took: 300.340078ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:19:13.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5808" for this suite.
May 14 10:19:19.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:19:19.336: INFO: namespace emptydir-wrapper-5808 deletion completed in 6.076736661s

• [SLOW TEST:184.195 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:19:19.336: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7339
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 14 10:19:23.495: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:23.497: INFO: Pod pod-with-prestop-http-hook still exists
May 14 10:19:25.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:25.499: INFO: Pod pod-with-prestop-http-hook still exists
May 14 10:19:27.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:27.500: INFO: Pod pod-with-prestop-http-hook still exists
May 14 10:19:29.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:29.500: INFO: Pod pod-with-prestop-http-hook still exists
May 14 10:19:31.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:31.500: INFO: Pod pod-with-prestop-http-hook still exists
May 14 10:19:33.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 14 10:19:33.499: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:19:33.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7339" for this suite.
May 14 10:19:55.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:19:55.583: INFO: namespace container-lifecycle-hook-7339 deletion completed in 22.074557672s

• [SLOW TEST:36.247 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:19:55.584: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d1d0f418-7631-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:19:55.718: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3" in namespace "projected-2892" to be "success or failure"
May 14 10:19:55.721: INFO: Pod "pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.378441ms
May 14 10:19:57.724: INFO: Pod "pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006020135s
STEP: Saw pod success
May 14 10:19:57.724: INFO: Pod "pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:19:57.726: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 10:19:57.739: INFO: Waiting for pod pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:19:57.741: INFO: Pod pod-projected-secrets-d1d140e1-7631-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:19:57.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2892" for this suite.
May 14 10:20:03.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:20:03.826: INFO: namespace projected-2892 deletion completed in 6.083255787s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:20:03.827: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-d6bae59d-7631-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:20:03.963: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3" in namespace "projected-540" to be "success or failure"
May 14 10:20:03.970: INFO: Pod "pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.276089ms
May 14 10:20:05.973: INFO: Pod "pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009148354s
STEP: Saw pod success
May 14 10:20:05.973: INFO: Pod "pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:20:05.974: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 10:20:05.987: INFO: Waiting for pod pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:20:05.990: INFO: Pod pod-projected-secrets-d6bb5792-7631-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:20:05.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-540" for this suite.
May 14 10:20:11.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:20:12.068: INFO: namespace projected-540 deletion completed in 6.075709034s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:20:12.068: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:20:12.205: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 14 10:20:12.212: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:12.216: INFO: Number of nodes with available pods: 0
May 14 10:20:12.216: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 10:20:13.219: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:13.221: INFO: Number of nodes with available pods: 1
May 14 10:20:13.221: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 14 10:20:13.238: INFO: Wrong image for pod: daemon-set-4sxbv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 14 10:20:13.240: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:14.242: INFO: Wrong image for pod: daemon-set-4sxbv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 14 10:20:14.245: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:15.242: INFO: Wrong image for pod: daemon-set-4sxbv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 14 10:20:15.245: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:16.242: INFO: Wrong image for pod: daemon-set-4sxbv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 14 10:20:16.242: INFO: Pod daemon-set-4sxbv is not available
May 14 10:20:16.246: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:17.242: INFO: Pod daemon-set-jxgdm is not available
May 14 10:20:17.244: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 14 10:20:17.246: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:17.248: INFO: Number of nodes with available pods: 0
May 14 10:20:17.248: INFO: Node ip-10-2-82-233.ec2.internal is running more than one daemon pod
May 14 10:20:18.258: INFO: DaemonSet pods can't tolerate node ip-10-2-82-30.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 14 10:20:18.260: INFO: Number of nodes with available pods: 1
May 14 10:20:18.260: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1987, will wait for the garbage collector to delete the pods
May 14 10:20:18.325: INFO: Deleting DaemonSet.extensions daemon-set took: 4.198554ms
May 14 10:20:18.626: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.252324ms
May 14 10:20:32.627: INFO: Number of nodes with available pods: 0
May 14 10:20:32.627: INFO: Number of running nodes: 0, number of available pods: 0
May 14 10:20:32.629: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1987/daemonsets","resourceVersion":"142431"},"items":null}

May 14 10:20:32.631: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1987/pods","resourceVersion":"142431"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:20:32.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1987" for this suite.
May 14 10:20:38.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:20:38.712: INFO: namespace daemonsets-1987 deletion completed in 6.074461393s

• [SLOW TEST:26.644 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:20:38.712: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-eb8666f3-7631-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume secrets
May 14 10:20:38.851: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3" in namespace "projected-5497" to be "success or failure"
May 14 10:20:38.854: INFO: Pod "pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.610297ms
May 14 10:20:40.856: INFO: Pod "pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005306528s
STEP: Saw pod success
May 14 10:20:40.856: INFO: Pod "pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:20:40.858: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 10:20:40.872: INFO: Waiting for pod pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:20:40.874: INFO: Pod pod-projected-secrets-eb86d19f-7631-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:20:40.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5497" for this suite.
May 14 10:20:46.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:20:46.954: INFO: namespace projected-5497 deletion completed in 6.078280149s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:20:46.955: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f070bc4d-7631-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:20:47.099: INFO: Waiting up to 5m0s for pod "pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3" in namespace "configmap-5836" to be "success or failure"
May 14 10:20:47.104: INFO: Pod "pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.848017ms
May 14 10:20:49.107: INFO: Pod "pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007808358s
STEP: Saw pod success
May 14 10:20:49.107: INFO: Pod "pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:20:49.109: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3 container configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:20:49.121: INFO: Waiting for pod pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:20:49.122: INFO: Pod pod-configmaps-f07133a6-7631-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:20:49.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5836" for this suite.
May 14 10:20:55.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:20:55.199: INFO: namespace configmap-5836 deletion completed in 6.073951826s

• [SLOW TEST:8.244 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:20:55.199: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8918
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0514 10:20:55.923056      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 10:20:55.923: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:20:55.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8918" for this suite.
May 14 10:21:01.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:21:02.005: INFO: namespace gc-8918 deletion completed in 6.080139272s

• [SLOW TEST:6.806 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:21:02.005: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May 14 10:21:02.134: INFO: Creating ReplicaSet my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3
May 14 10:21:02.140: INFO: Pod name my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3: Found 0 pods out of 1
May 14 10:21:07.143: INFO: Pod name my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3: Found 1 pods out of 1
May 14 10:21:07.143: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3" is running
May 14 10:21:07.144: INFO: Pod "my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3-72rv5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 10:21:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 10:21:03 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 10:21:03 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 10:21:02 +0000 UTC Reason: Message:}])
May 14 10:21:07.145: INFO: Trying to dial the pod
May 14 10:21:12.152: INFO: Controller my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3: Got expected result from replica 1 [my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3-72rv5]: "my-hostname-basic-f9684e15-7631-11e9-8d5d-c6eb97da6be3-72rv5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:21:12.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1438" for this suite.
May 14 10:21:18.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:21:18.249: INFO: namespace replicaset-1438 deletion completed in 6.094784833s

• [SLOW TEST:16.244 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:21:18.249: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9181
May 14 10:21:20.389: INFO: Started pod liveness-http in namespace container-probe-9181
STEP: checking the pod's current state and verifying that restartCount is present
May 14 10:21:20.391: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:25:20.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9181" for this suite.
May 14 10:25:26.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:25:26.833: INFO: namespace container-probe-9181 deletion completed in 6.101762282s

• [SLOW TEST:248.584 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:25:26.834: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
May 14 10:25:26.963: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 14 10:25:26.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:27.127: INFO: stderr: ""
May 14 10:25:27.127: INFO: stdout: "service/redis-slave created\n"
May 14 10:25:27.128: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 14 10:25:27.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:27.322: INFO: stderr: ""
May 14 10:25:27.322: INFO: stdout: "service/redis-master created\n"
May 14 10:25:27.323: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 14 10:25:27.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:27.582: INFO: stderr: ""
May 14 10:25:27.582: INFO: stdout: "service/frontend created\n"
May 14 10:25:27.582: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 14 10:25:27.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:27.770: INFO: stderr: ""
May 14 10:25:27.770: INFO: stdout: "deployment.apps/frontend created\n"
May 14 10:25:27.770: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 14 10:25:27.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:27.987: INFO: stderr: ""
May 14 10:25:27.987: INFO: stdout: "deployment.apps/redis-master created\n"
May 14 10:25:27.987: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 14 10:25:27.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-8985'
May 14 10:25:28.171: INFO: stderr: ""
May 14 10:25:28.171: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May 14 10:25:28.171: INFO: Waiting for all frontend pods to be Running.
May 14 10:25:33.225: INFO: Waiting for frontend to serve content.
May 14 10:25:33.240: INFO: Trying to add a new entry to the guestbook.
May 14 10:25:33.251: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 14 10:25:33.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.343: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.343: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 14 10:25:33.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.463: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.463: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 14 10:25:33.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.580: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.580: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 14 10:25:33.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.680: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.680: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 14 10:25:33.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.769: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.769: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 14 10:25:33.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete --grace-period=0 --force -f - --namespace=kubectl-8985'
May 14 10:25:33.844: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 10:25:33.844: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:25:33.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8985" for this suite.
May 14 10:26:13.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:26:13.918: INFO: namespace kubectl-8985 deletion completed in 40.071246646s

• [SLOW TEST:47.084 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:26:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-85
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-b3525170-7632-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:26:14.054: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3" in namespace "projected-85" to be "success or failure"
May 14 10:26:14.058: INFO: Pod "pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.631717ms
May 14 10:26:16.060: INFO: Pod "pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006171123s
May 14 10:26:18.063: INFO: Pod "pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008672565s
STEP: Saw pod success
May 14 10:26:18.063: INFO: Pod "pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:26:18.065: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 10:26:18.078: INFO: Waiting for pod pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:26:18.080: INFO: Pod pod-projected-configmaps-b352c109-7632-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:26:18.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-85" for this suite.
May 14 10:26:24.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:26:24.156: INFO: namespace projected-85 deletion completed in 6.073821487s

• [SLOW TEST:10.237 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:26:24.156: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4522
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 10:26:24.284: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 10:26:38.344: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.1.252 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4522 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 10:26:38.344: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
May 14 10:26:39.444: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:26:39.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4522" for this suite.
May 14 10:27:01.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:27:01.524: INFO: namespace pod-network-test-4522 deletion completed in 22.077733647s

• [SLOW TEST:37.368 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:27:01.526: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8841/configmap-test-cfb2b6cd-7632-11e9-8d5d-c6eb97da6be3
STEP: Creating a pod to test consume configMaps
May 14 10:27:01.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3" in namespace "configmap-8841" to be "success or failure"
May 14 10:27:01.667: INFO: Pod "pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092917ms
May 14 10:27:03.669: INFO: Pod "pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006548184s
STEP: Saw pod success
May 14 10:27:03.669: INFO: Pod "pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:27:03.671: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3 container env-test: <nil>
STEP: delete the pod
May 14 10:27:03.684: INFO: Waiting for pod pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:27:03.686: INFO: Pod pod-configmaps-cfb332ce-7632-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:27:03.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8841" for this suite.
May 14 10:27:09.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:27:09.764: INFO: namespace configmap-8841 deletion completed in 6.076172003s

• [SLOW TEST:8.238 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:27:09.765: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6588
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6588
STEP: Creating statefulset with conflicting port in namespace statefulset-6588
STEP: Waiting until pod test-pod will start running in namespace statefulset-6588
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6588
May 14 10:27:14.101: INFO: Observed stateful pod in namespace: statefulset-6588, name: ss-0, uid: d70983e6-7632-11e9-a442-02538a874012, status phase: Pending. Waiting for statefulset controller to delete.
May 14 10:27:14.761: INFO: Observed stateful pod in namespace: statefulset-6588, name: ss-0, uid: d70983e6-7632-11e9-a442-02538a874012, status phase: Failed. Waiting for statefulset controller to delete.
May 14 10:27:14.765: INFO: Observed stateful pod in namespace: statefulset-6588, name: ss-0, uid: d70983e6-7632-11e9-a442-02538a874012, status phase: Failed. Waiting for statefulset controller to delete.
May 14 10:27:14.768: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6588
STEP: Removing pod with conflicting port in namespace statefulset-6588
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6588 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 14 10:27:18.785: INFO: Deleting all statefulset in ns statefulset-6588
May 14 10:27:18.787: INFO: Scaling statefulset ss to 0
May 14 10:27:38.798: INFO: Waiting for statefulset status.replicas updated to 0
May 14 10:27:38.800: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:27:38.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6588" for this suite.
May 14 10:27:44.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:27:44.888: INFO: namespace statefulset-6588 deletion completed in 6.074572023s

• [SLOW TEST:35.124 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:27:44.888: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 14 10:27:45.016: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 14 10:27:45.020: INFO: Waiting for terminating namespaces to be deleted...
May 14 10:27:45.022: INFO: 
Logging pods the kubelet thinks is on node ip-10-2-82-233.ec2.internal before test
May 14 10:27:45.028: INFO: prometheus-operator-kube-state-metrics-5d7558d7cc-jm7r4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.028: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 14 10:27:45.028: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-14 09:04:33 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.028: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 14 10:27:45.029: INFO: sonobuoy-systemd-logs-daemon-set-9584be86564342a8-cgp7q from heptio-sonobuoy started at 2019-05-14 09:04:37 +0000 UTC (2 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 14 10:27:45.029: INFO: 	Container systemd-logs ready: true, restart count 1
May 14 10:27:45.029: INFO: prometheus-operator-prometheus-node-exporter-frpgv from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container node-exporter ready: true, restart count 0
May 14 10:27:45.029: INFO: prometheus-operator-operator-55445689db-bqr4b from kube-system started at 2019-05-13 13:22:55 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container prometheus-operator ready: true, restart count 0
May 14 10:27:45.029: INFO: liveness-http from container-probe-8911 started at 2019-05-13 13:25:40 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container liveness ready: true, restart count 0
May 14 10:27:45.029: INFO: kube-flannel-ds-amd64-kr6f4 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container kube-flannel ready: true, restart count 1
May 14 10:27:45.029: INFO: alertmanager-prometheus-operator-alertmanager-0 from kube-system started at 2019-05-13 13:23:08 +0000 UTC (2 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container alertmanager ready: true, restart count 0
May 14 10:27:45.029: INFO: 	Container config-reloader ready: true, restart count 0
May 14 10:27:45.029: INFO: prometheus-prometheus-operator-prometheus-0 from kube-system started at 2019-05-13 13:23:15 +0000 UTC (3 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container prometheus ready: true, restart count 1
May 14 10:27:45.029: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
May 14 10:27:45.029: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
May 14 10:27:45.029: INFO: prometheus-operator-grafana-5d74ccd7bd-4rch4 from kube-system started at 2019-05-13 13:22:55 +0000 UTC (2 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container grafana ready: true, restart count 0
May 14 10:27:45.029: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
May 14 10:27:45.029: INFO: kube-proxy-f4nj2 from kube-system started at 2019-05-13 13:21:59 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container kube-proxy ready: true, restart count 0
May 14 10:27:45.029: INFO: tiller-deploy-65949f8696-22447 from kube-system started at 2019-05-13 13:22:15 +0000 UTC (1 container statuses recorded)
May 14 10:27:45.029: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159e85d39d659859], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:27:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4472" for this suite.
May 14 10:27:52.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:27:52.120: INFO: namespace sched-pred-4472 deletion completed in 6.074138678s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.232 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:27:52.121: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 10:27:52.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-5047" to be "success or failure"
May 14 10:27:52.264: INFO: Pod "downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.970485ms
May 14 10:27:54.268: INFO: Pod "downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007958787s
STEP: Saw pod success
May 14 10:27:54.268: INFO: Pod "downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:27:54.270: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 10:27:54.283: INFO: Waiting for pod downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:27:54.285: INFO: Pod downwardapi-volume-eddba4e8-7632-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:27:54.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5047" for this suite.
May 14 10:28:00.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:28:00.361: INFO: namespace downward-api-5047 deletion completed in 6.074091537s

• [SLOW TEST:8.241 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:28:00.362: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-469
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 10:28:00.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-469'
May 14 10:28:00.803: INFO: stderr: ""
May 14 10:28:00.803: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
May 14 10:28:00.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete pods e2e-test-nginx-pod --namespace=kubectl-469'
May 14 10:28:12.540: INFO: stderr: ""
May 14 10:28:12.540: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:28:12.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-469" for this suite.
May 14 10:28:18.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:28:18.617: INFO: namespace kubectl-469 deletion completed in 6.074344646s

• [SLOW TEST:18.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:28:18.618: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May 14 10:28:18.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9060'
May 14 10:28:18.857: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 14 10:28:18.857: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
May 14 10:28:20.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9060'
May 14 10:28:20.943: INFO: stderr: ""
May 14 10:28:20.943: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:28:20.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9060" for this suite.
May 14 10:28:26.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:28:27.025: INFO: namespace kubectl-9060 deletion completed in 6.077797926s

• [SLOW TEST:8.407 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:28:27.025: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May 14 10:28:27.159: INFO: Waiting up to 5m0s for pod "pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-9703" to be "success or failure"
May 14 10:28:27.164: INFO: Pod "pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036554ms
May 14 10:28:29.166: INFO: Pod "pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006432795s
STEP: Saw pod success
May 14 10:28:29.166: INFO: Pod "pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:28:29.168: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 10:28:29.182: INFO: Waiting for pod pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:28:29.185: INFO: Pod pod-02a9039f-7633-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:28:29.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9703" for this suite.
May 14 10:28:35.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:28:35.261: INFO: namespace emptydir-9703 deletion completed in 6.072884953s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:28:35.262: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May 14 10:28:35.395: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3" in namespace "downward-api-3306" to be "success or failure"
May 14 10:28:35.398: INFO: Pod "downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.68479ms
May 14 10:28:37.400: INFO: Pod "downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004861873s
STEP: Saw pod success
May 14 10:28:37.400: INFO: Pod "downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:28:37.402: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3 container client-container: <nil>
STEP: delete the pod
May 14 10:28:37.414: INFO: Waiting for pod downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:28:37.416: INFO: Pod downwardapi-volume-07918c15-7633-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:28:37.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3306" for this suite.
May 14 10:28:43.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:28:43.495: INFO: namespace downward-api-3306 deletion completed in 6.076711099s

• [SLOW TEST:8.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:28:43.496: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May 14 10:28:43.622: INFO: namespace kubectl-4076
May 14 10:28:43.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 create -f - --namespace=kubectl-4076'
May 14 10:28:43.768: INFO: stderr: ""
May 14 10:28:43.768: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 14 10:28:44.770: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:28:44.770: INFO: Found 0 / 1
May 14 10:28:45.770: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:28:45.770: INFO: Found 1 / 1
May 14 10:28:45.771: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 14 10:28:45.773: INFO: Selector matched 1 pods for map[app:redis]
May 14 10:28:45.773: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 14 10:28:45.773: INFO: wait on redis-master startup in kubectl-4076 
May 14 10:28:45.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 logs redis-master-rw74l redis-master --namespace=kubectl-4076'
May 14 10:28:45.849: INFO: stderr: ""
May 14 10:28:45.849: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 10:28:44.949 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 10:28:44.949 # Server started, Redis version 3.2.12\n1:M 14 May 10:28:44.949 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 10:28:44.949 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 14 10:28:45.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4076'
May 14 10:28:45.935: INFO: stderr: ""
May 14 10:28:45.936: INFO: stdout: "service/rm2 exposed\n"
May 14 10:28:45.941: INFO: Service rm2 in namespace kubectl-4076 found.
STEP: exposing service
May 14 10:28:47.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-862630419 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4076'
May 14 10:28:48.036: INFO: stderr: ""
May 14 10:28:48.036: INFO: stdout: "service/rm3 exposed\n"
May 14 10:28:48.038: INFO: Service rm3 in namespace kubectl-4076 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:28:50.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4076" for this suite.
May 14 10:29:12.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:29:12.121: INFO: namespace kubectl-4076 deletion completed in 22.076762648s

• [SLOW TEST:28.626 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May 14 10:29:12.121: INFO: >>> kubeConfig: /tmp/kubeconfig-862630419
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 14 10:29:12.253: INFO: Waiting up to 5m0s for pod "pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3" in namespace "emptydir-6187" to be "success or failure"
May 14 10:29:12.257: INFO: Pod "pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113354ms
May 14 10:29:14.259: INFO: Pod "pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005449106s
STEP: Saw pod success
May 14 10:29:14.259: INFO: Pod "pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3" satisfied condition "success or failure"
May 14 10:29:14.261: INFO: Trying to get logs from node ip-10-2-82-233.ec2.internal pod pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3 container test-container: <nil>
STEP: delete the pod
May 14 10:29:14.294: INFO: Waiting for pod pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3 to disappear
May 14 10:29:14.296: INFO: Pod pod-1d89ef0c-7633-11e9-8d5d-c6eb97da6be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 14 10:29:14.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6187" for this suite.
May 14 10:29:20.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 10:29:20.378: INFO: namespace emptydir-6187 deletion completed in 6.079942583s

• [SLOW TEST:8.257 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSMay 14 10:29:20.379: INFO: Running AfterSuite actions on all nodes
May 14 10:29:20.379: INFO: Running AfterSuite actions on node 1
May 14 10:29:20.379: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5070.948 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h24m33.596180113s
Test Suite Passed
