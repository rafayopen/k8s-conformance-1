I0415 09:55:35.742421      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-357557484
I0415 09:55:35.742511      16 e2e.go:240] Starting e2e run "9d206de5-5f64-11e9-a7dc-a6e5a2dd4982" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1555322134 - Will randomize all specs
Will run 204 of 3584 specs

Apr 15 09:55:35.873: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 09:55:35.874: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 15 09:55:35.889: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 15 09:55:35.921: INFO: 27 / 27 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 15 09:55:35.921: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Apr 15 09:55:35.921: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 15 09:55:35.929: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 15 09:55:35.929: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 15 09:55:35.929: INFO: e2e test version: v1.14.1
Apr 15 09:55:35.930: INFO: kube-apiserver version: v1.14.1
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:55:35.930: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
Apr 15 09:55:36.049: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 15 09:55:36.060: INFO: Waiting up to 5m0s for pod "pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-7972" to be "success or failure"
Apr 15 09:55:36.065: INFO: Pod "pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032996ms
Apr 15 09:55:38.069: INFO: Pod "pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008776802s
Apr 15 09:55:40.073: INFO: Pod "pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01301387s
STEP: Saw pod success
Apr 15 09:55:40.073: INFO: Pod "pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:55:40.077: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 09:55:40.108: INFO: Waiting for pod pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:55:40.111: INFO: Pod pod-9dcf868b-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:55:40.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7972" for this suite.
Apr 15 09:55:46.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:55:46.242: INFO: namespace emptydir-7972 deletion completed in 6.126960709s

• [SLOW TEST:10.312 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:55:46.242: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-a3e92450-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating configMap with name cm-test-opt-upd-a3e9247c-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a3e92450-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Updating configmap cm-test-opt-upd-a3e9247c-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating configMap with name cm-test-opt-create-a3e9248a-5f64-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:55:52.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2846" for this suite.
Apr 15 09:56:14.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:56:14.533: INFO: namespace configmap-2846 deletion completed in 22.1286003s

• [SLOW TEST:28.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:56:14.533: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-b4d00cee-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 09:56:14.660: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "projected-9721" to be "success or failure"
Apr 15 09:56:14.666: INFO: Pod "pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136394ms
Apr 15 09:56:16.671: INFO: Pod "pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010516561s
STEP: Saw pod success
Apr 15 09:56:16.671: INFO: Pod "pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:56:16.674: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 09:56:16.696: INFO: Waiting for pod pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:56:16.699: INFO: Pod pod-projected-configmaps-b4d14566-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:56:16.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9721" for this suite.
Apr 15 09:56:22.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:56:22.822: INFO: namespace projected-9721 deletion completed in 6.118791877s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:56:22.822: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 09:56:22.858: INFO: Creating deployment "test-recreate-deployment"
Apr 15 09:56:22.868: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 15 09:56:22.877: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 15 09:56:24.884: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 15 09:56:24.887: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690918982, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690918982, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690918982, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690918982, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 09:56:26.891: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 15 09:56:26.900: INFO: Updating deployment test-recreate-deployment
Apr 15 09:56:26.900: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 15 09:56:27.002: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9368,SelfLink:/apis/apps/v1/namespaces/deployment-9368/deployments/test-recreate-deployment,UID:b9b5ffd3-5f64-11e9-adae-06c5682e2662,ResourceVersion:4936,Generation:2,CreationTimestamp:2019-04-15 09:56:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-15 09:56:26 +0000 UTC 2019-04-15 09:56:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-15 09:56:26 +0000 UTC 2019-04-15 09:56:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 15 09:56:27.005: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-9368,SelfLink:/apis/apps/v1/namespaces/deployment-9368/replicasets/test-recreate-deployment-c9cbd8684,UID:bc262649-5f64-11e9-b895-0a5a25aca864,ResourceVersion:4934,Generation:1,CreationTimestamp:2019-04-15 09:56:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b9b5ffd3-5f64-11e9-adae-06c5682e2662 0xc00201c540 0xc00201c541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 09:56:27.006: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 15 09:56:27.006: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-9368,SelfLink:/apis/apps/v1/namespaces/deployment-9368/replicasets/test-recreate-deployment-7d57d5ff7c,UID:b9b76ac0-5f64-11e9-b895-0a5a25aca864,ResourceVersion:4924,Generation:2,CreationTimestamp:2019-04-15 09:56:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b9b5ffd3-5f64-11e9-adae-06c5682e2662 0xc00201c487 0xc00201c488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 09:56:27.009: INFO: Pod "test-recreate-deployment-c9cbd8684-f9snw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-f9snw,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-9368,SelfLink:/api/v1/namespaces/deployment-9368/pods/test-recreate-deployment-c9cbd8684-f9snw,UID:bc27ba2a-5f64-11e9-b895-0a5a25aca864,ResourceVersion:4933,Generation:0,CreationTimestamp:2019-04-15 09:56:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 bc262649-5f64-11e9-b895-0a5a25aca864 0xc00201d100 0xc00201d101}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6j7pg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6j7pg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6j7pg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00201d2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00201d360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 09:56:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 09:56:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 09:56:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 09:56:26 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 09:56:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:56:27.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9368" for this suite.
Apr 15 09:56:33.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:56:33.125: INFO: namespace deployment-9368 deletion completed in 6.112254634s

• [SLOW TEST:10.303 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:56:33.125: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-bfda3d24-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 09:56:33.178: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "projected-7025" to be "success or failure"
Apr 15 09:56:33.183: INFO: Pod "pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.861879ms
Apr 15 09:56:35.188: INFO: Pod "pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009579581s
STEP: Saw pod success
Apr 15 09:56:35.188: INFO: Pod "pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:56:35.192: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 09:56:35.218: INFO: Waiting for pod pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:56:35.223: INFO: Pod pod-projected-configmaps-bfdb5550-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:56:35.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7025" for this suite.
Apr 15 09:56:41.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:56:41.345: INFO: namespace projected-7025 deletion completed in 6.11784152s

• [SLOW TEST:8.220 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:56:41.346: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 15 09:56:41.395: INFO: Waiting up to 5m0s for pod "client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "containers-8870" to be "success or failure"
Apr 15 09:56:41.399: INFO: Pod "client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235544ms
Apr 15 09:56:43.403: INFO: Pod "client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008451022s
Apr 15 09:56:45.407: INFO: Pod "client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012853228s
STEP: Saw pod success
Apr 15 09:56:45.407: INFO: Pod "client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:56:45.411: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 09:56:45.434: INFO: Waiting for pod client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:56:45.438: INFO: Pod client-containers-c4c07de6-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:56:45.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8870" for this suite.
Apr 15 09:56:51.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:56:51.571: INFO: namespace containers-8870 deletion completed in 6.12759403s

• [SLOW TEST:10.225 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:56:51.571: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 09:56:51.637: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 15 09:56:51.648: INFO: Number of nodes with available pods: 0
Apr 15 09:56:51.648: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 15 09:56:51.668: INFO: Number of nodes with available pods: 0
Apr 15 09:56:51.668: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:52.672: INFO: Number of nodes with available pods: 0
Apr 15 09:56:52.672: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:53.672: INFO: Number of nodes with available pods: 1
Apr 15 09:56:53.672: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 15 09:56:53.691: INFO: Number of nodes with available pods: 1
Apr 15 09:56:53.691: INFO: Number of running nodes: 0, number of available pods: 1
Apr 15 09:56:54.696: INFO: Number of nodes with available pods: 0
Apr 15 09:56:54.696: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 15 09:56:54.718: INFO: Number of nodes with available pods: 0
Apr 15 09:56:54.718: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:55.722: INFO: Number of nodes with available pods: 0
Apr 15 09:56:55.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:56.722: INFO: Number of nodes with available pods: 0
Apr 15 09:56:56.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:57.722: INFO: Number of nodes with available pods: 0
Apr 15 09:56:57.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:58.722: INFO: Number of nodes with available pods: 0
Apr 15 09:56:58.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:56:59.723: INFO: Number of nodes with available pods: 0
Apr 15 09:56:59.723: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:00.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:00.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:01.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:01.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:02.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:02.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:03.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:03.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:04.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:04.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:05.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:05.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:06.722: INFO: Number of nodes with available pods: 0
Apr 15 09:57:06.722: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:57:07.722: INFO: Number of nodes with available pods: 1
Apr 15 09:57:07.722: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9195, will wait for the garbage collector to delete the pods
Apr 15 09:57:07.790: INFO: Deleting DaemonSet.extensions daemon-set took: 8.763805ms
Apr 15 09:57:08.090: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.235629ms
Apr 15 09:57:16.295: INFO: Number of nodes with available pods: 0
Apr 15 09:57:16.295: INFO: Number of running nodes: 0, number of available pods: 0
Apr 15 09:57:16.300: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9195/daemonsets","resourceVersion":"5196"},"items":null}

Apr 15 09:57:16.303: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9195/pods","resourceVersion":"5196"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:16.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9195" for this suite.
Apr 15 09:57:22.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:57:22.439: INFO: namespace daemonsets-9195 deletion completed in 6.113511874s

• [SLOW TEST:30.868 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:57:22.440: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 15 09:57:22.496: INFO: Waiting up to 5m0s for pod "pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-6257" to be "success or failure"
Apr 15 09:57:22.502: INFO: Pod "pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016001ms
Apr 15 09:57:24.506: INFO: Pod "pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010072135s
Apr 15 09:57:26.510: INFO: Pod "pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014688599s
STEP: Saw pod success
Apr 15 09:57:26.510: INFO: Pod "pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:57:26.514: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 09:57:26.537: INFO: Waiting for pod pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:57:26.541: INFO: Pod pod-dd403941-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:26.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6257" for this suite.
Apr 15 09:57:32.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:57:32.661: INFO: namespace emptydir-6257 deletion completed in 6.116612524s

• [SLOW TEST:10.221 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:57:32.661: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 15 09:57:32.707: INFO: Waiting up to 5m0s for pod "var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "var-expansion-7780" to be "success or failure"
Apr 15 09:57:32.714: INFO: Pod "var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.81165ms
Apr 15 09:57:34.718: INFO: Pod "var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010860951s
Apr 15 09:57:36.722: INFO: Pod "var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015188822s
STEP: Saw pod success
Apr 15 09:57:36.723: INFO: Pod "var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:57:36.726: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 09:57:36.746: INFO: Waiting for pod var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:57:36.750: INFO: Pod var-expansion-e356818c-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:36.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7780" for this suite.
Apr 15 09:57:42.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:57:42.874: INFO: namespace var-expansion-7780 deletion completed in 6.120359063s

• [SLOW TEST:10.212 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:57:42.874: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e96cc694-5f64-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 09:57:42.926: INFO: Waiting up to 5m0s for pod "pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-2222" to be "success or failure"
Apr 15 09:57:42.929: INFO: Pod "pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.527126ms
Apr 15 09:57:44.933: INFO: Pod "pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007687623s
STEP: Saw pod success
Apr 15 09:57:44.933: INFO: Pod "pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:57:44.937: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 09:57:44.958: INFO: Waiting for pod pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:57:44.962: INFO: Pod pod-secrets-e96e1f36-5f64-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:44.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2222" for this suite.
Apr 15 09:57:50.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:57:51.097: INFO: namespace secrets-2222 deletion completed in 6.13078224s

• [SLOW TEST:8.223 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:57:51.098: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 09:57:51.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 version'
Apr 15 09:57:51.202: INFO: stderr: ""
Apr 15 09:57:51.202: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:51.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8580" for this suite.
Apr 15 09:57:57.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:57:57.317: INFO: namespace kubectl-8580 deletion completed in 6.110146301s

• [SLOW TEST:6.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:57:57.317: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 09:57:57.353: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:57:59.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4945" for this suite.
Apr 15 09:58:37.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:58:37.623: INFO: namespace pods-4945 deletion completed in 38.119141186s

• [SLOW TEST:40.305 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:58:37.623: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 09:58:37.728: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 15 09:58:37.739: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:37.739: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:37.740: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:37.744: INFO: Number of nodes with available pods: 0
Apr 15 09:58:37.744: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:58:38.749: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:38.749: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:38.749: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:38.752: INFO: Number of nodes with available pods: 0
Apr 15 09:58:38.752: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:58:39.749: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:39.749: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:39.749: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:39.752: INFO: Number of nodes with available pods: 1
Apr 15 09:58:39.752: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:58:40.749: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:40.749: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:40.749: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:40.752: INFO: Number of nodes with available pods: 1
Apr 15 09:58:40.752: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:58:41.749: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:41.749: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:41.749: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:41.753: INFO: Number of nodes with available pods: 2
Apr 15 09:58:41.753: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 15 09:58:41.777: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:41.777: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:41.780: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:41.780: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:41.780: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:42.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:42.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:42.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:42.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:42.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:43.784: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:43.784: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:43.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:43.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:43.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:44.784: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:44.784: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:44.784: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:44.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:44.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:44.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:45.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:45.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:45.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:45.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:45.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:45.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:46.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:46.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:46.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:46.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:46.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:46.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:47.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:47.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:47.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:47.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:47.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:47.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:48.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:48.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:48.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:48.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:48.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:48.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:49.784: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:49.784: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:49.784: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:49.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:49.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:49.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:50.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:50.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:50.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:50.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:50.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:50.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:51.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:51.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:51.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:51.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:51.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:51.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:52.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:52.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:52.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:52.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:52.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:52.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:53.784: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:53.784: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:53.784: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:53.787: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:53.787: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:53.787: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:54.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:54.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:54.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:54.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:54.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:54.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:55.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:55.785: INFO: Wrong image for pod: daemon-set-8fzc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:55.785: INFO: Pod daemon-set-8fzc5 is not available
Apr 15 09:58:55.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:55.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:55.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:56.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:56.785: INFO: Pod daemon-set-9zbmc is not available
Apr 15 09:58:56.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:56.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:56.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:57.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:57.785: INFO: Pod daemon-set-9zbmc is not available
Apr 15 09:58:57.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:57.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:57.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:58.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:58.785: INFO: Pod daemon-set-9zbmc is not available
Apr 15 09:58:58.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:58.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:58.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:59.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:58:59.791: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:59.791: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:58:59.791: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:00.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:00.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:00.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:00.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:00.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:01.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:01.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:01.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:01.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:01.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:02.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:02.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:02.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:02.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:02.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:03.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:03.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:03.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:03.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:03.788: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:04.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:04.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:04.788: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:04.788: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:04.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:05.785: INFO: Wrong image for pod: daemon-set-7h6x9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 15 09:59:05.785: INFO: Pod daemon-set-7h6x9 is not available
Apr 15 09:59:05.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:05.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:05.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.785: INFO: Pod daemon-set-hscz5 is not available
Apr 15 09:59:06.789: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.789: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.789: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 15 09:59:06.793: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.793: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.793: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:06.796: INFO: Number of nodes with available pods: 1
Apr 15 09:59:06.797: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 09:59:07.801: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:07.801: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:07.801: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 09:59:07.805: INFO: Number of nodes with available pods: 2
Apr 15 09:59:07.805: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9910, will wait for the garbage collector to delete the pods
Apr 15 09:59:07.903: INFO: Deleting DaemonSet.extensions daemon-set took: 17.834169ms
Apr 15 09:59:08.203: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.163864ms
Apr 15 09:59:16.307: INFO: Number of nodes with available pods: 0
Apr 15 09:59:16.307: INFO: Number of running nodes: 0, number of available pods: 0
Apr 15 09:59:16.310: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9910/daemonsets","resourceVersion":"5683"},"items":null}

Apr 15 09:59:16.313: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9910/pods","resourceVersion":"5683"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:59:16.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9910" for this suite.
Apr 15 09:59:22.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:59:22.437: INFO: namespace daemonsets-9910 deletion completed in 6.111963804s

• [SLOW TEST:44.815 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:59:22.439: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 15 09:59:22.482: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:59:25.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3229" for this suite.
Apr 15 09:59:31.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:59:31.588: INFO: namespace init-container-3229 deletion completed in 6.134179129s

• [SLOW TEST:9.149 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:59:31.588: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 09:59:31.642: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-8102" to be "success or failure"
Apr 15 09:59:31.651: INFO: Pod "downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 9.47936ms
Apr 15 09:59:33.656: INFO: Pod "downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014369915s
STEP: Saw pod success
Apr 15 09:59:33.656: INFO: Pod "downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 09:59:33.660: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 09:59:33.682: INFO: Waiting for pod downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 09:59:33.684: INFO: Pod downwardapi-volume-2a3a4115-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 09:59:33.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8102" for this suite.
Apr 15 09:59:39.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 09:59:39.800: INFO: namespace downward-api-8102 deletion completed in 6.112162205s

• [SLOW TEST:8.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 09:59:39.800: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 15 09:59:39.846: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5829,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 15 09:59:39.846: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5829,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 15 09:59:49.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5850,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 15 09:59:49.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5850,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 15 09:59:59.867: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5869,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 15 09:59:59.867: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5869,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 15 10:00:09.876: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5889,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 15 10:00:09.876: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-a,UID:2f1e9c32-5f65-11e9-adae-06c5682e2662,ResourceVersion:5889,Generation:0,CreationTimestamp:2019-04-15 09:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 15 10:00:19.885: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-b,UID:46fc2ff4-5f65-11e9-adae-06c5682e2662,ResourceVersion:5909,Generation:0,CreationTimestamp:2019-04-15 10:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 15 10:00:19.885: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-b,UID:46fc2ff4-5f65-11e9-adae-06c5682e2662,ResourceVersion:5909,Generation:0,CreationTimestamp:2019-04-15 10:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 15 10:00:29.894: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-b,UID:46fc2ff4-5f65-11e9-adae-06c5682e2662,ResourceVersion:5928,Generation:0,CreationTimestamp:2019-04-15 10:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 15 10:00:29.894: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9394,SelfLink:/api/v1/namespaces/watch-9394/configmaps/e2e-watch-test-configmap-b,UID:46fc2ff4-5f65-11e9-adae-06c5682e2662,ResourceVersion:5928,Generation:0,CreationTimestamp:2019-04-15 10:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:00:39.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9394" for this suite.
Apr 15 10:00:45.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:00:46.029: INFO: namespace watch-9394 deletion completed in 6.129725356s

• [SLOW TEST:66.229 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:00:46.029: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 10:00:46.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5336'
Apr 15 10:00:46.327: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 15 10:00:46.327: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 15 10:00:48.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5336'
Apr 15 10:00:48.413: INFO: stderr: ""
Apr 15 10:00:48.413: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:00:48.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5336" for this suite.
Apr 15 10:01:10.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:01:10.577: INFO: namespace kubectl-5336 deletion completed in 22.159763301s

• [SLOW TEST:24.548 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:01:10.577: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-g6s8
STEP: Creating a pod to test atomic-volume-subpath
Apr 15 10:01:10.639: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-g6s8" in namespace "subpath-2344" to be "success or failure"
Apr 15 10:01:10.645: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.856803ms
Apr 15 10:01:12.649: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 2.009988642s
Apr 15 10:01:14.653: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 4.014077833s
Apr 15 10:01:16.657: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 6.01819495s
Apr 15 10:01:18.663: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 8.023849294s
Apr 15 10:01:20.667: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 10.02840046s
Apr 15 10:01:22.672: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 12.032916262s
Apr 15 10:01:24.676: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 14.036826397s
Apr 15 10:01:26.681: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 16.04198049s
Apr 15 10:01:28.685: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 18.046292267s
Apr 15 10:01:30.689: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Running", Reason="", readiness=true. Elapsed: 20.050163312s
Apr 15 10:01:32.694: INFO: Pod "pod-subpath-test-downwardapi-g6s8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055008036s
STEP: Saw pod success
Apr 15 10:01:32.694: INFO: Pod "pod-subpath-test-downwardapi-g6s8" satisfied condition "success or failure"
Apr 15 10:01:32.697: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-g6s8 container test-container-subpath-downwardapi-g6s8: <nil>
STEP: delete the pod
Apr 15 10:01:32.726: INFO: Waiting for pod pod-subpath-test-downwardapi-g6s8 to disappear
Apr 15 10:01:32.729: INFO: Pod pod-subpath-test-downwardapi-g6s8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-g6s8
Apr 15 10:01:32.729: INFO: Deleting pod "pod-subpath-test-downwardapi-g6s8" in namespace "subpath-2344"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:01:32.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2344" for this suite.
Apr 15 10:01:38.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:01:38.881: INFO: namespace subpath-2344 deletion completed in 6.144854849s

• [SLOW TEST:28.304 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:01:38.882: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 15 10:01:38.923: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:01:42.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9928" for this suite.
Apr 15 10:02:04.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:02:04.795: INFO: namespace init-container-9928 deletion completed in 22.16035343s

• [SLOW TEST:25.913 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:02:04.795: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 15 10:02:07.433: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8593d41f-5f65-11e9-a7dc-a6e5a2dd4982"
Apr 15 10:02:07.433: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8593d41f-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "pods-9240" to be "terminated due to deadline exceeded"
Apr 15 10:02:07.438: INFO: Pod "pod-update-activedeadlineseconds-8593d41f-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Running", Reason="", readiness=true. Elapsed: 4.722499ms
Apr 15 10:02:09.441: INFO: Pod "pod-update-activedeadlineseconds-8593d41f-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.008478608s
Apr 15 10:02:09.441: INFO: Pod "pod-update-activedeadlineseconds-8593d41f-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:02:09.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9240" for this suite.
Apr 15 10:02:17.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:02:17.595: INFO: namespace pods-9240 deletion completed in 8.149301532s

• [SLOW TEST:12.800 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:02:17.595: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6025.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6025.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6025.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6025.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6025.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6025.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 15 10:02:31.757: INFO: DNS probes using dns-6025/dns-test-8d34c646-5f65-11e9-a7dc-a6e5a2dd4982 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:02:31.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6025" for this suite.
Apr 15 10:02:37.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:02:37.958: INFO: namespace dns-6025 deletion completed in 6.174534156s

• [SLOW TEST:20.363 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:02:37.959: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 15 10:02:40.602: INFO: Successfully updated pod "annotationupdate9957a03f-5f65-11e9-a7dc-a6e5a2dd4982"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:02:44.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2294" for this suite.
Apr 15 10:03:06.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:06.749: INFO: namespace downward-api-2294 deletion completed in 22.121368694s

• [SLOW TEST:28.790 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:06.749: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 15 10:03:06.791: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 15 10:03:06.799: INFO: Waiting for terminating namespaces to be deleted...
Apr 15 10:03:06.802: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-206.eu-west-1.compute.internal before test
Apr 15 10:03:06.808: INFO: kube-proxy-p22f4 from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:03:06.808: INFO: calico-node-jf886 from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container calico-node ready: true, restart count 0
Apr 15 10:03:06.808: INFO: coredns-fb8b8dccf-wzk6q from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:03:06.808: INFO: calico-kube-controllers-5cbcccc885-9wk5c from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Apr 15 10:03:06.808: INFO: calico-typha-6ddbb994-brhgt from kube-system started at 2019-04-15 09:54:03 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container calico-typha ready: true, restart count 0
Apr 15 10:03:06.808: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-95t5f from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:03:06.808: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:03:06.808: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:03:06.808: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-88.eu-west-1.compute.internal before test
Apr 15 10:03:06.827: INFO: kube-proxy-ktvkt from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:03:06.827: INFO: calico-node-sjhhv from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container calico-node ready: true, restart count 0
Apr 15 10:03:06.827: INFO: calicoctl from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container calicoctl ready: true, restart count 0
Apr 15 10:03:06.827: INFO: coredns-fb8b8dccf-khkh8 from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:03:06.827: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-15 09:55:01 +0000 UTC (1 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 15 10:03:06.827: INFO: sonobuoy-e2e-job-b24a9b66ba984d5a from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container e2e ready: true, restart count 0
Apr 15 10:03:06.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:03:06.827: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-phs4j from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:03:06.827: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:03:06.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-0-1-206.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod sonobuoy-e2e-job-b24a9b66ba984d5a requesting resource cpu=0m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-95t5f requesting resource cpu=0m on Node ip-10-0-1-206.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-phs4j requesting resource cpu=0m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod calico-kube-controllers-5cbcccc885-9wk5c requesting resource cpu=0m on Node ip-10-0-1-206.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod calico-node-jf886 requesting resource cpu=250m on Node ip-10-0-1-206.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod calico-node-sjhhv requesting resource cpu=250m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod calico-typha-6ddbb994-brhgt requesting resource cpu=0m on Node ip-10-0-1-206.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod calicoctl requesting resource cpu=0m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod coredns-fb8b8dccf-khkh8 requesting resource cpu=100m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod coredns-fb8b8dccf-wzk6q requesting resource cpu=100m on Node ip-10-0-1-206.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod kube-proxy-ktvkt requesting resource cpu=0m on Node ip-10-0-3-88.eu-west-1.compute.internal
Apr 15 10:03:06.875: INFO: Pod kube-proxy-p22f4 requesting resource cpu=0m on Node ip-10-0-1-206.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982.15959da6fec6123d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9924/filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982 to ip-10-0-1-206.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982.15959da72189d2e9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982.15959da725715cfc], Reason = [Created], Message = [Created container filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982.15959da72afa3582], Reason = [Started], Message = [Started container filler-pod-aa861324-5f65-11e9-a7dc-a6e5a2dd4982]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982.15959da6ff40a3fc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9924/filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982 to ip-10-0-3-88.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982.15959da723e8b93b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982.15959da72820499d], Reason = [Created], Message = [Created container filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982.15959da72d48d3e6], Reason = [Started], Message = [Started container filler-pod-aa87c43d-5f65-11e9-a7dc-a6e5a2dd4982]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15959da777a9d018], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-10-0-3-88.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-1-206.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:09.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9924" for this suite.
Apr 15 10:03:15.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:16.078: INFO: namespace sched-pred-9924 deletion completed in 6.11440126s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.328 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:16.078: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:03:16.115: INFO: Creating ReplicaSet my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982
Apr 15 10:03:16.127: INFO: Pod name my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982: Found 0 pods out of 1
Apr 15 10:03:21.131: INFO: Pod name my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982: Found 1 pods out of 1
Apr 15 10:03:21.131: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982" is running
Apr 15 10:03:21.134: INFO: Pod "my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982-wvc8b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:03:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:03:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:03:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:03:16 +0000 UTC Reason: Message:}])
Apr 15 10:03:21.134: INFO: Trying to dial the pod
Apr 15 10:03:26.146: INFO: Controller my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982: Got expected result from replica 1 [my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982-wvc8b]: "my-hostname-basic-b007d83b-5f65-11e9-a7dc-a6e5a2dd4982-wvc8b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:26.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-345" for this suite.
Apr 15 10:03:32.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:32.262: INFO: namespace replicaset-345 deletion completed in 6.112426211s

• [SLOW TEST:16.184 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:32.263: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 15 10:03:32.315: INFO: Waiting up to 5m0s for pod "downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-3848" to be "success or failure"
Apr 15 10:03:32.319: INFO: Pod "downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789505ms
Apr 15 10:03:34.323: INFO: Pod "downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007675518s
STEP: Saw pod success
Apr 15 10:03:34.323: INFO: Pod "downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:03:34.326: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:03:34.348: INFO: Waiting for pod downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:03:34.351: INFO: Pod downward-api-b9ae12b4-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:34.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3848" for this suite.
Apr 15 10:03:40.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:40.482: INFO: namespace downward-api-3848 deletion completed in 6.127506245s

• [SLOW TEST:8.219 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:40.482: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:03:40.532: INFO: (0) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.49744ms)
Apr 15 10:03:40.536: INFO: (1) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.88146ms)
Apr 15 10:03:40.540: INFO: (2) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.814468ms)
Apr 15 10:03:40.544: INFO: (3) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.657449ms)
Apr 15 10:03:40.548: INFO: (4) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.618805ms)
Apr 15 10:03:40.551: INFO: (5) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.681893ms)
Apr 15 10:03:40.555: INFO: (6) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.742219ms)
Apr 15 10:03:40.560: INFO: (7) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.690106ms)
Apr 15 10:03:40.564: INFO: (8) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.939145ms)
Apr 15 10:03:40.568: INFO: (9) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.895442ms)
Apr 15 10:03:40.572: INFO: (10) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.236723ms)
Apr 15 10:03:40.586: INFO: (11) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.886609ms)
Apr 15 10:03:40.591: INFO: (12) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.251655ms)
Apr 15 10:03:40.599: INFO: (13) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.116371ms)
Apr 15 10:03:40.603: INFO: (14) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.272586ms)
Apr 15 10:03:40.608: INFO: (15) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.521308ms)
Apr 15 10:03:40.612: INFO: (16) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.901197ms)
Apr 15 10:03:40.616: INFO: (17) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.033833ms)
Apr 15 10:03:40.620: INFO: (18) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.888521ms)
Apr 15 10:03:40.624: INFO: (19) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.405691ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:40.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-515" for this suite.
Apr 15 10:03:46.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:46.741: INFO: namespace proxy-515 deletion completed in 6.113353153s

• [SLOW TEST:6.259 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:46.742: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:03:46.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "projected-4045" to be "success or failure"
Apr 15 10:03:46.847: INFO: Pod "downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.934153ms
Apr 15 10:03:48.851: INFO: Pod "downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010030133s
STEP: Saw pod success
Apr 15 10:03:48.851: INFO: Pod "downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:03:48.855: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:03:48.881: INFO: Waiting for pod downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:03:48.884: INFO: Pod downwardapi-volume-c256a425-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:48.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4045" for this suite.
Apr 15 10:03:54.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:03:55.018: INFO: namespace projected-4045 deletion completed in 6.129366756s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:03:55.019: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c740e7e7-5f65-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:03:55.106: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-2781" to be "success or failure"
Apr 15 10:03:55.116: INFO: Pod "pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 10.283332ms
Apr 15 10:03:57.121: INFO: Pod "pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014520464s
STEP: Saw pod success
Apr 15 10:03:57.121: INFO: Pod "pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:03:57.124: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:03:57.149: INFO: Waiting for pod pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:03:57.152: INFO: Pod pod-configmaps-c7432314-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:03:57.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2781" for this suite.
Apr 15 10:04:03.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:03.289: INFO: namespace configmap-2781 deletion completed in 6.133773271s

• [SLOW TEST:8.270 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:03.289: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 10:04:03.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7094'
Apr 15 10:04:03.467: INFO: stderr: ""
Apr 15 10:04:03.467: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 15 10:04:08.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pod e2e-test-nginx-pod --namespace=kubectl-7094 -o json'
Apr 15 10:04:08.581: INFO: stderr: ""
Apr 15 10:04:08.581: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.14.31/32\"\n        },\n        \"creationTimestamp\": \"2019-04-15T10:04:03Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7094\",\n        \"resourceVersion\": \"6813\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7094/pods/e2e-test-nginx-pod\",\n        \"uid\": \"cc3d8925-5f65-11e9-bacc-02b684a18ad6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7p4xf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-1-206.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7p4xf\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7p4xf\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-15T10:04:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-15T10:04:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-15T10:04:05Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-15T10:04:03Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://3b5c0aa03afdf040249f8bcca5df07e5677e1940b4bedc5fbc85f9363fc6718c\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-15T10:04:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.1.206\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.14.31\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-15T10:04:03Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 15 10:04:08.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 replace -f - --namespace=kubectl-7094'
Apr 15 10:04:08.803: INFO: stderr: ""
Apr 15 10:04:08.803: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 15 10:04:08.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete pods e2e-test-nginx-pod --namespace=kubectl-7094'
Apr 15 10:04:11.110: INFO: stderr: ""
Apr 15 10:04:11.110: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:04:11.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7094" for this suite.
Apr 15 10:04:17.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:17.229: INFO: namespace kubectl-7094 deletion completed in 6.114957827s

• [SLOW TEST:13.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:17.229: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d47ab0a5-5f65-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:04:17.282: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "projected-9952" to be "success or failure"
Apr 15 10:04:17.287: INFO: Pod "pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.95655ms
Apr 15 10:04:19.291: INFO: Pod "pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009555096s
STEP: Saw pod success
Apr 15 10:04:19.291: INFO: Pod "pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:04:19.296: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:04:19.321: INFO: Waiting for pod pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:04:19.325: INFO: Pod pod-projected-secrets-d47bed50-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:04:19.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9952" for this suite.
Apr 15 10:04:25.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:25.555: INFO: namespace projected-9952 deletion completed in 6.225218338s

• [SLOW TEST:8.326 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:25.555: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-d9741368-5f65-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:04:25.632: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "projected-3117" to be "success or failure"
Apr 15 10:04:25.638: INFO: Pod "pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.704192ms
Apr 15 10:04:27.642: INFO: Pod "pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009602004s
STEP: Saw pod success
Apr 15 10:04:27.642: INFO: Pod "pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:04:27.646: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:04:27.673: INFO: Waiting for pod pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:04:27.676: INFO: Pod pod-projected-secrets-d9757af6-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:04:27.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3117" for this suite.
Apr 15 10:04:33.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:33.799: INFO: namespace projected-3117 deletion completed in 6.118772063s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:33.800: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 15 10:04:33.864: INFO: Waiting up to 5m0s for pod "downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-95" to be "success or failure"
Apr 15 10:04:33.868: INFO: Pod "downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677207ms
Apr 15 10:04:35.872: INFO: Pod "downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007688811s
STEP: Saw pod success
Apr 15 10:04:35.872: INFO: Pod "downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:04:35.875: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:04:35.896: INFO: Waiting for pod downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:04:35.899: INFO: Pod downward-api-de5d8d00-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:04:35.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-95" for this suite.
Apr 15 10:04:41.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:42.036: INFO: namespace downward-api-95 deletion completed in 6.132943116s

• [SLOW TEST:8.236 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:42.036: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e34e0a68-5f65-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:04:42.157: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "projected-1770" to be "success or failure"
Apr 15 10:04:42.162: INFO: Pod "pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.810235ms
Apr 15 10:04:44.166: INFO: Pod "pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009242962s
STEP: Saw pod success
Apr 15 10:04:44.166: INFO: Pod "pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:04:44.169: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:04:44.195: INFO: Waiting for pod pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:04:44.198: INFO: Pod pod-projected-configmaps-e34f3796-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:04:44.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1770" for this suite.
Apr 15 10:04:50.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:04:50.318: INFO: namespace projected-1770 deletion completed in 6.11661677s

• [SLOW TEST:8.282 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:04:50.319: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 15 10:04:50.880: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 15 10:04:52.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:04:54.936: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:04:56.936: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:04:58.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690919490, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:05:01.665: INFO: Waited 722.099889ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:05:02.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6781" for this suite.
Apr 15 10:05:08.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:05:08.508: INFO: namespace aggregator-6781 deletion completed in 6.321848922s

• [SLOW TEST:18.189 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:05:08.508: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f30be968-5f65-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:05:08.593: INFO: Waiting up to 5m0s for pod "pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-9530" to be "success or failure"
Apr 15 10:05:08.605: INFO: Pod "pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385431ms
Apr 15 10:05:10.609: INFO: Pod "pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016359024s
STEP: Saw pod success
Apr 15 10:05:10.609: INFO: Pod "pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:05:10.612: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982 container secret-env-test: <nil>
STEP: delete the pod
Apr 15 10:05:10.635: INFO: Waiting for pod pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:05:10.638: INFO: Pod pod-secrets-f30eef55-5f65-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:05:10.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9530" for this suite.
Apr 15 10:05:16.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:05:16.812: INFO: namespace secrets-9530 deletion completed in 6.169487582s

• [SLOW TEST:8.303 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:05:16.812: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 15 10:05:16.860: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 15 10:05:21.864: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:05:22.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8094" for this suite.
Apr 15 10:05:28.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:05:29.006: INFO: namespace replication-controller-8094 deletion completed in 6.116494576s

• [SLOW TEST:12.194 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:05:29.008: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 10:05:29.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2494'
Apr 15 10:05:29.122: INFO: stderr: ""
Apr 15 10:05:29.122: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 15 10:05:29.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete pods e2e-test-nginx-pod --namespace=kubectl-2494'
Apr 15 10:05:36.233: INFO: stderr: ""
Apr 15 10:05:36.233: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:05:36.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2494" for this suite.
Apr 15 10:05:42.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:05:42.352: INFO: namespace kubectl-2494 deletion completed in 6.113711003s

• [SLOW TEST:13.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:05:42.352: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9635
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 15 10:05:42.464: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 15 10:06:02.550: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.126.199:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9635 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:06:02.550: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:06:02.693: INFO: Found all expected endpoints: [netserver-0]
Apr 15 10:06:02.697: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.14.41:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9635 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:06:02.697: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:06:02.851: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:06:02.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9635" for this suite.
Apr 15 10:06:26.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:06:26.972: INFO: namespace pod-network-test-9635 deletion completed in 24.116484495s

• [SLOW TEST:44.621 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:06:26.973: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:06:27.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-6963" to be "success or failure"
Apr 15 10:06:27.034: INFO: Pod "downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.651849ms
Apr 15 10:06:29.038: INFO: Pod "downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008591064s
STEP: Saw pod success
Apr 15 10:06:29.038: INFO: Pod "downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:06:29.042: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:06:29.062: INFO: Waiting for pod downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:06:29.066: INFO: Pod downwardapi-volume-21d0e645-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:06:29.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6963" for this suite.
Apr 15 10:06:35.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:06:35.226: INFO: namespace downward-api-6963 deletion completed in 6.15568008s

• [SLOW TEST:8.252 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:06:35.226: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 15 10:06:35.265: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 15 10:06:35.273: INFO: Waiting for terminating namespaces to be deleted...
Apr 15 10:06:35.277: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-206.eu-west-1.compute.internal before test
Apr 15 10:06:35.285: INFO: kube-proxy-p22f4 from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:06:35.285: INFO: calico-node-jf886 from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container calico-node ready: true, restart count 0
Apr 15 10:06:35.285: INFO: coredns-fb8b8dccf-wzk6q from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:06:35.285: INFO: calico-kube-controllers-5cbcccc885-9wk5c from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Apr 15 10:06:35.285: INFO: calico-typha-6ddbb994-brhgt from kube-system started at 2019-04-15 09:54:03 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container calico-typha ready: true, restart count 0
Apr 15 10:06:35.285: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-95t5f from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:06:35.285: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:06:35.285: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:06:35.285: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-88.eu-west-1.compute.internal before test
Apr 15 10:06:35.291: INFO: calico-node-sjhhv from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container calico-node ready: true, restart count 0
Apr 15 10:06:35.291: INFO: coredns-fb8b8dccf-khkh8 from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:06:35.291: INFO: kube-proxy-ktvkt from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:06:35.291: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-15 09:55:01 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 15 10:06:35.291: INFO: sonobuoy-e2e-job-b24a9b66ba984d5a from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container e2e ready: true, restart count 0
Apr 15 10:06:35.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:06:35.291: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-phs4j from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:06:35.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:06:35.291: INFO: calicoctl from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:06:35.291: INFO: 	Container calicoctl ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-27f821f7-5f66-11e9-a7dc-a6e5a2dd4982 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-27f821f7-5f66-11e9-a7dc-a6e5a2dd4982 off the node ip-10-0-1-206.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-27f821f7-5f66-11e9-a7dc-a6e5a2dd4982
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:06:39.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2115" for this suite.
Apr 15 10:06:59.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:06:59.513: INFO: namespace sched-pred-2115 deletion completed in 20.115166974s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.287 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:06:59.514: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:06:59.572: INFO: Create a RollingUpdate DaemonSet
Apr 15 10:06:59.580: INFO: Check that daemon pods launch on every node of the cluster
Apr 15 10:06:59.583: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:06:59.583: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:06:59.583: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:06:59.586: INFO: Number of nodes with available pods: 0
Apr 15 10:06:59.586: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:07:00.591: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:00.591: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:00.591: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:00.598: INFO: Number of nodes with available pods: 2
Apr 15 10:07:00.598: INFO: Number of running nodes: 2, number of available pods: 2
Apr 15 10:07:00.598: INFO: Update the DaemonSet to trigger a rollout
Apr 15 10:07:00.608: INFO: Updating DaemonSet daemon-set
Apr 15 10:07:04.618: INFO: Roll back the DaemonSet before rollout is complete
Apr 15 10:07:04.626: INFO: Updating DaemonSet daemon-set
Apr 15 10:07:04.626: INFO: Make sure DaemonSet rollback is complete
Apr 15 10:07:04.630: INFO: Wrong image for pod: daemon-set-p5lsz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 15 10:07:04.630: INFO: Pod daemon-set-p5lsz is not available
Apr 15 10:07:04.633: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:04.633: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:04.633: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:05.637: INFO: Wrong image for pod: daemon-set-p5lsz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 15 10:07:05.637: INFO: Pod daemon-set-p5lsz is not available
Apr 15 10:07:05.641: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:05.641: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:05.641: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:06.638: INFO: Pod daemon-set-5xsns is not available
Apr 15 10:07:06.641: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:06.641: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:07:06.642: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9814, will wait for the garbage collector to delete the pods
Apr 15 10:07:06.712: INFO: Deleting DaemonSet.extensions daemon-set took: 9.445085ms
Apr 15 10:07:07.012: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.180038ms
Apr 15 10:08:38.616: INFO: Number of nodes with available pods: 0
Apr 15 10:08:38.616: INFO: Number of running nodes: 0, number of available pods: 0
Apr 15 10:08:38.619: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9814/daemonsets","resourceVersion":"7972"},"items":null}

Apr 15 10:08:38.622: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9814/pods","resourceVersion":"7972"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:08:38.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9814" for this suite.
Apr 15 10:08:44.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:08:44.748: INFO: namespace daemonsets-9814 deletion completed in 6.111645572s

• [SLOW TEST:105.233 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:08:44.748: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 15 10:08:44.801: INFO: Waiting up to 5m0s for pod "pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-9891" to be "success or failure"
Apr 15 10:08:44.807: INFO: Pod "pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542458ms
Apr 15 10:08:46.811: INFO: Pod "pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009607009s
STEP: Saw pod success
Apr 15 10:08:46.811: INFO: Pod "pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:08:46.814: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:08:46.838: INFO: Waiting for pod pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:08:46.840: INFO: Pod pod-73efb4df-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:08:46.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9891" for this suite.
Apr 15 10:08:52.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:08:52.970: INFO: namespace emptydir-9891 deletion completed in 6.125428398s

• [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:08:52.970: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:08:55.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9297" for this suite.
Apr 15 10:09:33.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:09:33.182: INFO: namespace kubelet-test-9297 deletion completed in 38.130358496s

• [SLOW TEST:40.213 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:09:33.183: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 15 10:09:33.232: INFO: Waiting up to 5m0s for pod "pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-2892" to be "success or failure"
Apr 15 10:09:33.238: INFO: Pod "pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.531256ms
Apr 15 10:09:35.242: INFO: Pod "pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009807633s
STEP: Saw pod success
Apr 15 10:09:35.242: INFO: Pod "pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:09:35.245: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:09:35.266: INFO: Waiting for pod pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:09:35.269: INFO: Pod pod-90cd9993-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:09:35.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2892" for this suite.
Apr 15 10:09:41.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:09:41.383: INFO: namespace emptydir-2892 deletion completed in 6.109867035s

• [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:09:41.383: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:09:41.434: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-3980" to be "success or failure"
Apr 15 10:09:41.439: INFO: Pod "downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706111ms
Apr 15 10:09:43.443: INFO: Pod "downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009273609s
STEP: Saw pod success
Apr 15 10:09:43.443: INFO: Pod "downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:09:43.448: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:09:43.468: INFO: Waiting for pod downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:09:43.471: INFO: Pod downwardapi-volume-95b10262-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:09:43.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3980" for this suite.
Apr 15 10:09:49.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:09:49.586: INFO: namespace downward-api-3980 deletion completed in 6.111081977s

• [SLOW TEST:8.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:09:49.586: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4517
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-4517
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4517
Apr 15 10:09:49.645: INFO: Found 0 stateful pods, waiting for 1
Apr 15 10:09:59.649: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 15 10:09:59.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:09:59.845: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:09:59.845: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:09:59.845: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:09:59.849: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 15 10:10:09.854: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:10:09.854: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:10:09.869: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:09.869: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:09.869: INFO: 
Apr 15 10:10:09.869: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 15 10:10:10.873: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996623321s
Apr 15 10:10:11.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992297366s
Apr 15 10:10:12.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987686845s
Apr 15 10:10:13.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982954437s
Apr 15 10:10:14.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978528179s
Apr 15 10:10:15.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973106006s
Apr 15 10:10:16.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968907873s
Apr 15 10:10:17.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96450687s
Apr 15 10:10:18.910: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.072527ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4517
Apr 15 10:10:19.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:10:20.112: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:10:20.113: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:10:20.113: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:10:20.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:10:20.316: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 15 10:10:20.316: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:10:20.316: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:10:20.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:10:20.511: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 15 10:10:20.511: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:10:20.511: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:10:20.516: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 15 10:10:30.521: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:10:30.521: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:10:30.521: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 15 10:10:30.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:10:30.737: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:10:30.737: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:10:30.737: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:10:30.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:10:30.935: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:10:30.935: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:10:30.935: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:10:30.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-4517 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:10:31.180: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:10:31.180: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:10:31.180: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:10:31.180: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:10:31.184: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 15 10:10:41.191: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:10:41.191: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:10:41.191: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:10:41.202: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:41.202: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:41.202: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:41.202: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:41.202: INFO: 
Apr 15 10:10:41.202: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:42.207: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:42.207: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:42.207: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:42.207: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:42.207: INFO: 
Apr 15 10:10:42.207: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:43.211: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:43.211: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:43.211: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:43.211: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:43.211: INFO: 
Apr 15 10:10:43.211: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:44.218: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:44.218: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:44.218: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:44.218: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:44.218: INFO: 
Apr 15 10:10:44.218: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:45.223: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:45.223: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:45.223: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:45.223: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:45.223: INFO: 
Apr 15 10:10:45.223: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:46.228: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Apr 15 10:10:46.228: INFO: ss-0  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:09:49 +0000 UTC  }]
Apr 15 10:10:46.228: INFO: ss-1  ip-10-0-3-88.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:46.228: INFO: ss-2  ip-10-0-1-206.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:10:09 +0000 UTC  }]
Apr 15 10:10:46.228: INFO: 
Apr 15 10:10:46.228: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 15 10:10:47.232: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.971306206s
Apr 15 10:10:48.236: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.967495715s
Apr 15 10:10:49.240: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.963462238s
Apr 15 10:10:50.246: INFO: Verifying statefulset ss doesn't scale past 0 for another 958.461597ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4517
Apr 15 10:10:51.250: INFO: Scaling statefulset ss to 0
Apr 15 10:10:51.261: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 15 10:10:51.264: INFO: Deleting all statefulset in ns statefulset-4517
Apr 15 10:10:51.267: INFO: Scaling statefulset ss to 0
Apr 15 10:10:51.276: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:10:51.279: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:10:51.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4517" for this suite.
Apr 15 10:10:57.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:10:57.404: INFO: namespace statefulset-4517 deletion completed in 6.108318726s

• [SLOW TEST:67.818 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:10:57.406: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:10:57.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "projected-3226" to be "success or failure"
Apr 15 10:10:57.461: INFO: Pod "downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.614574ms
Apr 15 10:10:59.465: INFO: Pod "downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009663093s
STEP: Saw pod success
Apr 15 10:10:59.466: INFO: Pod "downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:10:59.469: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:10:59.498: INFO: Waiting for pod downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:10:59.505: INFO: Pod downwardapi-volume-c3013de1-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:10:59.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3226" for this suite.
Apr 15 10:11:05.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:11:05.645: INFO: namespace projected-3226 deletion completed in 6.135013875s

• [SLOW TEST:8.239 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:11:05.645: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 15 10:11:05.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-9738'
Apr 15 10:11:06.165: INFO: stderr: ""
Apr 15 10:11:06.165: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 15 10:11:07.170: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:11:07.170: INFO: Found 0 / 1
Apr 15 10:11:08.170: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:11:08.170: INFO: Found 1 / 1
Apr 15 10:11:08.170: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 15 10:11:08.173: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:11:08.173: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 15 10:11:08.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 patch pod redis-master-q7drl --namespace=kubectl-9738 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 15 10:11:08.258: INFO: stderr: ""
Apr 15 10:11:08.258: INFO: stdout: "pod/redis-master-q7drl patched\n"
STEP: checking annotations
Apr 15 10:11:08.261: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:11:08.261: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:11:08.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9738" for this suite.
Apr 15 10:11:30.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:11:30.373: INFO: namespace kubectl-9738 deletion completed in 22.107497594s

• [SLOW TEST:24.728 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:11:30.374: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 15 10:11:30.412: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357557484 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:11:30.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1902" for this suite.
Apr 15 10:11:36.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:11:36.659: INFO: namespace kubectl-1902 deletion completed in 6.179123328s

• [SLOW TEST:6.284 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:11:36.660: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 15 10:11:36.771: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:36.772: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:36.772: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:36.779: INFO: Number of nodes with available pods: 0
Apr 15 10:11:36.779: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:37.784: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:37.784: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:37.784: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:37.788: INFO: Number of nodes with available pods: 1
Apr 15 10:11:37.788: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:38.783: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.783: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.784: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.787: INFO: Number of nodes with available pods: 2
Apr 15 10:11:38.787: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 15 10:11:38.805: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.805: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.805: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:38.808: INFO: Number of nodes with available pods: 1
Apr 15 10:11:38.808: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:39.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:39.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:39.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:39.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:39.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:40.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:40.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:40.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:40.816: INFO: Number of nodes with available pods: 1
Apr 15 10:11:40.816: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:41.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:41.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:41.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:41.816: INFO: Number of nodes with available pods: 1
Apr 15 10:11:41.816: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:42.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:42.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:42.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:42.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:42.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:43.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:43.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:43.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:43.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:43.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:44.814: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:44.814: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:44.814: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:44.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:44.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:45.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:45.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:45.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:45.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:45.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:46.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:46.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:46.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:46.817: INFO: Number of nodes with available pods: 1
Apr 15 10:11:46.817: INFO: Node ip-10-0-3-88.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:11:47.813: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:47.813: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:47.813: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:11:47.816: INFO: Number of nodes with available pods: 2
Apr 15 10:11:47.816: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1367, will wait for the garbage collector to delete the pods
Apr 15 10:11:47.882: INFO: Deleting DaemonSet.extensions daemon-set took: 8.932256ms
Apr 15 10:11:48.182: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.20739ms
Apr 15 10:11:56.286: INFO: Number of nodes with available pods: 0
Apr 15 10:11:56.286: INFO: Number of running nodes: 0, number of available pods: 0
Apr 15 10:11:56.289: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1367/daemonsets","resourceVersion":"8839"},"items":null}

Apr 15 10:11:56.292: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1367/pods","resourceVersion":"8839"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:11:56.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1367" for this suite.
Apr 15 10:12:02.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:12:02.416: INFO: namespace daemonsets-1367 deletion completed in 6.110686652s

• [SLOW TEST:25.756 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:12:02.416: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-e9c0a82a-5f66-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:12:02.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-7898" to be "success or failure"
Apr 15 10:12:02.481: INFO: Pod "pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 8.855485ms
Apr 15 10:12:04.485: INFO: Pod "pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012851596s
STEP: Saw pod success
Apr 15 10:12:04.485: INFO: Pod "pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:12:04.488: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:12:04.512: INFO: Waiting for pod pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:12:04.514: INFO: Pod pod-configmaps-e9c23fa3-5f66-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:12:04.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7898" for this suite.
Apr 15 10:12:10.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:12:10.637: INFO: namespace configmap-7898 deletion completed in 6.118474302s

• [SLOW TEST:8.221 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:12:10.637: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-eea72b52-5f66-11e9-a7dc-a6e5a2dd4982
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:12:10.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7662" for this suite.
Apr 15 10:12:16.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:12:16.788: INFO: namespace configmap-7662 deletion completed in 6.108180782s

• [SLOW TEST:6.151 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:12:16.788: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6076
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6076
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6076
Apr 15 10:12:16.848: INFO: Found 0 stateful pods, waiting for 1
Apr 15 10:12:26.853: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 15 10:12:26.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:12:27.088: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:12:27.088: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:12:27.088: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:12:27.092: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 15 10:12:37.103: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:12:37.103: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:12:37.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999778s
Apr 15 10:12:38.149: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989066908s
Apr 15 10:12:39.153: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981102929s
Apr 15 10:12:40.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977130267s
Apr 15 10:12:41.163: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.973226318s
Apr 15 10:12:42.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.967238347s
Apr 15 10:12:43.171: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963266652s
Apr 15 10:12:44.175: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.959226852s
Apr 15 10:12:45.179: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.955410651s
Apr 15 10:12:46.183: INFO: Verifying statefulset ss doesn't scale past 1 for another 950.837831ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6076
Apr 15 10:12:47.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:12:47.368: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:12:47.368: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:12:47.368: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:12:47.373: INFO: Found 1 stateful pods, waiting for 3
Apr 15 10:12:57.377: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:12:57.378: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:12:57.378: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 15 10:12:57.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:12:57.570: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:12:57.570: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:12:57.570: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:12:57.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:12:57.761: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:12:57.761: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:12:57.761: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:12:57.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:12:57.935: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:12:57.935: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:12:57.935: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:12:57.935: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:12:57.940: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 15 10:13:07.949: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:13:07.949: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:13:07.949: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 15 10:13:07.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999787s
Apr 15 10:13:08.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991869274s
Apr 15 10:13:09.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987471103s
Apr 15 10:13:10.981: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982828182s
Apr 15 10:13:11.986: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978612547s
Apr 15 10:13:12.994: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9735582s
Apr 15 10:13:13.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965540147s
Apr 15 10:13:15.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961242895s
Apr 15 10:13:16.006: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957125446s
Apr 15 10:13:17.011: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.830478ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6076
Apr 15 10:13:18.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:18.204: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:13:18.204: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:13:18.204: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:13:18.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:18.424: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:13:18.424: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:13:18.424: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:13:18.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:18.642: INFO: rc: 137
Apr 15 10:13:18.642: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  + mvcommand terminated with exit code 137
 [] <nil> 0xc002ca6690 exit status 137 <nil> <nil> true [0xc00187cca8 0xc00187cd68 0xc00187ce58] [0xc00187cca8 0xc00187cd68 0xc00187ce58] [0xc00187cd48 0xc00187ce10] [0x9bf9f0 0x9bf9f0] 0xc002ac02a0 <nil>}:
Command stdout:

stderr:
+ mvcommand terminated with exit code 137

error:
exit status 137

Apr 15 10:13:28.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:28.700: INFO: rc: 1
Apr 15 10:13:28.700: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca6a50 exit status 1 <nil> <nil> true [0xc00187cea8 0xc00187cfb0 0xc00187d078] [0xc00187cea8 0xc00187cfb0 0xc00187d078] [0xc00187cf90 0xc00187d050] [0x9bf9f0 0x9bf9f0] 0xc002ac0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:13:38.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:38.759: INFO: rc: 1
Apr 15 10:13:38.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028b4990 exit status 1 <nil> <nil> true [0xc00251c1d0 0xc00251c210 0xc00251c240] [0xc00251c1d0 0xc00251c210 0xc00251c240] [0xc00251c1f0 0xc00251c230] [0x9bf9f0 0x9bf9f0] 0xc0028ed320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:13:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:48.817: INFO: rc: 1
Apr 15 10:13:48.817: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028b4cf0 exit status 1 <nil> <nil> true [0xc00251c250 0xc00251c280 0xc00251c2c8] [0xc00251c250 0xc00251c280 0xc00251c2c8] [0xc00251c270 0xc00251c2b8] [0x9bf9f0 0x9bf9f0] 0xc0028ed680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:13:58.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:13:58.876: INFO: rc: 1
Apr 15 10:13:58.877: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca6d80 exit status 1 <nil> <nil> true [0xc00187d0b0 0xc00187d140 0xc00187d188] [0xc00187d0b0 0xc00187d140 0xc00187d188] [0xc00187d138 0xc00187d170] [0x9bf9f0 0x9bf9f0] 0xc002ac0ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:08.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:08.939: INFO: rc: 1
Apr 15 10:14:08.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca70e0 exit status 1 <nil> <nil> true [0xc00187d1c0 0xc00187d208 0xc00187d258] [0xc00187d1c0 0xc00187d208 0xc00187d258] [0xc00187d1e0 0xc00187d248] [0x9bf9f0 0x9bf9f0] 0xc002ac0e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:18.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:18.999: INFO: rc: 1
Apr 15 10:14:18.999: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028b5050 exit status 1 <nil> <nil> true [0xc00251c2e0 0xc00251c318 0xc00251c358] [0xc00251c2e0 0xc00251c318 0xc00251c358] [0xc00251c308 0xc00251c340] [0x9bf9f0 0x9bf9f0] 0xc0028ed9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:28.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:29.066: INFO: rc: 1
Apr 15 10:14:29.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028b5650 exit status 1 <nil> <nil> true [0xc00251c368 0xc00251c398 0xc00251c3e0] [0xc00251c368 0xc00251c398 0xc00251c3e0] [0xc00251c388 0xc00251c3c8] [0x9bf9f0 0x9bf9f0] 0xc0028edd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:39.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:39.128: INFO: rc: 1
Apr 15 10:14:39.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca7470 exit status 1 <nil> <nil> true [0xc00187d260 0xc00187d290 0xc00187d380] [0xc00187d260 0xc00187d290 0xc00187d380] [0xc00187d280 0xc00187d330] [0x9bf9f0 0x9bf9f0] 0xc002ac11a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:49.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:49.194: INFO: rc: 1
Apr 15 10:14:49.194: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028b59b0 exit status 1 <nil> <nil> true [0xc00251c3f0 0xc00251c428 0xc00251c468] [0xc00251c3f0 0xc00251c428 0xc00251c468] [0xc00251c410 0xc00251c450] [0x9bf9f0 0x9bf9f0] 0xc002f6a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:14:59.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:14:59.255: INFO: rc: 1
Apr 15 10:14:59.256: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca77d0 exit status 1 <nil> <nil> true [0xc00187d3b0 0xc00187d468 0xc00187d510] [0xc00187d3b0 0xc00187d468 0xc00187d510] [0xc00187d440 0xc00187d4d0] [0x9bf9f0 0x9bf9f0] 0xc002ac1500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:09.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:09.314: INFO: rc: 1
Apr 15 10:15:09.314: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00312c300 exit status 1 <nil> <nil> true [0xc00187c098 0xc00187c160 0xc00187c1f8] [0xc00187c098 0xc00187c160 0xc00187c1f8] [0xc00187c118 0xc00187c1b0] [0x9bf9f0 0x9bf9f0] 0xc0028ec540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:19.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:19.387: INFO: rc: 1
Apr 15 10:15:19.387: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54300 exit status 1 <nil> <nil> true [0xc00251c000 0xc00251c030 0xc00251c068] [0xc00251c000 0xc00251c030 0xc00251c068] [0xc00251c020 0xc00251c058] [0x9bf9f0 0x9bf9f0] 0xc002d2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:29.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:29.459: INFO: rc: 1
Apr 15 10:15:29.459: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54660 exit status 1 <nil> <nil> true [0xc00251c078 0xc00251c0b0 0xc00251c0e0] [0xc00251c078 0xc00251c0b0 0xc00251c0e0] [0xc00251c0a0 0xc00251c0d0] [0x9bf9f0 0x9bf9f0] 0xc002d2a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:39.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:39.524: INFO: rc: 1
Apr 15 10:15:39.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e549c0 exit status 1 <nil> <nil> true [0xc00251c0f0 0xc00251c128 0xc00251c170] [0xc00251c0f0 0xc00251c128 0xc00251c170] [0xc00251c110 0xc00251c160] [0x9bf9f0 0x9bf9f0] 0xc002d2a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:49.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:49.585: INFO: rc: 1
Apr 15 10:15:49.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54d20 exit status 1 <nil> <nil> true [0xc00251c180 0xc00251c1c0 0xc00251c1f0] [0xc00251c180 0xc00251c1c0 0xc00251c1f0] [0xc00251c1b0 0xc00251c1e0] [0x9bf9f0 0x9bf9f0] 0xc002d2ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:15:59.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:15:59.651: INFO: rc: 1
Apr 15 10:15:59.651: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55080 exit status 1 <nil> <nil> true [0xc00251c210 0xc00251c240 0xc00251c270] [0xc00251c210 0xc00251c240 0xc00251c270] [0xc00251c230 0xc00251c260] [0x9bf9f0 0x9bf9f0] 0xc002d2b4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:09.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:16:09.714: INFO: rc: 1
Apr 15 10:16:09.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55530 exit status 1 <nil> <nil> true [0xc00251c280 0xc00251c2c8 0xc00251c308] [0xc00251c280 0xc00251c2c8 0xc00251c308] [0xc00251c2b8 0xc00251c2f0] [0x9bf9f0 0x9bf9f0] 0xc002d2bec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:19.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:16:19.775: INFO: rc: 1
Apr 15 10:16:19.775: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00312c690 exit status 1 <nil> <nil> true [0xc00187c230 0xc00187c2d0 0xc00187c348] [0xc00187c230 0xc00187c2d0 0xc00187c348] [0xc00187c288 0xc00187c328] [0x9bf9f0 0x9bf9f0] 0xc0028eca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:29.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:16:29.833: INFO: rc: 1
Apr 15 10:16:29.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55860 exit status 1 <nil> <nil> true [0xc00251c318 0xc00251c358 0xc00251c388] [0xc00251c318 0xc00251c358 0xc00251c388] [0xc00251c340 0xc00251c378] [0x9bf9f0 0x9bf9f0] 0xc002ac05a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:39.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:16:39.895: INFO: rc: 1
Apr 15 10:16:39.895: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55bc0 exit status 1 <nil> <nil> true [0xc00251c398 0xc00251c3e0 0xc00251c410] [0xc00251c398 0xc00251c3e0 0xc00251c410] [0xc00251c3c8 0xc00251c400] [0x9bf9f0 0x9bf9f0] 0xc002ac0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:49.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:16:49.963: INFO: rc: 1
Apr 15 10:16:49.963: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55f20 exit status 1 <nil> <nil> true [0xc00251c428 0xc00251c468 0xc00251c4a0] [0xc00251c428 0xc00251c468 0xc00251c4a0] [0xc00251c450 0xc00251c490] [0x9bf9f0 0x9bf9f0] 0xc002ac0cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:16:59.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:00.021: INFO: rc: 1
Apr 15 10:17:00.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e702a0 exit status 1 <nil> <nil> true [0xc00251c4b8 0xc00251c520 0xc00251c5c0] [0xc00251c4b8 0xc00251c520 0xc00251c5c0] [0xc00251c500 0xc00251c580] [0x9bf9f0 0x9bf9f0] 0xc002ac1020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:17:10.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:10.084: INFO: rc: 1
Apr 15 10:17:10.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54330 exit status 1 <nil> <nil> true [0xc00251c010 0xc00251c040 0xc00251c078] [0xc00251c010 0xc00251c040 0xc00251c078] [0xc00251c030 0xc00251c068] [0x9bf9f0 0x9bf9f0] 0xc002d2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:17:20.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:20.137: INFO: rc: 1
Apr 15 10:17:20.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e546c0 exit status 1 <nil> <nil> true [0xc00251c088 0xc00251c0c0 0xc00251c0f0] [0xc00251c088 0xc00251c0c0 0xc00251c0f0] [0xc00251c0b0 0xc00251c0e0] [0x9bf9f0 0x9bf9f0] 0xc002d2a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:17:30.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:30.197: INFO: rc: 1
Apr 15 10:17:30.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54a50 exit status 1 <nil> <nil> true [0xc00251c100 0xc00251c150 0xc00251c180] [0xc00251c100 0xc00251c150 0xc00251c180] [0xc00251c128 0xc00251c170] [0x9bf9f0 0x9bf9f0] 0xc002d2a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:17:40.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:40.258: INFO: rc: 1
Apr 15 10:17:40.258: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e70360 exit status 1 <nil> <nil> true [0xc00187c050 0xc00187c118 0xc00187c1b0] [0xc00187c050 0xc00187c118 0xc00187c1b0] [0xc00187c0f0 0xc00187c190] [0x9bf9f0 0x9bf9f0] 0xc002ac0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:17:50.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:17:50.319: INFO: rc: 1
Apr 15 10:17:50.319: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e54db0 exit status 1 <nil> <nil> true [0xc00251c1a0 0xc00251c1d0 0xc00251c210] [0xc00251c1a0 0xc00251c1d0 0xc00251c210] [0xc00251c1c0 0xc00251c1f0] [0x9bf9f0 0x9bf9f0] 0xc002d2ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:18:00.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:18:00.376: INFO: rc: 1
Apr 15 10:18:00.376: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002e55110 exit status 1 <nil> <nil> true [0xc00251c220 0xc00251c250 0xc00251c280] [0xc00251c220 0xc00251c250 0xc00251c280] [0xc00251c240 0xc00251c270] [0x9bf9f0 0x9bf9f0] 0xc002d2b4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:18:10.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:18:10.440: INFO: rc: 1
Apr 15 10:18:10.440: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001e70b40 exit status 1 <nil> <nil> true [0xc00187c1f8 0xc00187c288 0xc00187c328] [0xc00187c1f8 0xc00187c288 0xc00187c328] [0xc00187c240 0xc00187c300] [0x9bf9f0 0x9bf9f0] 0xc002ac0900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 15 10:18:20.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-6076 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:18:20.507: INFO: rc: 1
Apr 15 10:18:20.507: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Apr 15 10:18:20.507: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 15 10:18:20.519: INFO: Deleting all statefulset in ns statefulset-6076
Apr 15 10:18:20.522: INFO: Scaling statefulset ss to 0
Apr 15 10:18:20.530: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:18:20.533: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:18:20.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6076" for this suite.
Apr 15 10:18:26.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:18:26.663: INFO: namespace statefulset-6076 deletion completed in 6.112719529s

• [SLOW TEST:369.876 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:18:26.665: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 15 10:18:26.705: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 15 10:18:26.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:26.921: INFO: stderr: ""
Apr 15 10:18:26.921: INFO: stdout: "service/redis-slave created\n"
Apr 15 10:18:26.921: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 15 10:18:26.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:27.146: INFO: stderr: ""
Apr 15 10:18:27.146: INFO: stdout: "service/redis-master created\n"
Apr 15 10:18:27.146: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 15 10:18:27.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:27.339: INFO: stderr: ""
Apr 15 10:18:27.339: INFO: stdout: "service/frontend created\n"
Apr 15 10:18:27.340: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 15 10:18:27.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:27.584: INFO: stderr: ""
Apr 15 10:18:27.584: INFO: stdout: "deployment.apps/frontend created\n"
Apr 15 10:18:27.584: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 15 10:18:27.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:27.785: INFO: stderr: ""
Apr 15 10:18:27.785: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 15 10:18:27.785: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 15 10:18:27.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5982'
Apr 15 10:18:28.012: INFO: stderr: ""
Apr 15 10:18:28.012: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 15 10:18:28.012: INFO: Waiting for all frontend pods to be Running.
Apr 15 10:18:48.063: INFO: Waiting for frontend to serve content.
Apr 15 10:18:53.082: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr 15 10:18:58.095: INFO: Trying to add a new entry to the guestbook.
Apr 15 10:18:58.108: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 15 10:18:58.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.217: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.217: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 15 10:18:58.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.334: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.334: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 15 10:18:58.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.486: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.486: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 15 10:18:58.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.561: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.561: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 15 10:18:58.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.629: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.629: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 15 10:18:58.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-5982'
Apr 15 10:18:58.703: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 10:18:58.703: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:18:58.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5982" for this suite.
Apr 15 10:19:36.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:19:36.822: INFO: namespace kubectl-5982 deletion completed in 38.115934571s

• [SLOW TEST:70.158 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:19:36.823: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:19:36.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5120" to be "success or failure"
Apr 15 10:19:36.885: INFO: Pod "downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.204391ms
Apr 15 10:19:38.890: INFO: Pod "downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009499703s
STEP: Saw pod success
Apr 15 10:19:38.890: INFO: Pod "downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:19:38.893: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:19:38.923: INFO: Waiting for pod downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:19:38.926: INFO: Pod downwardapi-volume-f899adc3-5f67-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:19:38.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5120" for this suite.
Apr 15 10:19:44.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:19:45.045: INFO: namespace projected-5120 deletion completed in 6.11497303s

• [SLOW TEST:8.222 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:19:45.046: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:19:47.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5454" for this suite.
Apr 15 10:19:53.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:19:53.302: INFO: namespace emptydir-wrapper-5454 deletion completed in 6.104828052s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:19:53.302: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982
Apr 15 10:19:53.352: INFO: Pod name my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982: Found 0 pods out of 1
Apr 15 10:19:58.355: INFO: Pod name my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982: Found 1 pods out of 1
Apr 15 10:19:58.356: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982" are running
Apr 15 10:19:58.359: INFO: Pod "my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982-tnzkr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:19:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:19:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:19:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-15 10:19:53 +0000 UTC Reason: Message:}])
Apr 15 10:19:58.360: INFO: Trying to dial the pod
Apr 15 10:20:03.372: INFO: Controller my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982: Got expected result from replica 1 [my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982-tnzkr]: "my-hostname-basic-026c8854-5f68-11e9-a7dc-a6e5a2dd4982-tnzkr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:03.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6008" for this suite.
Apr 15 10:20:09.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:09.486: INFO: namespace replication-controller-6008 deletion completed in 6.109547992s

• [SLOW TEST:16.184 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:09.486: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 15 10:20:09.594: INFO: Waiting up to 5m0s for pod "pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-6569" to be "success or failure"
Apr 15 10:20:09.597: INFO: Pod "pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.268661ms
Apr 15 10:20:11.601: INFO: Pod "pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007308577s
STEP: Saw pod success
Apr 15 10:20:11.601: INFO: Pod "pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:20:11.605: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:20:11.639: INFO: Waiting for pod pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:20:11.642: INFO: Pod pod-0c1ad9c1-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:11.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6569" for this suite.
Apr 15 10:20:17.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:17.752: INFO: namespace emptydir-6569 deletion completed in 6.105474941s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:17.752: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-4647/configmap-test-11079c9f-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:20:17.861: INFO: Waiting up to 5m0s for pod "pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-4647" to be "success or failure"
Apr 15 10:20:17.866: INFO: Pod "pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.409196ms
Apr 15 10:20:19.870: INFO: Pod "pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008550602s
STEP: Saw pod success
Apr 15 10:20:19.870: INFO: Pod "pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:20:19.873: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982 container env-test: <nil>
STEP: delete the pod
Apr 15 10:20:19.895: INFO: Waiting for pod pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:20:19.898: INFO: Pod pod-configmaps-1108c818-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:19.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4647" for this suite.
Apr 15 10:20:25.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:26.014: INFO: namespace configmap-4647 deletion completed in 6.112823365s

• [SLOW TEST:8.262 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:26.015: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-15ec8118-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:20:26.074: INFO: Waiting up to 5m0s for pod "pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-9192" to be "success or failure"
Apr 15 10:20:26.079: INFO: Pod "pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.296601ms
Apr 15 10:20:28.084: INFO: Pod "pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009870181s
STEP: Saw pod success
Apr 15 10:20:28.084: INFO: Pod "pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:20:28.088: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:20:28.112: INFO: Waiting for pod pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:20:28.116: INFO: Pod pod-configmaps-15edb60b-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:28.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9192" for this suite.
Apr 15 10:20:34.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:34.274: INFO: namespace configmap-9192 deletion completed in 6.152656672s

• [SLOW TEST:8.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:34.274: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 15 10:20:34.315: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357557484 proxy --unix-socket=/tmp/kubectl-proxy-unix233401535/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:34.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8586" for this suite.
Apr 15 10:20:40.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:40.482: INFO: namespace kubectl-8586 deletion completed in 6.107899071s

• [SLOW TEST:6.208 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:40.483: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-1e94dfb1-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:20:40.598: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "projected-3452" to be "success or failure"
Apr 15 10:20:40.602: INFO: Pod "pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390658ms
Apr 15 10:20:42.606: INFO: Pod "pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008633147s
STEP: Saw pod success
Apr 15 10:20:42.606: INFO: Pod "pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:20:42.610: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:20:42.633: INFO: Waiting for pod pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:20:42.636: INFO: Pod pod-projected-configmaps-1e961aab-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:20:42.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3452" for this suite.
Apr 15 10:20:48.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:20:48.766: INFO: namespace projected-3452 deletion completed in 6.126409213s

• [SLOW TEST:8.283 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:20:48.766: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0415 10:21:18.909448      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 10:21:18.909: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:21:18.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-657" for this suite.
Apr 15 10:21:24.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:21:25.027: INFO: namespace gc-657 deletion completed in 6.11493225s

• [SLOW TEST:36.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:21:25.028: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:21:25.127: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 15 10:21:25.150: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 15 10:21:30.154: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 15 10:21:30.154: INFO: Creating deployment "test-rolling-update-deployment"
Apr 15 10:21:30.160: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 15 10:21:30.186: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Apr 15 10:21:32.194: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 15 10:21:32.197: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 15 10:21:32.211: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7750,SelfLink:/apis/apps/v1/namespaces/deployment-7750/deployments/test-rolling-update-deployment,UID:3c2116c3-5f68-11e9-adae-06c5682e2662,ResourceVersion:10785,Generation:1,CreationTimestamp:2019-04-15 10:21:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-15 10:21:30 +0000 UTC 2019-04-15 10:21:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-15 10:21:31 +0000 UTC 2019-04-15 10:21:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 15 10:21:32.214: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-7750,SelfLink:/apis/apps/v1/namespaces/deployment-7750/replicasets/test-rolling-update-deployment-67599b4d9,UID:3c244bca-5f68-11e9-b895-0a5a25aca864,ResourceVersion:10774,Generation:1,CreationTimestamp:2019-04-15 10:21:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3c2116c3-5f68-11e9-adae-06c5682e2662 0xc0031e0d80 0xc0031e0d81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 15 10:21:32.214: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 15 10:21:32.214: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7750,SelfLink:/apis/apps/v1/namespaces/deployment-7750/replicasets/test-rolling-update-controller,UID:39222882-5f68-11e9-adae-06c5682e2662,ResourceVersion:10784,Generation:2,CreationTimestamp:2019-04-15 10:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3c2116c3-5f68-11e9-adae-06c5682e2662 0xc0031e0cb7 0xc0031e0cb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 10:21:32.218: INFO: Pod "test-rolling-update-deployment-67599b4d9-sh6t9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-sh6t9,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-7750,SelfLink:/api/v1/namespaces/deployment-7750/pods/test-rolling-update-deployment-67599b4d9-sh6t9,UID:3c25cb1a-5f68-11e9-b895-0a5a25aca864,ResourceVersion:10773,Generation:0,CreationTimestamp:2019-04-15 10:21:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.208/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 3c244bca-5f68-11e9-b895-0a5a25aca864 0xc0031e1610 0xc0031e1611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pw2mq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pw2mq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pw2mq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031e1670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031e1690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:21:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:21:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:21:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:21:30 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.208,StartTime:2019-04-15 10:21:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-15 10:21:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://b0ec856e1df447ed327148f6af6118ecdd9d6d7c71bad75ac9ca338494f7110e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:21:32.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7750" for this suite.
Apr 15 10:21:38.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:21:38.388: INFO: namespace deployment-7750 deletion completed in 6.165809478s

• [SLOW TEST:13.360 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:21:38.388: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3969
I0415 10:21:38.465067      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3969, replica count: 1
I0415 10:21:39.515504      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0415 10:21:40.515732      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 15 10:21:40.631: INFO: Created: latency-svc-px226
Apr 15 10:21:40.644: INFO: Got endpoints: latency-svc-px226 [28.48593ms]
Apr 15 10:21:40.670: INFO: Created: latency-svc-ld6kb
Apr 15 10:21:40.678: INFO: Got endpoints: latency-svc-ld6kb [33.935179ms]
Apr 15 10:21:40.697: INFO: Created: latency-svc-cdwjk
Apr 15 10:21:40.698: INFO: Got endpoints: latency-svc-cdwjk [53.363831ms]
Apr 15 10:21:40.718: INFO: Created: latency-svc-zh6m7
Apr 15 10:21:40.724: INFO: Got endpoints: latency-svc-zh6m7 [79.080068ms]
Apr 15 10:21:40.741: INFO: Created: latency-svc-4bnzq
Apr 15 10:21:40.754: INFO: Got endpoints: latency-svc-4bnzq [109.218613ms]
Apr 15 10:21:40.763: INFO: Created: latency-svc-4x9bh
Apr 15 10:21:40.775: INFO: Got endpoints: latency-svc-4x9bh [130.791954ms]
Apr 15 10:21:40.795: INFO: Created: latency-svc-jdw69
Apr 15 10:21:40.795: INFO: Got endpoints: latency-svc-jdw69 [150.049407ms]
Apr 15 10:21:40.830: INFO: Created: latency-svc-rk6rk
Apr 15 10:21:40.848: INFO: Got endpoints: latency-svc-rk6rk [202.998767ms]
Apr 15 10:21:40.850: INFO: Created: latency-svc-bfmtg
Apr 15 10:21:40.868: INFO: Created: latency-svc-ktcw9
Apr 15 10:21:40.881: INFO: Created: latency-svc-rkdsp
Apr 15 10:21:40.913: INFO: Got endpoints: latency-svc-bfmtg [267.696539ms]
Apr 15 10:21:40.918: INFO: Got endpoints: latency-svc-ktcw9 [272.77613ms]
Apr 15 10:21:40.919: INFO: Got endpoints: latency-svc-rkdsp [273.766447ms]
Apr 15 10:21:40.928: INFO: Created: latency-svc-mmqk6
Apr 15 10:21:40.957: INFO: Got endpoints: latency-svc-mmqk6 [312.019099ms]
Apr 15 10:21:40.964: INFO: Created: latency-svc-sgf67
Apr 15 10:21:40.992: INFO: Created: latency-svc-fshfd
Apr 15 10:21:41.008: INFO: Created: latency-svc-q2dqh
Apr 15 10:21:41.035: INFO: Got endpoints: latency-svc-sgf67 [390.059278ms]
Apr 15 10:21:41.036: INFO: Got endpoints: latency-svc-fshfd [390.848271ms]
Apr 15 10:21:41.038: INFO: Created: latency-svc-z4fzg
Apr 15 10:21:41.053: INFO: Got endpoints: latency-svc-q2dqh [407.408785ms]
Apr 15 10:21:41.061: INFO: Got endpoints: latency-svc-z4fzg [415.81516ms]
Apr 15 10:21:41.068: INFO: Created: latency-svc-nzh7z
Apr 15 10:21:41.078: INFO: Got endpoints: latency-svc-nzh7z [400.237319ms]
Apr 15 10:21:41.085: INFO: Created: latency-svc-6phxp
Apr 15 10:21:41.096: INFO: Got endpoints: latency-svc-6phxp [398.078364ms]
Apr 15 10:21:41.104: INFO: Created: latency-svc-8sj22
Apr 15 10:21:41.110: INFO: Got endpoints: latency-svc-8sj22 [385.762933ms]
Apr 15 10:21:41.136: INFO: Created: latency-svc-wg9n5
Apr 15 10:21:41.142: INFO: Got endpoints: latency-svc-wg9n5 [388.299317ms]
Apr 15 10:21:41.155: INFO: Created: latency-svc-m6ndq
Apr 15 10:21:41.166: INFO: Got endpoints: latency-svc-m6ndq [390.857924ms]
Apr 15 10:21:41.173: INFO: Created: latency-svc-bzsxf
Apr 15 10:21:41.189: INFO: Got endpoints: latency-svc-bzsxf [393.70905ms]
Apr 15 10:21:41.192: INFO: Created: latency-svc-ctsl4
Apr 15 10:21:41.212: INFO: Got endpoints: latency-svc-ctsl4 [363.550277ms]
Apr 15 10:21:41.216: INFO: Created: latency-svc-b8k77
Apr 15 10:21:41.243: INFO: Got endpoints: latency-svc-b8k77 [330.077862ms]
Apr 15 10:21:41.252: INFO: Created: latency-svc-z45v2
Apr 15 10:21:41.263: INFO: Got endpoints: latency-svc-z45v2 [344.734721ms]
Apr 15 10:21:41.265: INFO: Created: latency-svc-kk4nk
Apr 15 10:21:41.285: INFO: Got endpoints: latency-svc-kk4nk [365.62959ms]
Apr 15 10:21:41.286: INFO: Created: latency-svc-vt6cc
Apr 15 10:21:41.295: INFO: Got endpoints: latency-svc-vt6cc [337.328307ms]
Apr 15 10:21:41.315: INFO: Created: latency-svc-zwfr8
Apr 15 10:21:41.336: INFO: Created: latency-svc-phmgk
Apr 15 10:21:41.359: INFO: Created: latency-svc-777kh
Apr 15 10:21:41.366: INFO: Got endpoints: latency-svc-zwfr8 [330.322967ms]
Apr 15 10:21:41.374: INFO: Got endpoints: latency-svc-phmgk [338.156153ms]
Apr 15 10:21:41.381: INFO: Got endpoints: latency-svc-777kh [328.547531ms]
Apr 15 10:21:41.403: INFO: Created: latency-svc-gfwgt
Apr 15 10:21:41.425: INFO: Created: latency-svc-l9256
Apr 15 10:21:41.440: INFO: Created: latency-svc-5vcn6
Apr 15 10:21:41.463: INFO: Created: latency-svc-8pxpk
Apr 15 10:21:41.475: INFO: Created: latency-svc-gf7z8
Apr 15 10:21:41.503: INFO: Created: latency-svc-29hbf
Apr 15 10:21:41.504: INFO: Got endpoints: latency-svc-l9256 [123.057693ms]
Apr 15 10:21:41.505: INFO: Got endpoints: latency-svc-gfwgt [443.509025ms]
Apr 15 10:21:41.515: INFO: Got endpoints: latency-svc-5vcn6 [436.694097ms]
Apr 15 10:21:41.519: INFO: Got endpoints: latency-svc-gf7z8 [409.080669ms]
Apr 15 10:21:41.519: INFO: Got endpoints: latency-svc-8pxpk [423.238157ms]
Apr 15 10:21:41.530: INFO: Got endpoints: latency-svc-29hbf [387.422536ms]
Apr 15 10:21:41.539: INFO: Created: latency-svc-fbg8s
Apr 15 10:21:41.551: INFO: Got endpoints: latency-svc-fbg8s [384.841387ms]
Apr 15 10:21:41.554: INFO: Created: latency-svc-kdck5
Apr 15 10:21:41.570: INFO: Got endpoints: latency-svc-kdck5 [381.21525ms]
Apr 15 10:21:41.580: INFO: Created: latency-svc-ffdnj
Apr 15 10:21:41.584: INFO: Got endpoints: latency-svc-ffdnj [372.134797ms]
Apr 15 10:21:41.610: INFO: Created: latency-svc-8svzf
Apr 15 10:21:41.637: INFO: Created: latency-svc-7xk55
Apr 15 10:21:41.651: INFO: Got endpoints: latency-svc-8svzf [408.353746ms]
Apr 15 10:21:41.669: INFO: Created: latency-svc-vf4c7
Apr 15 10:21:41.674: INFO: Got endpoints: latency-svc-7xk55 [411.36402ms]
Apr 15 10:21:41.681: INFO: Got endpoints: latency-svc-vf4c7 [396.473628ms]
Apr 15 10:21:41.683: INFO: Created: latency-svc-h5zbp
Apr 15 10:21:41.705: INFO: Got endpoints: latency-svc-h5zbp [410.170518ms]
Apr 15 10:21:41.710: INFO: Created: latency-svc-85jdj
Apr 15 10:21:41.731: INFO: Got endpoints: latency-svc-85jdj [365.292226ms]
Apr 15 10:21:41.825: INFO: Created: latency-svc-shbns
Apr 15 10:21:41.841: INFO: Got endpoints: latency-svc-shbns [466.384591ms]
Apr 15 10:21:41.842: INFO: Created: latency-svc-6f86d
Apr 15 10:21:41.854: INFO: Got endpoints: latency-svc-6f86d [349.432562ms]
Apr 15 10:21:41.860: INFO: Created: latency-svc-mcb8h
Apr 15 10:21:41.883: INFO: Got endpoints: latency-svc-mcb8h [378.770194ms]
Apr 15 10:21:41.898: INFO: Created: latency-svc-4pjmk
Apr 15 10:21:41.900: INFO: Got endpoints: latency-svc-4pjmk [384.814339ms]
Apr 15 10:21:41.922: INFO: Created: latency-svc-d7wpf
Apr 15 10:21:41.934: INFO: Got endpoints: latency-svc-d7wpf [414.742697ms]
Apr 15 10:21:41.949: INFO: Created: latency-svc-9xh2n
Apr 15 10:21:41.951: INFO: Got endpoints: latency-svc-9xh2n [432.110133ms]
Apr 15 10:21:41.987: INFO: Created: latency-svc-ldrk8
Apr 15 10:21:42.018: INFO: Got endpoints: latency-svc-ldrk8 [488.241753ms]
Apr 15 10:21:42.031: INFO: Created: latency-svc-tzpf6
Apr 15 10:21:42.034: INFO: Got endpoints: latency-svc-tzpf6 [482.678886ms]
Apr 15 10:21:42.064: INFO: Created: latency-svc-6799r
Apr 15 10:21:42.069: INFO: Got endpoints: latency-svc-6799r [499.252272ms]
Apr 15 10:21:42.084: INFO: Created: latency-svc-zdnrd
Apr 15 10:21:42.091: INFO: Got endpoints: latency-svc-zdnrd [506.211512ms]
Apr 15 10:21:42.106: INFO: Created: latency-svc-g9ls6
Apr 15 10:21:42.113: INFO: Got endpoints: latency-svc-g9ls6 [461.08719ms]
Apr 15 10:21:42.141: INFO: Created: latency-svc-p9s4m
Apr 15 10:21:42.152: INFO: Got endpoints: latency-svc-p9s4m [477.469246ms]
Apr 15 10:21:42.163: INFO: Created: latency-svc-nv5rf
Apr 15 10:21:42.178: INFO: Created: latency-svc-rnpg8
Apr 15 10:21:42.179: INFO: Got endpoints: latency-svc-nv5rf [497.998862ms]
Apr 15 10:21:42.188: INFO: Got endpoints: latency-svc-rnpg8 [482.777061ms]
Apr 15 10:21:42.197: INFO: Created: latency-svc-hs6cz
Apr 15 10:21:42.220: INFO: Got endpoints: latency-svc-hs6cz [489.154654ms]
Apr 15 10:21:42.234: INFO: Created: latency-svc-krz79
Apr 15 10:21:42.235: INFO: Got endpoints: latency-svc-krz79 [394.136067ms]
Apr 15 10:21:42.252: INFO: Created: latency-svc-tddcw
Apr 15 10:21:42.270: INFO: Created: latency-svc-b7scc
Apr 15 10:21:42.280: INFO: Got endpoints: latency-svc-tddcw [425.84859ms]
Apr 15 10:21:42.283: INFO: Created: latency-svc-ps9w2
Apr 15 10:21:42.290: INFO: Got endpoints: latency-svc-b7scc [406.248055ms]
Apr 15 10:21:42.308: INFO: Got endpoints: latency-svc-ps9w2 [407.697362ms]
Apr 15 10:21:42.323: INFO: Created: latency-svc-gv9tz
Apr 15 10:21:42.334: INFO: Created: latency-svc-wvrjg
Apr 15 10:21:42.342: INFO: Got endpoints: latency-svc-gv9tz [408.421004ms]
Apr 15 10:21:42.360: INFO: Created: latency-svc-8pmlk
Apr 15 10:21:42.378: INFO: Created: latency-svc-j52lf
Apr 15 10:21:42.397: INFO: Got endpoints: latency-svc-wvrjg [446.068706ms]
Apr 15 10:21:42.403: INFO: Created: latency-svc-drcll
Apr 15 10:21:42.425: INFO: Created: latency-svc-chnvz
Apr 15 10:21:42.443: INFO: Got endpoints: latency-svc-8pmlk [425.344127ms]
Apr 15 10:21:42.456: INFO: Created: latency-svc-7kpc6
Apr 15 10:21:42.493: INFO: Got endpoints: latency-svc-j52lf [458.329584ms]
Apr 15 10:21:42.501: INFO: Created: latency-svc-c52zq
Apr 15 10:21:42.530: INFO: Created: latency-svc-6j9p8
Apr 15 10:21:42.544: INFO: Got endpoints: latency-svc-drcll [474.031163ms]
Apr 15 10:21:42.550: INFO: Created: latency-svc-mlrjw
Apr 15 10:21:42.563: INFO: Created: latency-svc-bgccj
Apr 15 10:21:42.588: INFO: Created: latency-svc-pnf2n
Apr 15 10:21:42.614: INFO: Got endpoints: latency-svc-chnvz [523.312172ms]
Apr 15 10:21:42.624: INFO: Created: latency-svc-zs9ww
Apr 15 10:21:42.645: INFO: Created: latency-svc-64c7s
Apr 15 10:21:42.650: INFO: Got endpoints: latency-svc-7kpc6 [537.006263ms]
Apr 15 10:21:42.663: INFO: Created: latency-svc-bjllj
Apr 15 10:21:42.673: INFO: Created: latency-svc-c2c6z
Apr 15 10:21:42.695: INFO: Got endpoints: latency-svc-c52zq [542.775601ms]
Apr 15 10:21:42.706: INFO: Created: latency-svc-6lcgv
Apr 15 10:21:42.722: INFO: Created: latency-svc-zdvtg
Apr 15 10:21:42.741: INFO: Created: latency-svc-svtdj
Apr 15 10:21:42.745: INFO: Got endpoints: latency-svc-6j9p8 [565.088997ms]
Apr 15 10:21:42.756: INFO: Created: latency-svc-mzzkp
Apr 15 10:21:42.786: INFO: Created: latency-svc-vw7qj
Apr 15 10:21:42.791: INFO: Got endpoints: latency-svc-mlrjw [603.337203ms]
Apr 15 10:21:42.810: INFO: Created: latency-svc-zlqvt
Apr 15 10:21:42.833: INFO: Created: latency-svc-26tvg
Apr 15 10:21:42.843: INFO: Got endpoints: latency-svc-bgccj [622.862159ms]
Apr 15 10:21:42.856: INFO: Created: latency-svc-98sqs
Apr 15 10:21:42.881: INFO: Created: latency-svc-xhzf6
Apr 15 10:21:42.892: INFO: Got endpoints: latency-svc-pnf2n [657.443731ms]
Apr 15 10:21:42.900: INFO: Created: latency-svc-fs698
Apr 15 10:21:42.920: INFO: Created: latency-svc-cl8vk
Apr 15 10:21:42.939: INFO: Got endpoints: latency-svc-zs9ww [658.634429ms]
Apr 15 10:21:42.962: INFO: Created: latency-svc-5ng4l
Apr 15 10:21:42.990: INFO: Got endpoints: latency-svc-64c7s [699.780597ms]
Apr 15 10:21:43.028: INFO: Created: latency-svc-kk99m
Apr 15 10:21:43.045: INFO: Got endpoints: latency-svc-bjllj [736.764744ms]
Apr 15 10:21:43.095: INFO: Got endpoints: latency-svc-c2c6z [752.728139ms]
Apr 15 10:21:43.097: INFO: Created: latency-svc-tzl65
Apr 15 10:21:43.118: INFO: Created: latency-svc-ccf7k
Apr 15 10:21:43.139: INFO: Got endpoints: latency-svc-6lcgv [741.402353ms]
Apr 15 10:21:43.165: INFO: Created: latency-svc-v7q5m
Apr 15 10:21:43.188: INFO: Got endpoints: latency-svc-zdvtg [744.417988ms]
Apr 15 10:21:43.223: INFO: Created: latency-svc-8287x
Apr 15 10:21:43.242: INFO: Got endpoints: latency-svc-svtdj [749.549547ms]
Apr 15 10:21:43.265: INFO: Created: latency-svc-58lj6
Apr 15 10:21:43.294: INFO: Got endpoints: latency-svc-mzzkp [749.793281ms]
Apr 15 10:21:43.318: INFO: Created: latency-svc-f692f
Apr 15 10:21:43.344: INFO: Got endpoints: latency-svc-vw7qj [729.390193ms]
Apr 15 10:21:43.366: INFO: Created: latency-svc-g8wv6
Apr 15 10:21:43.388: INFO: Got endpoints: latency-svc-zlqvt [738.34771ms]
Apr 15 10:21:43.494: INFO: Got endpoints: latency-svc-98sqs [749.713674ms]
Apr 15 10:21:43.495: INFO: Got endpoints: latency-svc-26tvg [799.419023ms]
Apr 15 10:21:43.532: INFO: Created: latency-svc-j6wqn
Apr 15 10:21:43.542: INFO: Got endpoints: latency-svc-xhzf6 [750.391993ms]
Apr 15 10:21:43.554: INFO: Created: latency-svc-xzvk5
Apr 15 10:21:43.573: INFO: Created: latency-svc-x7w22
Apr 15 10:21:43.584: INFO: Created: latency-svc-6cw5l
Apr 15 10:21:43.594: INFO: Got endpoints: latency-svc-fs698 [750.254686ms]
Apr 15 10:21:43.635: INFO: Created: latency-svc-zkx8f
Apr 15 10:21:43.643: INFO: Got endpoints: latency-svc-cl8vk [750.640964ms]
Apr 15 10:21:43.666: INFO: Created: latency-svc-gs5fn
Apr 15 10:21:43.691: INFO: Got endpoints: latency-svc-5ng4l [751.852683ms]
Apr 15 10:21:43.716: INFO: Created: latency-svc-svf8p
Apr 15 10:21:43.739: INFO: Got endpoints: latency-svc-kk99m [749.03936ms]
Apr 15 10:21:43.760: INFO: Created: latency-svc-xntw7
Apr 15 10:21:43.789: INFO: Got endpoints: latency-svc-tzl65 [743.906737ms]
Apr 15 10:21:43.823: INFO: Created: latency-svc-2ckvx
Apr 15 10:21:43.840: INFO: Got endpoints: latency-svc-ccf7k [745.164306ms]
Apr 15 10:21:43.864: INFO: Created: latency-svc-9bmtp
Apr 15 10:21:43.893: INFO: Got endpoints: latency-svc-v7q5m [754.018265ms]
Apr 15 10:21:43.918: INFO: Created: latency-svc-2qxcs
Apr 15 10:21:43.941: INFO: Got endpoints: latency-svc-8287x [752.771126ms]
Apr 15 10:21:43.962: INFO: Created: latency-svc-mrxst
Apr 15 10:21:43.991: INFO: Got endpoints: latency-svc-58lj6 [748.201433ms]
Apr 15 10:21:44.024: INFO: Created: latency-svc-bpxrv
Apr 15 10:21:44.040: INFO: Got endpoints: latency-svc-f692f [746.115653ms]
Apr 15 10:21:44.065: INFO: Created: latency-svc-mrk2s
Apr 15 10:21:44.088: INFO: Got endpoints: latency-svc-g8wv6 [744.80491ms]
Apr 15 10:21:44.117: INFO: Created: latency-svc-c88vd
Apr 15 10:21:44.142: INFO: Got endpoints: latency-svc-j6wqn [753.424449ms]
Apr 15 10:21:44.164: INFO: Created: latency-svc-v65qc
Apr 15 10:21:44.209: INFO: Got endpoints: latency-svc-xzvk5 [714.044481ms]
Apr 15 10:21:44.254: INFO: Got endpoints: latency-svc-x7w22 [759.451359ms]
Apr 15 10:21:44.257: INFO: Created: latency-svc-9xv5k
Apr 15 10:21:44.278: INFO: Created: latency-svc-p9tz2
Apr 15 10:21:44.294: INFO: Got endpoints: latency-svc-6cw5l [752.293876ms]
Apr 15 10:21:44.318: INFO: Created: latency-svc-t2rsd
Apr 15 10:21:44.361: INFO: Got endpoints: latency-svc-zkx8f [767.189005ms]
Apr 15 10:21:44.389: INFO: Created: latency-svc-mwxtk
Apr 15 10:21:44.396: INFO: Got endpoints: latency-svc-gs5fn [752.489836ms]
Apr 15 10:21:44.432: INFO: Created: latency-svc-nhz9t
Apr 15 10:21:44.441: INFO: Got endpoints: latency-svc-svf8p [750.061053ms]
Apr 15 10:21:44.469: INFO: Created: latency-svc-s2965
Apr 15 10:21:44.491: INFO: Got endpoints: latency-svc-xntw7 [752.275075ms]
Apr 15 10:21:44.514: INFO: Created: latency-svc-v6dt6
Apr 15 10:21:44.539: INFO: Got endpoints: latency-svc-2ckvx [750.325465ms]
Apr 15 10:21:44.565: INFO: Created: latency-svc-x4hcz
Apr 15 10:21:44.594: INFO: Got endpoints: latency-svc-9bmtp [753.897035ms]
Apr 15 10:21:44.624: INFO: Created: latency-svc-wfzcg
Apr 15 10:21:44.639: INFO: Got endpoints: latency-svc-2qxcs [746.122692ms]
Apr 15 10:21:44.662: INFO: Created: latency-svc-fsgqw
Apr 15 10:21:44.692: INFO: Got endpoints: latency-svc-mrxst [751.624191ms]
Apr 15 10:21:44.714: INFO: Created: latency-svc-l5lsv
Apr 15 10:21:44.740: INFO: Got endpoints: latency-svc-bpxrv [749.678645ms]
Apr 15 10:21:44.766: INFO: Created: latency-svc-wd27z
Apr 15 10:21:44.791: INFO: Got endpoints: latency-svc-mrk2s [751.109036ms]
Apr 15 10:21:44.825: INFO: Created: latency-svc-b9lmv
Apr 15 10:21:44.855: INFO: Got endpoints: latency-svc-c88vd [766.538946ms]
Apr 15 10:21:44.892: INFO: Created: latency-svc-ccjxd
Apr 15 10:21:44.909: INFO: Got endpoints: latency-svc-v65qc [767.544724ms]
Apr 15 10:21:44.930: INFO: Created: latency-svc-xcksx
Apr 15 10:21:44.938: INFO: Got endpoints: latency-svc-9xv5k [729.045339ms]
Apr 15 10:21:44.962: INFO: Created: latency-svc-7xmrd
Apr 15 10:21:44.999: INFO: Got endpoints: latency-svc-p9tz2 [744.440465ms]
Apr 15 10:21:45.038: INFO: Created: latency-svc-mm6ls
Apr 15 10:21:45.045: INFO: Got endpoints: latency-svc-t2rsd [751.125933ms]
Apr 15 10:21:45.105: INFO: Got endpoints: latency-svc-mwxtk [743.655491ms]
Apr 15 10:21:45.115: INFO: Created: latency-svc-ncvsz
Apr 15 10:21:45.148: INFO: Got endpoints: latency-svc-nhz9t [752.161844ms]
Apr 15 10:21:45.161: INFO: Created: latency-svc-8hbvs
Apr 15 10:21:45.195: INFO: Created: latency-svc-2kbw4
Apr 15 10:21:45.202: INFO: Got endpoints: latency-svc-s2965 [761.31519ms]
Apr 15 10:21:45.241: INFO: Got endpoints: latency-svc-v6dt6 [749.878568ms]
Apr 15 10:21:45.288: INFO: Created: latency-svc-tsgtt
Apr 15 10:21:45.295: INFO: Created: latency-svc-txw7j
Apr 15 10:21:45.302: INFO: Got endpoints: latency-svc-x4hcz [762.98229ms]
Apr 15 10:21:45.325: INFO: Created: latency-svc-n6wsq
Apr 15 10:21:45.345: INFO: Got endpoints: latency-svc-wfzcg [749.990701ms]
Apr 15 10:21:45.366: INFO: Created: latency-svc-fwznb
Apr 15 10:21:45.388: INFO: Got endpoints: latency-svc-fsgqw [748.408188ms]
Apr 15 10:21:45.444: INFO: Got endpoints: latency-svc-l5lsv [751.954556ms]
Apr 15 10:21:45.447: INFO: Created: latency-svc-wtzt6
Apr 15 10:21:45.474: INFO: Created: latency-svc-2s85l
Apr 15 10:21:45.487: INFO: Got endpoints: latency-svc-wd27z [746.628712ms]
Apr 15 10:21:45.525: INFO: Created: latency-svc-l72r8
Apr 15 10:21:45.545: INFO: Got endpoints: latency-svc-b9lmv [754.458095ms]
Apr 15 10:21:45.592: INFO: Got endpoints: latency-svc-ccjxd [736.308794ms]
Apr 15 10:21:45.596: INFO: Created: latency-svc-dwxg8
Apr 15 10:21:45.624: INFO: Created: latency-svc-f52ws
Apr 15 10:21:45.643: INFO: Got endpoints: latency-svc-xcksx [733.64271ms]
Apr 15 10:21:45.676: INFO: Created: latency-svc-pwzz2
Apr 15 10:21:45.689: INFO: Got endpoints: latency-svc-7xmrd [750.428912ms]
Apr 15 10:21:45.718: INFO: Created: latency-svc-6f6sn
Apr 15 10:21:45.744: INFO: Got endpoints: latency-svc-mm6ls [745.084965ms]
Apr 15 10:21:45.768: INFO: Created: latency-svc-6ntt9
Apr 15 10:21:45.788: INFO: Got endpoints: latency-svc-ncvsz [742.228382ms]
Apr 15 10:21:45.822: INFO: Created: latency-svc-cfvnv
Apr 15 10:21:45.840: INFO: Got endpoints: latency-svc-8hbvs [735.822004ms]
Apr 15 10:21:45.863: INFO: Created: latency-svc-zwnfc
Apr 15 10:21:45.888: INFO: Got endpoints: latency-svc-2kbw4 [740.173866ms]
Apr 15 10:21:45.909: INFO: Created: latency-svc-fqgqm
Apr 15 10:21:45.939: INFO: Got endpoints: latency-svc-tsgtt [737.008581ms]
Apr 15 10:21:45.959: INFO: Created: latency-svc-557bk
Apr 15 10:21:45.998: INFO: Got endpoints: latency-svc-txw7j [757.05355ms]
Apr 15 10:21:46.028: INFO: Created: latency-svc-nt9g6
Apr 15 10:21:46.048: INFO: Got endpoints: latency-svc-n6wsq [745.632171ms]
Apr 15 10:21:46.072: INFO: Created: latency-svc-6zjlt
Apr 15 10:21:46.106: INFO: Got endpoints: latency-svc-fwznb [760.958608ms]
Apr 15 10:21:46.125: INFO: Created: latency-svc-dlx4n
Apr 15 10:21:46.149: INFO: Got endpoints: latency-svc-wtzt6 [761.117587ms]
Apr 15 10:21:46.303: INFO: Got endpoints: latency-svc-l72r8 [815.914993ms]
Apr 15 10:21:46.303: INFO: Got endpoints: latency-svc-2s85l [858.63722ms]
Apr 15 10:21:46.304: INFO: Got endpoints: latency-svc-dwxg8 [758.039954ms]
Apr 15 10:21:46.330: INFO: Created: latency-svc-c9sff
Apr 15 10:21:46.345: INFO: Got endpoints: latency-svc-f52ws [752.836808ms]
Apr 15 10:21:46.351: INFO: Created: latency-svc-895pw
Apr 15 10:21:46.370: INFO: Created: latency-svc-7p8bm
Apr 15 10:21:46.389: INFO: Got endpoints: latency-svc-pwzz2 [745.499674ms]
Apr 15 10:21:46.395: INFO: Created: latency-svc-7z9tq
Apr 15 10:21:46.416: INFO: Created: latency-svc-2n6rg
Apr 15 10:21:46.437: INFO: Created: latency-svc-w9lcl
Apr 15 10:21:46.456: INFO: Got endpoints: latency-svc-6f6sn [767.122369ms]
Apr 15 10:21:46.486: INFO: Created: latency-svc-gsjbx
Apr 15 10:21:46.488: INFO: Got endpoints: latency-svc-6ntt9 [744.277686ms]
Apr 15 10:21:46.517: INFO: Created: latency-svc-nkscd
Apr 15 10:21:46.538: INFO: Got endpoints: latency-svc-cfvnv [750.504387ms]
Apr 15 10:21:46.569: INFO: Created: latency-svc-jkzch
Apr 15 10:21:46.593: INFO: Got endpoints: latency-svc-zwnfc [752.402582ms]
Apr 15 10:21:46.618: INFO: Created: latency-svc-96r6x
Apr 15 10:21:46.638: INFO: Got endpoints: latency-svc-fqgqm [749.740052ms]
Apr 15 10:21:46.659: INFO: Created: latency-svc-w42zk
Apr 15 10:21:46.689: INFO: Got endpoints: latency-svc-557bk [749.30164ms]
Apr 15 10:21:46.730: INFO: Created: latency-svc-df6xw
Apr 15 10:21:46.738: INFO: Got endpoints: latency-svc-nt9g6 [739.478945ms]
Apr 15 10:21:46.772: INFO: Created: latency-svc-q4wz7
Apr 15 10:21:46.789: INFO: Got endpoints: latency-svc-6zjlt [740.724761ms]
Apr 15 10:21:46.815: INFO: Created: latency-svc-jd5nr
Apr 15 10:21:46.839: INFO: Got endpoints: latency-svc-dlx4n [732.787698ms]
Apr 15 10:21:46.862: INFO: Created: latency-svc-6l9w5
Apr 15 10:21:46.898: INFO: Got endpoints: latency-svc-c9sff [748.626333ms]
Apr 15 10:21:46.921: INFO: Created: latency-svc-7nd7r
Apr 15 10:21:46.939: INFO: Got endpoints: latency-svc-895pw [635.603066ms]
Apr 15 10:21:46.992: INFO: Got endpoints: latency-svc-7p8bm [688.816393ms]
Apr 15 10:21:46.999: INFO: Created: latency-svc-m7zcw
Apr 15 10:21:47.038: INFO: Created: latency-svc-pfgz8
Apr 15 10:21:47.049: INFO: Got endpoints: latency-svc-7z9tq [745.028542ms]
Apr 15 10:21:47.080: INFO: Created: latency-svc-r555m
Apr 15 10:21:47.088: INFO: Got endpoints: latency-svc-2n6rg [742.809349ms]
Apr 15 10:21:47.114: INFO: Created: latency-svc-8rvwc
Apr 15 10:21:47.138: INFO: Got endpoints: latency-svc-w9lcl [749.257853ms]
Apr 15 10:21:47.179: INFO: Created: latency-svc-xdxzq
Apr 15 10:21:47.188: INFO: Got endpoints: latency-svc-gsjbx [732.661619ms]
Apr 15 10:21:47.209: INFO: Created: latency-svc-zpzwz
Apr 15 10:21:47.243: INFO: Got endpoints: latency-svc-nkscd [753.986407ms]
Apr 15 10:21:47.265: INFO: Created: latency-svc-2gjtg
Apr 15 10:21:47.289: INFO: Got endpoints: latency-svc-jkzch [750.88153ms]
Apr 15 10:21:47.313: INFO: Created: latency-svc-zjj89
Apr 15 10:21:47.338: INFO: Got endpoints: latency-svc-96r6x [745.193831ms]
Apr 15 10:21:47.373: INFO: Created: latency-svc-8rvv9
Apr 15 10:21:47.391: INFO: Got endpoints: latency-svc-w42zk [752.943687ms]
Apr 15 10:21:47.419: INFO: Created: latency-svc-dqgpc
Apr 15 10:21:47.437: INFO: Got endpoints: latency-svc-df6xw [747.979988ms]
Apr 15 10:21:47.458: INFO: Created: latency-svc-xd5gw
Apr 15 10:21:47.491: INFO: Got endpoints: latency-svc-q4wz7 [752.558333ms]
Apr 15 10:21:47.513: INFO: Created: latency-svc-24f2m
Apr 15 10:21:47.538: INFO: Got endpoints: latency-svc-jd5nr [748.961295ms]
Apr 15 10:21:47.581: INFO: Created: latency-svc-xrbqw
Apr 15 10:21:47.591: INFO: Got endpoints: latency-svc-6l9w5 [752.549616ms]
Apr 15 10:21:47.617: INFO: Created: latency-svc-wfdwq
Apr 15 10:21:47.640: INFO: Got endpoints: latency-svc-7nd7r [740.03345ms]
Apr 15 10:21:47.660: INFO: Created: latency-svc-mk47w
Apr 15 10:21:47.692: INFO: Got endpoints: latency-svc-m7zcw [753.004252ms]
Apr 15 10:21:47.711: INFO: Created: latency-svc-xf6g8
Apr 15 10:21:47.742: INFO: Got endpoints: latency-svc-pfgz8 [749.813853ms]
Apr 15 10:21:47.776: INFO: Created: latency-svc-dzgqk
Apr 15 10:21:47.794: INFO: Got endpoints: latency-svc-r555m [745.123962ms]
Apr 15 10:21:47.818: INFO: Created: latency-svc-gm8z7
Apr 15 10:21:47.839: INFO: Got endpoints: latency-svc-8rvwc [750.886479ms]
Apr 15 10:21:47.860: INFO: Created: latency-svc-75v28
Apr 15 10:21:47.887: INFO: Got endpoints: latency-svc-xdxzq [749.346416ms]
Apr 15 10:21:47.913: INFO: Created: latency-svc-wnk46
Apr 15 10:21:47.938: INFO: Got endpoints: latency-svc-zpzwz [749.061189ms]
Apr 15 10:21:47.968: INFO: Created: latency-svc-mkkpj
Apr 15 10:21:47.989: INFO: Got endpoints: latency-svc-2gjtg [746.248054ms]
Apr 15 10:21:48.015: INFO: Created: latency-svc-fghdq
Apr 15 10:21:48.037: INFO: Got endpoints: latency-svc-zjj89 [747.478133ms]
Apr 15 10:21:48.062: INFO: Created: latency-svc-r8v9t
Apr 15 10:21:48.132: INFO: Got endpoints: latency-svc-8rvv9 [793.77788ms]
Apr 15 10:21:48.138: INFO: Got endpoints: latency-svc-dqgpc [746.258555ms]
Apr 15 10:21:48.158: INFO: Created: latency-svc-692kz
Apr 15 10:21:48.189: INFO: Created: latency-svc-rwvk8
Apr 15 10:21:48.190: INFO: Got endpoints: latency-svc-xd5gw [753.135923ms]
Apr 15 10:21:48.214: INFO: Created: latency-svc-47r5g
Apr 15 10:21:48.237: INFO: Got endpoints: latency-svc-24f2m [746.015002ms]
Apr 15 10:21:48.259: INFO: Created: latency-svc-4vwk7
Apr 15 10:21:48.287: INFO: Got endpoints: latency-svc-xrbqw [748.585838ms]
Apr 15 10:21:48.307: INFO: Created: latency-svc-mcp2f
Apr 15 10:21:48.339: INFO: Got endpoints: latency-svc-wfdwq [747.649356ms]
Apr 15 10:21:48.379: INFO: Created: latency-svc-slhqh
Apr 15 10:21:48.388: INFO: Got endpoints: latency-svc-mk47w [747.78457ms]
Apr 15 10:21:48.412: INFO: Created: latency-svc-9cjd6
Apr 15 10:21:48.463: INFO: Got endpoints: latency-svc-xf6g8 [770.838147ms]
Apr 15 10:21:48.486: INFO: Created: latency-svc-997fl
Apr 15 10:21:48.489: INFO: Got endpoints: latency-svc-dzgqk [746.659988ms]
Apr 15 10:21:48.545: INFO: Got endpoints: latency-svc-gm8z7 [751.52886ms]
Apr 15 10:21:48.588: INFO: Got endpoints: latency-svc-75v28 [749.158009ms]
Apr 15 10:21:48.638: INFO: Got endpoints: latency-svc-wnk46 [750.932232ms]
Apr 15 10:21:48.689: INFO: Got endpoints: latency-svc-mkkpj [750.919115ms]
Apr 15 10:21:48.738: INFO: Got endpoints: latency-svc-fghdq [749.074702ms]
Apr 15 10:21:48.789: INFO: Got endpoints: latency-svc-r8v9t [751.889572ms]
Apr 15 10:21:48.837: INFO: Got endpoints: latency-svc-692kz [704.299476ms]
Apr 15 10:21:48.888: INFO: Got endpoints: latency-svc-rwvk8 [750.545072ms]
Apr 15 10:21:48.940: INFO: Got endpoints: latency-svc-47r5g [749.797433ms]
Apr 15 10:21:48.988: INFO: Got endpoints: latency-svc-4vwk7 [751.263604ms]
Apr 15 10:21:49.038: INFO: Got endpoints: latency-svc-mcp2f [751.503385ms]
Apr 15 10:21:49.089: INFO: Got endpoints: latency-svc-slhqh [750.237876ms]
Apr 15 10:21:49.137: INFO: Got endpoints: latency-svc-9cjd6 [749.017444ms]
Apr 15 10:21:49.190: INFO: Got endpoints: latency-svc-997fl [727.147543ms]
Apr 15 10:21:49.190: INFO: Latencies: [33.935179ms 53.363831ms 79.080068ms 109.218613ms 123.057693ms 130.791954ms 150.049407ms 202.998767ms 267.696539ms 272.77613ms 273.766447ms 312.019099ms 328.547531ms 330.077862ms 330.322967ms 337.328307ms 338.156153ms 344.734721ms 349.432562ms 363.550277ms 365.292226ms 365.62959ms 372.134797ms 378.770194ms 381.21525ms 384.814339ms 384.841387ms 385.762933ms 387.422536ms 388.299317ms 390.059278ms 390.848271ms 390.857924ms 393.70905ms 394.136067ms 396.473628ms 398.078364ms 400.237319ms 406.248055ms 407.408785ms 407.697362ms 408.353746ms 408.421004ms 409.080669ms 410.170518ms 411.36402ms 414.742697ms 415.81516ms 423.238157ms 425.344127ms 425.84859ms 432.110133ms 436.694097ms 443.509025ms 446.068706ms 458.329584ms 461.08719ms 466.384591ms 474.031163ms 477.469246ms 482.678886ms 482.777061ms 488.241753ms 489.154654ms 497.998862ms 499.252272ms 506.211512ms 523.312172ms 537.006263ms 542.775601ms 565.088997ms 603.337203ms 622.862159ms 635.603066ms 657.443731ms 658.634429ms 688.816393ms 699.780597ms 704.299476ms 714.044481ms 727.147543ms 729.045339ms 729.390193ms 732.661619ms 732.787698ms 733.64271ms 735.822004ms 736.308794ms 736.764744ms 737.008581ms 738.34771ms 739.478945ms 740.03345ms 740.173866ms 740.724761ms 741.402353ms 742.228382ms 742.809349ms 743.655491ms 743.906737ms 744.277686ms 744.417988ms 744.440465ms 744.80491ms 745.028542ms 745.084965ms 745.123962ms 745.164306ms 745.193831ms 745.499674ms 745.632171ms 746.015002ms 746.115653ms 746.122692ms 746.248054ms 746.258555ms 746.628712ms 746.659988ms 747.478133ms 747.649356ms 747.78457ms 747.979988ms 748.201433ms 748.408188ms 748.585838ms 748.626333ms 748.961295ms 749.017444ms 749.03936ms 749.061189ms 749.074702ms 749.158009ms 749.257853ms 749.30164ms 749.346416ms 749.549547ms 749.678645ms 749.713674ms 749.740052ms 749.793281ms 749.797433ms 749.813853ms 749.878568ms 749.990701ms 750.061053ms 750.237876ms 750.254686ms 750.325465ms 750.391993ms 750.428912ms 750.504387ms 750.545072ms 750.640964ms 750.88153ms 750.886479ms 750.919115ms 750.932232ms 751.109036ms 751.125933ms 751.263604ms 751.503385ms 751.52886ms 751.624191ms 751.852683ms 751.889572ms 751.954556ms 752.161844ms 752.275075ms 752.293876ms 752.402582ms 752.489836ms 752.549616ms 752.558333ms 752.728139ms 752.771126ms 752.836808ms 752.943687ms 753.004252ms 753.135923ms 753.424449ms 753.897035ms 753.986407ms 754.018265ms 754.458095ms 757.05355ms 758.039954ms 759.451359ms 760.958608ms 761.117587ms 761.31519ms 762.98229ms 766.538946ms 767.122369ms 767.189005ms 767.544724ms 770.838147ms 793.77788ms 799.419023ms 815.914993ms 858.63722ms]
Apr 15 10:21:49.191: INFO: 50 %ile: 744.277686ms
Apr 15 10:21:49.191: INFO: 90 %ile: 753.897035ms
Apr 15 10:21:49.191: INFO: 99 %ile: 815.914993ms
Apr 15 10:21:49.191: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:21:49.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3969" for this suite.
Apr 15 10:22:09.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:22:09.310: INFO: namespace svc-latency-3969 deletion completed in 20.111395955s

• [SLOW TEST:30.922 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:22:09.310: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-537dc1fe-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:22:09.366: INFO: Waiting up to 5m0s for pod "pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-608" to be "success or failure"
Apr 15 10:22:09.370: INFO: Pod "pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.324625ms
Apr 15 10:22:11.374: INFO: Pod "pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008459256s
STEP: Saw pod success
Apr 15 10:22:11.375: INFO: Pod "pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:22:11.378: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:22:11.398: INFO: Waiting for pod pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:22:11.401: INFO: Pod pod-secrets-537ef635-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:22:11.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-608" for this suite.
Apr 15 10:22:17.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:22:17.518: INFO: namespace secrets-608 deletion completed in 6.113635452s

• [SLOW TEST:8.208 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:22:17.519: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:22:21.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4193" for this suite.
Apr 15 10:22:27.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:22:27.693: INFO: namespace kubelet-test-4193 deletion completed in 6.112544269s

• [SLOW TEST:10.174 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:22:27.694: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-5e916792-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:22:27.948: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "projected-3903" to be "success or failure"
Apr 15 10:22:27.953: INFO: Pod "pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.891685ms
Apr 15 10:22:29.957: INFO: Pod "pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00924482s
STEP: Saw pod success
Apr 15 10:22:29.957: INFO: Pod "pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:22:29.963: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:22:29.989: INFO: Waiting for pod pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:22:29.997: INFO: Pod pod-projected-configmaps-5e927230-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:22:29.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3903" for this suite.
Apr 15 10:22:36.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:22:36.117: INFO: namespace projected-3903 deletion completed in 6.113952792s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:22:36.118: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:22:36.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 version --client'
Apr 15 10:22:36.258: INFO: stderr: ""
Apr 15 10:22:36.258: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 15 10:22:36.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-113'
Apr 15 10:22:36.585: INFO: stderr: ""
Apr 15 10:22:36.585: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 15 10:22:36.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-113'
Apr 15 10:22:36.781: INFO: stderr: ""
Apr 15 10:22:36.781: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 15 10:22:37.785: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:22:37.785: INFO: Found 0 / 1
Apr 15 10:22:38.786: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:22:38.786: INFO: Found 1 / 1
Apr 15 10:22:38.786: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 15 10:22:38.794: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 10:22:38.794: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 15 10:22:38.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 describe pod redis-master-b5w5g --namespace=kubectl-113'
Apr 15 10:22:38.874: INFO: stderr: ""
Apr 15 10:22:38.874: INFO: stdout: "Name:               redis-master-b5w5g\nNamespace:          kubectl-113\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-1-206.eu-west-1.compute.internal/10.0.1.206\nStart Time:         Mon, 15 Apr 2019 10:22:36 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.14.17/32\nStatus:             Running\nIP:                 192.168.14.17\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a9b5fd238cb7ed64715a1fa7148f068070aea56a2ca6c71ba65d7b806bfdb7ee\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 15 Apr 2019 10:22:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gjw9q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gjw9q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gjw9q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                               Message\n  ----    ------     ----  ----                                               -------\n  Normal  Scheduled  2s    default-scheduler                                  Successfully assigned kubectl-113/redis-master-b5w5g to ip-10-0-1-206.eu-west-1.compute.internal\n  Normal  Pulled     1s    kubelet, ip-10-0-1-206.eu-west-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-0-1-206.eu-west-1.compute.internal  Created container redis-master\n  Normal  Started    1s    kubelet, ip-10-0-1-206.eu-west-1.compute.internal  Started container redis-master\n"
Apr 15 10:22:38.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 describe rc redis-master --namespace=kubectl-113'
Apr 15 10:22:38.967: INFO: stderr: ""
Apr 15 10:22:38.967: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-113\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-b5w5g\n"
Apr 15 10:22:38.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 describe service redis-master --namespace=kubectl-113'
Apr 15 10:22:39.046: INFO: stderr: ""
Apr 15 10:22:39.046: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-113\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.98.58.30\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.14.17:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 15 10:22:39.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 describe node ip-10-0-1-206.eu-west-1.compute.internal'
Apr 15 10:22:39.148: INFO: stderr: ""
Apr 15 10:22:39.148: INFO: stdout: "Name:               ip-10-0-1-206.eu-west-1.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-1\n                    failure-domain.beta.kubernetes.io/zone=eu-west-1a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-1-206.eu-west-1.compute.internal\n                    kubernetes.io/os=linux\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.1.206/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.14.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 15 Apr 2019 09:24:38 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 15 Apr 2019 09:53:55 +0000   Mon, 15 Apr 2019 09:53:55 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 15 Apr 2019 10:22:00 +0000   Mon, 15 Apr 2019 09:24:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 15 Apr 2019 10:22:00 +0000   Mon, 15 Apr 2019 09:24:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 15 Apr 2019 10:22:00 +0000   Mon, 15 Apr 2019 09:24:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 15 Apr 2019 10:22:00 +0000   Mon, 15 Apr 2019 09:53:59 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.0.1.206\n  InternalDNS:  ip-10-0-1-206.eu-west-1.compute.internal\n  Hostname:     ip-10-0-1-206.eu-west-1.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           48375392Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8065692Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           44582761194\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      7963292Ki\n pods:                        110\nSystem Info:\n Machine ID:                 ec2d87bd20aeefed88dd08ed6025a472\n System UUID:                ec2d87bd-20ae-efed-88dd-08ed6025a472\n Boot ID:                    356c2e12-17c9-4e53-b154-cf94dd2a53db\n Kernel Version:             4.19.25-coreos\n OS Image:                   Container Linux by CoreOS 2023.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.5\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     192.168.3.0/24\nProviderID:                  aws:///eu-west-1a/i-0cf6151c8820fea10\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-95t5f    0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                calico-kube-controllers-5cbcccc885-9wk5c                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                calico-node-jf886                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                calico-typha-6ddbb994-brhgt                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                coredns-fb8b8dccf-wzk6q                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     58m\n  kube-system                kube-proxy-p22f4                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         58m\n  kubectl-113                redis-master-b5w5g                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         350m (17%)  0 (0%)\n  memory                      70Mi (0%)   170Mi (2%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:\n  Type    Reason                   Age                From                                                  Message\n  ----    ------                   ----               ----                                                  -------\n  Normal  NodeHasSufficientMemory  58m (x8 over 58m)  kubelet, ip-10-0-1-206.eu-west-1.compute.internal     Node ip-10-0-1-206.eu-west-1.compute.internal status is now: NodeHasSufficientMemory\n  Normal  Starting                 57m                kube-proxy, ip-10-0-1-206.eu-west-1.compute.internal  Starting kube-proxy.\n  Normal  NodeReady                28m                kubelet, ip-10-0-1-206.eu-west-1.compute.internal     Node ip-10-0-1-206.eu-west-1.compute.internal status is now: NodeReady\n"
Apr 15 10:22:39.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 describe namespace kubectl-113'
Apr 15 10:22:39.230: INFO: stderr: ""
Apr 15 10:22:39.230: INFO: stdout: "Name:         kubectl-113\nLabels:       e2e-framework=kubectl\n              e2e-run=9d206de5-5f64-11e9-a7dc-a6e5a2dd4982\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:22:39.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-113" for this suite.
Apr 15 10:23:01.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:23:01.339: INFO: namespace kubectl-113 deletion completed in 22.105475199s

• [SLOW TEST:25.221 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:23:01.339: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 15 10:23:01.380: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 15 10:23:01.387: INFO: Waiting for terminating namespaces to be deleted...
Apr 15 10:23:01.390: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-206.eu-west-1.compute.internal before test
Apr 15 10:23:01.396: INFO: calico-kube-controllers-5cbcccc885-9wk5c from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Apr 15 10:23:01.396: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-95t5f from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:23:01.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:23:01.396: INFO: calico-node-jf886 from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container calico-node ready: true, restart count 0
Apr 15 10:23:01.396: INFO: coredns-fb8b8dccf-wzk6q from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:23:01.396: INFO: kube-proxy-p22f4 from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:23:01.396: INFO: calico-typha-6ddbb994-brhgt from kube-system started at 2019-04-15 09:54:03 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.396: INFO: 	Container calico-typha ready: true, restart count 0
Apr 15 10:23:01.396: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-88.eu-west-1.compute.internal before test
Apr 15 10:23:01.404: INFO: sonobuoy-e2e-job-b24a9b66ba984d5a from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container e2e ready: true, restart count 0
Apr 15 10:23:01.404: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:23:01.404: INFO: sonobuoy-systemd-logs-daemon-set-c579e22645c94ab5-phs4j from heptio-sonobuoy started at 2019-04-15 09:55:07 +0000 UTC (2 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 15 10:23:01.404: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 15 10:23:01.404: INFO: calicoctl from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container calicoctl ready: true, restart count 0
Apr 15 10:23:01.404: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-15 09:55:01 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 15 10:23:01.404: INFO: coredns-fb8b8dccf-khkh8 from kube-system started at 2019-04-15 09:54:00 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container coredns ready: true, restart count 1
Apr 15 10:23:01.404: INFO: kube-proxy-ktvkt from kube-system started at 2019-04-15 09:24:39 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 15 10:23:01.404: INFO: calico-node-sjhhv from kube-system started at 2019-04-15 09:53:46 +0000 UTC (1 container statuses recorded)
Apr 15 10:23:01.404: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15959ebd1ea5824e], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:23:02.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1664" for this suite.
Apr 15 10:23:08.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:23:08.553: INFO: namespace sched-pred-1664 deletion completed in 6.117798557s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.214 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:23:08.553: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 15 10:23:08.596: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:23:16.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8770" for this suite.
Apr 15 10:23:22.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:23:22.351: INFO: namespace pods-8770 deletion completed in 6.109949106s

• [SLOW TEST:13.798 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:23:22.352: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-7f0750d2-5f68-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:23:24.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7006" for this suite.
Apr 15 10:23:46.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:23:46.613: INFO: namespace configmap-7006 deletion completed in 22.173709045s

• [SLOW TEST:24.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:23:46.613: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 15 10:23:46.681: INFO: Waiting up to 5m0s for pod "client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "containers-878" to be "success or failure"
Apr 15 10:23:46.696: INFO: Pod "client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 14.118607ms
Apr 15 10:23:48.700: INFO: Pod "client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018296079s
STEP: Saw pod success
Apr 15 10:23:48.700: INFO: Pod "client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:23:48.703: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:23:48.724: INFO: Waiting for pod client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:23:48.727: INFO: Pod client-containers-8d7e63e6-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:23:48.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-878" for this suite.
Apr 15 10:23:54.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:23:54.850: INFO: namespace containers-878 deletion completed in 6.118644735s

• [SLOW TEST:8.236 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:23:54.850: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:24:19.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4199" for this suite.
Apr 15 10:24:25.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:24:25.195: INFO: namespace namespaces-4199 deletion completed in 6.150240198s
STEP: Destroying namespace "nsdeletetest-7343" for this suite.
Apr 15 10:24:25.199: INFO: Namespace nsdeletetest-7343 was already deleted
STEP: Destroying namespace "nsdeletetest-1075" for this suite.
Apr 15 10:24:31.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:24:31.310: INFO: namespace nsdeletetest-1075 deletion completed in 6.110656315s

• [SLOW TEST:36.460 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:24:31.310: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 15 10:24:31.360: INFO: Waiting up to 5m0s for pod "pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-8904" to be "success or failure"
Apr 15 10:24:31.367: INFO: Pod "pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.516799ms
Apr 15 10:24:33.372: INFO: Pod "pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011579289s
STEP: Saw pod success
Apr 15 10:24:33.372: INFO: Pod "pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:24:33.375: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:24:33.398: INFO: Waiting for pod pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:24:33.402: INFO: Pod pod-a820d850-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:24:33.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8904" for this suite.
Apr 15 10:24:39.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:24:39.536: INFO: namespace emptydir-8904 deletion completed in 6.129678825s

• [SLOW TEST:8.226 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:24:39.537: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 15 10:24:43.639: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:43.642: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:45.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:45.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:47.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:47.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:49.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:49.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:51.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:51.647: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:53.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:53.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:55.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:55.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:57.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:57.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:24:59.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:24:59.652: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:25:01.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:25:01.652: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:25:03.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:25:03.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:25:05.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:25:05.646: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 15 10:25:07.642: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 15 10:25:07.647: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:25:07.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9196" for this suite.
Apr 15 10:25:29.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:25:29.791: INFO: namespace container-lifecycle-hook-9196 deletion completed in 22.139024838s

• [SLOW TEST:50.254 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:25:29.791: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 15 10:25:29.839: INFO: Waiting up to 5m0s for pod "var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982" in namespace "var-expansion-4756" to be "success or failure"
Apr 15 10:25:29.845: INFO: Pod "var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.302382ms
Apr 15 10:25:31.849: INFO: Pod "var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010353152s
STEP: Saw pod success
Apr 15 10:25:31.849: INFO: Pod "var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:25:31.852: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:25:31.873: INFO: Waiting for pod var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:25:31.877: INFO: Pod var-expansion-cafc5860-5f68-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:25:31.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4756" for this suite.
Apr 15 10:25:37.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:25:38.019: INFO: namespace var-expansion-4756 deletion completed in 6.13749539s

• [SLOW TEST:8.227 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:25:38.019: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:25:38.066: INFO: (0) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.599176ms)
Apr 15 10:25:38.070: INFO: (1) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.411476ms)
Apr 15 10:25:38.074: INFO: (2) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.861743ms)
Apr 15 10:25:38.078: INFO: (3) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.208583ms)
Apr 15 10:25:38.082: INFO: (4) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.77907ms)
Apr 15 10:25:38.086: INFO: (5) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.762889ms)
Apr 15 10:25:38.090: INFO: (6) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.794694ms)
Apr 15 10:25:38.093: INFO: (7) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.787769ms)
Apr 15 10:25:38.098: INFO: (8) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.367255ms)
Apr 15 10:25:38.103: INFO: (9) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.884294ms)
Apr 15 10:25:38.107: INFO: (10) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.839267ms)
Apr 15 10:25:38.111: INFO: (11) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.898507ms)
Apr 15 10:25:38.115: INFO: (12) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.052206ms)
Apr 15 10:25:38.119: INFO: (13) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.94923ms)
Apr 15 10:25:38.123: INFO: (14) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.281357ms)
Apr 15 10:25:38.127: INFO: (15) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.93434ms)
Apr 15 10:25:38.131: INFO: (16) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.054729ms)
Apr 15 10:25:38.135: INFO: (17) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.17912ms)
Apr 15 10:25:38.139: INFO: (18) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.887564ms)
Apr 15 10:25:38.143: INFO: (19) /api/v1/nodes/ip-10-0-1-206.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.781321ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:25:38.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3205" for this suite.
Apr 15 10:25:44.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:25:44.269: INFO: namespace proxy-3205 deletion completed in 6.12167673s

• [SLOW TEST:6.250 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:25:44.269: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 15 10:25:48.422: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:48.422: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:48.550: INFO: Exec stderr: ""
Apr 15 10:25:48.550: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:48.550: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:48.669: INFO: Exec stderr: ""
Apr 15 10:25:48.669: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:48.669: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:48.791: INFO: Exec stderr: ""
Apr 15 10:25:48.791: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:48.791: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:48.920: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 15 10:25:48.921: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:48.921: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.039: INFO: Exec stderr: ""
Apr 15 10:25:49.039: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:49.039: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.157: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 15 10:25:49.157: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:49.157: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.269: INFO: Exec stderr: ""
Apr 15 10:25:49.269: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:49.269: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.392: INFO: Exec stderr: ""
Apr 15 10:25:49.392: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:49.392: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.576: INFO: Exec stderr: ""
Apr 15 10:25:49.576: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9132 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:25:49.576: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:25:49.698: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:25:49.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9132" for this suite.
Apr 15 10:26:41.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:26:41.820: INFO: namespace e2e-kubelet-etc-hosts-9132 deletion completed in 52.117705782s

• [SLOW TEST:57.551 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:26:41.821: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 15 10:26:44.401: INFO: Successfully updated pod "labelsupdatef5eb1e4d-5f68-11e9-a7dc-a6e5a2dd4982"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:26:48.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-581" for this suite.
Apr 15 10:27:10.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:27:10.559: INFO: namespace projected-581 deletion completed in 22.131427622s

• [SLOW TEST:28.738 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:27:10.559: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 15 10:27:10.663: INFO: Waiting up to 5m0s for pod "pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-1950" to be "success or failure"
Apr 15 10:27:10.669: INFO: Pod "pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.336286ms
Apr 15 10:27:12.675: INFO: Pod "pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011404504s
STEP: Saw pod success
Apr 15 10:27:12.675: INFO: Pod "pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:27:12.683: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:27:12.715: INFO: Waiting for pod pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:27:12.718: INFO: Pod pod-0714cb5f-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:27:12.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1950" for this suite.
Apr 15 10:27:18.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:27:18.838: INFO: namespace emptydir-1950 deletion completed in 6.116490763s

• [SLOW TEST:8.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:27:18.839: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:27:18.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9887" for this suite.
Apr 15 10:27:40.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:27:41.014: INFO: namespace kubelet-test-9887 deletion completed in 22.110726526s

• [SLOW TEST:22.176 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:27:41.015: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-19338be7-5f69-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:27:41.068: INFO: Waiting up to 5m0s for pod "pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-7564" to be "success or failure"
Apr 15 10:27:41.073: INFO: Pod "pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.644813ms
Apr 15 10:27:43.077: INFO: Pod "pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008536868s
STEP: Saw pod success
Apr 15 10:27:43.077: INFO: Pod "pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:27:43.080: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:27:43.100: INFO: Waiting for pod pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:27:43.103: INFO: Pod pod-configmaps-1934a33f-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:27:43.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7564" for this suite.
Apr 15 10:27:49.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:27:49.223: INFO: namespace configmap-7564 deletion completed in 6.116337753s

• [SLOW TEST:8.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:27:49.224: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-3037
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3037 to expose endpoints map[]
Apr 15 10:27:49.299: INFO: successfully validated that service endpoint-test2 in namespace services-3037 exposes endpoints map[] (5.939754ms elapsed)
STEP: Creating pod pod1 in namespace services-3037
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3037 to expose endpoints map[pod1:[80]]
Apr 15 10:27:51.343: INFO: successfully validated that service endpoint-test2 in namespace services-3037 exposes endpoints map[pod1:[80]] (2.031939687s elapsed)
STEP: Creating pod pod2 in namespace services-3037
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3037 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 15 10:27:52.371: INFO: successfully validated that service endpoint-test2 in namespace services-3037 exposes endpoints map[pod1:[80] pod2:[80]] (1.021163901s elapsed)
STEP: Deleting pod pod1 in namespace services-3037
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3037 to expose endpoints map[pod2:[80]]
Apr 15 10:27:53.395: INFO: successfully validated that service endpoint-test2 in namespace services-3037 exposes endpoints map[pod2:[80]] (1.0167974s elapsed)
STEP: Deleting pod pod2 in namespace services-3037
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3037 to expose endpoints map[]
Apr 15 10:27:54.412: INFO: successfully validated that service endpoint-test2 in namespace services-3037 exposes endpoints map[] (1.010215255s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:27:54.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3037" for this suite.
Apr 15 10:28:16.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:28:16.598: INFO: namespace services-3037 deletion completed in 22.116604366s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.374 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:28:16.598: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-2e68db52-5f69-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:28:16.650: INFO: Waiting up to 5m0s for pod "pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-3500" to be "success or failure"
Apr 15 10:28:16.654: INFO: Pod "pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88445ms
Apr 15 10:28:18.659: INFO: Pod "pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008925941s
STEP: Saw pod success
Apr 15 10:28:18.659: INFO: Pod "pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:28:18.666: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:28:18.686: INFO: Waiting for pod pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:28:18.689: INFO: Pod pod-secrets-2e6a194e-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:28:18.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3500" for this suite.
Apr 15 10:28:24.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:28:24.811: INFO: namespace secrets-3500 deletion completed in 6.117856382s

• [SLOW TEST:8.212 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:28:24.811: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:28:24.859: INFO: Waiting up to 5m0s for pod "downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-7810" to be "success or failure"
Apr 15 10:28:24.874: INFO: Pod "downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 14.170517ms
Apr 15 10:28:26.878: INFO: Pod "downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018351607s
STEP: Saw pod success
Apr 15 10:28:26.878: INFO: Pod "downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:28:26.881: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:28:26.904: INFO: Waiting for pod downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:28:26.908: INFO: Pod downwardapi-volume-334e191d-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:28:26.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7810" for this suite.
Apr 15 10:28:32.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:28:33.038: INFO: namespace downward-api-7810 deletion completed in 6.126249338s

• [SLOW TEST:8.226 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:28:33.038: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-8plk
STEP: Creating a pod to test atomic-volume-subpath
Apr 15 10:28:33.145: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8plk" in namespace "subpath-2086" to be "success or failure"
Apr 15 10:28:33.150: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.678912ms
Apr 15 10:28:35.155: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 2.010343826s
Apr 15 10:28:37.159: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 4.014382115s
Apr 15 10:28:39.164: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 6.019477183s
Apr 15 10:28:41.168: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 8.023469724s
Apr 15 10:28:43.173: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 10.027822857s
Apr 15 10:28:45.178: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 12.03307253s
Apr 15 10:28:47.183: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 14.037664778s
Apr 15 10:28:49.187: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 16.04177159s
Apr 15 10:28:51.192: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 18.046719952s
Apr 15 10:28:53.196: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Running", Reason="", readiness=true. Elapsed: 20.051393683s
Apr 15 10:28:55.202: INFO: Pod "pod-subpath-test-projected-8plk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.057265117s
STEP: Saw pod success
Apr 15 10:28:55.202: INFO: Pod "pod-subpath-test-projected-8plk" satisfied condition "success or failure"
Apr 15 10:28:55.206: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-subpath-test-projected-8plk container test-container-subpath-projected-8plk: <nil>
STEP: delete the pod
Apr 15 10:28:55.227: INFO: Waiting for pod pod-subpath-test-projected-8plk to disappear
Apr 15 10:28:55.231: INFO: Pod pod-subpath-test-projected-8plk no longer exists
STEP: Deleting pod pod-subpath-test-projected-8plk
Apr 15 10:28:55.231: INFO: Deleting pod "pod-subpath-test-projected-8plk" in namespace "subpath-2086"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:28:55.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2086" for this suite.
Apr 15 10:29:01.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:29:01.404: INFO: namespace subpath-2086 deletion completed in 6.166124541s

• [SLOW TEST:28.366 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:29:01.405: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 15 10:29:01.467: INFO: Waiting up to 5m0s for pod "downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-7740" to be "success or failure"
Apr 15 10:29:01.477: INFO: Pod "downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 9.424119ms
Apr 15 10:29:03.481: INFO: Pod "downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013887709s
STEP: Saw pod success
Apr 15 10:29:03.481: INFO: Pod "downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:29:03.485: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:29:03.511: INFO: Waiting for pod downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:29:03.517: INFO: Pod downward-api-491fa12b-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:29:03.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7740" for this suite.
Apr 15 10:29:09.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:29:09.635: INFO: namespace downward-api-7740 deletion completed in 6.113826126s

• [SLOW TEST:8.231 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:29:09.636: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:29:11.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4624" for this suite.
Apr 15 10:29:49.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:29:49.827: INFO: namespace kubelet-test-4624 deletion completed in 38.121323237s

• [SLOW TEST:40.192 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:29:49.828: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:29:49.881: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-5446" to be "success or failure"
Apr 15 10:29:49.887: INFO: Pod "downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.666621ms
Apr 15 10:29:51.898: INFO: Pod "downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017038208s
STEP: Saw pod success
Apr 15 10:29:51.898: INFO: Pod "downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:29:51.903: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:29:51.942: INFO: Waiting for pod downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:29:51.948: INFO: Pod downwardapi-volume-65fb37d7-5f69-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:29:51.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5446" for this suite.
Apr 15 10:29:57.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:29:58.073: INFO: namespace downward-api-5446 deletion completed in 6.120996328s

• [SLOW TEST:8.246 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:29:58.074: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 15 10:29:58.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-964'
Apr 15 10:29:58.269: INFO: stderr: ""
Apr 15 10:29:58.269: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 10:29:58.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-964'
Apr 15 10:29:58.355: INFO: stderr: ""
Apr 15 10:29:58.355: INFO: stdout: "update-demo-nautilus-56d54 update-demo-nautilus-v74t4 "
Apr 15 10:29:58.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-56d54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:29:58.423: INFO: stderr: ""
Apr 15 10:29:58.423: INFO: stdout: ""
Apr 15 10:29:58.423: INFO: update-demo-nautilus-56d54 is created but not running
Apr 15 10:30:03.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-964'
Apr 15 10:30:03.498: INFO: stderr: ""
Apr 15 10:30:03.498: INFO: stdout: "update-demo-nautilus-56d54 update-demo-nautilus-v74t4 "
Apr 15 10:30:03.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-56d54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:03.559: INFO: stderr: ""
Apr 15 10:30:03.559: INFO: stdout: "true"
Apr 15 10:30:03.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-56d54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:03.623: INFO: stderr: ""
Apr 15 10:30:03.623: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 10:30:03.623: INFO: validating pod update-demo-nautilus-56d54
Apr 15 10:30:03.630: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 10:30:03.630: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 10:30:03.630: INFO: update-demo-nautilus-56d54 is verified up and running
Apr 15 10:30:03.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-v74t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:03.701: INFO: stderr: ""
Apr 15 10:30:03.701: INFO: stdout: "true"
Apr 15 10:30:03.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-v74t4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:03.764: INFO: stderr: ""
Apr 15 10:30:03.764: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 10:30:03.764: INFO: validating pod update-demo-nautilus-v74t4
Apr 15 10:30:03.770: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 10:30:03.770: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 10:30:03.770: INFO: update-demo-nautilus-v74t4 is verified up and running
STEP: rolling-update to new replication controller
Apr 15 10:30:03.771: INFO: scanned /root for discovery docs: <nil>
Apr 15 10:30:03.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-964'
Apr 15 10:30:26.163: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 15 10:30:26.163: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 10:30:26.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-964'
Apr 15 10:30:26.239: INFO: stderr: ""
Apr 15 10:30:26.239: INFO: stdout: "update-demo-kitten-6t9vm update-demo-kitten-zhl7x update-demo-nautilus-56d54 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Apr 15 10:30:31.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-964'
Apr 15 10:30:31.312: INFO: stderr: ""
Apr 15 10:30:31.312: INFO: stdout: "update-demo-kitten-6t9vm update-demo-kitten-zhl7x "
Apr 15 10:30:31.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-kitten-6t9vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:31.388: INFO: stderr: ""
Apr 15 10:30:31.388: INFO: stdout: "true"
Apr 15 10:30:31.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-kitten-6t9vm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:31.453: INFO: stderr: ""
Apr 15 10:30:31.453: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 15 10:30:31.453: INFO: validating pod update-demo-kitten-6t9vm
Apr 15 10:30:31.458: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 15 10:30:31.458: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 15 10:30:31.458: INFO: update-demo-kitten-6t9vm is verified up and running
Apr 15 10:30:31.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-kitten-zhl7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:31.531: INFO: stderr: ""
Apr 15 10:30:31.531: INFO: stdout: "true"
Apr 15 10:30:31.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-kitten-zhl7x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-964'
Apr 15 10:30:31.594: INFO: stderr: ""
Apr 15 10:30:31.594: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 15 10:30:31.594: INFO: validating pod update-demo-kitten-zhl7x
Apr 15 10:30:31.600: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 15 10:30:31.600: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 15 10:30:31.600: INFO: update-demo-kitten-zhl7x is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:30:31.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-964" for this suite.
Apr 15 10:30:53.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:30:53.726: INFO: namespace kubectl-964 deletion completed in 22.122331145s

• [SLOW TEST:55.653 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:30:53.726: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7007
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 15 10:30:53.764: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 15 10:31:15.857: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.215:8080/dial?request=hostName&protocol=udp&host=192.168.14.37&port=8081&tries=1'] Namespace:pod-network-test-7007 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:31:15.857: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:31:15.969: INFO: Waiting for endpoints: map[]
Apr 15 10:31:15.973: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.215:8080/dial?request=hostName&protocol=udp&host=192.168.126.214&port=8081&tries=1'] Namespace:pod-network-test-7007 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:31:15.973: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:31:16.097: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:31:16.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7007" for this suite.
Apr 15 10:31:38.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:31:38.231: INFO: namespace pod-network-test-7007 deletion completed in 22.127141988s

• [SLOW TEST:44.505 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:31:38.234: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2898
Apr 15 10:31:40.294: INFO: Started pod liveness-exec in namespace container-probe-2898
STEP: checking the pod's current state and verifying that restartCount is present
Apr 15 10:31:40.297: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:35:40.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2898" for this suite.
Apr 15 10:35:46.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:35:47.008: INFO: namespace container-probe-2898 deletion completed in 6.118194449s

• [SLOW TEST:248.774 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:35:47.008: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 15 10:35:47.108: INFO: Waiting up to 5m0s for pod "pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-4628" to be "success or failure"
Apr 15 10:35:47.113: INFO: Pod "pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.626286ms
Apr 15 10:35:49.117: INFO: Pod "pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009540017s
STEP: Saw pod success
Apr 15 10:35:49.117: INFO: Pod "pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:35:49.125: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:35:49.148: INFO: Waiting for pod pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:35:49.151: INFO: Pod pod-3ae7e08b-5f6a-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:35:49.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4628" for this suite.
Apr 15 10:35:55.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:35:55.294: INFO: namespace emptydir-4628 deletion completed in 6.138719315s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:35:55.294: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9938
Apr 15 10:35:59.355: INFO: Started pod liveness-http in namespace container-probe-9938
STEP: checking the pod's current state and verifying that restartCount is present
Apr 15 10:35:59.358: INFO: Initial restart count of pod liveness-http is 0
Apr 15 10:36:15.396: INFO: Restart count of pod container-probe-9938/liveness-http is now 1 (16.038183014s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:36:15.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9938" for this suite.
Apr 15 10:36:21.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:36:21.559: INFO: namespace container-probe-9938 deletion completed in 6.145266726s

• [SLOW TEST:26.265 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:36:21.560: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-fnfg
STEP: Creating a pod to test atomic-volume-subpath
Apr 15 10:36:21.617: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-fnfg" in namespace "subpath-388" to be "success or failure"
Apr 15 10:36:21.630: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Pending", Reason="", readiness=false. Elapsed: 13.300027ms
Apr 15 10:36:23.635: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 2.017566516s
Apr 15 10:36:25.644: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 4.027205871s
Apr 15 10:36:27.649: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 6.031885956s
Apr 15 10:36:29.654: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 8.036436261s
Apr 15 10:36:31.658: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 10.040830156s
Apr 15 10:36:33.662: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 12.045183034s
Apr 15 10:36:35.671: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 14.054050629s
Apr 15 10:36:37.676: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 16.058416105s
Apr 15 10:36:39.679: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 18.062293244s
Apr 15 10:36:41.684: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Running", Reason="", readiness=true. Elapsed: 20.067240375s
Apr 15 10:36:43.689: INFO: Pod "pod-subpath-test-secret-fnfg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.072184422s
STEP: Saw pod success
Apr 15 10:36:43.689: INFO: Pod "pod-subpath-test-secret-fnfg" satisfied condition "success or failure"
Apr 15 10:36:43.694: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-subpath-test-secret-fnfg container test-container-subpath-secret-fnfg: <nil>
STEP: delete the pod
Apr 15 10:36:43.715: INFO: Waiting for pod pod-subpath-test-secret-fnfg to disappear
Apr 15 10:36:43.719: INFO: Pod pod-subpath-test-secret-fnfg no longer exists
STEP: Deleting pod pod-subpath-test-secret-fnfg
Apr 15 10:36:43.719: INFO: Deleting pod "pod-subpath-test-secret-fnfg" in namespace "subpath-388"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:36:43.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-388" for this suite.
Apr 15 10:36:49.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:36:49.858: INFO: namespace subpath-388 deletion completed in 6.131372622s

• [SLOW TEST:28.298 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:36:49.858: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 15 10:36:52.440: INFO: Successfully updated pod "labelsupdate605664d3-5f6a-11e9-a7dc-a6e5a2dd4982"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:36:56.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7182" for this suite.
Apr 15 10:37:18.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:37:18.585: INFO: namespace downward-api-7182 deletion completed in 22.115301559s

• [SLOW TEST:28.727 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:37:18.585: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:37:18.639: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 15 10:37:23.643: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 15 10:37:23.644: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 15 10:37:25.648: INFO: Creating deployment "test-rollover-deployment"
Apr 15 10:37:25.659: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 15 10:37:27.669: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 15 10:37:27.678: INFO: Ensure that both replica sets have 1 created replica
Apr 15 10:37:27.684: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 15 10:37:27.694: INFO: Updating deployment test-rollover-deployment
Apr 15 10:37:27.695: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 15 10:37:29.702: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 15 10:37:29.708: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 15 10:37:29.714: INFO: all replica sets need to contain the pod-template-hash label
Apr 15 10:37:29.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921449, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:37:31.722: INFO: all replica sets need to contain the pod-template-hash label
Apr 15 10:37:31.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921449, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:37:33.729: INFO: all replica sets need to contain the pod-template-hash label
Apr 15 10:37:33.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921449, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:37:35.724: INFO: all replica sets need to contain the pod-template-hash label
Apr 15 10:37:35.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921449, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:37:37.722: INFO: all replica sets need to contain the pod-template-hash label
Apr 15 10:37:37.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921449, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690921445, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 15 10:37:39.722: INFO: 
Apr 15 10:37:39.722: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 15 10:37:39.732: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-4996,SelfLink:/apis/apps/v1/namespaces/deployment-4996/deployments/test-rollover-deployment,UID:75a5edc9-5f6a-11e9-adae-06c5682e2662,ResourceVersion:15434,Generation:2,CreationTimestamp:2019-04-15 10:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-15 10:37:25 +0000 UTC 2019-04-15 10:37:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-15 10:37:39 +0000 UTC 2019-04-15 10:37:25 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 15 10:37:39.736: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-4996,SelfLink:/apis/apps/v1/namespaces/deployment-4996/replicasets/test-rollover-deployment-766b4d6c9d,UID:76df8819-5f6a-11e9-b895-0a5a25aca864,ResourceVersion:15423,Generation:2,CreationTimestamp:2019-04-15 10:37:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 75a5edc9-5f6a-11e9-adae-06c5682e2662 0xc002ba8627 0xc002ba8628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 15 10:37:39.736: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 15 10:37:39.736: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-4996,SelfLink:/apis/apps/v1/namespaces/deployment-4996/replicasets/test-rollover-controller,UID:717607bc-5f6a-11e9-adae-06c5682e2662,ResourceVersion:15433,Generation:2,CreationTimestamp:2019-04-15 10:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 75a5edc9-5f6a-11e9-adae-06c5682e2662 0xc002ba8477 0xc002ba8478}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 10:37:39.736: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-4996,SelfLink:/apis/apps/v1/namespaces/deployment-4996/replicasets/test-rollover-deployment-6455657675,UID:75aa688c-5f6a-11e9-b895-0a5a25aca864,ResourceVersion:15388,Generation:2,CreationTimestamp:2019-04-15 10:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 75a5edc9-5f6a-11e9-adae-06c5682e2662 0xc002ba8547 0xc002ba8548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 10:37:39.740: INFO: Pod "test-rollover-deployment-766b4d6c9d-wh667" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-wh667,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-4996,SelfLink:/api/v1/namespaces/deployment-4996/pods/test-rollover-deployment-766b4d6c9d-wh667,UID:76ee8e50-5f6a-11e9-b895-0a5a25aca864,ResourceVersion:15400,Generation:0,CreationTimestamp:2019-04-15 10:37:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.44/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 76df8819-5f6a-11e9-b895-0a5a25aca864 0xc002ba9167 0xc002ba9168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nv8mp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nv8mp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nv8mp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ba91d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ba91f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:37:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:37:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:37:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:37:27 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.44,StartTime:2019-04-15 10:37:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-15 10:37:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://659aa000af562e014867478565abe3252042b07f95c687672b796868c5e5cbf2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:37:39.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4996" for this suite.
Apr 15 10:37:45.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:37:45.860: INFO: namespace deployment-4996 deletion completed in 6.1154103s

• [SLOW TEST:27.274 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:37:45.860: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 15 10:37:45.970: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9329" to be "success or failure"
Apr 15 10:37:45.975: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.330861ms
Apr 15 10:37:47.980: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009773849s
Apr 15 10:37:49.986: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015647184s
STEP: Saw pod success
Apr 15 10:37:49.986: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 15 10:37:49.989: INFO: Trying to get logs from node ip-10-0-3-88.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 15 10:37:50.012: INFO: Waiting for pod pod-host-path-test to disappear
Apr 15 10:37:50.016: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:37:50.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9329" for this suite.
Apr 15 10:37:56.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:37:56.192: INFO: namespace hostpath-9329 deletion completed in 6.17124341s

• [SLOW TEST:10.332 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:37:56.192: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3571.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3571.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 15 10:38:12.286: INFO: DNS probes using dns-3571/dns-test-87e04c3a-5f6a-11e9-a7dc-a6e5a2dd4982 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:38:12.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3571" for this suite.
Apr 15 10:38:18.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:38:18.439: INFO: namespace dns-3571 deletion completed in 6.116783467s

• [SLOW TEST:22.247 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:38:18.439: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-dfbv
STEP: Creating a pod to test atomic-volume-subpath
Apr 15 10:38:18.499: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dfbv" in namespace "subpath-8048" to be "success or failure"
Apr 15 10:38:18.504: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Pending", Reason="", readiness=false. Elapsed: 5.514516ms
Apr 15 10:38:20.508: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 2.00952286s
Apr 15 10:38:22.512: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 4.013791459s
Apr 15 10:38:24.516: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 6.017743815s
Apr 15 10:38:26.520: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 8.021824959s
Apr 15 10:38:28.525: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 10.025890296s
Apr 15 10:38:30.529: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 12.030111681s
Apr 15 10:38:32.533: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 14.034438652s
Apr 15 10:38:34.537: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 16.03860439s
Apr 15 10:38:36.541: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 18.042663329s
Apr 15 10:38:38.552: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Running", Reason="", readiness=true. Elapsed: 20.053564906s
Apr 15 10:38:40.556: INFO: Pod "pod-subpath-test-configmap-dfbv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.057744762s
STEP: Saw pod success
Apr 15 10:38:40.556: INFO: Pod "pod-subpath-test-configmap-dfbv" satisfied condition "success or failure"
Apr 15 10:38:40.560: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-subpath-test-configmap-dfbv container test-container-subpath-configmap-dfbv: <nil>
STEP: delete the pod
Apr 15 10:38:40.588: INFO: Waiting for pod pod-subpath-test-configmap-dfbv to disappear
Apr 15 10:38:40.591: INFO: Pod pod-subpath-test-configmap-dfbv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dfbv
Apr 15 10:38:40.591: INFO: Deleting pod "pod-subpath-test-configmap-dfbv" in namespace "subpath-8048"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:38:40.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8048" for this suite.
Apr 15 10:38:46.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:38:46.727: INFO: namespace subpath-8048 deletion completed in 6.124159042s

• [SLOW TEST:28.288 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:38:46.727: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 15 10:38:46.780: INFO: Waiting up to 5m0s for pod "pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-7472" to be "success or failure"
Apr 15 10:38:46.784: INFO: Pod "pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05868ms
Apr 15 10:38:48.788: INFO: Pod "pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008159572s
STEP: Saw pod success
Apr 15 10:38:48.788: INFO: Pod "pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:38:48.792: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:38:48.810: INFO: Waiting for pod pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:38:48.814: INFO: Pod pod-a5ffe938-5f6a-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:38:48.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7472" for this suite.
Apr 15 10:38:54.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:38:55.008: INFO: namespace emptydir-7472 deletion completed in 6.189099752s

• [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:38:55.008: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1199
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 15 10:38:55.133: INFO: Found 0 stateful pods, waiting for 3
Apr 15 10:39:05.139: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:39:05.139: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:39:05.139: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 10:39:05.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-1199 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:39:05.359: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:39:05.359: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:39:05.359: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 15 10:39:15.397: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 15 10:39:25.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-1199 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:39:25.602: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:39:25.602: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:39:25.602: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:39:35.624: INFO: Waiting for StatefulSet statefulset-1199/ss2 to complete update
Apr 15 10:39:35.624: INFO: Waiting for Pod statefulset-1199/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 10:39:35.624: INFO: Waiting for Pod statefulset-1199/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 10:39:35.624: INFO: Waiting for Pod statefulset-1199/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 10:39:45.635: INFO: Waiting for StatefulSet statefulset-1199/ss2 to complete update
Apr 15 10:39:45.635: INFO: Waiting for Pod statefulset-1199/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 10:39:55.632: INFO: Waiting for StatefulSet statefulset-1199/ss2 to complete update
Apr 15 10:39:55.632: INFO: Waiting for Pod statefulset-1199/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr 15 10:40:05.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-1199 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 15 10:40:05.832: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 15 10:40:05.832: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 15 10:40:05.832: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 15 10:40:15.868: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 15 10:40:25.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 exec --namespace=statefulset-1199 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 15 10:40:26.087: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 15 10:40:26.087: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 15 10:40:26.087: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 15 10:40:36.109: INFO: Waiting for StatefulSet statefulset-1199/ss2 to complete update
Apr 15 10:40:36.109: INFO: Waiting for Pod statefulset-1199/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 15 10:40:46.118: INFO: Deleting all statefulset in ns statefulset-1199
Apr 15 10:40:46.121: INFO: Scaling statefulset ss2 to 0
Apr 15 10:41:06.139: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:41:06.142: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:41:06.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1199" for this suite.
Apr 15 10:41:14.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:41:14.300: INFO: namespace statefulset-1199 deletion completed in 8.138243588s

• [SLOW TEST:139.292 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:41:14.300: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-309
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 15 10:41:14.338: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 15 10:41:36.414: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.126.224 8081 | grep -v '^\s*$'] Namespace:pod-network-test-309 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:41:36.414: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:41:37.522: INFO: Found all expected endpoints: [netserver-0]
Apr 15 10:41:37.526: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.14.51 8081 | grep -v '^\s*$'] Namespace:pod-network-test-309 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:41:37.526: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:41:38.651: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:41:38.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-309" for this suite.
Apr 15 10:42:00.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:00.773: INFO: namespace pod-network-test-309 deletion completed in 22.117229667s

• [SLOW TEST:46.473 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:00.774: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 15 10:42:02.838: INFO: Pod pod-hostip-19a8640c-5f6b-11e9-a7dc-a6e5a2dd4982 has hostIP: 10.0.1.206
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:42:02.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2903" for this suite.
Apr 15 10:42:24.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:24.962: INFO: namespace pods-2903 deletion completed in 22.119946407s

• [SLOW TEST:24.189 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:24.963: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:42:25.023: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5058" to be "success or failure"
Apr 15 10:42:25.041: INFO: Pod "downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 18.273838ms
Apr 15 10:42:27.046: INFO: Pod "downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022647561s
STEP: Saw pod success
Apr 15 10:42:27.046: INFO: Pod "downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:42:27.049: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:42:27.071: INFO: Waiting for pod downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:42:27.074: INFO: Pod downwardapi-volume-2814aeec-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:42:27.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5058" for this suite.
Apr 15 10:42:35.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:35.235: INFO: namespace projected-5058 deletion completed in 8.157359513s

• [SLOW TEST:10.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:35.236: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-2e32f361-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:42:35.302: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-9701" to be "success or failure"
Apr 15 10:42:35.307: INFO: Pod "pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270299ms
Apr 15 10:42:37.311: INFO: Pod "pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008464291s
STEP: Saw pod success
Apr 15 10:42:37.311: INFO: Pod "pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:42:37.314: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:42:37.337: INFO: Waiting for pod pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:42:37.339: INFO: Pod pod-configmaps-2e34670c-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:42:37.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9701" for this suite.
Apr 15 10:42:43.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:43.456: INFO: namespace configmap-9701 deletion completed in 6.11290129s

• [SLOW TEST:8.221 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:43.457: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:42:43.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-9085" to be "success or failure"
Apr 15 10:42:43.509: INFO: Pod "downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176747ms
Apr 15 10:42:45.532: INFO: Pod "downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027100853s
STEP: Saw pod success
Apr 15 10:42:45.532: INFO: Pod "downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:42:45.538: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:42:45.577: INFO: Waiting for pod downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:42:45.581: INFO: Pod downwardapi-volume-3318fd81-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:42:45.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9085" for this suite.
Apr 15 10:42:51.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:51.704: INFO: namespace downward-api-9085 deletion completed in 6.116804053s

• [SLOW TEST:8.247 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:51.705: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 15 10:42:51.760: INFO: Waiting up to 5m0s for pod "var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "var-expansion-5644" to be "success or failure"
Apr 15 10:42:51.765: INFO: Pod "var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.48983ms
Apr 15 10:42:53.770: INFO: Pod "var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009527589s
STEP: Saw pod success
Apr 15 10:42:53.770: INFO: Pod "var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:42:53.773: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:42:53.793: INFO: Waiting for pod var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:42:53.796: INFO: Pod var-expansion-38048b93-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:42:53.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5644" for this suite.
Apr 15 10:42:59.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:42:59.911: INFO: namespace var-expansion-5644 deletion completed in 6.110901305s

• [SLOW TEST:8.207 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:42:59.912: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:43:00.012: INFO: Creating deployment "nginx-deployment"
Apr 15 10:43:00.031: INFO: Waiting for observed generation 1
Apr 15 10:43:02.038: INFO: Waiting for all required pods to come up
Apr 15 10:43:02.043: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 15 10:43:04.052: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 15 10:43:04.059: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 15 10:43:04.067: INFO: Updating deployment nginx-deployment
Apr 15 10:43:04.067: INFO: Waiting for observed generation 2
Apr 15 10:43:06.075: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 15 10:43:06.078: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 15 10:43:06.081: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 15 10:43:06.091: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 15 10:43:06.091: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 15 10:43:06.094: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 15 10:43:06.100: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 15 10:43:06.100: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 15 10:43:06.109: INFO: Updating deployment nginx-deployment
Apr 15 10:43:06.109: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 15 10:43:06.119: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 15 10:43:08.142: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 15 10:43:08.148: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6812,SelfLink:/apis/apps/v1/namespaces/deployment-6812/deployments/nginx-deployment,UID:3cf212ba-5f6b-11e9-adae-06c5682e2662,ResourceVersion:17230,Generation:3,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-15 10:43:06 +0000 UTC 2019-04-15 10:43:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-15 10:43:06 +0000 UTC 2019-04-15 10:43:00 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 15 10:43:08.152: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-6812,SelfLink:/apis/apps/v1/namespaces/deployment-6812/replicasets/nginx-deployment-5f9595f595,UID:3f5cc31e-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17225,Generation:3,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3cf212ba-5f6b-11e9-adae-06c5682e2662 0xc0031a1977 0xc0031a1978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 15 10:43:08.152: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 15 10:43:08.152: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-6812,SelfLink:/apis/apps/v1/namespaces/deployment-6812/replicasets/nginx-deployment-6f478d8d8,UID:3cf4f400-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17222,Generation:3,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3cf212ba-5f6b-11e9-adae-06c5682e2662 0xc0031a1a57 0xc0031a1a58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 15 10:43:08.158: INFO: Pod "nginx-deployment-5f9595f595-2jvt9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2jvt9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-2jvt9,UID:409b4bd3-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17288,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.8/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5c357 0xc002c5c358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5c3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5c3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.158: INFO: Pod "nginx-deployment-5f9595f595-2mbcd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2mbcd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-2mbcd,UID:3f6b85c8-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17120,Generation:0,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.231/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5c4b0 0xc002c5c4b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5c520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5c540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.158: INFO: Pod "nginx-deployment-5f9595f595-2zfcg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2zfcg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-2zfcg,UID:409fa1af-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17300,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.10/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5c620 0xc002c5c621}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5c690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5c6b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-cd7xx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-cd7xx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-cd7xx,UID:409f6313-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17337,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.240/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5c780 0xc002c5c781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5c7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5c810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-fcjxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fcjxr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-fcjxr,UID:3f5fa3e7-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17129,Generation:0,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.3/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5c8a0 0xc002c5c8a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5c910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5c930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-hgj7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hgj7t,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-hgj7t,UID:3f6d4a46-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17133,Generation:0,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.4/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5ca10 0xc002c5ca11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5ca90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5cab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-j76kr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j76kr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-j76kr,UID:3f5f1d56-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17143,Generation:0,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.230/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5cb80 0xc002c5cb81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5cbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5cc10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.230,StartTime:2019-04-15 10:43:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-q5ctg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-q5ctg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-q5ctg,UID:40ad0e0c-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17325,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.238/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5cd00 0xc002c5cd01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5cd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5cd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-rv2pb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rv2pb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-rv2pb,UID:409b73ea-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17264,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.232/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5ce10 0xc002c5ce11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5ce80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5cea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.159: INFO: Pod "nginx-deployment-5f9595f595-tdqf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-tdqf5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-tdqf5,UID:3f5d8c60-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17124,Generation:0,CreationTimestamp:2019-04-15 10:43:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.61/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5cf80 0xc002c5cf81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5cff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-5f9595f595-tjwr8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-tjwr8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-tjwr8,UID:409fb9ec-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17311,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5d0f0 0xc002c5d0f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-5f9595f595-vtrbz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vtrbz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-vtrbz,UID:409fcaf6-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17274,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.234/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5d250 0xc002c5d251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-5f9595f595-zvl2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zvl2m,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-5f9595f595-zvl2m,UID:409689e3-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17268,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.233/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3f5cc31e-5f6b-11e9-b895-0a5a25aca864 0xc002c5d3b0 0xc002c5d3b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-6f478d8d8-9pnr9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9pnr9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-9pnr9,UID:3cfdd8d9-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17014,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.63/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5d520 0xc002c5d521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.63,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://65c4f4f8a62f9bbabcb30c1d0b2627b415299b3cf3b5485416263e7556e4d524}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-6f478d8d8-9rnq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9rnq9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-9rnq9,UID:40a2ea4a-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17334,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.239/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5d670 0xc002c5d671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.160: INFO: Pod "nginx-deployment-6f478d8d8-9shtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9shtp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-9shtp,UID:40a2f395-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17332,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5d7c0 0xc002c5d7c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-bdq9c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bdq9c,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-bdq9c,UID:3cfa89af-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17016,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.60/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5d8d0 0xc002c5d8d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5d930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5d950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.60,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://004126e455ff13646691ab0dd40be73c351c0cbaf792f43734a83ea2b0616415}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-cp2lw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cp2lw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-cp2lw,UID:40a2d5d3-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17321,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.12/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5da30 0xc002c5da31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5da90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5dab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-cpbdh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cpbdh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-cpbdh,UID:3cf87207-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17038,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.225/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5db30 0xc002c5db31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5db90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5dbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.225,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://1df9b9623834e05ce30bcee29cabc5b9e8c1b5e7a617e42501ff9d0f8ec3eb38}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-fgktm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fgktm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-fgktm,UID:3cfaa897-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17042,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.227/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5dc80 0xc002c5dc81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5dce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5dd00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.227,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a85f9664bb5c30c3efbf4592690361c8355bf364d7372eba5eee04bbb8063d83}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-fgx24" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fgx24,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-fgx24,UID:409d9196-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17294,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.9/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5ddf0 0xc002c5ddf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5de50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5de70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.161: INFO: Pod "nginx-deployment-6f478d8d8-gr4nj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gr4nj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-gr4nj,UID:3cfa7235-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17019,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.59/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002c5df40 0xc002c5df41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c5dfa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c5dfc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.59,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://22d670c2b16d8c5ca008a4bd119954b2b6726ff2c38f32eef0b3a544464d9a25}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-gvkkl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gvkkl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-gvkkl,UID:3cf879a4-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17028,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.229/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c0c0 0xc002b0c0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.229,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f13816ada3a046cb028692cf5158d6b319d986560df0b7dbdddf6b04c473adc4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-j4k7q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j4k7q,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-j4k7q,UID:409a0e88-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17275,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.7/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c220 0xc002b0c221}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-k26qv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-k26qv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-k26qv,UID:40a31867-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17353,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.241/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c370 0xc002b0c371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-kshlb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kshlb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-kshlb,UID:409dd031-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17322,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.235/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c4b0 0xc002b0c4b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-r7q69" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-r7q69,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-r7q69,UID:3cfdcd92-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17031,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.226/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c5f0 0xc002b0c5f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.226,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://9f98364553335c97546011f2bd0e3d258d8066850768070c6763eae2857d9000}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-r852g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-r852g,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-r852g,UID:40954258-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17271,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.5/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c750 0xc002b0c751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-rpsdj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rpsdj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-rpsdj,UID:3cfdc7b4-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17025,Generation:0,CreationTimestamp:2019-04-15 10:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.228/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c890 0xc002b0c891}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0c8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0c910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:192.168.126.228,StartTime:2019-04-15 10:43:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:43:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://dbe95fb2ae767982ac2cac1906d8ce711c1b407ab1100b71560d728e0d75e1d9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-rthlr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rthlr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-rthlr,UID:409a28a2-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17281,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.6/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0c9f0 0xc002b0c9f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0ca50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0ca70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.162: INFO: Pod "nginx-deployment-6f478d8d8-sqcn4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sqcn4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-sqcn4,UID:409db6cf-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17310,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.237/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0cb30 0xc002b0cb31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0cb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0cbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.163: INFO: Pod "nginx-deployment-6f478d8d8-tz2mb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tz2mb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-tz2mb,UID:409df83a-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17305,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.126.236/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0cc70 0xc002b0cc71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-88.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0ccd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0ccf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.88,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 15 10:43:08.163: INFO: Pod "nginx-deployment-6f478d8d8-vswhz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vswhz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6812,SelfLink:/api/v1/namespaces/deployment-6812/pods/nginx-deployment-6f478d8d8-vswhz,UID:40a2669c-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17338,Generation:0,CreationTimestamp:2019-04-15 10:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3cf4f400-5f6b-11e9-b895-0a5a25aca864 0xc002b0cdc0 0xc002b0cdc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qwc2n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qwc2n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qwc2n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b0ce20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b0ce40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:43:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:,StartTime:2019-04-15 10:43:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:43:08.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6812" for this suite.
Apr 15 10:43:16.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:43:16.316: INFO: namespace deployment-6812 deletion completed in 8.147502606s

• [SLOW TEST:16.405 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:43:16.317: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:43:40.429: INFO: Container started at 2019-04-15 10:43:18 +0000 UTC, pod became ready at 2019-04-15 10:43:40 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:43:40.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4183" for this suite.
Apr 15 10:44:02.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:44:02.570: INFO: namespace container-probe-4183 deletion completed in 22.136674094s

• [SLOW TEST:46.253 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:44:02.570: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:44:02.620: INFO: Waiting up to 5m0s for pod "downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "projected-7296" to be "success or failure"
Apr 15 10:44:02.626: INFO: Pod "downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.258451ms
Apr 15 10:44:04.631: INFO: Pod "downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010511491s
STEP: Saw pod success
Apr 15 10:44:04.631: INFO: Pod "downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:44:04.636: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:44:04.670: INFO: Waiting for pod downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:44:04.676: INFO: Pod downwardapi-volume-624135aa-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:44:04.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7296" for this suite.
Apr 15 10:44:10.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:44:10.801: INFO: namespace projected-7296 deletion completed in 6.119746532s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:44:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:44:10.848: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 15 10:44:15.852: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 15 10:44:15.852: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 15 10:44:15.873: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4806,SelfLink:/apis/apps/v1/namespaces/deployment-4806/deployments/test-cleanup-deployment,UID:6a26c627-5f6b-11e9-adae-06c5682e2662,ResourceVersion:17933,Generation:1,CreationTimestamp:2019-04-15 10:44:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 15 10:44:15.876: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Apr 15 10:44:15.876: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 15 10:44:15.876: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-4806,SelfLink:/apis/apps/v1/namespaces/deployment-4806/replicasets/test-cleanup-controller,UID:6728b631-5f6b-11e9-adae-06c5682e2662,ResourceVersion:17934,Generation:1,CreationTimestamp:2019-04-15 10:44:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6a26c627-5f6b-11e9-adae-06c5682e2662 0xc00242e907 0xc00242e908}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 15 10:44:15.880: INFO: Pod "test-cleanup-controller-lfz7d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-lfz7d,GenerateName:test-cleanup-controller-,Namespace:deployment-4806,SelfLink:/api/v1/namespaces/deployment-4806/pods/test-cleanup-controller-lfz7d,UID:672aa352-5f6b-11e9-b895-0a5a25aca864,ResourceVersion:17919,Generation:0,CreationTimestamp:2019-04-15 10:44:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.17/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 6728b631-5f6b-11e9-adae-06c5682e2662 0xc00242ee77 0xc00242ee78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-n88mp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n88mp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-n88mp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00242eee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00242efb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:44:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:44:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:44:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:44:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.17,StartTime:2019-04-15 10:44:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-15 10:44:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e4e682eac874d72b4d5b92fff3473591d9beba381602a6a5597c87b20f83473e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:44:15.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4806" for this suite.
Apr 15 10:44:21.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:44:22.019: INFO: namespace deployment-4806 deletion completed in 6.13181097s

• [SLOW TEST:11.217 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:44:22.019: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-6dd9c95e-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating secret with name s-test-opt-upd-6dd9c990-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6dd9c95e-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Updating secret s-test-opt-upd-6dd9c990-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating secret with name s-test-opt-create-6dd9c9a4-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:44:26.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2650" for this suite.
Apr 15 10:44:48.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:44:48.347: INFO: namespace secrets-2650 deletion completed in 22.182319111s

• [SLOW TEST:26.327 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:44:48.347: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 10:44:48.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1681'
Apr 15 10:44:48.617: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 15 10:44:48.617: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 15 10:44:48.633: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cp546]
Apr 15 10:44:48.633: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cp546" in namespace "kubectl-1681" to be "running and ready"
Apr 15 10:44:48.636: INFO: Pod "e2e-test-nginx-rc-cp546": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038547ms
Apr 15 10:44:50.640: INFO: Pod "e2e-test-nginx-rc-cp546": Phase="Running", Reason="", readiness=true. Elapsed: 2.007358744s
Apr 15 10:44:50.640: INFO: Pod "e2e-test-nginx-rc-cp546" satisfied condition "running and ready"
Apr 15 10:44:50.640: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cp546]
Apr 15 10:44:50.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 logs rc/e2e-test-nginx-rc --namespace=kubectl-1681'
Apr 15 10:44:50.728: INFO: stderr: ""
Apr 15 10:44:50.728: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 15 10:44:50.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete rc e2e-test-nginx-rc --namespace=kubectl-1681'
Apr 15 10:44:50.811: INFO: stderr: ""
Apr 15 10:44:50.811: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:44:50.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1681" for this suite.
Apr 15 10:45:12.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:45:12.943: INFO: namespace kubectl-1681 deletion completed in 22.128399115s

• [SLOW TEST:24.597 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:45:12.944: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-8dlz
STEP: Creating a pod to test atomic-volume-subpath
Apr 15 10:45:13.004: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8dlz" in namespace "subpath-2128" to be "success or failure"
Apr 15 10:45:13.008: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982159ms
Apr 15 10:45:15.013: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 2.008919776s
Apr 15 10:45:17.019: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 4.015103881s
Apr 15 10:45:19.032: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 6.028438567s
Apr 15 10:45:21.036: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 8.032524809s
Apr 15 10:45:23.040: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 10.036572002s
Apr 15 10:45:25.045: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 12.041223906s
Apr 15 10:45:27.049: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 14.045044338s
Apr 15 10:45:29.053: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 16.049052176s
Apr 15 10:45:31.061: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 18.057547352s
Apr 15 10:45:33.066: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Running", Reason="", readiness=true. Elapsed: 20.061876146s
Apr 15 10:45:35.082: INFO: Pod "pod-subpath-test-configmap-8dlz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.077909954s
STEP: Saw pod success
Apr 15 10:45:35.082: INFO: Pod "pod-subpath-test-configmap-8dlz" satisfied condition "success or failure"
Apr 15 10:45:35.089: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-subpath-test-configmap-8dlz container test-container-subpath-configmap-8dlz: <nil>
STEP: delete the pod
Apr 15 10:45:35.124: INFO: Waiting for pod pod-subpath-test-configmap-8dlz to disappear
Apr 15 10:45:35.130: INFO: Pod pod-subpath-test-configmap-8dlz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8dlz
Apr 15 10:45:35.130: INFO: Deleting pod "pod-subpath-test-configmap-8dlz" in namespace "subpath-2128"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:45:35.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2128" for this suite.
Apr 15 10:45:41.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:45:41.285: INFO: namespace subpath-2128 deletion completed in 6.146990031s

• [SLOW TEST:28.342 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:45:41.286: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 15 10:45:41.335: INFO: Waiting up to 5m0s for pod "downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-2568" to be "success or failure"
Apr 15 10:45:41.339: INFO: Pod "downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744635ms
Apr 15 10:45:43.344: INFO: Pod "downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008263309s
STEP: Saw pod success
Apr 15 10:45:43.344: INFO: Pod "downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:45:43.348: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 10:45:43.369: INFO: Waiting for pod downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:45:43.372: INFO: Pod downward-api-9d17da29-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:45:43.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2568" for this suite.
Apr 15 10:45:49.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:45:49.494: INFO: namespace downward-api-2568 deletion completed in 6.118569462s

• [SLOW TEST:8.209 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:45:49.495: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-a1fc5736-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating secret with name secret-projected-all-test-volume-a1fc5721-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 15 10:45:49.551: INFO: Waiting up to 5m0s for pod "projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5491" to be "success or failure"
Apr 15 10:45:49.555: INFO: Pod "projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.636454ms
Apr 15 10:45:51.559: INFO: Pod "projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007901591s
STEP: Saw pod success
Apr 15 10:45:51.559: INFO: Pod "projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:45:51.562: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 15 10:45:51.583: INFO: Waiting for pod projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:45:51.587: INFO: Pod projected-volume-a1fc56e9-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:45:51.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5491" for this suite.
Apr 15 10:45:57.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:45:57.710: INFO: namespace projected-5491 deletion completed in 6.117793923s

• [SLOW TEST:8.215 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:45:57.710: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 15 10:46:01.873: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 15 10:46:01.876: INFO: Pod pod-with-prestop-http-hook still exists
Apr 15 10:46:03.876: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 15 10:46:03.880: INFO: Pod pod-with-prestop-http-hook still exists
Apr 15 10:46:05.876: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 15 10:46:05.881: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:46:05.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4348" for this suite.
Apr 15 10:46:27.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:46:28.022: INFO: namespace container-lifecycle-hook-4348 deletion completed in 22.130772155s

• [SLOW TEST:30.312 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:46:28.022: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 15 10:46:28.127: INFO: Waiting up to 5m0s for pod "pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-940" to be "success or failure"
Apr 15 10:46:28.131: INFO: Pod "pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068357ms
Apr 15 10:46:30.135: INFO: Pod "pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008153872s
STEP: Saw pod success
Apr 15 10:46:30.135: INFO: Pod "pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:46:30.138: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:46:30.161: INFO: Waiting for pod pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:46:30.164: INFO: Pod pod-b8fba70c-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:46:30.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-940" for this suite.
Apr 15 10:46:36.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:46:36.285: INFO: namespace emptydir-940 deletion completed in 6.116752453s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:46:36.285: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 15 10:46:36.352: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18525,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 15 10:46:36.352: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18526,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 15 10:46:36.352: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18527,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 15 10:46:46.383: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18549,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 15 10:46:46.384: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18550,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 15 10:46:46.384: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5165,SelfLink:/api/v1/namespaces/watch-5165/configmaps/e2e-watch-test-label-changed,UID:bde0c198-5f6b-11e9-adae-06c5682e2662,ResourceVersion:18551,Generation:0,CreationTimestamp:2019-04-15 10:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:46:46.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5165" for this suite.
Apr 15 10:46:52.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:46:52.495: INFO: namespace watch-5165 deletion completed in 6.107726474s

• [SLOW TEST:16.211 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:46:52.496: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 15 10:46:52.609: INFO: Waiting up to 5m0s for pod "pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-511" to be "success or failure"
Apr 15 10:46:52.615: INFO: Pod "pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.658568ms
Apr 15 10:46:54.619: INFO: Pod "pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010559958s
STEP: Saw pod success
Apr 15 10:46:54.619: INFO: Pod "pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:46:54.622: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:46:54.643: INFO: Waiting for pod pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:46:54.647: INFO: Pod pod-c7928afb-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:46:54.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-511" for this suite.
Apr 15 10:47:00.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:47:00.780: INFO: namespace emptydir-511 deletion completed in 6.128426303s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:47:00.780: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-cc7a5062-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating secret with name s-test-opt-upd-cc7a509e-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cc7a5062-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Updating secret s-test-opt-upd-cc7a509e-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating secret with name s-test-opt-create-cc7a50b9-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:47:04.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3633" for this suite.
Apr 15 10:47:26.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:47:27.056: INFO: namespace projected-3633 deletion completed in 22.131027023s

• [SLOW TEST:26.276 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:47:27.057: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-444
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 15 10:47:27.095: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 15 10:47:45.197: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.244:8080/dial?request=hostName&protocol=http&host=192.168.14.28&port=8080&tries=1'] Namespace:pod-network-test-444 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:47:45.197: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:47:45.329: INFO: Waiting for endpoints: map[]
Apr 15 10:47:45.332: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.244:8080/dial?request=hostName&protocol=http&host=192.168.126.243&port=8080&tries=1'] Namespace:pod-network-test-444 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 15 10:47:45.332: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
Apr 15 10:47:45.509: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:47:45.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-444" for this suite.
Apr 15 10:48:07.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:48:07.646: INFO: namespace pod-network-test-444 deletion completed in 22.128788825s

• [SLOW TEST:40.589 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:48:07.646: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-f45d3986-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:48:07.756: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "projected-6764" to be "success or failure"
Apr 15 10:48:07.762: INFO: Pod "pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.148949ms
Apr 15 10:48:09.766: INFO: Pod "pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01033658s
STEP: Saw pod success
Apr 15 10:48:09.766: INFO: Pod "pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:48:09.769: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:48:09.793: INFO: Waiting for pod pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:48:09.797: INFO: Pod pod-projected-secrets-f45e78d5-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:48:09.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6764" for this suite.
Apr 15 10:48:15.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:48:15.924: INFO: namespace projected-6764 deletion completed in 6.123858537s

• [SLOW TEST:8.278 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:48:15.925: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5640/secret-test-f94434cb-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:48:15.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-5640" to be "success or failure"
Apr 15 10:48:15.986: INFO: Pod "pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745885ms
Apr 15 10:48:17.990: INFO: Pod "pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009087885s
STEP: Saw pod success
Apr 15 10:48:17.990: INFO: Pod "pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:48:17.993: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982 container env-test: <nil>
STEP: delete the pod
Apr 15 10:48:18.015: INFO: Waiting for pod pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:48:18.018: INFO: Pod pod-configmaps-f9456a13-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:48:18.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5640" for this suite.
Apr 15 10:48:24.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:48:24.133: INFO: namespace secrets-5640 deletion completed in 6.112385771s

• [SLOW TEST:8.209 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:48:24.135: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-fe28c891-5f6b-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 10:48:24.193: INFO: Waiting up to 5m0s for pod "pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-1720" to be "success or failure"
Apr 15 10:48:24.200: INFO: Pod "pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 7.344275ms
Apr 15 10:48:26.205: INFO: Pod "pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011748593s
STEP: Saw pod success
Apr 15 10:48:26.205: INFO: Pod "pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:48:26.208: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 10:48:26.229: INFO: Waiting for pod pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:48:26.233: INFO: Pod pod-secrets-fe2a2597-5f6b-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:48:26.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1720" for this suite.
Apr 15 10:48:32.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:48:32.359: INFO: namespace secrets-1720 deletion completed in 6.122163939s

• [SLOW TEST:8.224 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:48:32.359: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 15 10:48:34.430: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-031098f9-5f6c-11e9-a7dc-a6e5a2dd4982,GenerateName:,Namespace:events-2775,SelfLink:/api/v1/namespaces/events-2775/pods/send-events-031098f9-5f6c-11e9-a7dc-a6e5a2dd4982,UID:031124f8-5f6c-11e9-adae-06c5682e2662,ResourceVersion:19032,Generation:0,CreationTimestamp:2019-04-15 10:48:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 403690851,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.14.32/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-m8dw9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m8dw9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-m8dw9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-206.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022bf4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022bf4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:48:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:48:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:48:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-15 10:48:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.206,PodIP:192.168.14.32,StartTime:2019-04-15 10:48:32 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-15 10:48:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://04680f73873afe5076b7f10aa39fd3195026c643df13978f08c27d26055055ae}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 15 10:48:36.435: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 15 10:48:38.439: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:48:38.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2775" for this suite.
Apr 15 10:49:16.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:49:16.570: INFO: namespace events-2775 deletion completed in 38.116681322s

• [SLOW TEST:44.211 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:49:16.570: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 15 10:49:16.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 api-versions'
Apr 15 10:49:16.674: INFO: stderr: ""
Apr 15 10:49:16.674: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:49:16.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8206" for this suite.
Apr 15 10:49:22.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:49:22.792: INFO: namespace kubectl-8206 deletion completed in 6.113551831s

• [SLOW TEST:6.221 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:49:22.792: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0415 10:50:02.864940      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 10:50:02.864: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:50:02.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7904" for this suite.
Apr 15 10:50:08.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:50:09.030: INFO: namespace gc-7904 deletion completed in 6.161994555s

• [SLOW TEST:46.239 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:50:09.031: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0415 10:50:15.161787      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 10:50:15.161: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:50:15.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9508" for this suite.
Apr 15 10:50:21.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:50:21.291: INFO: namespace gc-9508 deletion completed in 6.122988409s

• [SLOW TEST:12.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:50:21.292: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 15 10:50:21.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6548,SelfLink:/api/v1/namespaces/watch-6548/configmaps/e2e-watch-test-resource-version,UID:43fd2ce2-5f6c-11e9-adae-06c5682e2662,ResourceVersion:19834,Generation:0,CreationTimestamp:2019-04-15 10:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 15 10:50:21.360: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6548,SelfLink:/api/v1/namespaces/watch-6548/configmaps/e2e-watch-test-resource-version,UID:43fd2ce2-5f6c-11e9-adae-06c5682e2662,ResourceVersion:19835,Generation:0,CreationTimestamp:2019-04-15 10:50:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:50:21.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6548" for this suite.
Apr 15 10:50:27.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:50:27.491: INFO: namespace watch-6548 deletion completed in 6.126172151s

• [SLOW TEST:6.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:50:27.491: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-3577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3577 to expose endpoints map[]
Apr 15 10:50:27.551: INFO: Get endpoints failed (5.298364ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr 15 10:50:28.556: INFO: successfully validated that service multi-endpoint-test in namespace services-3577 exposes endpoints map[] (1.010561771s elapsed)
STEP: Creating pod pod1 in namespace services-3577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3577 to expose endpoints map[pod1:[100]]
Apr 15 10:50:30.621: INFO: successfully validated that service multi-endpoint-test in namespace services-3577 exposes endpoints map[pod1:[100]] (2.053084951s elapsed)
STEP: Creating pod pod2 in namespace services-3577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3577 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 15 10:50:32.662: INFO: successfully validated that service multi-endpoint-test in namespace services-3577 exposes endpoints map[pod1:[100] pod2:[101]] (2.035209395s elapsed)
STEP: Deleting pod pod1 in namespace services-3577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3577 to expose endpoints map[pod2:[101]]
Apr 15 10:50:32.683: INFO: successfully validated that service multi-endpoint-test in namespace services-3577 exposes endpoints map[pod2:[101]] (7.846051ms elapsed)
STEP: Deleting pod pod2 in namespace services-3577
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3577 to expose endpoints map[]
Apr 15 10:50:33.705: INFO: successfully validated that service multi-endpoint-test in namespace services-3577 exposes endpoints map[] (1.012528882s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:50:33.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3577" for this suite.
Apr 15 10:50:55.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:50:55.866: INFO: namespace services-3577 deletion completed in 22.124660697s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.376 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:50:55.867: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-713
Apr 15 10:50:57.926: INFO: Started pod liveness-exec in namespace container-probe-713
STEP: checking the pod's current state and verifying that restartCount is present
Apr 15 10:50:57.930: INFO: Initial restart count of pod liveness-exec is 0
Apr 15 10:51:52.071: INFO: Restart count of pod container-probe-713/liveness-exec is now 1 (54.141219632s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:51:52.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-713" for this suite.
Apr 15 10:51:58.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:51:58.207: INFO: namespace container-probe-713 deletion completed in 6.116317588s

• [SLOW TEST:62.340 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:51:58.208: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 10:51:58.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-5122" to be "success or failure"
Apr 15 10:51:58.265: INFO: Pod "downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.345986ms
Apr 15 10:52:00.270: INFO: Pod "downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009783482s
STEP: Saw pod success
Apr 15 10:52:00.270: INFO: Pod "downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:52:00.273: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 10:52:00.308: INFO: Waiting for pod downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:52:00.311: INFO: Pod downwardapi-volume-7dc21420-5f6c-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:52:00.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5122" for this suite.
Apr 15 10:52:06.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:52:06.439: INFO: namespace downward-api-5122 deletion completed in 6.123514317s

• [SLOW TEST:8.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:52:06.439: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 15 10:52:06.516: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:06.516: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:06.516: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:06.519: INFO: Number of nodes with available pods: 0
Apr 15 10:52:06.519: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:52:07.524: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:07.524: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:07.524: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:07.528: INFO: Number of nodes with available pods: 0
Apr 15 10:52:07.528: INFO: Node ip-10-0-1-206.eu-west-1.compute.internal is running more than one daemon pod
Apr 15 10:52:08.525: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.525: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.525: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.528: INFO: Number of nodes with available pods: 2
Apr 15 10:52:08.528: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 15 10:52:08.545: INFO: DaemonSet pods can't tolerate node ip-10-0-1-64.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.545: INFO: DaemonSet pods can't tolerate node ip-10-0-2-87.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.545: INFO: DaemonSet pods can't tolerate node ip-10-0-3-193.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 15 10:52:08.548: INFO: Number of nodes with available pods: 2
Apr 15 10:52:08.548: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3243, will wait for the garbage collector to delete the pods
Apr 15 10:52:09.627: INFO: Deleting DaemonSet.extensions daemon-set took: 12.394311ms
Apr 15 10:52:09.927: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.221219ms
Apr 15 10:53:16.331: INFO: Number of nodes with available pods: 0
Apr 15 10:53:16.331: INFO: Number of running nodes: 0, number of available pods: 0
Apr 15 10:53:16.334: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3243/daemonsets","resourceVersion":"20384"},"items":null}

Apr 15 10:53:16.343: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3243/pods","resourceVersion":"20384"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:53:16.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3243" for this suite.
Apr 15 10:53:22.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:53:22.491: INFO: namespace daemonsets-3243 deletion completed in 6.130535281s

• [SLOW TEST:76.051 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:53:22.491: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 15 10:53:22.543: INFO: Waiting up to 5m0s for pod "client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982" in namespace "containers-6630" to be "success or failure"
Apr 15 10:53:22.548: INFO: Pod "client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.623782ms
Apr 15 10:53:24.552: INFO: Pod "client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008711786s
STEP: Saw pod success
Apr 15 10:53:24.552: INFO: Pod "client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:53:24.555: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:53:24.580: INFO: Waiting for pod client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:53:24.583: INFO: Pod client-containers-affedaa6-5f6c-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:53:24.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6630" for this suite.
Apr 15 10:53:30.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:53:30.709: INFO: namespace containers-6630 deletion completed in 6.122392647s

• [SLOW TEST:8.218 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:53:30.709: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:53:30.837: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b4eef6fd-5f6c-11e9-adae-06c5682e2662", Controller:(*bool)(0xc0030eba3a), BlockOwnerDeletion:(*bool)(0xc0030eba3b)}}
Apr 15 10:53:30.843: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b4ec4d01-5f6c-11e9-adae-06c5682e2662", Controller:(*bool)(0xc0030ebc46), BlockOwnerDeletion:(*bool)(0xc0030ebc47)}}
Apr 15 10:53:30.856: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b4edef52-5f6c-11e9-adae-06c5682e2662", Controller:(*bool)(0xc0031c81f6), BlockOwnerDeletion:(*bool)(0xc0031c81f7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:53:35.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1500" for this suite.
Apr 15 10:53:41.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:53:41.987: INFO: namespace gc-1500 deletion completed in 6.111777509s

• [SLOW TEST:11.278 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:53:41.987: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:53:45.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8415" for this suite.
Apr 15 10:54:07.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:54:07.186: INFO: namespace replication-controller-8415 deletion completed in 22.123339806s

• [SLOW TEST:25.199 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:54:07.187: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 15 10:54:07.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 --namespace=kubectl-9223 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 15 10:54:08.251: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 15 10:54:08.251: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:54:10.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9223" for this suite.
Apr 15 10:54:18.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:54:18.376: INFO: namespace kubectl-9223 deletion completed in 8.11499049s

• [SLOW TEST:11.189 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:54:18.376: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-d157da78-5f6c-11e9-a7dc-a6e5a2dd4982
STEP: Creating configMap with name cm-test-opt-upd-d157dab8-5f6c-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d157da78-5f6c-11e9-a7dc-a6e5a2dd4982
STEP: Updating configmap cm-test-opt-upd-d157dab8-5f6c-11e9-a7dc-a6e5a2dd4982
STEP: Creating configMap with name cm-test-opt-create-d157dad3-5f6c-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:54:24.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-650" for this suite.
Apr 15 10:54:46.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:54:46.760: INFO: namespace projected-650 deletion completed in 22.138171114s

• [SLOW TEST:28.384 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:54:46.760: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:54:46.805: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:54:48.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1285" for this suite.
Apr 15 10:55:28.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:55:29.000: INFO: namespace pods-1285 deletion completed in 40.128287492s

• [SLOW TEST:42.240 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:55:29.000: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7620
Apr 15 10:55:31.068: INFO: Started pod liveness-http in namespace container-probe-7620
STEP: checking the pod's current state and verifying that restartCount is present
Apr 15 10:55:31.071: INFO: Initial restart count of pod liveness-http is 0
Apr 15 10:55:49.132: INFO: Restart count of pod container-probe-7620/liveness-http is now 1 (18.061321738s elapsed)
Apr 15 10:56:09.180: INFO: Restart count of pod container-probe-7620/liveness-http is now 2 (38.108502509s elapsed)
Apr 15 10:56:29.221: INFO: Restart count of pod container-probe-7620/liveness-http is now 3 (58.15008384s elapsed)
Apr 15 10:56:49.264: INFO: Restart count of pod container-probe-7620/liveness-http is now 4 (1m18.192665274s elapsed)
Apr 15 10:57:59.438: INFO: Restart count of pod container-probe-7620/liveness-http is now 5 (2m28.367077553s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:57:59.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7620" for this suite.
Apr 15 10:58:05.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:58:05.632: INFO: namespace container-probe-7620 deletion completed in 6.175019274s

• [SLOW TEST:156.632 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:58:05.632: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 10:58:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:58:06.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8417" for this suite.
Apr 15 10:58:12.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:58:12.926: INFO: namespace custom-resource-definition-8417 deletion completed in 6.172487813s

• [SLOW TEST:7.294 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:58:12.926: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-5d1d78e5-5f6d-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 10:58:13.015: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-4181" to be "success or failure"
Apr 15 10:58:13.025: INFO: Pod "pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 10.434133ms
Apr 15 10:58:15.029: INFO: Pod "pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014518294s
STEP: Saw pod success
Apr 15 10:58:15.029: INFO: Pod "pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:58:15.034: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 10:58:15.086: INFO: Waiting for pod pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:58:15.092: INFO: Pod pod-configmaps-5d204a2c-5f6d-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:58:15.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4181" for this suite.
Apr 15 10:58:21.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:58:21.247: INFO: namespace configmap-4181 deletion completed in 6.140514047s

• [SLOW TEST:8.321 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:58:21.247: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3835
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3835
STEP: Creating statefulset with conflicting port in namespace statefulset-3835
STEP: Waiting until pod test-pod will start running in namespace statefulset-3835
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3835
Apr 15 10:58:23.409: INFO: Observed stateful pod in namespace: statefulset-3835, name: ss-0, uid: 622e1cbe-5f6d-11e9-b895-0a5a25aca864, status phase: Pending. Waiting for statefulset controller to delete.
Apr 15 10:58:26.225: INFO: Observed stateful pod in namespace: statefulset-3835, name: ss-0, uid: 622e1cbe-5f6d-11e9-b895-0a5a25aca864, status phase: Failed. Waiting for statefulset controller to delete.
Apr 15 10:58:26.236: INFO: Observed stateful pod in namespace: statefulset-3835, name: ss-0, uid: 622e1cbe-5f6d-11e9-b895-0a5a25aca864, status phase: Failed. Waiting for statefulset controller to delete.
Apr 15 10:58:26.243: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3835
STEP: Removing pod with conflicting port in namespace statefulset-3835
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3835 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 15 10:58:36.290: INFO: Deleting all statefulset in ns statefulset-3835
Apr 15 10:58:36.293: INFO: Scaling statefulset ss to 0
Apr 15 10:58:46.309: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 10:58:46.313: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:58:46.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3835" for this suite.
Apr 15 10:58:52.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:58:52.457: INFO: namespace statefulset-3835 deletion completed in 6.116641009s

• [SLOW TEST:31.210 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:58:52.457: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 10:58:52.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9827'
Apr 15 10:58:52.787: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 15 10:58:52.787: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 15 10:58:52.794: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr 15 10:58:52.814: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 15 10:58:52.830: INFO: scanned /root for discovery docs: <nil>
Apr 15 10:58:52.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9827'
Apr 15 10:59:08.611: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 15 10:59:08.611: INFO: stdout: "Created e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e\nScaling up e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 15 10:59:08.611: INFO: stdout: "Created e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e\nScaling up e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 15 10:59:08.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9827'
Apr 15 10:59:08.681: INFO: stderr: ""
Apr 15 10:59:08.681: INFO: stdout: "e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e-fvg99 "
Apr 15 10:59:08.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e-fvg99 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9827'
Apr 15 10:59:08.741: INFO: stderr: ""
Apr 15 10:59:08.741: INFO: stdout: "true"
Apr 15 10:59:08.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e-fvg99 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9827'
Apr 15 10:59:08.810: INFO: stderr: ""
Apr 15 10:59:08.810: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 15 10:59:08.810: INFO: e2e-test-nginx-rc-b71e29e3d4b8eebcb47a4e3e886b629e-fvg99 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 15 10:59:08.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete rc e2e-test-nginx-rc --namespace=kubectl-9827'
Apr 15 10:59:08.881: INFO: stderr: ""
Apr 15 10:59:08.881: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:59:08.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9827" for this suite.
Apr 15 10:59:14.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:59:15.002: INFO: namespace kubectl-9827 deletion completed in 6.117352431s

• [SLOW TEST:22.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:59:15.002: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 15 10:59:17.666: INFO: Successfully updated pod "annotationupdate82259a43-5f6d-11e9-a7dc-a6e5a2dd4982"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:59:19.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5498" for this suite.
Apr 15 10:59:41.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:59:41.804: INFO: namespace projected-5498 deletion completed in 22.117879118s

• [SLOW TEST:26.802 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:59:41.804: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 15 10:59:41.855: INFO: Waiting up to 5m0s for pod "pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-8295" to be "success or failure"
Apr 15 10:59:41.859: INFO: Pod "pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.847526ms
Apr 15 10:59:43.862: INFO: Pod "pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007610609s
STEP: Saw pod success
Apr 15 10:59:43.862: INFO: Pod "pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 10:59:43.866: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 10:59:43.886: INFO: Waiting for pod pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 10:59:43.889: INFO: Pod pod-92150107-5f6d-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 10:59:43.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8295" for this suite.
Apr 15 10:59:49.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 10:59:50.010: INFO: namespace emptydir-8295 deletion completed in 6.117035606s

• [SLOW TEST:8.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 10:59:50.010: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:00:11.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3446" for this suite.
Apr 15 11:00:17.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:00:17.465: INFO: namespace container-runtime-3446 deletion completed in 6.134969521s

• [SLOW TEST:27.455 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:00:17.468: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-a758db0a-5f6d-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:00:17.538: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982" in namespace "projected-6715" to be "success or failure"
Apr 15 11:00:17.542: INFO: Pod "pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.552908ms
Apr 15 11:00:19.547: INFO: Pod "pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009131552s
STEP: Saw pod success
Apr 15 11:00:19.547: INFO: Pod "pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:00:19.550: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:00:19.579: INFO: Waiting for pod pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:00:19.583: INFO: Pod pod-projected-secrets-a75a148a-5f6d-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:00:19.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6715" for this suite.
Apr 15 11:00:25.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:00:25.712: INFO: namespace projected-6715 deletion completed in 6.125116462s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:00:25.713: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 15 11:00:25.768: INFO: Waiting up to 5m0s for pod "downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-862" to be "success or failure"
Apr 15 11:00:25.772: INFO: Pod "downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263895ms
Apr 15 11:00:27.777: INFO: Pod "downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008586098s
STEP: Saw pod success
Apr 15 11:00:27.777: INFO: Pod "downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:00:27.780: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982 container dapi-container: <nil>
STEP: delete the pod
Apr 15 11:00:27.803: INFO: Waiting for pod downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:00:27.807: INFO: Pod downward-api-ac412626-5f6d-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:00:27.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-862" for this suite.
Apr 15 11:00:33.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:00:33.924: INFO: namespace downward-api-862 deletion completed in 6.114019834s

• [SLOW TEST:8.212 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:00:33.925: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 15 11:00:33.999: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8240,SelfLink:/api/v1/namespaces/watch-8240/configmaps/e2e-watch-test-watch-closed,UID:b129395c-5f6d-11e9-adae-06c5682e2662,ResourceVersion:22069,Generation:0,CreationTimestamp:2019-04-15 11:00:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 15 11:00:34.000: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8240,SelfLink:/api/v1/namespaces/watch-8240/configmaps/e2e-watch-test-watch-closed,UID:b129395c-5f6d-11e9-adae-06c5682e2662,ResourceVersion:22070,Generation:0,CreationTimestamp:2019-04-15 11:00:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 15 11:00:34.017: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8240,SelfLink:/api/v1/namespaces/watch-8240/configmaps/e2e-watch-test-watch-closed,UID:b129395c-5f6d-11e9-adae-06c5682e2662,ResourceVersion:22071,Generation:0,CreationTimestamp:2019-04-15 11:00:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 15 11:00:34.017: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8240,SelfLink:/api/v1/namespaces/watch-8240/configmaps/e2e-watch-test-watch-closed,UID:b129395c-5f6d-11e9-adae-06c5682e2662,ResourceVersion:22072,Generation:0,CreationTimestamp:2019-04-15 11:00:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:00:34.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8240" for this suite.
Apr 15 11:00:40.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:00:40.138: INFO: namespace watch-8240 deletion completed in 6.116076362s

• [SLOW TEST:6.213 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:00:40.138: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 15 11:00:40.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-3839'
Apr 15 11:00:40.380: INFO: stderr: ""
Apr 15 11:00:40.380: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 11:00:40.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:40.458: INFO: stderr: ""
Apr 15 11:00:40.458: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-vf87b "
Apr 15 11:00:40.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:40.526: INFO: stderr: ""
Apr 15 11:00:40.526: INFO: stdout: ""
Apr 15 11:00:40.526: INFO: update-demo-nautilus-8ldlj is created but not running
Apr 15 11:00:45.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:45.591: INFO: stderr: ""
Apr 15 11:00:45.591: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-vf87b "
Apr 15 11:00:45.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:45.668: INFO: stderr: ""
Apr 15 11:00:45.668: INFO: stdout: "true"
Apr 15 11:00:45.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:45.733: INFO: stderr: ""
Apr 15 11:00:45.733: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:00:45.733: INFO: validating pod update-demo-nautilus-8ldlj
Apr 15 11:00:45.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:00:45.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:00:45.739: INFO: update-demo-nautilus-8ldlj is verified up and running
Apr 15 11:00:45.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-vf87b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:45.809: INFO: stderr: ""
Apr 15 11:00:45.809: INFO: stdout: "true"
Apr 15 11:00:45.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-vf87b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:45.879: INFO: stderr: ""
Apr 15 11:00:45.879: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:00:45.879: INFO: validating pod update-demo-nautilus-vf87b
Apr 15 11:00:45.884: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:00:45.884: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:00:45.884: INFO: update-demo-nautilus-vf87b is verified up and running
STEP: scaling down the replication controller
Apr 15 11:00:45.886: INFO: scanned /root for discovery docs: <nil>
Apr 15 11:00:45.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3839'
Apr 15 11:00:46.977: INFO: stderr: ""
Apr 15 11:00:46.977: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 11:00:46.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:47.047: INFO: stderr: ""
Apr 15 11:00:47.047: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-vf87b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 15 11:00:52.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:52.116: INFO: stderr: ""
Apr 15 11:00:52.116: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-vf87b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 15 11:00:57.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:57.184: INFO: stderr: ""
Apr 15 11:00:57.184: INFO: stdout: "update-demo-nautilus-8ldlj "
Apr 15 11:00:57.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:57.248: INFO: stderr: ""
Apr 15 11:00:57.248: INFO: stdout: "true"
Apr 15 11:00:57.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:57.320: INFO: stderr: ""
Apr 15 11:00:57.320: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:00:57.320: INFO: validating pod update-demo-nautilus-8ldlj
Apr 15 11:00:57.325: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:00:57.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:00:57.325: INFO: update-demo-nautilus-8ldlj is verified up and running
STEP: scaling up the replication controller
Apr 15 11:00:57.327: INFO: scanned /root for discovery docs: <nil>
Apr 15 11:00:57.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3839'
Apr 15 11:00:58.440: INFO: stderr: ""
Apr 15 11:00:58.440: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 11:00:58.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:00:58.512: INFO: stderr: ""
Apr 15 11:00:58.512: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-qm6hk "
Apr 15 11:00:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:58.578: INFO: stderr: ""
Apr 15 11:00:58.578: INFO: stdout: "true"
Apr 15 11:00:58.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:58.643: INFO: stderr: ""
Apr 15 11:00:58.643: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:00:58.643: INFO: validating pod update-demo-nautilus-8ldlj
Apr 15 11:00:58.647: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:00:58.647: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:00:58.647: INFO: update-demo-nautilus-8ldlj is verified up and running
Apr 15 11:00:58.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-qm6hk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:00:58.712: INFO: stderr: ""
Apr 15 11:00:58.712: INFO: stdout: ""
Apr 15 11:00:58.712: INFO: update-demo-nautilus-qm6hk is created but not running
Apr 15 11:01:03.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3839'
Apr 15 11:01:03.777: INFO: stderr: ""
Apr 15 11:01:03.777: INFO: stdout: "update-demo-nautilus-8ldlj update-demo-nautilus-qm6hk "
Apr 15 11:01:03.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:01:03.844: INFO: stderr: ""
Apr 15 11:01:03.844: INFO: stdout: "true"
Apr 15 11:01:03.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-8ldlj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:01:03.914: INFO: stderr: ""
Apr 15 11:01:03.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:01:03.914: INFO: validating pod update-demo-nautilus-8ldlj
Apr 15 11:01:03.918: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:01:03.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:01:03.919: INFO: update-demo-nautilus-8ldlj is verified up and running
Apr 15 11:01:03.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-qm6hk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:01:03.988: INFO: stderr: ""
Apr 15 11:01:03.988: INFO: stdout: "true"
Apr 15 11:01:03.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-qm6hk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3839'
Apr 15 11:01:04.059: INFO: stderr: ""
Apr 15 11:01:04.059: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:01:04.059: INFO: validating pod update-demo-nautilus-qm6hk
Apr 15 11:01:04.065: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:01:04.065: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:01:04.065: INFO: update-demo-nautilus-qm6hk is verified up and running
STEP: using delete to clean up resources
Apr 15 11:01:04.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-3839'
Apr 15 11:01:04.143: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 11:01:04.143: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 15 11:01:04.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3839'
Apr 15 11:01:04.289: INFO: stderr: "No resources found.\n"
Apr 15 11:01:04.289: INFO: stdout: ""
Apr 15 11:01:04.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=update-demo --namespace=kubectl-3839 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:01:04.395: INFO: stderr: ""
Apr 15 11:01:04.395: INFO: stdout: "update-demo-nautilus-8ldlj\nupdate-demo-nautilus-qm6hk\n"
Apr 15 11:01:04.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3839'
Apr 15 11:01:05.026: INFO: stderr: "No resources found.\n"
Apr 15 11:01:05.026: INFO: stdout: ""
Apr 15 11:01:05.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=update-demo --namespace=kubectl-3839 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:01:05.132: INFO: stderr: ""
Apr 15 11:01:05.132: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:01:05.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3839" for this suite.
Apr 15 11:01:29.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:01:29.255: INFO: namespace kubectl-3839 deletion completed in 24.118248414s

• [SLOW TEST:49.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:01:29.258: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-567jf in namespace proxy-84
I0415 11:01:29.329728      16 runners.go:184] Created replication controller with name: proxy-service-567jf, namespace: proxy-84, replica count: 1
I0415 11:01:30.380170      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0415 11:01:31.380457      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0415 11:01:32.380738      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:33.380965      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:34.381248      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:35.381436      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:36.381554      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:37.381710      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:38.381901      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:39.382076      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0415 11:01:40.382223      16 runners.go:184] proxy-service-567jf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 15 11:01:40.390: INFO: setup took 11.091352703s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 15 11:01:40.403: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 12.071351ms)
Apr 15 11:01:40.404: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.034654ms)
Apr 15 11:01:40.404: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 14.188216ms)
Apr 15 11:01:40.405: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 15.105459ms)
Apr 15 11:01:40.406: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 14.763947ms)
Apr 15 11:01:40.406: INFO: (0) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 14.920359ms)
Apr 15 11:01:40.406: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 15.985354ms)
Apr 15 11:01:40.411: INFO: (0) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 20.066029ms)
Apr 15 11:01:40.411: INFO: (0) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 20.061306ms)
Apr 15 11:01:40.411: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 21.191668ms)
Apr 15 11:01:40.412: INFO: (0) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 21.668447ms)
Apr 15 11:01:40.414: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 23.1506ms)
Apr 15 11:01:40.415: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 24.844691ms)
Apr 15 11:01:40.419: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 28.236673ms)
Apr 15 11:01:40.420: INFO: (0) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 29.699314ms)
Apr 15 11:01:40.421: INFO: (0) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 30.234243ms)
Apr 15 11:01:40.433: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 11.634626ms)
Apr 15 11:01:40.434: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.036286ms)
Apr 15 11:01:40.436: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.751512ms)
Apr 15 11:01:40.436: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 14.485636ms)
Apr 15 11:01:40.436: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 14.290581ms)
Apr 15 11:01:40.437: INFO: (1) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 15.551708ms)
Apr 15 11:01:40.437: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 15.689098ms)
Apr 15 11:01:40.437: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 15.880148ms)
Apr 15 11:01:40.437: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 15.335299ms)
Apr 15 11:01:40.438: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 17.42867ms)
Apr 15 11:01:40.439: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 16.908231ms)
Apr 15 11:01:40.440: INFO: (1) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 18.100218ms)
Apr 15 11:01:40.441: INFO: (1) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 19.201915ms)
Apr 15 11:01:40.441: INFO: (1) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 19.727622ms)
Apr 15 11:01:40.441: INFO: (1) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 19.504449ms)
Apr 15 11:01:40.441: INFO: (1) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 19.39815ms)
Apr 15 11:01:40.453: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 11.012347ms)
Apr 15 11:01:40.453: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 10.771327ms)
Apr 15 11:01:40.453: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.6876ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.903649ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 11.382927ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.930841ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.02326ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 12.374893ms)
Apr 15 11:01:40.454: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 12.041898ms)
Apr 15 11:01:40.455: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 13.850222ms)
Apr 15 11:01:40.457: INFO: (2) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 15.235573ms)
Apr 15 11:01:40.458: INFO: (2) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.407111ms)
Apr 15 11:01:40.461: INFO: (2) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 18.128685ms)
Apr 15 11:01:40.461: INFO: (2) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 19.020212ms)
Apr 15 11:01:40.461: INFO: (2) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 18.683234ms)
Apr 15 11:01:40.462: INFO: (2) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 19.941766ms)
Apr 15 11:01:40.470: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 7.912534ms)
Apr 15 11:01:40.473: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 11.186667ms)
Apr 15 11:01:40.475: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.594097ms)
Apr 15 11:01:40.475: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 12.905069ms)
Apr 15 11:01:40.475: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 12.724167ms)
Apr 15 11:01:40.475: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 13.068016ms)
Apr 15 11:01:40.476: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.424009ms)
Apr 15 11:01:40.476: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.730575ms)
Apr 15 11:01:40.477: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 14.131727ms)
Apr 15 11:01:40.477: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 14.407768ms)
Apr 15 11:01:40.477: INFO: (3) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.673198ms)
Apr 15 11:01:40.478: INFO: (3) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 15.821479ms)
Apr 15 11:01:40.478: INFO: (3) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.999846ms)
Apr 15 11:01:40.479: INFO: (3) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 16.468734ms)
Apr 15 11:01:40.479: INFO: (3) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.709328ms)
Apr 15 11:01:40.480: INFO: (3) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 18.366935ms)
Apr 15 11:01:40.497: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 16.715766ms)
Apr 15 11:01:40.497: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 16.506918ms)
Apr 15 11:01:40.498: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 16.512057ms)
Apr 15 11:01:40.498: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 16.530376ms)
Apr 15 11:01:40.501: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 20.472648ms)
Apr 15 11:01:40.501: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 20.413197ms)
Apr 15 11:01:40.501: INFO: (4) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 20.756284ms)
Apr 15 11:01:40.501: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 20.495583ms)
Apr 15 11:01:40.502: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 20.850776ms)
Apr 15 11:01:40.502: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 20.657222ms)
Apr 15 11:01:40.502: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 21.531691ms)
Apr 15 11:01:40.502: INFO: (4) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 21.881608ms)
Apr 15 11:01:40.504: INFO: (4) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 23.277826ms)
Apr 15 11:01:40.505: INFO: (4) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 23.879529ms)
Apr 15 11:01:40.505: INFO: (4) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 23.892516ms)
Apr 15 11:01:40.505: INFO: (4) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 24.11305ms)
Apr 15 11:01:40.514: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 8.401799ms)
Apr 15 11:01:40.515: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.543187ms)
Apr 15 11:01:40.516: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 10.596879ms)
Apr 15 11:01:40.516: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 10.923836ms)
Apr 15 11:01:40.517: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 12.037017ms)
Apr 15 11:01:40.517: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.451369ms)
Apr 15 11:01:40.518: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 12.664651ms)
Apr 15 11:01:40.518: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 12.956961ms)
Apr 15 11:01:40.518: INFO: (5) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 13.467537ms)
Apr 15 11:01:40.519: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 13.476192ms)
Apr 15 11:01:40.519: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.633467ms)
Apr 15 11:01:40.519: INFO: (5) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 13.707445ms)
Apr 15 11:01:40.520: INFO: (5) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.485141ms)
Apr 15 11:01:40.521: INFO: (5) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 15.168205ms)
Apr 15 11:01:40.521: INFO: (5) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 15.684067ms)
Apr 15 11:01:40.521: INFO: (5) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.642632ms)
Apr 15 11:01:40.525: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 4.471756ms)
Apr 15 11:01:40.531: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 10.434799ms)
Apr 15 11:01:40.532: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 10.551762ms)
Apr 15 11:01:40.532: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 11.543177ms)
Apr 15 11:01:40.533: INFO: (6) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 12.116148ms)
Apr 15 11:01:40.534: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.843096ms)
Apr 15 11:01:40.534: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 12.53559ms)
Apr 15 11:01:40.534: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 13.096815ms)
Apr 15 11:01:40.534: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 12.816888ms)
Apr 15 11:01:40.535: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.307891ms)
Apr 15 11:01:40.535: INFO: (6) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 13.10571ms)
Apr 15 11:01:40.536: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 14.156465ms)
Apr 15 11:01:40.536: INFO: (6) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 14.548923ms)
Apr 15 11:01:40.536: INFO: (6) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 14.519623ms)
Apr 15 11:01:40.536: INFO: (6) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 14.409074ms)
Apr 15 11:01:40.536: INFO: (6) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 14.48635ms)
Apr 15 11:01:40.547: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.278486ms)
Apr 15 11:01:40.549: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 12.589765ms)
Apr 15 11:01:40.549: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.689716ms)
Apr 15 11:01:40.549: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 12.933615ms)
Apr 15 11:01:40.549: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.173094ms)
Apr 15 11:01:40.549: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 12.878408ms)
Apr 15 11:01:40.550: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 13.149988ms)
Apr 15 11:01:40.550: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 13.331327ms)
Apr 15 11:01:40.550: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.510089ms)
Apr 15 11:01:40.550: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 13.613699ms)
Apr 15 11:01:40.551: INFO: (7) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 14.502939ms)
Apr 15 11:01:40.552: INFO: (7) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.517135ms)
Apr 15 11:01:40.552: INFO: (7) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 16.095402ms)
Apr 15 11:01:40.552: INFO: (7) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 16.224494ms)
Apr 15 11:01:40.552: INFO: (7) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.876252ms)
Apr 15 11:01:40.552: INFO: (7) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 15.827203ms)
Apr 15 11:01:40.559: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 6.534527ms)
Apr 15 11:01:40.563: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 9.479384ms)
Apr 15 11:01:40.563: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 9.563387ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.589454ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.900683ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 11.017622ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 10.776611ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.156274ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 10.705755ms)
Apr 15 11:01:40.564: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 11.04194ms)
Apr 15 11:01:40.566: INFO: (8) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 13.784431ms)
Apr 15 11:01:40.568: INFO: (8) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.909096ms)
Apr 15 11:01:40.568: INFO: (8) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.709146ms)
Apr 15 11:01:40.568: INFO: (8) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.682483ms)
Apr 15 11:01:40.568: INFO: (8) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 15.11906ms)
Apr 15 11:01:40.568: INFO: (8) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 15.211165ms)
Apr 15 11:01:40.579: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 9.702597ms)
Apr 15 11:01:40.580: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.114919ms)
Apr 15 11:01:40.580: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 11.297752ms)
Apr 15 11:01:40.580: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 10.149883ms)
Apr 15 11:01:40.580: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 10.03348ms)
Apr 15 11:01:40.580: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.08294ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 11.723589ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.892739ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 12.530781ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.687281ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 12.508118ms)
Apr 15 11:01:40.581: INFO: (9) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 11.685305ms)
Apr 15 11:01:40.584: INFO: (9) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.544603ms)
Apr 15 11:01:40.586: INFO: (9) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 16.505874ms)
Apr 15 11:01:40.586: INFO: (9) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 15.898661ms)
Apr 15 11:01:40.586: INFO: (9) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 16.883709ms)
Apr 15 11:01:40.595: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 8.71832ms)
Apr 15 11:01:40.597: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.709541ms)
Apr 15 11:01:40.597: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 10.635534ms)
Apr 15 11:01:40.601: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.753943ms)
Apr 15 11:01:40.601: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 13.807487ms)
Apr 15 11:01:40.601: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 14.814339ms)
Apr 15 11:01:40.602: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 15.273158ms)
Apr 15 11:01:40.602: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 14.770151ms)
Apr 15 11:01:40.602: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 14.611932ms)
Apr 15 11:01:40.602: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 15.334646ms)
Apr 15 11:01:40.603: INFO: (10) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 15.509595ms)
Apr 15 11:01:40.605: INFO: (10) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 18.32379ms)
Apr 15 11:01:40.605: INFO: (10) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 18.301233ms)
Apr 15 11:01:40.605: INFO: (10) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 17.854935ms)
Apr 15 11:01:40.605: INFO: (10) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 17.996099ms)
Apr 15 11:01:40.605: INFO: (10) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 17.979026ms)
Apr 15 11:01:40.613: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 7.950511ms)
Apr 15 11:01:40.616: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 9.942423ms)
Apr 15 11:01:40.616: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.445163ms)
Apr 15 11:01:40.616: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 10.471347ms)
Apr 15 11:01:40.617: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 11.064246ms)
Apr 15 11:01:40.617: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.340795ms)
Apr 15 11:01:40.618: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 12.376181ms)
Apr 15 11:01:40.618: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 12.284084ms)
Apr 15 11:01:40.618: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 12.765399ms)
Apr 15 11:01:40.618: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 12.843874ms)
Apr 15 11:01:40.620: INFO: (11) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.390615ms)
Apr 15 11:01:40.620: INFO: (11) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 14.870388ms)
Apr 15 11:01:40.622: INFO: (11) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 16.123864ms)
Apr 15 11:01:40.622: INFO: (11) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.812645ms)
Apr 15 11:01:40.622: INFO: (11) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 16.893174ms)
Apr 15 11:01:40.622: INFO: (11) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 17.041727ms)
Apr 15 11:01:40.629: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 6.160127ms)
Apr 15 11:01:40.630: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 7.023357ms)
Apr 15 11:01:40.633: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 9.87932ms)
Apr 15 11:01:40.633: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 9.986621ms)
Apr 15 11:01:40.633: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 10.146442ms)
Apr 15 11:01:40.633: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 10.599021ms)
Apr 15 11:01:40.633: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.492972ms)
Apr 15 11:01:40.634: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.997497ms)
Apr 15 11:01:40.634: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 11.702098ms)
Apr 15 11:01:40.635: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 11.973138ms)
Apr 15 11:01:40.635: INFO: (12) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 12.988623ms)
Apr 15 11:01:40.637: INFO: (12) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 14.359998ms)
Apr 15 11:01:40.637: INFO: (12) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.648172ms)
Apr 15 11:01:40.638: INFO: (12) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 14.686945ms)
Apr 15 11:01:40.638: INFO: (12) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 15.353997ms)
Apr 15 11:01:40.638: INFO: (12) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 15.369126ms)
Apr 15 11:01:40.651: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 11.605687ms)
Apr 15 11:01:40.651: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 12.41311ms)
Apr 15 11:01:40.652: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.178609ms)
Apr 15 11:01:40.652: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.036363ms)
Apr 15 11:01:40.652: INFO: (13) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.014148ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 14.372416ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 13.91338ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 14.09842ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 14.086099ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 14.080349ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 14.643876ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 14.664542ms)
Apr 15 11:01:40.653: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 14.291274ms)
Apr 15 11:01:40.654: INFO: (13) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 15.283129ms)
Apr 15 11:01:40.654: INFO: (13) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.164236ms)
Apr 15 11:01:40.655: INFO: (13) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 16.129042ms)
Apr 15 11:01:40.662: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 5.686179ms)
Apr 15 11:01:40.662: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 6.74608ms)
Apr 15 11:01:40.662: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 6.894288ms)
Apr 15 11:01:40.662: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 6.27828ms)
Apr 15 11:01:40.664: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 8.365259ms)
Apr 15 11:01:40.666: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 9.963655ms)
Apr 15 11:01:40.667: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.897674ms)
Apr 15 11:01:40.667: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.264588ms)
Apr 15 11:01:40.667: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.322439ms)
Apr 15 11:01:40.668: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 12.436344ms)
Apr 15 11:01:40.669: INFO: (14) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 13.369971ms)
Apr 15 11:01:40.670: INFO: (14) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 14.794652ms)
Apr 15 11:01:40.670: INFO: (14) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 14.60702ms)
Apr 15 11:01:40.671: INFO: (14) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.257153ms)
Apr 15 11:01:40.672: INFO: (14) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.474515ms)
Apr 15 11:01:40.672: INFO: (14) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 16.337969ms)
Apr 15 11:01:40.678: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 6.519866ms)
Apr 15 11:01:40.682: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 9.906271ms)
Apr 15 11:01:40.685: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 13.323514ms)
Apr 15 11:01:40.685: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.119721ms)
Apr 15 11:01:40.686: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 13.381573ms)
Apr 15 11:01:40.686: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.803517ms)
Apr 15 11:01:40.686: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 13.849519ms)
Apr 15 11:01:40.686: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 13.78966ms)
Apr 15 11:01:40.687: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 14.165945ms)
Apr 15 11:01:40.687: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 15.109474ms)
Apr 15 11:01:40.688: INFO: (15) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.492543ms)
Apr 15 11:01:40.690: INFO: (15) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 18.093034ms)
Apr 15 11:01:40.691: INFO: (15) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 18.656226ms)
Apr 15 11:01:40.691: INFO: (15) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 18.644731ms)
Apr 15 11:01:40.691: INFO: (15) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 18.503101ms)
Apr 15 11:01:40.691: INFO: (15) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 18.470756ms)
Apr 15 11:01:40.701: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 9.800438ms)
Apr 15 11:01:40.701: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.138194ms)
Apr 15 11:01:40.702: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 11.309643ms)
Apr 15 11:01:40.703: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 12.006738ms)
Apr 15 11:01:40.704: INFO: (16) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 12.789416ms)
Apr 15 11:01:40.704: INFO: (16) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 12.809643ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.622281ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 13.792953ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 13.945405ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 13.820371ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 13.813751ms)
Apr 15 11:01:40.705: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 14.064027ms)
Apr 15 11:01:40.706: INFO: (16) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 14.857711ms)
Apr 15 11:01:40.706: INFO: (16) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 14.79117ms)
Apr 15 11:01:40.708: INFO: (16) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 16.750112ms)
Apr 15 11:01:40.708: INFO: (16) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.472228ms)
Apr 15 11:01:40.718: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 9.497852ms)
Apr 15 11:01:40.718: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 10.075278ms)
Apr 15 11:01:40.718: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 10.727497ms)
Apr 15 11:01:40.719: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.019155ms)
Apr 15 11:01:40.719: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 10.819638ms)
Apr 15 11:01:40.719: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.216052ms)
Apr 15 11:01:40.720: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 11.632249ms)
Apr 15 11:01:40.720: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 11.797906ms)
Apr 15 11:01:40.720: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.969943ms)
Apr 15 11:01:40.720: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 12.329685ms)
Apr 15 11:01:40.720: INFO: (17) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 12.351376ms)
Apr 15 11:01:40.721: INFO: (17) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 13.130442ms)
Apr 15 11:01:40.723: INFO: (17) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 15.181226ms)
Apr 15 11:01:40.724: INFO: (17) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 16.220613ms)
Apr 15 11:01:40.725: INFO: (17) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 16.811835ms)
Apr 15 11:01:40.725: INFO: (17) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 16.477478ms)
Apr 15 11:01:40.734: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 7.748428ms)
Apr 15 11:01:40.735: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 8.813144ms)
Apr 15 11:01:40.736: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 9.59605ms)
Apr 15 11:01:40.736: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 10.071156ms)
Apr 15 11:01:40.736: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 10.487744ms)
Apr 15 11:01:40.736: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 11.210343ms)
Apr 15 11:01:40.736: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.489114ms)
Apr 15 11:01:40.737: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 11.260158ms)
Apr 15 11:01:40.737: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 11.048036ms)
Apr 15 11:01:40.737: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 10.600581ms)
Apr 15 11:01:40.737: INFO: (18) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 12.02886ms)
Apr 15 11:01:40.739: INFO: (18) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 13.515115ms)
Apr 15 11:01:40.740: INFO: (18) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 15.190092ms)
Apr 15 11:01:40.742: INFO: (18) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 16.191381ms)
Apr 15 11:01:40.742: INFO: (18) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 15.671213ms)
Apr 15 11:01:40.742: INFO: (18) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 16.069221ms)
Apr 15 11:01:40.752: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:162/proxy/: bar (200; 10.205026ms)
Apr 15 11:01:40.755: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:443/proxy/tlsrewriteme"... (200; 12.015887ms)
Apr 15 11:01:40.756: INFO: (19) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname1/proxy/: foo (200; 13.837921ms)
Apr 15 11:01:40.756: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:160/proxy/: foo (200; 13.286114ms)
Apr 15 11:01:40.757: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:160/proxy/: foo (200; 14.210084ms)
Apr 15 11:01:40.757: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq/proxy/rewriteme">test</a> (200; 14.73714ms)
Apr 15 11:01:40.757: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:462/proxy/: tls qux (200; 14.61279ms)
Apr 15 11:01:40.757: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-567jf-jh8dq:1080/proxy/rewriteme">te... (200; 14.870305ms)
Apr 15 11:01:40.758: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:1080/proxy/rewriteme">test</a... (200; 15.710195ms)
Apr 15 11:01:40.758: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-567jf-jh8dq:460/proxy/: tls baz (200; 15.0861ms)
Apr 15 11:01:40.758: INFO: (19) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname1/proxy/: foo (200; 15.937726ms)
Apr 15 11:01:40.758: INFO: (19) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname1/proxy/: tls baz (200; 15.575643ms)
Apr 15 11:01:40.759: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-567jf-jh8dq:162/proxy/: bar (200; 15.468087ms)
Apr 15 11:01:40.759: INFO: (19) /api/v1/namespaces/proxy-84/services/http:proxy-service-567jf:portname2/proxy/: bar (200; 15.707851ms)
Apr 15 11:01:40.759: INFO: (19) /api/v1/namespaces/proxy-84/services/https:proxy-service-567jf:tlsportname2/proxy/: tls qux (200; 16.127505ms)
Apr 15 11:01:40.759: INFO: (19) /api/v1/namespaces/proxy-84/services/proxy-service-567jf:portname2/proxy/: bar (200; 16.131988ms)
STEP: deleting ReplicationController proxy-service-567jf in namespace proxy-84, will wait for the garbage collector to delete the pods
Apr 15 11:01:40.823: INFO: Deleting ReplicationController proxy-service-567jf took: 9.633063ms
Apr 15 11:01:41.123: INFO: Terminating ReplicationController proxy-service-567jf pods took: 300.575383ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:01:46.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-84" for this suite.
Apr 15 11:01:52.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:01:52.457: INFO: namespace proxy-84 deletion completed in 6.128451297s

• [SLOW TEST:23.199 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:01:52.458: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-dff56786-5f6d-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:01:52.580: INFO: Waiting up to 5m0s for pod "pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-7927" to be "success or failure"
Apr 15 11:01:52.587: INFO: Pod "pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 7.214365ms
Apr 15 11:01:54.594: INFO: Pod "pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013714767s
STEP: Saw pod success
Apr 15 11:01:54.594: INFO: Pod "pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:01:54.600: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:01:54.638: INFO: Waiting for pod pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:01:54.647: INFO: Pod pod-secrets-e0007b07-5f6d-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:01:54.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7927" for this suite.
Apr 15 11:02:00.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:02:00.784: INFO: namespace secrets-7927 deletion completed in 6.129361826s
STEP: Destroying namespace "secret-namespace-7565" for this suite.
Apr 15 11:02:06.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:02:06.898: INFO: namespace secret-namespace-7565 deletion completed in 6.114211953s

• [SLOW TEST:14.441 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:02:06.899: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-481
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-481
STEP: Deleting pre-stop pod
Apr 15 11:02:22.117: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:02:22.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-481" for this suite.
Apr 15 11:03:02.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:02.243: INFO: namespace prestop-481 deletion completed in 40.111438044s

• [SLOW TEST:55.344 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:02.243: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-098d5086-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 11:03:02.294: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5755" to be "success or failure"
Apr 15 11:03:02.299: INFO: Pod "pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126023ms
Apr 15 11:03:04.304: INFO: Pod "pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00947486s
STEP: Saw pod success
Apr 15 11:03:04.304: INFO: Pod "pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:03:04.307: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 11:03:04.330: INFO: Waiting for pod pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:03:04.333: INFO: Pod pod-projected-configmaps-098e5e38-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:04.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5755" for this suite.
Apr 15 11:03:10.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:10.450: INFO: namespace projected-5755 deletion completed in 6.112067661s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:10.450: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 15 11:03:10.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 cluster-info'
Apr 15 11:03:10.575: INFO: stderr: ""
Apr 15 11:03:10.575: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:10.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7242" for this suite.
Apr 15 11:03:16.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:16.699: INFO: namespace kubectl-7242 deletion completed in 6.119559732s

• [SLOW TEST:6.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:16.700: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:03:16.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "projected-3367" to be "success or failure"
Apr 15 11:03:16.761: INFO: Pod "downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.179846ms
Apr 15 11:03:18.766: INFO: Pod "downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010485766s
STEP: Saw pod success
Apr 15 11:03:18.766: INFO: Pod "downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:03:18.770: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:03:18.791: INFO: Waiting for pod downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:03:18.795: INFO: Pod downwardapi-volume-122c63e7-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:18.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3367" for this suite.
Apr 15 11:03:24.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:24.923: INFO: namespace projected-3367 deletion completed in 6.124533238s

• [SLOW TEST:8.223 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:24.924: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6699.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6699.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6699.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6699.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 249.158.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.158.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.158.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.158.249_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6699.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6699.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6699.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6699.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6699.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6699.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 249.158.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.158.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.158.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.158.249_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 15 11:03:27.073: INFO: Unable to read wheezy_udp@dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.077: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.082: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.086: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.115: INFO: Unable to read jessie_udp@dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.122: INFO: Unable to read jessie_tcp@dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.127: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.131: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local from pod dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982: the server could not find the requested resource (get pods dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982)
Apr 15 11:03:27.158: INFO: Lookups using dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982 failed for: [wheezy_udp@dns-test-service.dns-6699.svc.cluster.local wheezy_tcp@dns-test-service.dns-6699.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local jessie_udp@dns-test-service.dns-6699.svc.cluster.local jessie_tcp@dns-test-service.dns-6699.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6699.svc.cluster.local]

Apr 15 11:03:32.230: INFO: DNS probes using dns-6699/dns-test-17192caf-5f6e-11e9-a7dc-a6e5a2dd4982 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:32.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6699" for this suite.
Apr 15 11:03:38.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:38.467: INFO: namespace dns-6699 deletion completed in 6.125427678s

• [SLOW TEST:13.544 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:38.468: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 15 11:03:38.523: INFO: Waiting up to 5m0s for pod "pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-6963" to be "success or failure"
Apr 15 11:03:38.528: INFO: Pod "pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.125003ms
Apr 15 11:03:40.533: INFO: Pod "pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009428868s
STEP: Saw pod success
Apr 15 11:03:40.533: INFO: Pod "pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:03:40.536: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 11:03:40.559: INFO: Waiting for pod pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:03:40.562: INFO: Pod pod-1f26031f-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:40.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6963" for this suite.
Apr 15 11:03:46.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:03:46.682: INFO: namespace emptydir-6963 deletion completed in 6.11586608s

• [SLOW TEST:8.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:03:46.682: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 15 11:03:47.310: INFO: created pod pod-service-account-defaultsa
Apr 15 11:03:47.310: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 15 11:03:47.317: INFO: created pod pod-service-account-mountsa
Apr 15 11:03:47.317: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 15 11:03:47.323: INFO: created pod pod-service-account-nomountsa
Apr 15 11:03:47.323: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 15 11:03:47.332: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 15 11:03:47.332: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 15 11:03:47.342: INFO: created pod pod-service-account-mountsa-mountspec
Apr 15 11:03:47.342: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 15 11:03:47.350: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 15 11:03:47.350: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 15 11:03:47.359: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 15 11:03:47.359: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 15 11:03:47.366: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 15 11:03:47.366: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 15 11:03:47.375: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 15 11:03:47.375: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:03:47.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3160" for this suite.
Apr 15 11:04:11.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:04:11.510: INFO: namespace svcaccounts-3160 deletion completed in 24.127732046s

• [SLOW TEST:24.828 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:04:11.510: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:04:11.638: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "projected-4683" to be "success or failure"
Apr 15 11:04:11.644: INFO: Pod "downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.055477ms
Apr 15 11:04:13.647: INFO: Pod "downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009009672s
STEP: Saw pod success
Apr 15 11:04:13.648: INFO: Pod "downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:04:13.652: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:04:13.674: INFO: Waiting for pod downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:04:13.677: INFO: Pod downwardapi-volume-32e27f07-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:04:13.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4683" for this suite.
Apr 15 11:04:19.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:04:19.797: INFO: namespace projected-4683 deletion completed in 6.116931995s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:04:19.799: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-37c7a296-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:04:19.852: INFO: Waiting up to 5m0s for pod "pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-3853" to be "success or failure"
Apr 15 11:04:19.857: INFO: Pod "pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.098389ms
Apr 15 11:04:21.861: INFO: Pod "pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009182266s
STEP: Saw pod success
Apr 15 11:04:21.861: INFO: Pod "pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:04:21.864: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:04:21.891: INFO: Waiting for pod pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:04:21.894: INFO: Pod pod-secrets-37c8b061-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:04:21.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3853" for this suite.
Apr 15 11:04:27.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:04:28.011: INFO: namespace secrets-3853 deletion completed in 6.113148163s

• [SLOW TEST:8.212 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:04:28.011: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0415 11:04:29.097463      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 11:04:29.097: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:04:29.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9234" for this suite.
Apr 15 11:04:35.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:04:35.302: INFO: namespace gc-9234 deletion completed in 6.201112786s

• [SLOW TEST:7.291 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:04:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:05:35.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4248" for this suite.
Apr 15 11:05:57.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:05:57.475: INFO: namespace container-probe-4248 deletion completed in 22.112759805s

• [SLOW TEST:82.172 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:05:57.475: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 15 11:06:01.604: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 15 11:06:01.608: INFO: Pod pod-with-poststart-http-hook still exists
Apr 15 11:06:03.608: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 15 11:06:03.612: INFO: Pod pod-with-poststart-http-hook still exists
Apr 15 11:06:05.608: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 15 11:06:05.612: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:06:05.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3359" for this suite.
Apr 15 11:06:27.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:06:27.735: INFO: namespace container-lifecycle-hook-3359 deletion completed in 22.118910886s

• [SLOW TEST:30.260 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:06:27.735: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 15 11:06:27.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-807'
Apr 15 11:06:28.018: INFO: stderr: ""
Apr 15 11:06:28.018: INFO: stdout: "pod/pause created\n"
Apr 15 11:06:28.018: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 15 11:06:28.018: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-807" to be "running and ready"
Apr 15 11:06:28.024: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.695039ms
Apr 15 11:06:30.030: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01169194s
Apr 15 11:06:30.030: INFO: Pod "pause" satisfied condition "running and ready"
Apr 15 11:06:30.030: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 15 11:06:30.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 label pods pause testing-label=testing-label-value --namespace=kubectl-807'
Apr 15 11:06:30.106: INFO: stderr: ""
Apr 15 11:06:30.106: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 15 11:06:30.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pod pause -L testing-label --namespace=kubectl-807'
Apr 15 11:06:30.174: INFO: stderr: ""
Apr 15 11:06:30.174: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 15 11:06:30.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 label pods pause testing-label- --namespace=kubectl-807'
Apr 15 11:06:30.241: INFO: stderr: ""
Apr 15 11:06:30.241: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 15 11:06:30.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pod pause -L testing-label --namespace=kubectl-807'
Apr 15 11:06:30.306: INFO: stderr: ""
Apr 15 11:06:30.306: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 15 11:06:30.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-807'
Apr 15 11:06:30.386: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 11:06:30.386: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 15 11:06:30.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=pause --no-headers --namespace=kubectl-807'
Apr 15 11:06:30.463: INFO: stderr: "No resources found.\n"
Apr 15 11:06:30.463: INFO: stdout: ""
Apr 15 11:06:30.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=pause --namespace=kubectl-807 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:06:30.532: INFO: stderr: ""
Apr 15 11:06:30.532: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:06:30.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-807" for this suite.
Apr 15 11:06:36.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:06:36.651: INFO: namespace kubectl-807 deletion completed in 6.114397148s

• [SLOW TEST:8.916 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:06:36.652: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-895a3e68-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-895a3e68-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:06:40.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3552" for this suite.
Apr 15 11:07:02.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:07:02.871: INFO: namespace projected-3552 deletion completed in 22.113888699s

• [SLOW TEST:26.219 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:07:02.872: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 15 11:07:05.951: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:07:06.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7057" for this suite.
Apr 15 11:07:28.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:07:29.111: INFO: namespace replicaset-7057 deletion completed in 22.136580161s

• [SLOW TEST:26.240 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:07:29.112: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:07:29.173: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-8346" to be "success or failure"
Apr 15 11:07:29.179: INFO: Pod "downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 6.37925ms
Apr 15 11:07:31.183: INFO: Pod "downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010615891s
STEP: Saw pod success
Apr 15 11:07:31.184: INFO: Pod "downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:07:31.187: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:07:31.213: INFO: Waiting for pod downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:07:31.216: INFO: Pod downwardapi-volume-a89fe11b-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:07:31.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8346" for this suite.
Apr 15 11:07:37.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:07:37.333: INFO: namespace downward-api-8346 deletion completed in 6.11301825s

• [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:07:37.333: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ad84b9a3-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 11:07:37.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-8105" to be "success or failure"
Apr 15 11:07:37.394: INFO: Pod "pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970468ms
Apr 15 11:07:39.398: INFO: Pod "pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010336599s
STEP: Saw pod success
Apr 15 11:07:39.398: INFO: Pod "pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:07:39.402: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 11:07:39.422: INFO: Waiting for pod pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:07:39.425: INFO: Pod pod-configmaps-ad85d7c1-5f6e-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:07:39.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8105" for this suite.
Apr 15 11:07:45.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:07:45.617: INFO: namespace configmap-8105 deletion completed in 6.186525414s

• [SLOW TEST:8.284 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:07:45.617: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-b275aad1-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b275aad1-5f6e-11e9-a7dc-a6e5a2dd4982
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:07:49.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8703" for this suite.
Apr 15 11:08:13.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:08:13.846: INFO: namespace configmap-8703 deletion completed in 24.125077076s

• [SLOW TEST:28.229 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:08:13.846: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-580
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 15 11:08:13.905: INFO: Found 0 stateful pods, waiting for 3
Apr 15 11:08:23.911: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 11:08:23.911: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 11:08:23.911: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 15 11:08:23.943: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 15 11:08:33.978: INFO: Updating stateful set ss2
Apr 15 11:08:33.987: INFO: Waiting for Pod statefulset-580/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 11:08:43.994: INFO: Waiting for Pod statefulset-580/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 15 11:08:54.046: INFO: Found 2 stateful pods, waiting for 3
Apr 15 11:09:04.051: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 11:09:04.051: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 15 11:09:04.051: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 15 11:09:04.078: INFO: Updating stateful set ss2
Apr 15 11:09:04.084: INFO: Waiting for Pod statefulset-580/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 11:09:14.092: INFO: Waiting for Pod statefulset-580/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 15 11:09:24.111: INFO: Updating stateful set ss2
Apr 15 11:09:24.121: INFO: Waiting for StatefulSet statefulset-580/ss2 to complete update
Apr 15 11:09:24.121: INFO: Waiting for Pod statefulset-580/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 15 11:09:34.129: INFO: Deleting all statefulset in ns statefulset-580
Apr 15 11:09:34.132: INFO: Scaling statefulset ss2 to 0
Apr 15 11:09:54.149: INFO: Waiting for statefulset status.replicas updated to 0
Apr 15 11:09:54.153: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:09:54.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-580" for this suite.
Apr 15 11:10:00.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:10:00.287: INFO: namespace statefulset-580 deletion completed in 6.115291055s

• [SLOW TEST:106.441 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:10:00.287: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 15 11:10:00.360: INFO: Waiting up to 5m0s for pod "pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982" in namespace "emptydir-5580" to be "success or failure"
Apr 15 11:10:00.365: INFO: Pod "pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.917089ms
Apr 15 11:10:02.370: INFO: Pod "pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009242805s
STEP: Saw pod success
Apr 15 11:10:02.370: INFO: Pod "pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:10:02.373: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 11:10:02.402: INFO: Waiting for pod pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:10:02.406: INFO: Pod pod-02bce6d6-5f6f-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:10:02.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5580" for this suite.
Apr 15 11:10:08.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:10:08.529: INFO: namespace emptydir-5580 deletion completed in 6.118607215s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:10:08.529: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0415 11:10:18.658154      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 11:10:18.658: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:10:18.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4165" for this suite.
Apr 15 11:10:24.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:10:24.772: INFO: namespace gc-4165 deletion completed in 6.110417461s

• [SLOW TEST:16.242 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:10:24.772: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 11:10:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5661'
Apr 15 11:10:25.138: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 15 11:10:25.138: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 15 11:10:25.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete jobs e2e-test-nginx-job --namespace=kubectl-5661'
Apr 15 11:10:25.216: INFO: stderr: ""
Apr 15 11:10:25.216: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:10:25.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5661" for this suite.
Apr 15 11:10:47.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:10:47.349: INFO: namespace kubectl-5661 deletion completed in 22.128284618s

• [SLOW TEST:22.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:10:47.350: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-1ec7a6dc-5f6f-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:10:47.409: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982" in namespace "projected-4118" to be "success or failure"
Apr 15 11:10:47.418: INFO: Pod "pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 8.58369ms
Apr 15 11:10:49.422: INFO: Pod "pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013284286s
STEP: Saw pod success
Apr 15 11:10:49.422: INFO: Pod "pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:10:49.426: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:10:49.451: INFO: Waiting for pod pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:10:49.454: INFO: Pod pod-projected-secrets-1ec8e0f2-5f6f-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:10:49.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4118" for this suite.
Apr 15 11:10:55.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:10:55.631: INFO: namespace projected-4118 deletion completed in 6.172602705s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:10:55.632: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 15 11:10:55.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-1953'
Apr 15 11:10:55.894: INFO: stderr: ""
Apr 15 11:10:55.894: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 15 11:10:55.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1953'
Apr 15 11:10:55.975: INFO: stderr: ""
Apr 15 11:10:55.975: INFO: stdout: "update-demo-nautilus-2mhhc update-demo-nautilus-sl57w "
Apr 15 11:10:55.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-2mhhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1953'
Apr 15 11:10:56.039: INFO: stderr: ""
Apr 15 11:10:56.039: INFO: stdout: ""
Apr 15 11:10:56.039: INFO: update-demo-nautilus-2mhhc is created but not running
Apr 15 11:11:01.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1953'
Apr 15 11:11:01.104: INFO: stderr: ""
Apr 15 11:11:01.104: INFO: stdout: "update-demo-nautilus-2mhhc update-demo-nautilus-sl57w "
Apr 15 11:11:01.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-2mhhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1953'
Apr 15 11:11:01.179: INFO: stderr: ""
Apr 15 11:11:01.179: INFO: stdout: "true"
Apr 15 11:11:01.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-2mhhc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1953'
Apr 15 11:11:01.243: INFO: stderr: ""
Apr 15 11:11:01.243: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:11:01.243: INFO: validating pod update-demo-nautilus-2mhhc
Apr 15 11:11:01.249: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:11:01.249: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:11:01.249: INFO: update-demo-nautilus-2mhhc is verified up and running
Apr 15 11:11:01.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-sl57w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1953'
Apr 15 11:11:01.320: INFO: stderr: ""
Apr 15 11:11:01.320: INFO: stdout: "true"
Apr 15 11:11:01.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods update-demo-nautilus-sl57w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1953'
Apr 15 11:11:01.388: INFO: stderr: ""
Apr 15 11:11:01.388: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 15 11:11:01.388: INFO: validating pod update-demo-nautilus-sl57w
Apr 15 11:11:01.395: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 15 11:11:01.395: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 15 11:11:01.395: INFO: update-demo-nautilus-sl57w is verified up and running
STEP: using delete to clean up resources
Apr 15 11:11:01.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-1953'
Apr 15 11:11:01.531: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 11:11:01.531: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 15 11:11:01.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1953'
Apr 15 11:11:01.612: INFO: stderr: "No resources found.\n"
Apr 15 11:11:01.612: INFO: stdout: ""
Apr 15 11:11:01.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=update-demo --namespace=kubectl-1953 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:11:01.675: INFO: stderr: ""
Apr 15 11:11:01.675: INFO: stdout: "update-demo-nautilus-2mhhc\nupdate-demo-nautilus-sl57w\n"
Apr 15 11:11:02.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1953'
Apr 15 11:11:02.294: INFO: stderr: "No resources found.\n"
Apr 15 11:11:02.295: INFO: stdout: ""
Apr 15 11:11:02.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=update-demo --namespace=kubectl-1953 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:11:02.366: INFO: stderr: ""
Apr 15 11:11:02.366: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:11:02.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1953" for this suite.
Apr 15 11:11:08.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:11:08.496: INFO: namespace kubectl-1953 deletion completed in 6.123236355s

• [SLOW TEST:12.864 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:11:08.497: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9993/configmap-test-2b622fe8-5f6f-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 11:11:08.554: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982" in namespace "configmap-9993" to be "success or failure"
Apr 15 11:11:08.558: INFO: Pod "pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.919158ms
Apr 15 11:11:10.563: INFO: Pod "pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009514125s
STEP: Saw pod success
Apr 15 11:11:10.563: INFO: Pod "pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:11:10.567: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982 container env-test: <nil>
STEP: delete the pod
Apr 15 11:11:10.591: INFO: Waiting for pod pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:11:10.601: INFO: Pod pod-configmaps-2b635672-5f6f-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:11:10.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9993" for this suite.
Apr 15 11:11:16.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:11:16.740: INFO: namespace configmap-9993 deletion completed in 6.133437552s

• [SLOW TEST:8.244 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:11:16.741: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:11:16.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3558" for this suite.
Apr 15 11:11:38.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:11:38.939: INFO: namespace pods-3558 deletion completed in 22.120826667s

• [SLOW TEST:22.198 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:11:38.940: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 15 11:11:41.511: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4168 pod-service-account-3dd57eae-5f6f-11e9-a7dc-a6e5a2dd4982 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 15 11:11:41.708: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4168 pod-service-account-3dd57eae-5f6f-11e9-a7dc-a6e5a2dd4982 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 15 11:11:41.988: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4168 pod-service-account-3dd57eae-5f6f-11e9-a7dc-a6e5a2dd4982 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:11:42.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4168" for this suite.
Apr 15 11:11:48.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:11:48.306: INFO: namespace svcaccounts-4168 deletion completed in 6.112445692s

• [SLOW TEST:9.366 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:11:48.307: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:11:48.365: INFO: Waiting up to 5m0s for pod "downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5741" to be "success or failure"
Apr 15 11:11:48.369: INFO: Pod "downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.359767ms
Apr 15 11:11:50.373: INFO: Pod "downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008624922s
STEP: Saw pod success
Apr 15 11:11:50.374: INFO: Pod "downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:11:50.377: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:11:50.401: INFO: Waiting for pod downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:11:50.404: INFO: Pod downwardapi-volume-431d8746-5f6f-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:11:50.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5741" for this suite.
Apr 15 11:11:56.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:11:56.523: INFO: namespace projected-5741 deletion completed in 6.114796937s

• [SLOW TEST:8.216 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:11:56.523: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0415 11:12:06.682604      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 15 11:12:06.682: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:12:06.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2144" for this suite.
Apr 15 11:12:14.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:12:14.807: INFO: namespace gc-2144 deletion completed in 8.121163629s

• [SLOW TEST:18.284 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:12:14.808: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 15 11:12:17.491: INFO: Successfully updated pod "pod-update-52f849da-5f6f-11e9-a7dc-a6e5a2dd4982"
STEP: verifying the updated pod is in kubernetes
Apr 15 11:12:17.498: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:12:17.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5335" for this suite.
Apr 15 11:12:39.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:12:39.619: INFO: namespace pods-5335 deletion completed in 22.117205164s

• [SLOW TEST:24.811 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:12:39.619: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 15 11:12:39.661: INFO: namespace kubectl-5086
Apr 15 11:12:39.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-5086'
Apr 15 11:12:39.846: INFO: stderr: ""
Apr 15 11:12:39.846: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 15 11:12:40.851: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:12:40.851: INFO: Found 0 / 1
Apr 15 11:12:41.850: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:12:41.850: INFO: Found 1 / 1
Apr 15 11:12:41.850: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 15 11:12:41.854: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:12:41.854: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 15 11:12:41.854: INFO: wait on redis-master startup in kubectl-5086 
Apr 15 11:12:41.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 logs redis-master-46mrx redis-master --namespace=kubectl-5086'
Apr 15 11:12:41.931: INFO: stderr: ""
Apr 15 11:12:41.931: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Apr 11:12:40.565 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Apr 11:12:40.565 # Server started, Redis version 3.2.12\n1:M 15 Apr 11:12:40.565 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Apr 11:12:40.565 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 15 11:12:41.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5086'
Apr 15 11:12:42.029: INFO: stderr: ""
Apr 15 11:12:42.029: INFO: stdout: "service/rm2 exposed\n"
Apr 15 11:12:42.036: INFO: Service rm2 in namespace kubectl-5086 found.
STEP: exposing service
Apr 15 11:12:44.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5086'
Apr 15 11:12:44.174: INFO: stderr: ""
Apr 15 11:12:44.174: INFO: stdout: "service/rm3 exposed\n"
Apr 15 11:12:44.179: INFO: Service rm3 in namespace kubectl-5086 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:12:46.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5086" for this suite.
Apr 15 11:13:08.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:13:08.305: INFO: namespace kubectl-5086 deletion completed in 22.114938948s

• [SLOW TEST:28.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:13:08.307: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:13:14.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6307" for this suite.
Apr 15 11:13:20.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:13:20.656: INFO: namespace namespaces-6307 deletion completed in 6.125172365s
STEP: Destroying namespace "nsdeletetest-9282" for this suite.
Apr 15 11:13:20.659: INFO: Namespace nsdeletetest-9282 was already deleted
STEP: Destroying namespace "nsdeletetest-2332" for this suite.
Apr 15 11:13:26.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:13:26.777: INFO: namespace nsdeletetest-2332 deletion completed in 6.117970431s

• [SLOW TEST:18.470 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:13:26.778: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 15 11:13:27.067: INFO: Pod name wrapped-volume-race-7df19141-5f6f-11e9-a7dc-a6e5a2dd4982: Found 0 pods out of 5
Apr 15 11:13:32.073: INFO: Pod name wrapped-volume-race-7df19141-5f6f-11e9-a7dc-a6e5a2dd4982: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7df19141-5f6f-11e9-a7dc-a6e5a2dd4982 in namespace emptydir-wrapper-7415, will wait for the garbage collector to delete the pods
Apr 15 11:13:42.168: INFO: Deleting ReplicationController wrapped-volume-race-7df19141-5f6f-11e9-a7dc-a6e5a2dd4982 took: 10.343961ms
Apr 15 11:13:42.568: INFO: Terminating ReplicationController wrapped-volume-race-7df19141-5f6f-11e9-a7dc-a6e5a2dd4982 pods took: 400.276504ms
STEP: Creating RC which spawns configmap-volume pods
Apr 15 11:14:19.197: INFO: Pod name wrapped-volume-race-9d023e24-5f6f-11e9-a7dc-a6e5a2dd4982: Found 0 pods out of 5
Apr 15 11:14:24.211: INFO: Pod name wrapped-volume-race-9d023e24-5f6f-11e9-a7dc-a6e5a2dd4982: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9d023e24-5f6f-11e9-a7dc-a6e5a2dd4982 in namespace emptydir-wrapper-7415, will wait for the garbage collector to delete the pods
Apr 15 11:14:34.306: INFO: Deleting ReplicationController wrapped-volume-race-9d023e24-5f6f-11e9-a7dc-a6e5a2dd4982 took: 11.276735ms
Apr 15 11:14:34.707: INFO: Terminating ReplicationController wrapped-volume-race-9d023e24-5f6f-11e9-a7dc-a6e5a2dd4982 pods took: 400.245139ms
STEP: Creating RC which spawns configmap-volume pods
Apr 15 11:15:09.828: INFO: Pod name wrapped-volume-race-bb310fa6-5f6f-11e9-a7dc-a6e5a2dd4982: Found 0 pods out of 5
Apr 15 11:15:14.834: INFO: Pod name wrapped-volume-race-bb310fa6-5f6f-11e9-a7dc-a6e5a2dd4982: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bb310fa6-5f6f-11e9-a7dc-a6e5a2dd4982 in namespace emptydir-wrapper-7415, will wait for the garbage collector to delete the pods
Apr 15 11:15:26.948: INFO: Deleting ReplicationController wrapped-volume-race-bb310fa6-5f6f-11e9-a7dc-a6e5a2dd4982 took: 12.000527ms
Apr 15 11:15:27.448: INFO: Terminating ReplicationController wrapped-volume-race-bb310fa6-5f6f-11e9-a7dc-a6e5a2dd4982 pods took: 500.292043ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:16:06.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7415" for this suite.
Apr 15 11:16:14.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:16:14.942: INFO: namespace emptydir-wrapper-7415 deletion completed in 8.115250275s

• [SLOW TEST:168.164 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:16:14.945: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 15 11:16:19.041: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:19.045: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:21.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:21.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:23.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:23.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:25.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:25.050: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:27.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:27.050: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:29.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:29.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:31.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:31.051: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:33.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:33.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:35.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:35.051: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:37.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:37.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:39.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:39.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:41.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:41.049: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:43.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:43.050: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:45.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:45.052: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 15 11:16:47.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 15 11:16:47.049: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:16:47.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4165" for this suite.
Apr 15 11:17:09.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:17:09.183: INFO: namespace container-lifecycle-hook-4165 deletion completed in 22.119101289s

• [SLOW TEST:54.238 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:17:09.184: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-025e5cb6-5f70-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume configMaps
Apr 15 11:17:09.239: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "projected-5443" to be "success or failure"
Apr 15 11:17:09.244: INFO: Pod "pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199141ms
Apr 15 11:17:11.249: INFO: Pod "pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010183516s
STEP: Saw pod success
Apr 15 11:17:11.249: INFO: Pod "pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:17:11.253: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 15 11:17:11.277: INFO: Waiting for pod pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:17:11.280: INFO: Pod pod-projected-configmaps-025faa4f-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:17:11.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5443" for this suite.
Apr 15 11:17:17.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:17:17.409: INFO: namespace projected-5443 deletion completed in 6.123114326s

• [SLOW TEST:8.226 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:17:17.410: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 15 11:17:19.521: INFO: Waiting up to 5m0s for pod "client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "pods-8919" to be "success or failure"
Apr 15 11:17:19.529: INFO: Pod "client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 7.521911ms
Apr 15 11:17:21.534: INFO: Pod "client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012416495s
STEP: Saw pod success
Apr 15 11:17:21.534: INFO: Pod "client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:17:21.538: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982 container env3cont: <nil>
STEP: delete the pod
Apr 15 11:17:21.559: INFO: Waiting for pod client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:17:21.563: INFO: Pod client-envvars-08809997-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:17:21.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8919" for this suite.
Apr 15 11:18:01.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:18:01.687: INFO: namespace pods-8919 deletion completed in 40.119533707s

• [SLOW TEST:44.277 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:18:01.687: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 15 11:18:01.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 create -f - --namespace=kubectl-9014'
Apr 15 11:18:01.876: INFO: stderr: ""
Apr 15 11:18:01.876: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 15 11:18:02.881: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:18:02.881: INFO: Found 0 / 1
Apr 15 11:18:03.881: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:18:03.881: INFO: Found 1 / 1
Apr 15 11:18:03.881: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 15 11:18:03.885: INFO: Selector matched 1 pods for map[app:redis]
Apr 15 11:18:03.885: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 15 11:18:03.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 logs redis-master-9n958 redis-master --namespace=kubectl-9014'
Apr 15 11:18:03.958: INFO: stderr: ""
Apr 15 11:18:03.958: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Apr 11:18:02.640 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Apr 11:18:02.640 # Server started, Redis version 3.2.12\n1:M 15 Apr 11:18:02.640 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Apr 11:18:02.640 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 15 11:18:03.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 log redis-master-9n958 redis-master --namespace=kubectl-9014 --tail=1'
Apr 15 11:18:04.036: INFO: stderr: ""
Apr 15 11:18:04.036: INFO: stdout: "1:M 15 Apr 11:18:02.640 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 15 11:18:04.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 log redis-master-9n958 redis-master --namespace=kubectl-9014 --limit-bytes=1'
Apr 15 11:18:04.107: INFO: stderr: ""
Apr 15 11:18:04.107: INFO: stdout: " "
STEP: exposing timestamps
Apr 15 11:18:04.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 log redis-master-9n958 redis-master --namespace=kubectl-9014 --tail=1 --timestamps'
Apr 15 11:18:04.237: INFO: stderr: ""
Apr 15 11:18:04.239: INFO: stdout: "2019-04-15T11:18:02.640541636Z 1:M 15 Apr 11:18:02.640 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 15 11:18:06.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 log redis-master-9n958 redis-master --namespace=kubectl-9014 --since=1s'
Apr 15 11:18:06.816: INFO: stderr: ""
Apr 15 11:18:06.816: INFO: stdout: ""
Apr 15 11:18:06.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 log redis-master-9n958 redis-master --namespace=kubectl-9014 --since=24h'
Apr 15 11:18:06.892: INFO: stderr: ""
Apr 15 11:18:06.892: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Apr 11:18:02.640 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Apr 11:18:02.640 # Server started, Redis version 3.2.12\n1:M 15 Apr 11:18:02.640 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Apr 11:18:02.640 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 15 11:18:06.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete --grace-period=0 --force -f - --namespace=kubectl-9014'
Apr 15 11:18:06.976: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 15 11:18:06.976: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 15 11:18:06.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get rc,svc -l name=nginx --no-headers --namespace=kubectl-9014'
Apr 15 11:18:07.050: INFO: stderr: "No resources found.\n"
Apr 15 11:18:07.050: INFO: stdout: ""
Apr 15 11:18:07.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 get pods -l name=nginx --namespace=kubectl-9014 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 15 11:18:07.121: INFO: stderr: ""
Apr 15 11:18:07.121: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:18:07.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9014" for this suite.
Apr 15 11:18:29.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:18:29.240: INFO: namespace kubectl-9014 deletion completed in 22.114289622s

• [SLOW TEST:27.553 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:18:29.240: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:18:31.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6333" for this suite.
Apr 15 11:19:09.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:19:09.500: INFO: namespace kubelet-test-6333 deletion completed in 38.136667913s

• [SLOW TEST:40.260 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:19:09.500: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4933
Apr 15 11:19:11.562: INFO: Started pod liveness-http in namespace container-probe-4933
STEP: checking the pod's current state and verifying that restartCount is present
Apr 15 11:19:11.566: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:12.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4933" for this suite.
Apr 15 11:23:18.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:23:18.248: INFO: namespace container-probe-4933 deletion completed in 6.119960058s

• [SLOW TEST:248.747 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:23:18.248: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-de5a26e8-5f70-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:23:18.311: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "projected-8948" to be "success or failure"
Apr 15 11:23:18.315: INFO: Pod "pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.909459ms
Apr 15 11:23:20.319: INFO: Pod "pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008035483s
STEP: Saw pod success
Apr 15 11:23:20.319: INFO: Pod "pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:23:20.322: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:23:20.358: INFO: Waiting for pod pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:23:20.361: INFO: Pod pod-projected-secrets-de5b66d9-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:20.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8948" for this suite.
Apr 15 11:23:26.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:23:26.488: INFO: namespace projected-8948 deletion completed in 6.122843258s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:23:26.488: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 15 11:23:26.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-381'
Apr 15 11:23:26.825: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 15 11:23:26.825: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 15 11:23:30.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357557484 delete deployment e2e-test-nginx-deployment --namespace=kubectl-381'
Apr 15 11:23:30.917: INFO: stderr: ""
Apr 15 11:23:30.917: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:30.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-381" for this suite.
Apr 15 11:23:36.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:23:37.038: INFO: namespace kubectl-381 deletion completed in 6.116758222s

• [SLOW TEST:10.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:23:37.038: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:23:37.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "downward-api-1551" to be "success or failure"
Apr 15 11:23:37.093: INFO: Pod "downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.997301ms
Apr 15 11:23:39.097: INFO: Pod "downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00841382s
STEP: Saw pod success
Apr 15 11:23:39.097: INFO: Pod "downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:23:39.101: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:23:39.124: INFO: Waiting for pod downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:23:39.127: INFO: Pod downwardapi-volume-e98c36bb-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:39.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1551" for this suite.
Apr 15 11:23:45.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:23:45.282: INFO: namespace downward-api-1551 deletion completed in 6.150478947s

• [SLOW TEST:8.244 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:23:45.282: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 15 11:23:45.380: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:48.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5384" for this suite.
Apr 15 11:23:54.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:23:54.944: INFO: namespace init-container-5384 deletion completed in 6.112287734s

• [SLOW TEST:9.662 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:23:54.944: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:23:54.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4697" for this suite.
Apr 15 11:24:01.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:24:01.125: INFO: namespace services-4697 deletion completed in 6.123595038s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.181 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:24:01.126: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f7e851c3-5f70-11e9-a7dc-a6e5a2dd4982
STEP: Creating a pod to test consume secrets
Apr 15 11:24:01.186: INFO: Waiting up to 5m0s for pod "pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "secrets-6263" to be "success or failure"
Apr 15 11:24:01.191: INFO: Pod "pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549048ms
Apr 15 11:24:03.195: INFO: Pod "pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009274166s
STEP: Saw pod success
Apr 15 11:24:03.195: INFO: Pod "pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:24:03.199: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982 container secret-volume-test: <nil>
STEP: delete the pod
Apr 15 11:24:03.221: INFO: Waiting for pod pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:24:03.225: INFO: Pod pod-secrets-f7e9a2cb-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:24:03.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6263" for this suite.
Apr 15 11:24:09.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:24:09.342: INFO: namespace secrets-6263 deletion completed in 6.112413612s

• [SLOW TEST:8.216 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:24:09.342: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 15 11:24:09.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982" in namespace "projected-4113" to be "success or failure"
Apr 15 11:24:09.407: INFO: Pod "downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584912ms
Apr 15 11:24:11.412: INFO: Pod "downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010438738s
STEP: Saw pod success
Apr 15 11:24:11.412: INFO: Pod "downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:24:11.415: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982 container client-container: <nil>
STEP: delete the pod
Apr 15 11:24:11.437: INFO: Waiting for pod downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:24:11.440: INFO: Pod downwardapi-volume-fccec248-5f70-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:24:11.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4113" for this suite.
Apr 15 11:24:17.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:24:17.563: INFO: namespace projected-4113 deletion completed in 6.118783786s

• [SLOW TEST:8.221 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:24:17.563: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 15 11:24:17.657: INFO: PodSpec: initContainers in spec.initContainers
Apr 15 11:25:06.086: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-01bc6019-5f71-11e9-a7dc-a6e5a2dd4982", GenerateName:"", Namespace:"init-container-4598", SelfLink:"/api/v1/namespaces/init-container-4598/pods/pod-init-01bc6019-5f71-11e9-a7dc-a6e5a2dd4982", UID:"01bd1a53-5f71-11e9-adae-06c5682e2662", ResourceVersion:"28398", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63690924257, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"657658293"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.14.6/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-v7c9s", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002932000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v7c9s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v7c9s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v7c9s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002d75e98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-1-206.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003100720), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d75f10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d75f30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002d75f38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002d75f3c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690924257, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690924257, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690924257, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690924257, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.206", PodIP:"192.168.14.6", StartTime:(*v1.Time)(0xc002bf0740), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e5c380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e5c460)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://5ffa32c3792d75112d75645c5e7734045d287ef64e173bef3dce0d3d616edd3a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002bf0780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002bf0760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:25:06.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4598" for this suite.
Apr 15 11:25:28.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:25:28.222: INFO: namespace init-container-4598 deletion completed in 22.129297071s

• [SLOW TEST:70.659 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 15 11:25:28.222: INFO: >>> kubeConfig: /tmp/kubeconfig-357557484
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 15 11:25:28.274: INFO: Waiting up to 5m0s for pod "client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982" in namespace "containers-1872" to be "success or failure"
Apr 15 11:25:28.279: INFO: Pod "client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982": Phase="Pending", Reason="", readiness=false. Elapsed: 4.480251ms
Apr 15 11:25:30.283: INFO: Pod "client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008739129s
STEP: Saw pod success
Apr 15 11:25:30.283: INFO: Pod "client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982" satisfied condition "success or failure"
Apr 15 11:25:30.286: INFO: Trying to get logs from node ip-10-0-1-206.eu-west-1.compute.internal pod client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982 container test-container: <nil>
STEP: delete the pod
Apr 15 11:25:30.356: INFO: Waiting for pod client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982 to disappear
Apr 15 11:25:30.360: INFO: Pod client-containers-2bd1c70a-5f71-11e9-a7dc-a6e5a2dd4982 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 15 11:25:30.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1872" for this suite.
Apr 15 11:25:36.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 15 11:25:36.523: INFO: namespace containers-1872 deletion completed in 6.15975373s

• [SLOW TEST:8.301 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSApr 15 11:25:36.524: INFO: Running AfterSuite actions on all nodes
Apr 15 11:25:36.524: INFO: Running AfterSuite actions on node 1
Apr 15 11:25:36.524: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5400.652 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h30m1.717362943s
Test Suite Passed
