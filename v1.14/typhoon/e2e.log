I0407 09:49:21.491467      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-030244346
I0407 09:49:21.491586      16 e2e.go:240] Starting e2e run "6a4f7e49-591a-11e9-9aa1-1aed65326ff2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554630559 - Will randomize all specs
Will run 204 of 3584 specs

Apr  7 09:49:21.794: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 09:49:21.797: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  7 09:49:21.811: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  7 09:49:21.839: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  7 09:49:21.839: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Apr  7 09:49:21.839: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  7 09:49:21.847: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr  7 09:49:21.847: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-apiserver' (0 seconds elapsed)
Apr  7 09:49:21.847: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr  7 09:49:21.847: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'pod-checkpointer' (0 seconds elapsed)
Apr  7 09:49:21.847: INFO: e2e test version: v1.14.0
Apr  7 09:49:21.848: INFO: kube-apiserver version: v1.14.0
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:49:21.848: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
Apr  7 09:49:21.919: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0407 09:49:22.952414      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 09:49:22.952: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:49:22.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3759" for this suite.
Apr  7 09:49:28.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:49:29.047: INFO: namespace gc-3759 deletion completed in 6.092689446s

• [SLOW TEST:7.199 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:49:29.047: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  7 09:49:29.073: INFO: Waiting up to 5m0s for pod "pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2" in namespace "emptydir-6694" to be "success or failure"
Apr  7 09:49:29.076: INFO: Pod "pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.260575ms
Apr  7 09:49:31.078: INFO: Pod "pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00587861s
Apr  7 09:49:33.082: INFO: Pod "pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009015413s
STEP: Saw pod success
Apr  7 09:49:33.082: INFO: Pod "pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:49:33.084: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 09:49:33.110: INFO: Waiting for pod pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:49:33.111: INFO: Pod pod-6fc4734b-591a-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:49:33.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6694" for this suite.
Apr  7 09:49:39.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:49:39.194: INFO: namespace emptydir-6694 deletion completed in 6.080708523s

• [SLOW TEST:10.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:49:39.194: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  7 09:49:43.806: INFO: Successfully updated pod "annotationupdate75d8e1ec-591a-11e9-9aa1-1aed65326ff2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:49:45.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9445" for this suite.
Apr  7 09:50:07.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:50:07.907: INFO: namespace downward-api-9445 deletion completed in 22.07625545s

• [SLOW TEST:28.713 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:50:07.907: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr  7 09:50:09.941: INFO: Pod pod-hostip-86ee2928-591a-11e9-9aa1-1aed65326ff2 has hostIP: 10.0.39.198
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:50:09.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7328" for this suite.
Apr  7 09:50:31.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:50:32.016: INFO: namespace pods-7328 deletion completed in 22.072872033s

• [SLOW TEST:24.108 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:50:32.016: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-954cdd29-591a-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 09:50:32.044: INFO: Waiting up to 5m0s for pod "pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2" in namespace "configmap-5753" to be "success or failure"
Apr  7 09:50:32.046: INFO: Pod "pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.217689ms
Apr  7 09:50:34.049: INFO: Pod "pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004837746s
STEP: Saw pod success
Apr  7 09:50:34.049: INFO: Pod "pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:50:34.051: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 09:50:34.071: INFO: Waiting for pod pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:50:34.074: INFO: Pod pod-configmaps-954d3971-591a-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:50:34.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5753" for this suite.
Apr  7 09:50:40.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:50:40.154: INFO: namespace configmap-5753 deletion completed in 6.07707796s

• [SLOW TEST:8.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:50:40.154: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-9a279925-591a-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 09:50:40.206: INFO: Waiting up to 5m0s for pod "pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2" in namespace "secrets-2331" to be "success or failure"
Apr  7 09:50:40.210: INFO: Pod "pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.947227ms
Apr  7 09:50:42.213: INFO: Pod "pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006818152s
STEP: Saw pod success
Apr  7 09:50:42.213: INFO: Pod "pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:50:42.215: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 09:50:42.227: INFO: Waiting for pod pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:50:42.229: INFO: Pod pod-secrets-9a2ab724-591a-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:50:42.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2331" for this suite.
Apr  7 09:50:48.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:50:48.308: INFO: namespace secrets-2331 deletion completed in 6.075171056s
STEP: Destroying namespace "secret-namespace-1167" for this suite.
Apr  7 09:50:54.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:50:54.385: INFO: namespace secret-namespace-1167 deletion completed in 6.076728456s

• [SLOW TEST:14.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:50:54.385: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  7 09:50:54.463: INFO: Waiting up to 5m0s for pod "downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2" in namespace "downward-api-9847" to be "success or failure"
Apr  7 09:50:54.465: INFO: Pod "downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.219252ms
Apr  7 09:50:56.468: INFO: Pod "downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005520245s
STEP: Saw pod success
Apr  7 09:50:56.468: INFO: Pod "downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:50:56.471: INFO: Trying to get logs from node ip-10-0-39-198 pod downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 09:50:56.489: INFO: Waiting for pod downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:50:56.491: INFO: Pod downward-api-a2aa1c38-591a-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:50:56.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9847" for this suite.
Apr  7 09:51:02.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:51:02.570: INFO: namespace downward-api-9847 deletion completed in 6.077189542s

• [SLOW TEST:8.185 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:51:02.570: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr  7 09:51:02.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 api-versions'
Apr  7 09:51:02.675: INFO: stderr: ""
Apr  7 09:51:02.675: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:51:02.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2553" for this suite.
Apr  7 09:51:08.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:51:08.769: INFO: namespace kubectl-2553 deletion completed in 6.089996746s

• [SLOW TEST:6.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:51:08.769: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-820
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  7 09:51:08.809: INFO: Found 0 stateful pods, waiting for 3
Apr  7 09:51:18.812: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 09:51:18.812: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 09:51:18.812: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  7 09:51:18.835: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  7 09:51:28.865: INFO: Updating stateful set ss2
Apr  7 09:51:28.874: INFO: Waiting for Pod statefulset-820/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  7 09:51:38.879: INFO: Waiting for Pod statefulset-820/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr  7 09:51:48.935: INFO: Found 2 stateful pods, waiting for 3
Apr  7 09:51:58.938: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 09:51:58.938: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 09:51:58.938: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  7 09:51:58.959: INFO: Updating stateful set ss2
Apr  7 09:51:58.969: INFO: Waiting for Pod statefulset-820/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  7 09:52:08.997: INFO: Updating stateful set ss2
Apr  7 09:52:09.008: INFO: Waiting for StatefulSet statefulset-820/ss2 to complete update
Apr  7 09:52:09.009: INFO: Waiting for Pod statefulset-820/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  7 09:52:19.016: INFO: Deleting all statefulset in ns statefulset-820
Apr  7 09:52:19.019: INFO: Scaling statefulset ss2 to 0
Apr  7 09:52:29.036: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 09:52:29.039: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:52:29.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-820" for this suite.
Apr  7 09:52:35.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:52:35.132: INFO: namespace statefulset-820 deletion completed in 6.08238557s

• [SLOW TEST:86.363 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:52:35.132: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 09:52:35.186: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  7 09:52:40.190: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 09:52:40.190: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  7 09:52:42.193: INFO: Creating deployment "test-rollover-deployment"
Apr  7 09:52:42.199: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  7 09:52:44.207: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  7 09:52:44.212: INFO: Ensure that both replica sets have 1 created replica
Apr  7 09:52:44.217: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  7 09:52:44.222: INFO: Updating deployment test-rollover-deployment
Apr  7 09:52:44.222: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  7 09:52:46.229: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  7 09:52:46.235: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  7 09:52:46.239: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:46.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227564, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:48.245: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:48.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227567, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:50.245: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:50.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227567, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:52.245: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:52.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227567, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:54.245: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:54.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227567, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:56.245: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 09:52:56.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227567, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690227562, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 09:52:58.245: INFO: 
Apr  7 09:52:58.245: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  7 09:52:58.251: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8003,SelfLink:/apis/apps/v1/namespaces/deployment-8003/deployments/test-rollover-deployment,UID:e2dffb5e-591a-11e9-99b0-0225f4f52196,ResourceVersion:2669,Generation:2,CreationTimestamp:2019-04-07 09:52:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-07 09:52:42 +0000 UTC 2019-04-07 09:52:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-07 09:52:57 +0000 UTC 2019-04-07 09:52:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 09:52:58.255: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-8003,SelfLink:/apis/apps/v1/namespaces/deployment-8003/replicasets/test-rollover-deployment-766b4d6c9d,UID:e4158ac3-591a-11e9-99b0-0225f4f52196,ResourceVersion:2659,Generation:2,CreationTimestamp:2019-04-07 09:52:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e2dffb5e-591a-11e9-99b0-0225f4f52196 0xc001ba9657 0xc001ba9658}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  7 09:52:58.255: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  7 09:52:58.255: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8003,SelfLink:/apis/apps/v1/namespaces/deployment-8003/replicasets/test-rollover-controller,UID:deb1c5b1-591a-11e9-99b0-0225f4f52196,ResourceVersion:2667,Generation:2,CreationTimestamp:2019-04-07 09:52:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e2dffb5e-591a-11e9-99b0-0225f4f52196 0xc001ba94af 0xc001ba94c0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 09:52:58.255: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-8003,SelfLink:/apis/apps/v1/namespaces/deployment-8003/replicasets/test-rollover-deployment-6455657675,UID:e2e179c1-591a-11e9-99b0-0225f4f52196,ResourceVersion:2618,Generation:2,CreationTimestamp:2019-04-07 09:52:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e2dffb5e-591a-11e9-99b0-0225f4f52196 0xc001ba9587 0xc001ba9588}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 09:52:58.257: INFO: Pod "test-rollover-deployment-766b4d6c9d-fcq2f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-fcq2f,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-8003,SelfLink:/api/v1/namespaces/deployment-8003/pods/test-rollover-deployment-766b4d6c9d-fcq2f,UID:e418be11-591a-11e9-99b0-0225f4f52196,ResourceVersion:2642,Generation:0,CreationTimestamp:2019-04-07 09:52:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.15/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d e4158ac3-591a-11e9-99b0-0225f4f52196 0xc0011c6417 0xc0011c6418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qnrjr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qnrjr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qnrjr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011c6560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011c6580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:52:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:52:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:52:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:52:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.15,StartTime:2019-04-07 09:52:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-07 09:52:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d7a219b5ed9d82a0a73a5a682466f4f5a4c69e33032eb493a2daf5a10252b9de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:52:58.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8003" for this suite.
Apr  7 09:53:04.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:53:04.347: INFO: namespace deployment-8003 deletion completed in 6.087150739s

• [SLOW TEST:29.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:53:04.348: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0407 09:53:44.467044      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 09:53:44.467: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:53:44.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7709" for this suite.
Apr  7 09:53:50.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:53:50.564: INFO: namespace gc-7709 deletion completed in 6.095087159s

• [SLOW TEST:46.216 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:53:50.564: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 09:53:50.610: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 09:53:50.622: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:50.628: INFO: Number of nodes with available pods: 0
Apr  7 09:53:50.628: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:53:51.631: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:51.633: INFO: Number of nodes with available pods: 0
Apr  7 09:53:51.633: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:53:52.632: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:52.634: INFO: Number of nodes with available pods: 0
Apr  7 09:53:52.634: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:53:53.632: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:53.636: INFO: Number of nodes with available pods: 1
Apr  7 09:53:53.636: INFO: Node ip-10-0-39-198 is running more than one daemon pod
Apr  7 09:53:54.631: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:54.634: INFO: Number of nodes with available pods: 2
Apr  7 09:53:54.634: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  7 09:53:54.655: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:54.655: INFO: Wrong image for pod: daemon-set-qbxcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:54.657: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:55.660: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:55.660: INFO: Wrong image for pod: daemon-set-qbxcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:55.663: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:56.661: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:56.661: INFO: Wrong image for pod: daemon-set-qbxcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:56.663: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:57.669: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:57.670: INFO: Wrong image for pod: daemon-set-qbxcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:57.670: INFO: Pod daemon-set-qbxcn is not available
Apr  7 09:53:57.672: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:58.660: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:58.660: INFO: Pod daemon-set-w7675 is not available
Apr  7 09:53:58.663: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:53:59.662: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:53:59.665: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:00.661: INFO: Wrong image for pod: daemon-set-phklc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  7 09:54:00.661: INFO: Pod daemon-set-phklc is not available
Apr  7 09:54:00.663: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:01.661: INFO: Pod daemon-set-pr8jf is not available
Apr  7 09:54:01.664: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  7 09:54:01.666: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:01.668: INFO: Number of nodes with available pods: 1
Apr  7 09:54:01.668: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:54:02.671: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:02.673: INFO: Number of nodes with available pods: 1
Apr  7 09:54:02.673: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:54:03.674: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:03.679: INFO: Number of nodes with available pods: 1
Apr  7 09:54:03.679: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 09:54:04.671: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 09:54:04.673: INFO: Number of nodes with available pods: 2
Apr  7 09:54:04.673: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5931, will wait for the garbage collector to delete the pods
Apr  7 09:54:04.739: INFO: Deleting DaemonSet.extensions daemon-set took: 4.032662ms
Apr  7 09:54:05.040: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.174274ms
Apr  7 09:54:10.742: INFO: Number of nodes with available pods: 0
Apr  7 09:54:10.742: INFO: Number of running nodes: 0, number of available pods: 0
Apr  7 09:54:10.746: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5931/daemonsets","resourceVersion":"3187"},"items":null}

Apr  7 09:54:10.748: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5931/pods","resourceVersion":"3187"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:54:10.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5931" for this suite.
Apr  7 09:54:16.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:54:16.831: INFO: namespace daemonsets-5931 deletion completed in 6.073615886s

• [SLOW TEST:26.267 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:54:16.832: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  7 09:54:16.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-6478'
Apr  7 09:54:17.185: INFO: stderr: ""
Apr  7 09:54:17.185: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 09:54:17.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:17.282: INFO: stderr: ""
Apr  7 09:54:17.282: INFO: stdout: "update-demo-nautilus-8p22m update-demo-nautilus-m96x4 "
Apr  7 09:54:17.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-8p22m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:17.359: INFO: stderr: ""
Apr  7 09:54:17.359: INFO: stdout: ""
Apr  7 09:54:17.359: INFO: update-demo-nautilus-8p22m is created but not running
Apr  7 09:54:22.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:22.448: INFO: stderr: ""
Apr  7 09:54:22.448: INFO: stdout: "update-demo-nautilus-8p22m update-demo-nautilus-m96x4 "
Apr  7 09:54:22.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-8p22m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:22.572: INFO: stderr: ""
Apr  7 09:54:22.572: INFO: stdout: "true"
Apr  7 09:54:22.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-8p22m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:22.667: INFO: stderr: ""
Apr  7 09:54:22.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 09:54:22.667: INFO: validating pod update-demo-nautilus-8p22m
Apr  7 09:54:22.672: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 09:54:22.672: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 09:54:22.672: INFO: update-demo-nautilus-8p22m is verified up and running
Apr  7 09:54:22.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:22.750: INFO: stderr: ""
Apr  7 09:54:22.750: INFO: stdout: "true"
Apr  7 09:54:22.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:22.824: INFO: stderr: ""
Apr  7 09:54:22.824: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 09:54:22.824: INFO: validating pod update-demo-nautilus-m96x4
Apr  7 09:54:22.829: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 09:54:22.829: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 09:54:22.829: INFO: update-demo-nautilus-m96x4 is verified up and running
STEP: scaling down the replication controller
Apr  7 09:54:22.831: INFO: scanned /root for discovery docs: <nil>
Apr  7 09:54:22.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6478'
Apr  7 09:54:23.943: INFO: stderr: ""
Apr  7 09:54:23.943: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 09:54:23.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:24.023: INFO: stderr: ""
Apr  7 09:54:24.023: INFO: stdout: "update-demo-nautilus-8p22m update-demo-nautilus-m96x4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  7 09:54:29.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:29.096: INFO: stderr: ""
Apr  7 09:54:29.096: INFO: stdout: "update-demo-nautilus-8p22m update-demo-nautilus-m96x4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  7 09:54:34.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:34.171: INFO: stderr: ""
Apr  7 09:54:34.171: INFO: stdout: "update-demo-nautilus-m96x4 "
Apr  7 09:54:34.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:34.239: INFO: stderr: ""
Apr  7 09:54:34.239: INFO: stdout: "true"
Apr  7 09:54:34.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:34.306: INFO: stderr: ""
Apr  7 09:54:34.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 09:54:34.306: INFO: validating pod update-demo-nautilus-m96x4
Apr  7 09:54:34.310: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 09:54:34.310: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 09:54:34.310: INFO: update-demo-nautilus-m96x4 is verified up and running
STEP: scaling up the replication controller
Apr  7 09:54:34.311: INFO: scanned /root for discovery docs: <nil>
Apr  7 09:54:34.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6478'
Apr  7 09:54:35.425: INFO: stderr: ""
Apr  7 09:54:35.425: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 09:54:35.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6478'
Apr  7 09:54:35.496: INFO: stderr: ""
Apr  7 09:54:35.496: INFO: stdout: "update-demo-nautilus-m96x4 update-demo-nautilus-mpt8g "
Apr  7 09:54:35.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:35.584: INFO: stderr: ""
Apr  7 09:54:35.584: INFO: stdout: "true"
Apr  7 09:54:35.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-m96x4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:35.652: INFO: stderr: ""
Apr  7 09:54:35.652: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 09:54:35.652: INFO: validating pod update-demo-nautilus-m96x4
Apr  7 09:54:35.657: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 09:54:35.657: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 09:54:35.658: INFO: update-demo-nautilus-m96x4 is verified up and running
Apr  7 09:54:35.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-mpt8g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:35.731: INFO: stderr: ""
Apr  7 09:54:35.731: INFO: stdout: "true"
Apr  7 09:54:35.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-mpt8g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6478'
Apr  7 09:54:35.802: INFO: stderr: ""
Apr  7 09:54:35.802: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 09:54:35.802: INFO: validating pod update-demo-nautilus-mpt8g
Apr  7 09:54:35.808: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 09:54:35.808: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 09:54:35.808: INFO: update-demo-nautilus-mpt8g is verified up and running
STEP: using delete to clean up resources
Apr  7 09:54:35.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-6478'
Apr  7 09:54:35.889: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 09:54:35.889: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  7 09:54:35.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6478'
Apr  7 09:54:35.964: INFO: stderr: "No resources found.\n"
Apr  7 09:54:35.964: INFO: stdout: ""
Apr  7 09:54:35.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=update-demo --namespace=kubectl-6478 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 09:54:36.043: INFO: stderr: ""
Apr  7 09:54:36.043: INFO: stdout: "update-demo-nautilus-m96x4\nupdate-demo-nautilus-mpt8g\n"
Apr  7 09:54:36.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6478'
Apr  7 09:54:36.637: INFO: stderr: "No resources found.\n"
Apr  7 09:54:36.637: INFO: stdout: ""
Apr  7 09:54:36.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=update-demo --namespace=kubectl-6478 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 09:54:36.729: INFO: stderr: ""
Apr  7 09:54:36.729: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:54:36.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6478" for this suite.
Apr  7 09:54:58.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:54:58.808: INFO: namespace kubectl-6478 deletion completed in 22.076406516s

• [SLOW TEST:41.977 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:54:58.809: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  7 09:54:58.836: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:08.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6952" for this suite.
Apr  7 09:55:14.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:55:15.070: INFO: namespace pods-6952 deletion completed in 6.101970228s

• [SLOW TEST:16.261 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:55:15.071: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-3e05a189-591b-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 09:55:15.116: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2" in namespace "projected-771" to be "success or failure"
Apr  7 09:55:15.118: INFO: Pod "pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719526ms
Apr  7 09:55:17.123: INFO: Pod "pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007043859s
STEP: Saw pod success
Apr  7 09:55:17.123: INFO: Pod "pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:55:17.125: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 09:55:17.151: INFO: Waiting for pod pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:55:17.153: INFO: Pod pod-projected-secrets-3e060294-591b-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:17.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-771" for this suite.
Apr  7 09:55:23.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:55:23.231: INFO: namespace projected-771 deletion completed in 6.075812888s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:55:23.231: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 09:55:23.266: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  7 09:55:28.269: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 09:55:28.269: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  7 09:55:30.290: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2331,SelfLink:/apis/apps/v1/namespaces/deployment-2331/deployments/test-cleanup-deployment,UID:45dd43f7-591b-11e9-99b0-0225f4f52196,ResourceVersion:3558,Generation:1,CreationTimestamp:2019-04-07 09:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-07 09:55:28 +0000 UTC 2019-04-07 09:55:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-07 09:55:30 +0000 UTC 2019-04-07 09:55:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 09:55:30.295: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-2331,SelfLink:/apis/apps/v1/namespaces/deployment-2331/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:45de736f-591b-11e9-99b0-0225f4f52196,ResourceVersion:3546,Generation:1,CreationTimestamp:2019-04-07 09:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 45dd43f7-591b-11e9-99b0-0225f4f52196 0xc0025de1a7 0xc0025de1a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  7 09:55:30.300: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-2b8cp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-2b8cp,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-2331,SelfLink:/api/v1/namespaces/deployment-2331/pods/test-cleanup-deployment-55cbfbc8f5-2b8cp,UID:45df729e-591b-11e9-99b0-0225f4f52196,ResourceVersion:3545,Generation:0,CreationTimestamp:2019-04-07 09:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.16/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 45de736f-591b-11e9-99b0-0225f4f52196 0xc0025de747 0xc0025de748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xbtj6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xbtj6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xbtj6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025de7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025de7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:55:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:55:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:55:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:55:28 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.16,StartTime:2019-04-07 09:55:28 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-07 09:55:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c11be51273bfe435ddd5ffeef492c2b32d5031f63ffdf3c1f6460b1772dcd1e1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:30.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2331" for this suite.
Apr  7 09:55:36.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:55:36.380: INFO: namespace deployment-2331 deletion completed in 6.076827727s

• [SLOW TEST:13.149 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:55:36.381: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-4ab7255b-591b-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 09:55:36.407: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2" in namespace "projected-5741" to be "success or failure"
Apr  7 09:55:36.412: INFO: Pod "pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093908ms
Apr  7 09:55:38.415: INFO: Pod "pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007480106s
STEP: Saw pod success
Apr  7 09:55:38.415: INFO: Pod "pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:55:38.418: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 09:55:38.432: INFO: Waiting for pod pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:55:38.434: INFO: Pod pod-projected-configmaps-4ab77b38-591b-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:38.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5741" for this suite.
Apr  7 09:55:44.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:55:44.513: INFO: namespace projected-5741 deletion completed in 6.076569148s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:55:44.513: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 09:55:44.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2" in namespace "projected-4910" to be "success or failure"
Apr  7 09:55:44.547: INFO: Pod "downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.711251ms
Apr  7 09:55:46.550: INFO: Pod "downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006709878s
STEP: Saw pod success
Apr  7 09:55:46.550: INFO: Pod "downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:55:46.552: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 09:55:46.569: INFO: Waiting for pod downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:55:46.572: INFO: Pod downwardapi-volume-4f90ca37-591b-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:46.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4910" for this suite.
Apr  7 09:55:52.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:55:52.652: INFO: namespace projected-4910 deletion completed in 6.077395398s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:55:52.652: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-546a2da2-591b-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 09:55:52.680: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2" in namespace "projected-6222" to be "success or failure"
Apr  7 09:55:52.682: INFO: Pod "pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366528ms
Apr  7 09:55:54.686: INFO: Pod "pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005442336s
STEP: Saw pod success
Apr  7 09:55:54.686: INFO: Pod "pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 09:55:54.688: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 09:55:54.701: INFO: Waiting for pod pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 09:55:54.704: INFO: Pod pod-projected-configmaps-546a87b8-591b-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:55:54.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6222" for this suite.
Apr  7 09:56:00.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:56:00.794: INFO: namespace projected-6222 deletion completed in 6.084082815s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:56:00.795: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  7 09:56:00.814: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 09:56:00.819: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 09:56:00.820: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-29-139 before test
Apr  7 09:56:00.826: INFO: calico-node-jc2tf from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 09:56:00.826: INFO: 	Container calico-node ready: true, restart count 0
Apr  7 09:56:00.826: INFO: kube-proxy-vcfnq from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 09:56:00.826: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 09:56:00.826: INFO: sonobuoy-e2e-job-bd24bc4110464347 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:56:00.826: INFO: 	Container e2e ready: true, restart count 0
Apr  7 09:56:00.826: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 09:56:00.826: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-8b9mt from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:56:00.826: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 09:56:00.826: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 09:56:00.826: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-39-198 before test
Apr  7 09:56:00.830: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-07 09:48:57 +0000 UTC (1 container statuses recorded)
Apr  7 09:56:00.830: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 09:56:00.830: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-lf7g7 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:56:00.830: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 09:56:00.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 09:56:00.830: INFO: kube-proxy-9zkg8 from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 09:56:00.830: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 09:56:00.830: INFO: calico-node-tcp8p from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 09:56:00.830: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1593289f413dd51f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:56:01.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6198" for this suite.
Apr  7 09:56:07.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:56:07.925: INFO: namespace sched-pred-6198 deletion completed in 6.074900068s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.131 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:56:07.926: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  7 09:56:07.968: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2098,SelfLink:/api/v1/namespaces/watch-2098/configmaps/e2e-watch-test-resource-version,UID:5d83bee1-591b-11e9-99b0-0225f4f52196,ResourceVersion:3759,Generation:0,CreationTimestamp:2019-04-07 09:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  7 09:56:07.968: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2098,SelfLink:/api/v1/namespaces/watch-2098/configmaps/e2e-watch-test-resource-version,UID:5d83bee1-591b-11e9-99b0-0225f4f52196,ResourceVersion:3760,Generation:0,CreationTimestamp:2019-04-07 09:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:56:07.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2098" for this suite.
Apr  7 09:56:13.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:56:14.043: INFO: namespace watch-2098 deletion completed in 6.073203491s

• [SLOW TEST:6.117 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:56:14.044: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  7 09:56:14.310: INFO: Pod name wrapped-volume-race-613af277-591b-11e9-9aa1-1aed65326ff2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-613af277-591b-11e9-9aa1-1aed65326ff2 in namespace emptydir-wrapper-1170, will wait for the garbage collector to delete the pods
Apr  7 09:56:30.426: INFO: Deleting ReplicationController wrapped-volume-race-613af277-591b-11e9-9aa1-1aed65326ff2 took: 5.24794ms
Apr  7 09:56:30.826: INFO: Terminating ReplicationController wrapped-volume-race-613af277-591b-11e9-9aa1-1aed65326ff2 pods took: 400.189059ms
STEP: Creating RC which spawns configmap-volume pods
Apr  7 09:57:11.739: INFO: Pod name wrapped-volume-race-838894e2-591b-11e9-9aa1-1aed65326ff2: Found 0 pods out of 5
Apr  7 09:57:16.743: INFO: Pod name wrapped-volume-race-838894e2-591b-11e9-9aa1-1aed65326ff2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-838894e2-591b-11e9-9aa1-1aed65326ff2 in namespace emptydir-wrapper-1170, will wait for the garbage collector to delete the pods
Apr  7 09:57:28.850: INFO: Deleting ReplicationController wrapped-volume-race-838894e2-591b-11e9-9aa1-1aed65326ff2 took: 4.802856ms
Apr  7 09:57:29.250: INFO: Terminating ReplicationController wrapped-volume-race-838894e2-591b-11e9-9aa1-1aed65326ff2 pods took: 400.171782ms
STEP: Creating RC which spawns configmap-volume pods
Apr  7 09:58:10.765: INFO: Pod name wrapped-volume-race-a6b6e996-591b-11e9-9aa1-1aed65326ff2: Found 0 pods out of 5
Apr  7 09:58:15.769: INFO: Pod name wrapped-volume-race-a6b6e996-591b-11e9-9aa1-1aed65326ff2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a6b6e996-591b-11e9-9aa1-1aed65326ff2 in namespace emptydir-wrapper-1170, will wait for the garbage collector to delete the pods
Apr  7 09:58:25.847: INFO: Deleting ReplicationController wrapped-volume-race-a6b6e996-591b-11e9-9aa1-1aed65326ff2 took: 5.961485ms
Apr  7 09:58:26.152: INFO: Terminating ReplicationController wrapped-volume-race-a6b6e996-591b-11e9-9aa1-1aed65326ff2 pods took: 304.877935ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:59:10.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1170" for this suite.
Apr  7 09:59:16.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:59:17.002: INFO: namespace emptydir-wrapper-1170 deletion completed in 6.086356113s

• [SLOW TEST:182.959 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:59:17.003: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  7 09:59:20.058: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:59:20.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8810" for this suite.
Apr  7 09:59:42.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:59:42.250: INFO: namespace replicaset-8810 deletion completed in 22.1102162s

• [SLOW TEST:25.248 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:59:42.250: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 09:59:42.286: INFO: Creating deployment "test-recreate-deployment"
Apr  7 09:59:42.290: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  7 09:59:42.301: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  7 09:59:44.308: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  7 09:59:44.313: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  7 09:59:44.318: INFO: Updating deployment test-recreate-deployment
Apr  7 09:59:44.318: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  7 09:59:44.364: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/deployments/test-recreate-deployment,UID:dd4412ea-591b-11e9-99b0-0225f4f52196,ResourceVersion:5123,Generation:2,CreationTimestamp:2019-04-07 09:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-07 09:59:44 +0000 UTC 2019-04-07 09:59:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-07 09:59:44 +0000 UTC 2019-04-07 09:59:42 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr  7 09:59:44.367: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/replicasets/test-recreate-deployment-c9cbd8684,UID:de7d160a-591b-11e9-99b0-0225f4f52196,ResourceVersion:5121,Generation:1,CreationTimestamp:2019-04-07 09:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd4412ea-591b-11e9-99b0-0225f4f52196 0xc0025d4390 0xc0025d4391}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 09:59:44.367: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  7 09:59:44.368: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-8918,SelfLink:/apis/apps/v1/namespaces/deployment-8918/replicasets/test-recreate-deployment-7d57d5ff7c,UID:dd4498bc-591b-11e9-99b0-0225f4f52196,ResourceVersion:5113,Generation:2,CreationTimestamp:2019-04-07 09:59:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd4412ea-591b-11e9-99b0-0225f4f52196 0xc0025d42d7 0xc0025d42d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 09:59:44.370: INFO: Pod "test-recreate-deployment-c9cbd8684-6f4jb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-6f4jb,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-8918,SelfLink:/api/v1/namespaces/deployment-8918/pods/test-recreate-deployment-c9cbd8684-6f4jb,UID:de7d7d27-591b-11e9-99b0-0225f4f52196,ResourceVersion:5124,Generation:0,CreationTimestamp:2019-04-07 09:59:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 de7d160a-591b-11e9-99b0-0225f4f52196 0xc002ad2020 0xc002ad2021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-759bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-759bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-759bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ad2090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ad20b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:59:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:59:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:59:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 09:59:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:,StartTime:2019-04-07 09:59:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:59:44.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8918" for this suite.
Apr  7 09:59:50.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:59:50.452: INFO: namespace deployment-8918 deletion completed in 6.079804711s

• [SLOW TEST:8.201 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:59:50.453: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  7 09:59:50.479: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 09:59:50.483: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 09:59:50.485: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-29-139 before test
Apr  7 09:59:50.490: INFO: kube-proxy-vcfnq from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 09:59:50.490: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 09:59:50.490: INFO: sonobuoy-e2e-job-bd24bc4110464347 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:59:50.490: INFO: 	Container e2e ready: true, restart count 0
Apr  7 09:59:50.491: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 09:59:50.491: INFO: calico-node-jc2tf from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 09:59:50.491: INFO: 	Container calico-node ready: true, restart count 0
Apr  7 09:59:50.491: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-8b9mt from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:59:50.491: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 09:59:50.491: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 09:59:50.491: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-39-198 before test
Apr  7 09:59:50.497: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-07 09:48:57 +0000 UTC (1 container statuses recorded)
Apr  7 09:59:50.497: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 09:59:50.497: INFO: kube-proxy-9zkg8 from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 09:59:50.497: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 09:59:50.497: INFO: calico-node-tcp8p from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 09:59:50.497: INFO: 	Container calico-node ready: true, restart count 0
Apr  7 09:59:50.497: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-lf7g7 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 09:59:50.497: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 09:59:50.497: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-0-29-139
STEP: verifying the node has the label node ip-10-0-39-198
Apr  7 09:59:50.543: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-39-198
Apr  7 09:59:50.543: INFO: Pod sonobuoy-e2e-job-bd24bc4110464347 requesting resource cpu=0m on Node ip-10-0-29-139
Apr  7 09:59:50.543: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-8b9mt requesting resource cpu=0m on Node ip-10-0-29-139
Apr  7 09:59:50.543: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-lf7g7 requesting resource cpu=0m on Node ip-10-0-39-198
Apr  7 09:59:50.543: INFO: Pod calico-node-jc2tf requesting resource cpu=150m on Node ip-10-0-29-139
Apr  7 09:59:50.543: INFO: Pod calico-node-tcp8p requesting resource cpu=150m on Node ip-10-0-39-198
Apr  7 09:59:50.543: INFO: Pod kube-proxy-9zkg8 requesting resource cpu=0m on Node ip-10-0-39-198
Apr  7 09:59:50.543: INFO: Pod kube-proxy-vcfnq requesting resource cpu=0m on Node ip-10-0-29-139
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2.159328d4bcd92445], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4109/filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2 to ip-10-0-29-139]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2.159328d4e65b8f51], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2.159328d4ea2acac8], Reason = [Created], Message = [Created container filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2.159328d4f06fa7fe], Reason = [Started], Message = [Started container filler-pod-e232128b-591b-11e9-9aa1-1aed65326ff2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2.159328d4bdd4385b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4109/filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2 to ip-10-0-39-198]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2.159328d4e9fe1914], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2.159328d4edc03045], Reason = [Created], Message = [Created container filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2.159328d4f34c6497], Reason = [Started], Message = [Started container filler-pod-e232baf5-591b-11e9-9aa1-1aed65326ff2]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159328d5360615f7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-39-198
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-29-139
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 09:59:53.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4109" for this suite.
Apr  7 09:59:59.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 09:59:59.706: INFO: namespace sched-pred-4109 deletion completed in 6.077841174s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.253 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 09:59:59.706: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2884
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 09:59:59.726: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  7 10:00:25.782: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.122.32:8080/dial?request=hostName&protocol=http&host=10.2.210.36&port=8080&tries=1'] Namespace:pod-network-test-2884 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:00:25.782: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:00:25.874: INFO: Waiting for endpoints: map[]
Apr  7 10:00:25.877: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.122.32:8080/dial?request=hostName&protocol=http&host=10.2.122.31&port=8080&tries=1'] Namespace:pod-network-test-2884 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:00:25.878: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:00:25.966: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:00:25.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2884" for this suite.
Apr  7 10:00:47.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:00:48.043: INFO: namespace pod-network-test-2884 deletion completed in 22.073622274s

• [SLOW TEST:48.337 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:00:48.043: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6466
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6466
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6466
Apr  7 10:00:48.083: INFO: Found 0 stateful pods, waiting for 1
Apr  7 10:00:58.086: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  7 10:00:58.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:00:58.257: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:00:58.257: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:00:58.257: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:00:58.260: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  7 10:01:08.263: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:01:08.263: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:01:08.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999644s
Apr  7 10:01:09.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996300555s
Apr  7 10:01:10.282: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99333193s
Apr  7 10:01:11.285: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990478567s
Apr  7 10:01:12.287: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987573493s
Apr  7 10:01:13.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984792207s
Apr  7 10:01:14.293: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982149635s
Apr  7 10:01:15.296: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979111767s
Apr  7 10:01:16.299: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976091178s
Apr  7 10:01:17.302: INFO: Verifying statefulset ss doesn't scale past 1 for another 973.155749ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6466
Apr  7 10:01:18.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:01:18.465: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 10:01:18.466: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:01:18.466: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:01:18.468: INFO: Found 1 stateful pods, waiting for 3
Apr  7 10:01:28.471: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 10:01:28.471: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 10:01:28.471: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  7 10:01:28.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:01:28.642: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:01:28.642: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:01:28.642: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:01:28.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:01:28.826: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:01:28.827: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:01:28.827: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:01:28.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:01:28.997: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:01:28.997: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:01:28.997: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:01:28.997: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:01:29.000: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr  7 10:01:39.005: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:01:39.005: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:01:39.005: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:01:39.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999713s
Apr  7 10:01:40.016: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997525828s
Apr  7 10:01:41.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994372611s
Apr  7 10:01:42.022: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991531822s
Apr  7 10:01:43.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988781473s
Apr  7 10:01:44.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985698058s
Apr  7 10:01:45.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982404922s
Apr  7 10:01:46.035: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979314598s
Apr  7 10:01:47.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.97610088s
Apr  7 10:01:48.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.25098ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6466
Apr  7 10:01:49.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:01:49.234: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 10:01:49.234: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:01:49.234: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:01:49.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:01:49.413: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 10:01:49.413: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:01:49.413: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:01:49.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-6466 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:01:49.575: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 10:01:49.575: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:01:49.575: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:01:49.575: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  7 10:01:59.600: INFO: Deleting all statefulset in ns statefulset-6466
Apr  7 10:01:59.603: INFO: Scaling statefulset ss to 0
Apr  7 10:01:59.609: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:01:59.611: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:01:59.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6466" for this suite.
Apr  7 10:02:05.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:02:05.701: INFO: namespace statefulset-6466 deletion completed in 6.079704943s

• [SLOW TEST:77.658 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:02:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6705
I0407 10:02:05.733755      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6705, replica count: 1
I0407 10:02:06.784132      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0407 10:02:07.784310      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 10:02:07.890: INFO: Created: latency-svc-g44fp
Apr  7 10:02:07.894: INFO: Got endpoints: latency-svc-g44fp [10.244326ms]
Apr  7 10:02:07.907: INFO: Created: latency-svc-57cbc
Apr  7 10:02:07.907: INFO: Got endpoints: latency-svc-57cbc [12.663911ms]
Apr  7 10:02:07.913: INFO: Created: latency-svc-z2zxs
Apr  7 10:02:07.915: INFO: Created: latency-svc-b4wtq
Apr  7 10:02:07.922: INFO: Got endpoints: latency-svc-z2zxs [26.824412ms]
Apr  7 10:02:07.923: INFO: Got endpoints: latency-svc-b4wtq [25.39967ms]
Apr  7 10:02:07.927: INFO: Created: latency-svc-b78tf
Apr  7 10:02:07.928: INFO: Created: latency-svc-94czl
Apr  7 10:02:07.936: INFO: Created: latency-svc-plt8q
Apr  7 10:02:07.936: INFO: Got endpoints: latency-svc-b78tf [39.82206ms]
Apr  7 10:02:07.936: INFO: Got endpoints: latency-svc-94czl [40.526623ms]
Apr  7 10:02:07.946: INFO: Created: latency-svc-5c6w4
Apr  7 10:02:07.947: INFO: Created: latency-svc-xltv7
Apr  7 10:02:07.947: INFO: Got endpoints: latency-svc-plt8q [49.949247ms]
Apr  7 10:02:07.951: INFO: Got endpoints: latency-svc-5c6w4 [53.569919ms]
Apr  7 10:02:07.951: INFO: Got endpoints: latency-svc-xltv7 [53.627895ms]
Apr  7 10:02:07.951: INFO: Created: latency-svc-zv8w2
Apr  7 10:02:07.960: INFO: Got endpoints: latency-svc-zv8w2 [23.650761ms]
Apr  7 10:02:07.960: INFO: Created: latency-svc-5xqgr
Apr  7 10:02:07.960: INFO: Created: latency-svc-r882r
Apr  7 10:02:07.969: INFO: Created: latency-svc-65878
Apr  7 10:02:07.971: INFO: Got endpoints: latency-svc-5xqgr [73.16377ms]
Apr  7 10:02:07.971: INFO: Got endpoints: latency-svc-r882r [73.696907ms]
Apr  7 10:02:07.972: INFO: Created: latency-svc-zpf8n
Apr  7 10:02:07.979: INFO: Created: latency-svc-kdwb5
Apr  7 10:02:07.980: INFO: Got endpoints: latency-svc-65878 [82.655648ms]
Apr  7 10:02:07.980: INFO: Got endpoints: latency-svc-zpf8n [82.637643ms]
Apr  7 10:02:07.983: INFO: Got endpoints: latency-svc-kdwb5 [84.995029ms]
Apr  7 10:02:07.991: INFO: Created: latency-svc-vt865
Apr  7 10:02:07.992: INFO: Created: latency-svc-t9459
Apr  7 10:02:08.000: INFO: Created: latency-svc-l8wjq
Apr  7 10:02:08.000: INFO: Got endpoints: latency-svc-t9459 [102.132736ms]
Apr  7 10:02:08.000: INFO: Got endpoints: latency-svc-vt865 [102.409661ms]
Apr  7 10:02:08.007: INFO: Got endpoints: latency-svc-l8wjq [99.662568ms]
Apr  7 10:02:08.008: INFO: Created: latency-svc-jvnhd
Apr  7 10:02:08.015: INFO: Got endpoints: latency-svc-jvnhd [93.125889ms]
Apr  7 10:02:08.018: INFO: Created: latency-svc-5klw4
Apr  7 10:02:08.022: INFO: Got endpoints: latency-svc-5klw4 [99.468701ms]
Apr  7 10:02:08.024: INFO: Created: latency-svc-nwmqf
Apr  7 10:02:08.029: INFO: Got endpoints: latency-svc-nwmqf [92.599591ms]
Apr  7 10:02:08.033: INFO: Created: latency-svc-xhbkv
Apr  7 10:02:08.038: INFO: Created: latency-svc-gtbrw
Apr  7 10:02:08.038: INFO: Got endpoints: latency-svc-xhbkv [91.642816ms]
Apr  7 10:02:08.041: INFO: Got endpoints: latency-svc-gtbrw [90.292034ms]
Apr  7 10:02:08.048: INFO: Created: latency-svc-jnjs7
Apr  7 10:02:08.052: INFO: Got endpoints: latency-svc-jnjs7 [101.345957ms]
Apr  7 10:02:08.053: INFO: Created: latency-svc-n968h
Apr  7 10:02:08.058: INFO: Created: latency-svc-ctpnr
Apr  7 10:02:08.068: INFO: Got endpoints: latency-svc-ctpnr [96.772107ms]
Apr  7 10:02:08.068: INFO: Got endpoints: latency-svc-n968h [107.803614ms]
Apr  7 10:02:08.068: INFO: Created: latency-svc-gbmdq
Apr  7 10:02:08.104: INFO: Got endpoints: latency-svc-gbmdq [133.177617ms]
Apr  7 10:02:08.129: INFO: Created: latency-svc-kmtpp
Apr  7 10:02:08.129: INFO: Got endpoints: latency-svc-kmtpp [148.265636ms]
Apr  7 10:02:08.137: INFO: Created: latency-svc-wv6bw
Apr  7 10:02:08.138: INFO: Got endpoints: latency-svc-wv6bw [157.282618ms]
Apr  7 10:02:08.146: INFO: Created: latency-svc-8dmh6
Apr  7 10:02:08.149: INFO: Got endpoints: latency-svc-8dmh6 [166.72251ms]
Apr  7 10:02:08.160: INFO: Created: latency-svc-x7tf7
Apr  7 10:02:08.160: INFO: Got endpoints: latency-svc-x7tf7 [159.951493ms]
Apr  7 10:02:08.168: INFO: Created: latency-svc-6nh8k
Apr  7 10:02:08.171: INFO: Created: latency-svc-s6jl9
Apr  7 10:02:08.176: INFO: Created: latency-svc-69w86
Apr  7 10:02:08.180: INFO: Got endpoints: latency-svc-s6jl9 [180.238359ms]
Apr  7 10:02:08.181: INFO: Got endpoints: latency-svc-6nh8k [173.413799ms]
Apr  7 10:02:08.188: INFO: Created: latency-svc-26nzn
Apr  7 10:02:08.188: INFO: Got endpoints: latency-svc-26nzn [166.198181ms]
Apr  7 10:02:08.189: INFO: Got endpoints: latency-svc-69w86 [173.071341ms]
Apr  7 10:02:08.192: INFO: Created: latency-svc-2llsw
Apr  7 10:02:08.199: INFO: Got endpoints: latency-svc-2llsw [170.61772ms]
Apr  7 10:02:08.202: INFO: Created: latency-svc-xkdvk
Apr  7 10:02:08.206: INFO: Created: latency-svc-b5wzp
Apr  7 10:02:08.211: INFO: Created: latency-svc-2lkcs
Apr  7 10:02:08.214: INFO: Created: latency-svc-bxwml
Apr  7 10:02:08.216: INFO: Created: latency-svc-f8nr6
Apr  7 10:02:08.221: INFO: Created: latency-svc-zfpzt
Apr  7 10:02:08.227: INFO: Created: latency-svc-krgfr
Apr  7 10:02:08.229: INFO: Created: latency-svc-ttrpr
Apr  7 10:02:08.237: INFO: Created: latency-svc-hfrjz
Apr  7 10:02:08.240: INFO: Created: latency-svc-pxpw4
Apr  7 10:02:08.244: INFO: Got endpoints: latency-svc-xkdvk [202.993155ms]
Apr  7 10:02:08.252: INFO: Created: latency-svc-wmbkk
Apr  7 10:02:08.254: INFO: Created: latency-svc-rf6pm
Apr  7 10:02:08.254: INFO: Created: latency-svc-7757m
Apr  7 10:02:08.257: INFO: Created: latency-svc-6wn6j
Apr  7 10:02:08.260: INFO: Created: latency-svc-jt54m
Apr  7 10:02:08.269: INFO: Created: latency-svc-n26dw
Apr  7 10:02:08.294: INFO: Got endpoints: latency-svc-b5wzp [255.951224ms]
Apr  7 10:02:08.303: INFO: Created: latency-svc-ktg7v
Apr  7 10:02:08.345: INFO: Got endpoints: latency-svc-2lkcs [292.175786ms]
Apr  7 10:02:08.353: INFO: Created: latency-svc-d22p6
Apr  7 10:02:08.395: INFO: Got endpoints: latency-svc-bxwml [326.779437ms]
Apr  7 10:02:08.408: INFO: Created: latency-svc-6bz27
Apr  7 10:02:08.443: INFO: Got endpoints: latency-svc-f8nr6 [375.292962ms]
Apr  7 10:02:08.450: INFO: Created: latency-svc-fwxbn
Apr  7 10:02:08.493: INFO: Got endpoints: latency-svc-zfpzt [388.531182ms]
Apr  7 10:02:08.503: INFO: Created: latency-svc-27tcs
Apr  7 10:02:08.543: INFO: Got endpoints: latency-svc-krgfr [414.81107ms]
Apr  7 10:02:08.551: INFO: Created: latency-svc-7z5nq
Apr  7 10:02:08.594: INFO: Got endpoints: latency-svc-ttrpr [456.450726ms]
Apr  7 10:02:08.602: INFO: Created: latency-svc-xvhrl
Apr  7 10:02:08.644: INFO: Got endpoints: latency-svc-hfrjz [494.878901ms]
Apr  7 10:02:08.657: INFO: Created: latency-svc-8bhx2
Apr  7 10:02:08.693: INFO: Got endpoints: latency-svc-pxpw4 [533.321526ms]
Apr  7 10:02:08.701: INFO: Created: latency-svc-pl75v
Apr  7 10:02:08.745: INFO: Got endpoints: latency-svc-wmbkk [564.453686ms]
Apr  7 10:02:08.753: INFO: Created: latency-svc-f52wl
Apr  7 10:02:08.795: INFO: Got endpoints: latency-svc-7757m [614.153857ms]
Apr  7 10:02:08.802: INFO: Created: latency-svc-4jrr7
Apr  7 10:02:08.848: INFO: Got endpoints: latency-svc-rf6pm [659.655388ms]
Apr  7 10:02:08.859: INFO: Created: latency-svc-p28qn
Apr  7 10:02:08.894: INFO: Got endpoints: latency-svc-6wn6j [705.277142ms]
Apr  7 10:02:08.903: INFO: Created: latency-svc-rtfcj
Apr  7 10:02:08.945: INFO: Got endpoints: latency-svc-jt54m [745.882607ms]
Apr  7 10:02:08.952: INFO: Created: latency-svc-2mrdq
Apr  7 10:02:09.001: INFO: Got endpoints: latency-svc-n26dw [756.379718ms]
Apr  7 10:02:09.020: INFO: Created: latency-svc-mnhgv
Apr  7 10:02:09.044: INFO: Got endpoints: latency-svc-ktg7v [749.731436ms]
Apr  7 10:02:09.053: INFO: Created: latency-svc-djgfj
Apr  7 10:02:09.101: INFO: Got endpoints: latency-svc-d22p6 [755.933048ms]
Apr  7 10:02:09.110: INFO: Created: latency-svc-ssc6n
Apr  7 10:02:09.144: INFO: Got endpoints: latency-svc-6bz27 [749.874209ms]
Apr  7 10:02:09.153: INFO: Created: latency-svc-68lwd
Apr  7 10:02:09.196: INFO: Got endpoints: latency-svc-fwxbn [752.721186ms]
Apr  7 10:02:09.203: INFO: Created: latency-svc-m58fl
Apr  7 10:02:09.245: INFO: Got endpoints: latency-svc-27tcs [748.533439ms]
Apr  7 10:02:09.251: INFO: Created: latency-svc-mk2rs
Apr  7 10:02:09.296: INFO: Got endpoints: latency-svc-7z5nq [752.05713ms]
Apr  7 10:02:09.305: INFO: Created: latency-svc-l6l4z
Apr  7 10:02:09.344: INFO: Got endpoints: latency-svc-xvhrl [750.132159ms]
Apr  7 10:02:09.350: INFO: Created: latency-svc-rlvr6
Apr  7 10:02:09.395: INFO: Got endpoints: latency-svc-8bhx2 [744.293781ms]
Apr  7 10:02:09.405: INFO: Created: latency-svc-7d5wn
Apr  7 10:02:09.446: INFO: Got endpoints: latency-svc-pl75v [753.118469ms]
Apr  7 10:02:09.452: INFO: Created: latency-svc-q76j7
Apr  7 10:02:09.495: INFO: Got endpoints: latency-svc-f52wl [749.759084ms]
Apr  7 10:02:09.501: INFO: Created: latency-svc-phvwk
Apr  7 10:02:09.545: INFO: Got endpoints: latency-svc-4jrr7 [749.698162ms]
Apr  7 10:02:09.551: INFO: Created: latency-svc-sjgfx
Apr  7 10:02:09.596: INFO: Got endpoints: latency-svc-p28qn [747.549437ms]
Apr  7 10:02:09.602: INFO: Created: latency-svc-w5wcr
Apr  7 10:02:09.645: INFO: Got endpoints: latency-svc-rtfcj [750.811457ms]
Apr  7 10:02:09.650: INFO: Created: latency-svc-qzz4n
Apr  7 10:02:09.694: INFO: Got endpoints: latency-svc-2mrdq [748.408785ms]
Apr  7 10:02:09.704: INFO: Created: latency-svc-7vlp9
Apr  7 10:02:09.745: INFO: Got endpoints: latency-svc-mnhgv [744.687778ms]
Apr  7 10:02:09.753: INFO: Created: latency-svc-nwgtz
Apr  7 10:02:09.796: INFO: Got endpoints: latency-svc-djgfj [751.793574ms]
Apr  7 10:02:09.805: INFO: Created: latency-svc-5mrz6
Apr  7 10:02:09.844: INFO: Got endpoints: latency-svc-ssc6n [743.121424ms]
Apr  7 10:02:09.852: INFO: Created: latency-svc-jhqhq
Apr  7 10:02:09.897: INFO: Got endpoints: latency-svc-68lwd [751.918775ms]
Apr  7 10:02:09.915: INFO: Created: latency-svc-qbz5f
Apr  7 10:02:09.945: INFO: Got endpoints: latency-svc-m58fl [748.381498ms]
Apr  7 10:02:09.952: INFO: Created: latency-svc-np2pb
Apr  7 10:02:09.994: INFO: Got endpoints: latency-svc-mk2rs [749.330467ms]
Apr  7 10:02:10.002: INFO: Created: latency-svc-bw78r
Apr  7 10:02:10.044: INFO: Got endpoints: latency-svc-l6l4z [748.277242ms]
Apr  7 10:02:10.055: INFO: Created: latency-svc-ds4cn
Apr  7 10:02:10.095: INFO: Got endpoints: latency-svc-rlvr6 [750.585405ms]
Apr  7 10:02:10.107: INFO: Created: latency-svc-hkwxb
Apr  7 10:02:10.154: INFO: Got endpoints: latency-svc-7d5wn [755.556013ms]
Apr  7 10:02:10.164: INFO: Created: latency-svc-b84qz
Apr  7 10:02:10.196: INFO: Got endpoints: latency-svc-q76j7 [749.344023ms]
Apr  7 10:02:10.204: INFO: Created: latency-svc-9cnt9
Apr  7 10:02:10.244: INFO: Got endpoints: latency-svc-phvwk [748.884934ms]
Apr  7 10:02:10.254: INFO: Created: latency-svc-hl57m
Apr  7 10:02:10.296: INFO: Got endpoints: latency-svc-sjgfx [751.232588ms]
Apr  7 10:02:10.305: INFO: Created: latency-svc-x92sp
Apr  7 10:02:10.345: INFO: Got endpoints: latency-svc-w5wcr [749.581216ms]
Apr  7 10:02:10.352: INFO: Created: latency-svc-j8x55
Apr  7 10:02:10.399: INFO: Got endpoints: latency-svc-qzz4n [753.953963ms]
Apr  7 10:02:10.406: INFO: Created: latency-svc-9rfsl
Apr  7 10:02:10.445: INFO: Got endpoints: latency-svc-7vlp9 [748.185596ms]
Apr  7 10:02:10.453: INFO: Created: latency-svc-ql5ml
Apr  7 10:02:10.494: INFO: Got endpoints: latency-svc-nwgtz [748.604335ms]
Apr  7 10:02:10.503: INFO: Created: latency-svc-tlqrh
Apr  7 10:02:10.548: INFO: Got endpoints: latency-svc-5mrz6 [751.648257ms]
Apr  7 10:02:10.557: INFO: Created: latency-svc-582gq
Apr  7 10:02:10.594: INFO: Got endpoints: latency-svc-jhqhq [747.991649ms]
Apr  7 10:02:10.613: INFO: Created: latency-svc-cpdmw
Apr  7 10:02:10.649: INFO: Got endpoints: latency-svc-qbz5f [744.273789ms]
Apr  7 10:02:10.672: INFO: Created: latency-svc-b5874
Apr  7 10:02:10.695: INFO: Got endpoints: latency-svc-np2pb [750.899771ms]
Apr  7 10:02:10.724: INFO: Created: latency-svc-8btr2
Apr  7 10:02:10.744: INFO: Got endpoints: latency-svc-bw78r [750.127706ms]
Apr  7 10:02:10.768: INFO: Created: latency-svc-5t9db
Apr  7 10:02:10.806: INFO: Got endpoints: latency-svc-ds4cn [762.229534ms]
Apr  7 10:02:10.812: INFO: Created: latency-svc-zf46m
Apr  7 10:02:10.845: INFO: Got endpoints: latency-svc-hkwxb [750.354191ms]
Apr  7 10:02:10.856: INFO: Created: latency-svc-vt9nn
Apr  7 10:02:10.899: INFO: Got endpoints: latency-svc-b84qz [741.698915ms]
Apr  7 10:02:10.906: INFO: Created: latency-svc-bls87
Apr  7 10:02:10.945: INFO: Got endpoints: latency-svc-9cnt9 [748.549299ms]
Apr  7 10:02:10.951: INFO: Created: latency-svc-6rkfs
Apr  7 10:02:11.001: INFO: Got endpoints: latency-svc-hl57m [755.880558ms]
Apr  7 10:02:11.010: INFO: Created: latency-svc-bllvx
Apr  7 10:02:11.044: INFO: Got endpoints: latency-svc-x92sp [747.210733ms]
Apr  7 10:02:11.055: INFO: Created: latency-svc-q49lx
Apr  7 10:02:11.095: INFO: Got endpoints: latency-svc-j8x55 [750.038545ms]
Apr  7 10:02:11.103: INFO: Created: latency-svc-2ldsd
Apr  7 10:02:11.148: INFO: Got endpoints: latency-svc-9rfsl [749.650532ms]
Apr  7 10:02:11.163: INFO: Created: latency-svc-2rwrf
Apr  7 10:02:11.194: INFO: Got endpoints: latency-svc-ql5ml [749.140266ms]
Apr  7 10:02:11.202: INFO: Created: latency-svc-xxw54
Apr  7 10:02:11.245: INFO: Got endpoints: latency-svc-tlqrh [750.818493ms]
Apr  7 10:02:11.256: INFO: Created: latency-svc-q4bxh
Apr  7 10:02:11.295: INFO: Got endpoints: latency-svc-582gq [746.699033ms]
Apr  7 10:02:11.301: INFO: Created: latency-svc-82qfh
Apr  7 10:02:11.344: INFO: Got endpoints: latency-svc-cpdmw [747.236068ms]
Apr  7 10:02:11.351: INFO: Created: latency-svc-pdd5z
Apr  7 10:02:11.395: INFO: Got endpoints: latency-svc-b5874 [746.413972ms]
Apr  7 10:02:11.402: INFO: Created: latency-svc-n7d86
Apr  7 10:02:11.444: INFO: Got endpoints: latency-svc-8btr2 [748.221739ms]
Apr  7 10:02:11.451: INFO: Created: latency-svc-9tpvs
Apr  7 10:02:11.497: INFO: Got endpoints: latency-svc-5t9db [752.494445ms]
Apr  7 10:02:11.504: INFO: Created: latency-svc-vp6bf
Apr  7 10:02:11.546: INFO: Got endpoints: latency-svc-zf46m [739.299006ms]
Apr  7 10:02:11.553: INFO: Created: latency-svc-wm2m8
Apr  7 10:02:11.593: INFO: Got endpoints: latency-svc-vt9nn [743.107514ms]
Apr  7 10:02:11.602: INFO: Created: latency-svc-wccfh
Apr  7 10:02:11.644: INFO: Got endpoints: latency-svc-bls87 [744.779784ms]
Apr  7 10:02:11.650: INFO: Created: latency-svc-zbpwj
Apr  7 10:02:11.696: INFO: Got endpoints: latency-svc-6rkfs [751.391642ms]
Apr  7 10:02:11.711: INFO: Created: latency-svc-qt94q
Apr  7 10:02:11.745: INFO: Got endpoints: latency-svc-bllvx [744.2784ms]
Apr  7 10:02:11.753: INFO: Created: latency-svc-gpx77
Apr  7 10:02:11.795: INFO: Got endpoints: latency-svc-q49lx [747.206683ms]
Apr  7 10:02:11.809: INFO: Created: latency-svc-fftns
Apr  7 10:02:11.845: INFO: Got endpoints: latency-svc-2ldsd [749.142791ms]
Apr  7 10:02:11.854: INFO: Created: latency-svc-s6bwz
Apr  7 10:02:11.894: INFO: Got endpoints: latency-svc-2rwrf [745.678075ms]
Apr  7 10:02:11.905: INFO: Created: latency-svc-55cbq
Apr  7 10:02:11.945: INFO: Got endpoints: latency-svc-xxw54 [750.221071ms]
Apr  7 10:02:11.953: INFO: Created: latency-svc-4lpks
Apr  7 10:02:11.996: INFO: Got endpoints: latency-svc-q4bxh [748.180386ms]
Apr  7 10:02:12.004: INFO: Created: latency-svc-rzxfx
Apr  7 10:02:12.045: INFO: Got endpoints: latency-svc-82qfh [749.684204ms]
Apr  7 10:02:12.052: INFO: Created: latency-svc-925k5
Apr  7 10:02:12.095: INFO: Got endpoints: latency-svc-pdd5z [751.264532ms]
Apr  7 10:02:12.103: INFO: Created: latency-svc-c8pkq
Apr  7 10:02:12.145: INFO: Got endpoints: latency-svc-n7d86 [749.599236ms]
Apr  7 10:02:12.153: INFO: Created: latency-svc-tpdgd
Apr  7 10:02:12.194: INFO: Got endpoints: latency-svc-9tpvs [750.622154ms]
Apr  7 10:02:12.205: INFO: Created: latency-svc-dkqfz
Apr  7 10:02:12.244: INFO: Got endpoints: latency-svc-vp6bf [746.189923ms]
Apr  7 10:02:12.254: INFO: Created: latency-svc-2z5r2
Apr  7 10:02:12.297: INFO: Got endpoints: latency-svc-wm2m8 [750.91023ms]
Apr  7 10:02:12.306: INFO: Created: latency-svc-qq6x7
Apr  7 10:02:12.345: INFO: Got endpoints: latency-svc-wccfh [751.701414ms]
Apr  7 10:02:12.353: INFO: Created: latency-svc-55x7n
Apr  7 10:02:12.394: INFO: Got endpoints: latency-svc-zbpwj [749.856485ms]
Apr  7 10:02:12.403: INFO: Created: latency-svc-8vgbh
Apr  7 10:02:12.445: INFO: Got endpoints: latency-svc-qt94q [741.781471ms]
Apr  7 10:02:12.453: INFO: Created: latency-svc-9gm9k
Apr  7 10:02:12.500: INFO: Got endpoints: latency-svc-gpx77 [755.354114ms]
Apr  7 10:02:12.519: INFO: Created: latency-svc-cv9t2
Apr  7 10:02:12.547: INFO: Got endpoints: latency-svc-fftns [749.190667ms]
Apr  7 10:02:12.555: INFO: Created: latency-svc-st54x
Apr  7 10:02:12.594: INFO: Got endpoints: latency-svc-s6bwz [746.103807ms]
Apr  7 10:02:12.603: INFO: Created: latency-svc-4dbb6
Apr  7 10:02:12.651: INFO: Got endpoints: latency-svc-55cbq [753.055786ms]
Apr  7 10:02:12.659: INFO: Created: latency-svc-ss9d7
Apr  7 10:02:12.694: INFO: Got endpoints: latency-svc-4lpks [749.740512ms]
Apr  7 10:02:12.703: INFO: Created: latency-svc-rc8wk
Apr  7 10:02:12.745: INFO: Got endpoints: latency-svc-rzxfx [748.569374ms]
Apr  7 10:02:12.752: INFO: Created: latency-svc-pctdv
Apr  7 10:02:12.794: INFO: Got endpoints: latency-svc-925k5 [748.664124ms]
Apr  7 10:02:12.804: INFO: Created: latency-svc-ttf9j
Apr  7 10:02:12.844: INFO: Got endpoints: latency-svc-c8pkq [748.85675ms]
Apr  7 10:02:12.857: INFO: Created: latency-svc-g89zv
Apr  7 10:02:12.896: INFO: Got endpoints: latency-svc-tpdgd [750.515916ms]
Apr  7 10:02:12.907: INFO: Created: latency-svc-kvft7
Apr  7 10:02:12.945: INFO: Got endpoints: latency-svc-dkqfz [750.095206ms]
Apr  7 10:02:12.954: INFO: Created: latency-svc-b87tn
Apr  7 10:02:13.001: INFO: Got endpoints: latency-svc-2z5r2 [756.380592ms]
Apr  7 10:02:13.015: INFO: Created: latency-svc-2lwrw
Apr  7 10:02:13.044: INFO: Got endpoints: latency-svc-qq6x7 [747.530627ms]
Apr  7 10:02:13.051: INFO: Created: latency-svc-z86tc
Apr  7 10:02:13.094: INFO: Got endpoints: latency-svc-55x7n [748.991918ms]
Apr  7 10:02:13.103: INFO: Created: latency-svc-8w979
Apr  7 10:02:13.144: INFO: Got endpoints: latency-svc-8vgbh [749.512105ms]
Apr  7 10:02:13.153: INFO: Created: latency-svc-h6v5n
Apr  7 10:02:13.200: INFO: Got endpoints: latency-svc-9gm9k [754.11455ms]
Apr  7 10:02:13.213: INFO: Created: latency-svc-ptkfd
Apr  7 10:02:13.248: INFO: Got endpoints: latency-svc-cv9t2 [747.369778ms]
Apr  7 10:02:13.260: INFO: Created: latency-svc-gzwnt
Apr  7 10:02:13.294: INFO: Got endpoints: latency-svc-st54x [746.483391ms]
Apr  7 10:02:13.303: INFO: Created: latency-svc-wnprk
Apr  7 10:02:13.347: INFO: Got endpoints: latency-svc-4dbb6 [753.588608ms]
Apr  7 10:02:13.353: INFO: Created: latency-svc-gd8r5
Apr  7 10:02:13.395: INFO: Got endpoints: latency-svc-ss9d7 [744.250052ms]
Apr  7 10:02:13.407: INFO: Created: latency-svc-qnkld
Apr  7 10:02:13.445: INFO: Got endpoints: latency-svc-rc8wk [750.394579ms]
Apr  7 10:02:13.453: INFO: Created: latency-svc-7fsmb
Apr  7 10:02:13.495: INFO: Got endpoints: latency-svc-pctdv [749.71474ms]
Apr  7 10:02:13.502: INFO: Created: latency-svc-cm4zq
Apr  7 10:02:13.544: INFO: Got endpoints: latency-svc-ttf9j [747.32742ms]
Apr  7 10:02:13.552: INFO: Created: latency-svc-7jr5h
Apr  7 10:02:13.595: INFO: Got endpoints: latency-svc-g89zv [751.0533ms]
Apr  7 10:02:13.601: INFO: Created: latency-svc-ws7jk
Apr  7 10:02:13.645: INFO: Got endpoints: latency-svc-kvft7 [745.130753ms]
Apr  7 10:02:13.652: INFO: Created: latency-svc-plqcb
Apr  7 10:02:13.696: INFO: Got endpoints: latency-svc-b87tn [747.51436ms]
Apr  7 10:02:13.704: INFO: Created: latency-svc-z5sh5
Apr  7 10:02:13.745: INFO: Got endpoints: latency-svc-2lwrw [742.312477ms]
Apr  7 10:02:13.761: INFO: Created: latency-svc-g4dcz
Apr  7 10:02:13.796: INFO: Got endpoints: latency-svc-z86tc [751.242363ms]
Apr  7 10:02:13.804: INFO: Created: latency-svc-dm25m
Apr  7 10:02:13.843: INFO: Got endpoints: latency-svc-8w979 [747.719528ms]
Apr  7 10:02:13.852: INFO: Created: latency-svc-58wr4
Apr  7 10:02:13.894: INFO: Got endpoints: latency-svc-h6v5n [749.149148ms]
Apr  7 10:02:13.901: INFO: Created: latency-svc-tstdx
Apr  7 10:02:13.944: INFO: Got endpoints: latency-svc-ptkfd [744.339755ms]
Apr  7 10:02:13.951: INFO: Created: latency-svc-b2gwn
Apr  7 10:02:13.994: INFO: Got endpoints: latency-svc-gzwnt [743.093874ms]
Apr  7 10:02:14.002: INFO: Created: latency-svc-m5rgz
Apr  7 10:02:14.044: INFO: Got endpoints: latency-svc-wnprk [750.134398ms]
Apr  7 10:02:14.054: INFO: Created: latency-svc-vr44k
Apr  7 10:02:14.098: INFO: Got endpoints: latency-svc-gd8r5 [750.912087ms]
Apr  7 10:02:14.108: INFO: Created: latency-svc-pvwgf
Apr  7 10:02:14.146: INFO: Got endpoints: latency-svc-qnkld [751.324625ms]
Apr  7 10:02:14.154: INFO: Created: latency-svc-2s28x
Apr  7 10:02:14.201: INFO: Got endpoints: latency-svc-7fsmb [755.938627ms]
Apr  7 10:02:14.213: INFO: Created: latency-svc-bwr5b
Apr  7 10:02:14.244: INFO: Got endpoints: latency-svc-cm4zq [749.449323ms]
Apr  7 10:02:14.251: INFO: Created: latency-svc-qpq8h
Apr  7 10:02:14.296: INFO: Got endpoints: latency-svc-7jr5h [750.967957ms]
Apr  7 10:02:14.304: INFO: Created: latency-svc-8qxhl
Apr  7 10:02:14.345: INFO: Got endpoints: latency-svc-ws7jk [749.251086ms]
Apr  7 10:02:14.351: INFO: Created: latency-svc-s4ml4
Apr  7 10:02:14.395: INFO: Got endpoints: latency-svc-plqcb [749.589071ms]
Apr  7 10:02:14.403: INFO: Created: latency-svc-94nn2
Apr  7 10:02:14.446: INFO: Got endpoints: latency-svc-z5sh5 [748.67498ms]
Apr  7 10:02:14.454: INFO: Created: latency-svc-vr4gq
Apr  7 10:02:14.494: INFO: Got endpoints: latency-svc-g4dcz [748.964433ms]
Apr  7 10:02:14.505: INFO: Created: latency-svc-8ktd4
Apr  7 10:02:14.545: INFO: Got endpoints: latency-svc-dm25m [748.526683ms]
Apr  7 10:02:14.555: INFO: Created: latency-svc-6wg4c
Apr  7 10:02:14.596: INFO: Got endpoints: latency-svc-58wr4 [752.274323ms]
Apr  7 10:02:14.604: INFO: Created: latency-svc-nkbr9
Apr  7 10:02:14.652: INFO: Got endpoints: latency-svc-tstdx [758.232182ms]
Apr  7 10:02:14.660: INFO: Created: latency-svc-x2rkl
Apr  7 10:02:14.694: INFO: Got endpoints: latency-svc-b2gwn [750.007239ms]
Apr  7 10:02:14.701: INFO: Created: latency-svc-fkhdj
Apr  7 10:02:14.747: INFO: Got endpoints: latency-svc-m5rgz [752.341217ms]
Apr  7 10:02:14.755: INFO: Created: latency-svc-2lrzc
Apr  7 10:02:14.795: INFO: Got endpoints: latency-svc-vr44k [750.286129ms]
Apr  7 10:02:14.802: INFO: Created: latency-svc-ph4l4
Apr  7 10:02:14.844: INFO: Got endpoints: latency-svc-pvwgf [745.272136ms]
Apr  7 10:02:14.852: INFO: Created: latency-svc-r4bx4
Apr  7 10:02:14.900: INFO: Got endpoints: latency-svc-2s28x [753.864885ms]
Apr  7 10:02:14.911: INFO: Created: latency-svc-dg6dk
Apr  7 10:02:14.945: INFO: Got endpoints: latency-svc-bwr5b [744.546012ms]
Apr  7 10:02:14.953: INFO: Created: latency-svc-ctxjl
Apr  7 10:02:15.007: INFO: Got endpoints: latency-svc-qpq8h [762.745783ms]
Apr  7 10:02:15.020: INFO: Created: latency-svc-gx77h
Apr  7 10:02:15.045: INFO: Got endpoints: latency-svc-8qxhl [749.102242ms]
Apr  7 10:02:15.053: INFO: Created: latency-svc-8vj67
Apr  7 10:02:15.100: INFO: Got endpoints: latency-svc-s4ml4 [755.521931ms]
Apr  7 10:02:15.112: INFO: Created: latency-svc-8mjb7
Apr  7 10:02:15.144: INFO: Got endpoints: latency-svc-94nn2 [748.570587ms]
Apr  7 10:02:15.152: INFO: Created: latency-svc-7cpkq
Apr  7 10:02:15.194: INFO: Got endpoints: latency-svc-vr4gq [747.154173ms]
Apr  7 10:02:15.210: INFO: Created: latency-svc-4bdhm
Apr  7 10:02:15.246: INFO: Got endpoints: latency-svc-8ktd4 [747.962587ms]
Apr  7 10:02:15.252: INFO: Created: latency-svc-p8q89
Apr  7 10:02:15.297: INFO: Got endpoints: latency-svc-6wg4c [750.625416ms]
Apr  7 10:02:15.310: INFO: Created: latency-svc-pl228
Apr  7 10:02:15.345: INFO: Got endpoints: latency-svc-nkbr9 [748.790513ms]
Apr  7 10:02:15.354: INFO: Created: latency-svc-dkbjm
Apr  7 10:02:15.395: INFO: Got endpoints: latency-svc-x2rkl [742.490541ms]
Apr  7 10:02:15.405: INFO: Created: latency-svc-tkxdc
Apr  7 10:02:15.446: INFO: Got endpoints: latency-svc-fkhdj [751.549628ms]
Apr  7 10:02:15.464: INFO: Created: latency-svc-bk548
Apr  7 10:02:15.494: INFO: Got endpoints: latency-svc-2lrzc [746.64884ms]
Apr  7 10:02:15.501: INFO: Created: latency-svc-xxhfz
Apr  7 10:02:15.545: INFO: Got endpoints: latency-svc-ph4l4 [750.069911ms]
Apr  7 10:02:15.560: INFO: Created: latency-svc-ck4dh
Apr  7 10:02:15.594: INFO: Got endpoints: latency-svc-r4bx4 [750.119659ms]
Apr  7 10:02:15.604: INFO: Created: latency-svc-kwbrn
Apr  7 10:02:15.645: INFO: Got endpoints: latency-svc-dg6dk [744.835938ms]
Apr  7 10:02:15.655: INFO: Created: latency-svc-g6sk5
Apr  7 10:02:15.695: INFO: Got endpoints: latency-svc-ctxjl [749.468083ms]
Apr  7 10:02:15.703: INFO: Created: latency-svc-x6hfg
Apr  7 10:02:15.744: INFO: Got endpoints: latency-svc-gx77h [733.134634ms]
Apr  7 10:02:15.794: INFO: Got endpoints: latency-svc-8vj67 [749.237589ms]
Apr  7 10:02:15.845: INFO: Got endpoints: latency-svc-8mjb7 [744.189266ms]
Apr  7 10:02:15.897: INFO: Got endpoints: latency-svc-7cpkq [753.070809ms]
Apr  7 10:02:15.945: INFO: Got endpoints: latency-svc-4bdhm [751.677118ms]
Apr  7 10:02:15.995: INFO: Got endpoints: latency-svc-p8q89 [748.459984ms]
Apr  7 10:02:16.045: INFO: Got endpoints: latency-svc-pl228 [744.691737ms]
Apr  7 10:02:16.095: INFO: Got endpoints: latency-svc-dkbjm [747.444756ms]
Apr  7 10:02:16.145: INFO: Got endpoints: latency-svc-tkxdc [749.62442ms]
Apr  7 10:02:16.196: INFO: Got endpoints: latency-svc-bk548 [749.538266ms]
Apr  7 10:02:16.244: INFO: Got endpoints: latency-svc-xxhfz [750.605319ms]
Apr  7 10:02:16.303: INFO: Got endpoints: latency-svc-ck4dh [754.544657ms]
Apr  7 10:02:16.344: INFO: Got endpoints: latency-svc-kwbrn [746.1117ms]
Apr  7 10:02:16.396: INFO: Got endpoints: latency-svc-g6sk5 [750.696448ms]
Apr  7 10:02:16.445: INFO: Got endpoints: latency-svc-x6hfg [750.361921ms]
Apr  7 10:02:16.446: INFO: Latencies: [12.663911ms 23.650761ms 25.39967ms 26.824412ms 39.82206ms 40.526623ms 49.949247ms 53.569919ms 53.627895ms 73.16377ms 73.696907ms 82.637643ms 82.655648ms 84.995029ms 90.292034ms 91.642816ms 92.599591ms 93.125889ms 96.772107ms 99.468701ms 99.662568ms 101.345957ms 102.132736ms 102.409661ms 107.803614ms 133.177617ms 148.265636ms 157.282618ms 159.951493ms 166.198181ms 166.72251ms 170.61772ms 173.071341ms 173.413799ms 180.238359ms 202.993155ms 255.951224ms 292.175786ms 326.779437ms 375.292962ms 388.531182ms 414.81107ms 456.450726ms 494.878901ms 533.321526ms 564.453686ms 614.153857ms 659.655388ms 705.277142ms 733.134634ms 739.299006ms 741.698915ms 741.781471ms 742.312477ms 742.490541ms 743.093874ms 743.107514ms 743.121424ms 744.189266ms 744.250052ms 744.273789ms 744.2784ms 744.293781ms 744.339755ms 744.546012ms 744.687778ms 744.691737ms 744.779784ms 744.835938ms 745.130753ms 745.272136ms 745.678075ms 745.882607ms 746.103807ms 746.1117ms 746.189923ms 746.413972ms 746.483391ms 746.64884ms 746.699033ms 747.154173ms 747.206683ms 747.210733ms 747.236068ms 747.32742ms 747.369778ms 747.444756ms 747.51436ms 747.530627ms 747.549437ms 747.719528ms 747.962587ms 747.991649ms 748.180386ms 748.185596ms 748.221739ms 748.277242ms 748.381498ms 748.408785ms 748.459984ms 748.526683ms 748.533439ms 748.549299ms 748.569374ms 748.570587ms 748.604335ms 748.664124ms 748.67498ms 748.790513ms 748.85675ms 748.884934ms 748.964433ms 748.991918ms 749.102242ms 749.140266ms 749.142791ms 749.149148ms 749.190667ms 749.237589ms 749.251086ms 749.330467ms 749.344023ms 749.449323ms 749.468083ms 749.512105ms 749.538266ms 749.581216ms 749.589071ms 749.599236ms 749.62442ms 749.650532ms 749.684204ms 749.698162ms 749.71474ms 749.731436ms 749.740512ms 749.759084ms 749.856485ms 749.874209ms 750.007239ms 750.038545ms 750.069911ms 750.095206ms 750.119659ms 750.127706ms 750.132159ms 750.134398ms 750.221071ms 750.286129ms 750.354191ms 750.361921ms 750.394579ms 750.515916ms 750.585405ms 750.605319ms 750.622154ms 750.625416ms 750.696448ms 750.811457ms 750.818493ms 750.899771ms 750.91023ms 750.912087ms 750.967957ms 751.0533ms 751.232588ms 751.242363ms 751.264532ms 751.324625ms 751.391642ms 751.549628ms 751.648257ms 751.677118ms 751.701414ms 751.793574ms 751.918775ms 752.05713ms 752.274323ms 752.341217ms 752.494445ms 752.721186ms 753.055786ms 753.070809ms 753.118469ms 753.588608ms 753.864885ms 753.953963ms 754.11455ms 754.544657ms 755.354114ms 755.521931ms 755.556013ms 755.880558ms 755.933048ms 755.938627ms 756.379718ms 756.380592ms 758.232182ms 762.229534ms 762.745783ms]
Apr  7 10:02:16.449: INFO: 50 %ile: 748.526683ms
Apr  7 10:02:16.449: INFO: 90 %ile: 752.721186ms
Apr  7 10:02:16.449: INFO: 99 %ile: 762.229534ms
Apr  7 10:02:16.449: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:02:16.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6705" for this suite.
Apr  7 10:02:24.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:02:24.549: INFO: namespace svc-latency-6705 deletion completed in 8.091847529s

• [SLOW TEST:18.847 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:02:24.550: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  7 10:02:27.110: INFO: Successfully updated pod "pod-update-3e030df3-591c-11e9-9aa1-1aed65326ff2"
STEP: verifying the updated pod is in kubernetes
Apr  7 10:02:27.116: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:02:27.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-384" for this suite.
Apr  7 10:02:49.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:02:49.194: INFO: namespace pods-384 deletion completed in 22.075041131s

• [SLOW TEST:24.644 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:02:49.195: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:02:49.224: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2" in namespace "downward-api-2814" to be "success or failure"
Apr  7 10:02:49.228: INFO: Pod "downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.690798ms
Apr  7 10:02:51.231: INFO: Pod "downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006501216s
STEP: Saw pod success
Apr  7 10:02:51.231: INFO: Pod "downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:02:51.233: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:02:51.247: INFO: Waiting for pod downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:02:51.249: INFO: Pod downwardapi-volume-4cb1fce8-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:02:51.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2814" for this suite.
Apr  7 10:02:57.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:02:57.331: INFO: namespace downward-api-2814 deletion completed in 6.079032837s

• [SLOW TEST:8.136 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:02:57.331: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  7 10:02:57.360: INFO: Waiting up to 5m0s for pod "pod-518b6c42-591c-11e9-9aa1-1aed65326ff2" in namespace "emptydir-1344" to be "success or failure"
Apr  7 10:02:57.364: INFO: Pod "pod-518b6c42-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.46676ms
Apr  7 10:02:59.366: INFO: Pod "pod-518b6c42-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00617138s
STEP: Saw pod success
Apr  7 10:02:59.367: INFO: Pod "pod-518b6c42-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:02:59.369: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-518b6c42-591c-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:02:59.382: INFO: Waiting for pod pod-518b6c42-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:02:59.384: INFO: Pod pod-518b6c42-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:02:59.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1344" for this suite.
Apr  7 10:03:05.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:03:05.461: INFO: namespace emptydir-1344 deletion completed in 6.073965077s

• [SLOW TEST:8.129 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:03:05.461: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-5663d643-591c-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:03:05.491: INFO: Waiting up to 5m0s for pod "pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2" in namespace "secrets-7853" to be "success or failure"
Apr  7 10:03:05.494: INFO: Pod "pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.498924ms
Apr  7 10:03:07.497: INFO: Pod "pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005683995s
STEP: Saw pod success
Apr  7 10:03:07.497: INFO: Pod "pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:03:07.500: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:03:07.513: INFO: Waiting for pod pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:03:07.515: INFO: Pod pod-secrets-566435ba-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:03:07.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7853" for this suite.
Apr  7 10:03:13.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:03:13.591: INFO: namespace secrets-7853 deletion completed in 6.072855842s

• [SLOW TEST:8.130 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:03:13.591: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  7 10:03:17.629: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5b3cab13-591c-11e9-9aa1-1aed65326ff2,GenerateName:,Namespace:events-100,SelfLink:/api/v1/namespaces/events-100/pods/send-events-5b3cab13-591c-11e9-9aa1-1aed65326ff2,UID:5b3a6dc3-591c-11e9-99b0-0225f4f52196,ResourceVersion:7283,Generation:0,CreationTimestamp:2019-04-07 10:03:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 616979519,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.40/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nm44z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nm44z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-nm44z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eee110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eee130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:03:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:03:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:03:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:03:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.40,StartTime:2019-04-07 10:03:13 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-07 10:03:15 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a5d5e3ef2cd88caae10cad3f7607c32539861a254cf0636e1a60f14b6e28bdf4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr  7 10:03:19.632: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  7 10:03:21.640: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:03:21.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-100" for this suite.
Apr  7 10:04:01.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:04:01.740: INFO: namespace events-100 deletion completed in 40.086524418s

• [SLOW TEST:48.148 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:04:01.741: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr  7 10:04:01.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-9838'
Apr  7 10:04:01.967: INFO: stderr: ""
Apr  7 10:04:01.967: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr  7 10:04:02.970: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:04:02.970: INFO: Found 0 / 1
Apr  7 10:04:03.970: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:04:03.970: INFO: Found 1 / 1
Apr  7 10:04:03.970: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  7 10:04:03.973: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:04:03.973: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr  7 10:04:03.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 logs redis-master-xvnfx redis-master --namespace=kubectl-9838'
Apr  7 10:04:04.064: INFO: stderr: ""
Apr  7 10:04:04.064: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Apr 10:04:02.899 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Apr 10:04:02.899 # Server started, Redis version 3.2.12\n1:M 07 Apr 10:04:02.899 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Apr 10:04:02.899 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr  7 10:04:04.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 log redis-master-xvnfx redis-master --namespace=kubectl-9838 --tail=1'
Apr  7 10:04:04.150: INFO: stderr: ""
Apr  7 10:04:04.150: INFO: stdout: "1:M 07 Apr 10:04:02.899 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr  7 10:04:04.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 log redis-master-xvnfx redis-master --namespace=kubectl-9838 --limit-bytes=1'
Apr  7 10:04:04.270: INFO: stderr: ""
Apr  7 10:04:04.270: INFO: stdout: " "
STEP: exposing timestamps
Apr  7 10:04:04.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 log redis-master-xvnfx redis-master --namespace=kubectl-9838 --tail=1 --timestamps'
Apr  7 10:04:04.412: INFO: stderr: ""
Apr  7 10:04:04.412: INFO: stdout: "2019-04-07T10:04:02.900657992Z 1:M 07 Apr 10:04:02.899 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr  7 10:04:06.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 log redis-master-xvnfx redis-master --namespace=kubectl-9838 --since=1s'
Apr  7 10:04:07.017: INFO: stderr: ""
Apr  7 10:04:07.017: INFO: stdout: ""
Apr  7 10:04:07.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 log redis-master-xvnfx redis-master --namespace=kubectl-9838 --since=24h'
Apr  7 10:04:07.107: INFO: stderr: ""
Apr  7 10:04:07.107: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Apr 10:04:02.899 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Apr 10:04:02.899 # Server started, Redis version 3.2.12\n1:M 07 Apr 10:04:02.899 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Apr 10:04:02.899 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr  7 10:04:07.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-9838'
Apr  7 10:04:07.190: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:04:07.190: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr  7 10:04:07.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=nginx --no-headers --namespace=kubectl-9838'
Apr  7 10:04:07.277: INFO: stderr: "No resources found.\n"
Apr  7 10:04:07.277: INFO: stdout: ""
Apr  7 10:04:07.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=nginx --namespace=kubectl-9838 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 10:04:07.357: INFO: stderr: ""
Apr  7 10:04:07.357: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:04:07.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9838" for this suite.
Apr  7 10:04:29.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:04:29.434: INFO: namespace kubectl-9838 deletion completed in 22.07332001s

• [SLOW TEST:27.693 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:04:29.434: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr  7 10:04:29.462: INFO: Waiting up to 5m0s for pod "var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2" in namespace "var-expansion-7130" to be "success or failure"
Apr  7 10:04:29.464: INFO: Pod "var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.905824ms
Apr  7 10:04:31.468: INFO: Pod "var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006092776s
STEP: Saw pod success
Apr  7 10:04:31.468: INFO: Pod "var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:04:31.471: INFO: Trying to get logs from node ip-10-0-39-198 pod var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 10:04:31.485: INFO: Waiting for pod var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:04:31.487: INFO: Pod var-expansion-88712714-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:04:31.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7130" for this suite.
Apr  7 10:04:37.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:04:37.571: INFO: namespace var-expansion-7130 deletion completed in 6.07908554s

• [SLOW TEST:8.137 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:04:37.573: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  7 10:04:37.597: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:04:41.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5701" for this suite.
Apr  7 10:05:03.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:05:03.702: INFO: namespace init-container-5701 deletion completed in 22.077936019s

• [SLOW TEST:26.129 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:05:03.703: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr  7 10:05:03.730: INFO: Waiting up to 5m0s for pod "var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2" in namespace "var-expansion-120" to be "success or failure"
Apr  7 10:05:03.732: INFO: Pod "var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264574ms
Apr  7 10:05:05.735: INFO: Pod "var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005286639s
STEP: Saw pod success
Apr  7 10:05:05.735: INFO: Pod "var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:05:05.737: INFO: Trying to get logs from node ip-10-0-29-139 pod var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 10:05:05.750: INFO: Waiting for pod var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:05:05.751: INFO: Pod var-expansion-9cddbec2-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:05:05.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-120" for this suite.
Apr  7 10:05:11.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:05:11.828: INFO: namespace var-expansion-120 deletion completed in 6.074647112s

• [SLOW TEST:8.126 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:05:11.829: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0407 10:05:21.869843      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 10:05:21.869: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:05:21.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2253" for this suite.
Apr  7 10:05:27.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:05:27.955: INFO: namespace gc-2253 deletion completed in 6.083186962s

• [SLOW TEST:16.126 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:05:27.955: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-ab52fa9d-591c-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:05:27.987: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2" in namespace "projected-4936" to be "success or failure"
Apr  7 10:05:27.991: INFO: Pod "pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752004ms
Apr  7 10:05:29.994: INFO: Pod "pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006761582s
STEP: Saw pod success
Apr  7 10:05:29.994: INFO: Pod "pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:05:30.002: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:05:30.018: INFO: Waiting for pod pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:05:30.021: INFO: Pod pod-projected-configmaps-ab537164-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:05:30.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4936" for this suite.
Apr  7 10:05:36.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:05:36.101: INFO: namespace projected-4936 deletion completed in 6.075841448s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:05:36.103: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 10:05:36.142: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:36.144: INFO: Number of nodes with available pods: 0
Apr  7 10:05:36.144: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:05:37.148: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:37.150: INFO: Number of nodes with available pods: 0
Apr  7 10:05:37.150: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:05:38.147: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:38.150: INFO: Number of nodes with available pods: 2
Apr  7 10:05:38.150: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  7 10:05:38.175: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:38.184: INFO: Number of nodes with available pods: 1
Apr  7 10:05:38.184: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:05:39.189: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:39.198: INFO: Number of nodes with available pods: 1
Apr  7 10:05:39.198: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:05:40.187: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:05:40.189: INFO: Number of nodes with available pods: 2
Apr  7 10:05:40.189: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9185, will wait for the garbage collector to delete the pods
Apr  7 10:05:40.250: INFO: Deleting DaemonSet.extensions daemon-set took: 4.224818ms
Apr  7 10:05:40.550: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.198197ms
Apr  7 10:05:50.752: INFO: Number of nodes with available pods: 0
Apr  7 10:05:50.752: INFO: Number of running nodes: 0, number of available pods: 0
Apr  7 10:05:50.754: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9185/daemonsets","resourceVersion":"7841"},"items":null}

Apr  7 10:05:50.756: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9185/pods","resourceVersion":"7841"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:05:50.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9185" for this suite.
Apr  7 10:05:56.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:05:56.848: INFO: namespace daemonsets-9185 deletion completed in 6.082896242s

• [SLOW TEST:20.744 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:05:56.848: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:06:22.884: INFO: Container started at 2019-04-07 10:05:58 +0000 UTC, pod became ready at 2019-04-07 10:06:22 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:06:22.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4665" for this suite.
Apr  7 10:06:44.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:06:44.970: INFO: namespace container-probe-4665 deletion completed in 22.08311402s

• [SLOW TEST:48.122 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:06:44.972: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:06:45.016: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2" in namespace "projected-962" to be "success or failure"
Apr  7 10:06:45.019: INFO: Pod "downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.993334ms
Apr  7 10:06:47.022: INFO: Pod "downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005693847s
STEP: Saw pod success
Apr  7 10:06:47.022: INFO: Pod "downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:06:47.024: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:06:47.038: INFO: Waiting for pod downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:06:47.040: INFO: Pod downwardapi-volume-d93c96ae-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:06:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-962" for this suite.
Apr  7 10:06:53.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:06:53.116: INFO: namespace projected-962 deletion completed in 6.073324422s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:06:53.116: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:06:53.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4852'
Apr  7 10:06:53.416: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  7 10:06:53.416: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr  7 10:06:53.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4852'
Apr  7 10:06:53.510: INFO: stderr: ""
Apr  7 10:06:53.510: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:06:53.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4852" for this suite.
Apr  7 10:06:59.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:06:59.588: INFO: namespace kubectl-4852 deletion completed in 6.075242017s

• [SLOW TEST:6.472 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:06:59.588: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-e1f82a91-591c-11e9-9aa1-1aed65326ff2
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:06:59.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6351" for this suite.
Apr  7 10:07:05.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:07:05.749: INFO: namespace configmap-6351 deletion completed in 6.077044296s

• [SLOW TEST:6.160 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:07:05.749: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:07:05.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2286'
Apr  7 10:07:05.849: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  7 10:07:05.849: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr  7 10:07:05.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete jobs e2e-test-nginx-job --namespace=kubectl-2286'
Apr  7 10:07:05.933: INFO: stderr: ""
Apr  7 10:07:05.933: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:07:05.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2286" for this suite.
Apr  7 10:07:11.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:07:12.033: INFO: namespace kubectl-2286 deletion completed in 6.097022145s

• [SLOW TEST:6.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:07:12.034: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e95c79c6-591c-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:07:12.070: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2" in namespace "projected-3208" to be "success or failure"
Apr  7 10:07:12.074: INFO: Pod "pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513201ms
Apr  7 10:07:14.077: INFO: Pod "pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007504017s
STEP: Saw pod success
Apr  7 10:07:14.077: INFO: Pod "pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:07:14.080: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:07:14.094: INFO: Waiting for pod pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:07:14.096: INFO: Pod pod-projected-configmaps-e95ce611-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:07:14.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3208" for this suite.
Apr  7 10:07:20.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:07:20.175: INFO: namespace projected-3208 deletion completed in 6.076976317s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:07:20.176: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-ee376c20-591c-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:07:20.216: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2" in namespace "projected-3415" to be "success or failure"
Apr  7 10:07:20.221: INFO: Pod "pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379258ms
Apr  7 10:07:22.224: INFO: Pod "pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007589597s
STEP: Saw pod success
Apr  7 10:07:22.224: INFO: Pod "pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:07:22.226: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:07:22.240: INFO: Waiting for pod pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:07:22.242: INFO: Pod pod-projected-configmaps-ee37c789-591c-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:07:22.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3415" for this suite.
Apr  7 10:07:28.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:07:28.328: INFO: namespace projected-3415 deletion completed in 6.08282434s

• [SLOW TEST:8.152 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:07:28.328: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:07:32.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7283" for this suite.
Apr  7 10:07:38.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:07:38.446: INFO: namespace kubelet-test-7283 deletion completed in 6.079977218s

• [SLOW TEST:10.118 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:07:38.446: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-640
Apr  7 10:07:42.480: INFO: Started pod liveness-http in namespace container-probe-640
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 10:07:42.484: INFO: Initial restart count of pod liveness-http is 0
Apr  7 10:08:04.533: INFO: Restart count of pod container-probe-640/liveness-http is now 1 (22.048628586s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:08:04.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-640" for this suite.
Apr  7 10:08:10.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:08:10.636: INFO: namespace container-probe-640 deletion completed in 6.089265148s

• [SLOW TEST:32.190 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:08:10.636: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  7 10:08:14.740: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:14.743: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:16.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:16.750: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:18.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:18.747: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:20.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:20.747: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:22.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:22.746: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:24.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:24.746: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:26.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:26.746: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:28.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:28.746: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 10:08:30.744: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 10:08:30.746: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:08:30.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2025" for this suite.
Apr  7 10:08:52.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:08:52.842: INFO: namespace container-lifecycle-hook-2025 deletion completed in 22.086286795s

• [SLOW TEST:42.206 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:08:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  7 10:08:55.387: INFO: Successfully updated pod "labelsupdate257173eb-591d-11e9-9aa1-1aed65326ff2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:08:59.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5342" for this suite.
Apr  7 10:09:21.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:09:21.483: INFO: namespace downward-api-5342 deletion completed in 22.07411029s

• [SLOW TEST:28.641 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:09:21.486: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  7 10:09:25.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  7 10:09:25.603: INFO: Pod pod-with-poststart-http-hook still exists
Apr  7 10:09:27.603: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  7 10:09:27.606: INFO: Pod pod-with-poststart-http-hook still exists
Apr  7 10:09:29.603: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  7 10:09:29.606: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:09:29.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1118" for this suite.
Apr  7 10:09:51.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:09:51.688: INFO: namespace container-lifecycle-hook-1118 deletion completed in 22.078833679s

• [SLOW TEST:30.202 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:09:51.688: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-48852050-591d-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:09:51.718: INFO: Waiting up to 5m0s for pod "pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2" in namespace "secrets-1639" to be "success or failure"
Apr  7 10:09:51.720: INFO: Pod "pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.536225ms
Apr  7 10:09:53.723: INFO: Pod "pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004921754s
STEP: Saw pod success
Apr  7 10:09:53.723: INFO: Pod "pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:09:53.725: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2 container secret-env-test: <nil>
STEP: delete the pod
Apr  7 10:09:53.740: INFO: Waiting for pod pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:09:53.741: INFO: Pod pod-secrets-48858be0-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:09:53.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1639" for this suite.
Apr  7 10:09:59.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:09:59.824: INFO: namespace secrets-1639 deletion completed in 6.080252435s

• [SLOW TEST:8.136 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:09:59.824: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:09:59.854: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:10:00.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3101" for this suite.
Apr  7 10:10:07.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:10:07.073: INFO: namespace custom-resource-definition-3101 deletion completed in 6.087783238s

• [SLOW TEST:7.249 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:10:07.078: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:10:07.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6212" for this suite.
Apr  7 10:10:29.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:10:29.193: INFO: namespace pods-6212 deletion completed in 22.080696477s

• [SLOW TEST:22.114 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:10:29.193: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr  7 10:10:29.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 --namespace=kubectl-1845 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  7 10:10:31.326: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  7 10:10:31.326: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:10:33.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1845" for this suite.
Apr  7 10:10:39.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:10:39.407: INFO: namespace kubectl-1845 deletion completed in 6.07370436s

• [SLOW TEST:10.214 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:10:39.407: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:10:39.435: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2" in namespace "downward-api-609" to be "success or failure"
Apr  7 10:10:39.439: INFO: Pod "downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.603143ms
Apr  7 10:10:41.442: INFO: Pod "downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006526887s
STEP: Saw pod success
Apr  7 10:10:41.442: INFO: Pod "downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:10:41.444: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:10:41.458: INFO: Waiting for pod downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:10:41.460: INFO: Pod downwardapi-volume-64f65e0a-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:10:41.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-609" for this suite.
Apr  7 10:10:47.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:10:47.537: INFO: namespace downward-api-609 deletion completed in 6.074480874s

• [SLOW TEST:8.130 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:10:47.540: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-bmh9
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 10:10:47.621: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bmh9" in namespace "subpath-2787" to be "success or failure"
Apr  7 10:10:47.624: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417628ms
Apr  7 10:10:49.626: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 2.005048893s
Apr  7 10:10:51.629: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 4.008069077s
Apr  7 10:10:53.632: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 6.010781513s
Apr  7 10:10:55.635: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 8.013900599s
Apr  7 10:10:57.638: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 10.016799267s
Apr  7 10:10:59.641: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 12.019328827s
Apr  7 10:11:01.644: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 14.022240615s
Apr  7 10:11:03.647: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 16.025275035s
Apr  7 10:11:05.650: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 18.028400558s
Apr  7 10:11:07.653: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Running", Reason="", readiness=true. Elapsed: 20.031526867s
Apr  7 10:11:09.656: INFO: Pod "pod-subpath-test-projected-bmh9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034327206s
STEP: Saw pod success
Apr  7 10:11:09.656: INFO: Pod "pod-subpath-test-projected-bmh9" satisfied condition "success or failure"
Apr  7 10:11:09.658: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-subpath-test-projected-bmh9 container test-container-subpath-projected-bmh9: <nil>
STEP: delete the pod
Apr  7 10:11:09.675: INFO: Waiting for pod pod-subpath-test-projected-bmh9 to disappear
Apr  7 10:11:09.678: INFO: Pod pod-subpath-test-projected-bmh9 no longer exists
STEP: Deleting pod pod-subpath-test-projected-bmh9
Apr  7 10:11:09.678: INFO: Deleting pod "pod-subpath-test-projected-bmh9" in namespace "subpath-2787"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:11:09.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2787" for this suite.
Apr  7 10:11:15.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:11:15.759: INFO: namespace subpath-2787 deletion completed in 6.075630876s

• [SLOW TEST:28.218 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:11:15.759: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9567
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9567
STEP: Creating statefulset with conflicting port in namespace statefulset-9567
STEP: Waiting until pod test-pod will start running in namespace statefulset-9567
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9567
Apr  7 10:11:17.813: INFO: Observed stateful pod in namespace: statefulset-9567, name: ss-0, uid: 7b77861c-591d-11e9-99b0-0225f4f52196, status phase: Pending. Waiting for statefulset controller to delete.
Apr  7 10:11:18.201: INFO: Observed stateful pod in namespace: statefulset-9567, name: ss-0, uid: 7b77861c-591d-11e9-99b0-0225f4f52196, status phase: Failed. Waiting for statefulset controller to delete.
Apr  7 10:11:18.207: INFO: Observed stateful pod in namespace: statefulset-9567, name: ss-0, uid: 7b77861c-591d-11e9-99b0-0225f4f52196, status phase: Failed. Waiting for statefulset controller to delete.
Apr  7 10:11:18.209: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9567
STEP: Removing pod with conflicting port in namespace statefulset-9567
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9567 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  7 10:11:22.234: INFO: Deleting all statefulset in ns statefulset-9567
Apr  7 10:11:22.236: INFO: Scaling statefulset ss to 0
Apr  7 10:11:32.249: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:11:32.251: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:11:32.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9567" for this suite.
Apr  7 10:11:38.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:11:38.335: INFO: namespace statefulset-9567 deletion completed in 6.074437966s

• [SLOW TEST:22.576 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:11:38.336: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-fdt5
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 10:11:38.366: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fdt5" in namespace "subpath-8760" to be "success or failure"
Apr  7 10:11:38.370: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.443013ms
Apr  7 10:11:40.373: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 2.006443196s
Apr  7 10:11:42.376: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 4.009368039s
Apr  7 10:11:44.379: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 6.012261045s
Apr  7 10:11:46.382: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 8.01504431s
Apr  7 10:11:48.385: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 10.017954476s
Apr  7 10:11:50.388: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 12.020791138s
Apr  7 10:11:52.391: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 14.023727019s
Apr  7 10:11:54.394: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 16.026968464s
Apr  7 10:11:56.397: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 18.02989419s
Apr  7 10:11:58.400: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Running", Reason="", readiness=true. Elapsed: 20.033094097s
Apr  7 10:12:00.403: INFO: Pod "pod-subpath-test-downwardapi-fdt5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035735566s
STEP: Saw pod success
Apr  7 10:12:00.403: INFO: Pod "pod-subpath-test-downwardapi-fdt5" satisfied condition "success or failure"
Apr  7 10:12:00.405: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-subpath-test-downwardapi-fdt5 container test-container-subpath-downwardapi-fdt5: <nil>
STEP: delete the pod
Apr  7 10:12:00.419: INFO: Waiting for pod pod-subpath-test-downwardapi-fdt5 to disappear
Apr  7 10:12:00.421: INFO: Pod pod-subpath-test-downwardapi-fdt5 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fdt5
Apr  7 10:12:00.421: INFO: Deleting pod "pod-subpath-test-downwardapi-fdt5" in namespace "subpath-8760"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:12:00.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8760" for this suite.
Apr  7 10:12:06.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:12:06.510: INFO: namespace subpath-8760 deletion completed in 6.083918487s

• [SLOW TEST:28.175 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:12:06.511: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:12:06.595: INFO: (0) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.479067ms)
Apr  7 10:12:06.599: INFO: (1) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.609054ms)
Apr  7 10:12:06.602: INFO: (2) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.499888ms)
Apr  7 10:12:06.605: INFO: (3) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.02451ms)
Apr  7 10:12:06.608: INFO: (4) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.967785ms)
Apr  7 10:12:06.612: INFO: (5) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.395433ms)
Apr  7 10:12:06.615: INFO: (6) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.987631ms)
Apr  7 10:12:06.618: INFO: (7) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.030741ms)
Apr  7 10:12:06.621: INFO: (8) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.850102ms)
Apr  7 10:12:06.625: INFO: (9) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.117366ms)
Apr  7 10:12:06.628: INFO: (10) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.758854ms)
Apr  7 10:12:06.631: INFO: (11) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.93137ms)
Apr  7 10:12:06.634: INFO: (12) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.952393ms)
Apr  7 10:12:06.636: INFO: (13) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.792677ms)
Apr  7 10:12:06.640: INFO: (14) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.863527ms)
Apr  7 10:12:06.643: INFO: (15) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.868981ms)
Apr  7 10:12:06.646: INFO: (16) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.122471ms)
Apr  7 10:12:06.649: INFO: (17) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.898558ms)
Apr  7 10:12:06.652: INFO: (18) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.745919ms)
Apr  7 10:12:06.655: INFO: (19) /api/v1/nodes/ip-10-0-29-139/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.764595ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:12:06.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4998" for this suite.
Apr  7 10:12:12.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:12:12.731: INFO: namespace proxy-4998 deletion completed in 6.073236442s

• [SLOW TEST:6.219 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:12:12.733: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4556
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 10:12:12.754: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  7 10:12:32.818: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.122.54:8080/dial?request=hostName&protocol=udp&host=10.2.210.57&port=8081&tries=1'] Namespace:pod-network-test-4556 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:12:32.818: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:12:32.914: INFO: Waiting for endpoints: map[]
Apr  7 10:12:32.916: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.122.54:8080/dial?request=hostName&protocol=udp&host=10.2.122.53&port=8081&tries=1'] Namespace:pod-network-test-4556 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:12:32.916: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:12:33.009: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:12:33.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4556" for this suite.
Apr  7 10:12:55.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:12:55.087: INFO: namespace pod-network-test-4556 deletion completed in 22.075015123s

• [SLOW TEST:42.354 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:12:55.088: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  7 10:12:55.115: INFO: Waiting up to 5m0s for pod "pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2" in namespace "emptydir-786" to be "success or failure"
Apr  7 10:12:55.118: INFO: Pod "pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.005608ms
Apr  7 10:12:57.121: INFO: Pod "pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005682573s
Apr  7 10:12:59.123: INFO: Pod "pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008253543s
STEP: Saw pod success
Apr  7 10:12:59.123: INFO: Pod "pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:12:59.125: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:12:59.145: INFO: Waiting for pod pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:12:59.147: INFO: Pod pod-b5d5b297-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:12:59.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-786" for this suite.
Apr  7 10:13:05.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:13:05.228: INFO: namespace emptydir-786 deletion completed in 6.078538141s

• [SLOW TEST:10.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:13:05.228: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:13:05.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2" in namespace "projected-1717" to be "success or failure"
Apr  7 10:13:05.267: INFO: Pod "downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.548172ms
Apr  7 10:13:07.270: INFO: Pod "downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006636372s
STEP: Saw pod success
Apr  7 10:13:07.270: INFO: Pod "downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:13:07.273: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:13:07.288: INFO: Waiting for pod downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:13:07.290: INFO: Pod downwardapi-volume-bbe226f1-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:13:07.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1717" for this suite.
Apr  7 10:13:13.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:13:13.371: INFO: namespace projected-1717 deletion completed in 6.078184851s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:13:13.371: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c0bb963f-591d-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:13:13.403: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2" in namespace "projected-7555" to be "success or failure"
Apr  7 10:13:13.408: INFO: Pod "pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.410497ms
Apr  7 10:13:15.410: INFO: Pod "pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007283045s
STEP: Saw pod success
Apr  7 10:13:15.410: INFO: Pod "pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:13:15.413: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:13:15.425: INFO: Waiting for pod pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:13:15.427: INFO: Pod pod-projected-configmaps-c0bbf5b0-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:13:15.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7555" for this suite.
Apr  7 10:13:21.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:13:21.514: INFO: namespace projected-7555 deletion completed in 6.084309059s

• [SLOW TEST:8.143 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:13:21.514: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  7 10:13:21.546: INFO: Waiting up to 5m0s for pod "downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2" in namespace "downward-api-694" to be "success or failure"
Apr  7 10:13:21.550: INFO: Pod "downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.692907ms
Apr  7 10:13:23.555: INFO: Pod "downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008913578s
STEP: Saw pod success
Apr  7 10:13:23.555: INFO: Pod "downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:13:23.557: INFO: Trying to get logs from node ip-10-0-39-198 pod downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 10:13:23.570: INFO: Waiting for pod downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:13:23.573: INFO: Pod downward-api-c595c781-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:13:23.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-694" for this suite.
Apr  7 10:13:29.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:13:29.651: INFO: namespace downward-api-694 deletion completed in 6.075797249s

• [SLOW TEST:8.137 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:13:29.651: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3335
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 10:13:29.683: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  7 10:13:53.737: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.210.59:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:13:53.737: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:13:53.841: INFO: Found all expected endpoints: [netserver-0]
Apr  7 10:13:53.844: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.122.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3335 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:13:53.844: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:13:53.942: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:13:53.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3335" for this suite.
Apr  7 10:14:15.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:14:16.019: INFO: namespace pod-network-test-3335 deletion completed in 22.073868486s

• [SLOW TEST:46.368 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:14:16.019: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:14:20.064: INFO: Waiting up to 5m0s for pod "client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2" in namespace "pods-949" to be "success or failure"
Apr  7 10:14:20.067: INFO: Pod "client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.486996ms
Apr  7 10:14:22.071: INFO: Pod "client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006742105s
STEP: Saw pod success
Apr  7 10:14:22.071: INFO: Pod "client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:14:22.073: INFO: Trying to get logs from node ip-10-0-29-139 pod client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2 container env3cont: <nil>
STEP: delete the pod
Apr  7 10:14:22.091: INFO: Waiting for pod client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:14:22.093: INFO: Pod client-envvars-e877c503-591d-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:14:22.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-949" for this suite.
Apr  7 10:15:00.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:15:00.168: INFO: namespace pods-949 deletion completed in 38.07269691s

• [SLOW TEST:44.149 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:15:00.168: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  7 10:15:00.193: INFO: Waiting up to 5m0s for pod "pod-00630463-591e-11e9-9aa1-1aed65326ff2" in namespace "emptydir-305" to be "success or failure"
Apr  7 10:15:00.195: INFO: Pod "pod-00630463-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.235114ms
Apr  7 10:15:02.198: INFO: Pod "pod-00630463-591e-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005329779s
STEP: Saw pod success
Apr  7 10:15:02.198: INFO: Pod "pod-00630463-591e-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:15:02.200: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-00630463-591e-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:15:02.218: INFO: Waiting for pod pod-00630463-591e-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:15:02.221: INFO: Pod pod-00630463-591e-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:15:02.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-305" for this suite.
Apr  7 10:15:08.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:15:08.309: INFO: namespace emptydir-305 deletion completed in 6.085073769s

• [SLOW TEST:8.141 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:15:08.309: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr  7 10:15:08.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-770'
Apr  7 10:15:08.526: INFO: stderr: ""
Apr  7 10:15:08.526: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 10:15:08.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-770'
Apr  7 10:15:08.613: INFO: stderr: ""
Apr  7 10:15:08.613: INFO: stdout: "update-demo-nautilus-fk6nk update-demo-nautilus-phg76 "
Apr  7 10:15:08.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-fk6nk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:08.694: INFO: stderr: ""
Apr  7 10:15:08.694: INFO: stdout: ""
Apr  7 10:15:08.694: INFO: update-demo-nautilus-fk6nk is created but not running
Apr  7 10:15:13.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-770'
Apr  7 10:15:13.774: INFO: stderr: ""
Apr  7 10:15:13.774: INFO: stdout: "update-demo-nautilus-fk6nk update-demo-nautilus-phg76 "
Apr  7 10:15:13.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-fk6nk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:13.857: INFO: stderr: ""
Apr  7 10:15:13.857: INFO: stdout: "true"
Apr  7 10:15:13.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-fk6nk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:13.926: INFO: stderr: ""
Apr  7 10:15:13.926: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 10:15:13.926: INFO: validating pod update-demo-nautilus-fk6nk
Apr  7 10:15:13.931: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 10:15:13.931: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 10:15:13.931: INFO: update-demo-nautilus-fk6nk is verified up and running
Apr  7 10:15:13.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-phg76 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:14.025: INFO: stderr: ""
Apr  7 10:15:14.025: INFO: stdout: "true"
Apr  7 10:15:14.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-phg76 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:14.105: INFO: stderr: ""
Apr  7 10:15:14.105: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 10:15:14.105: INFO: validating pod update-demo-nautilus-phg76
Apr  7 10:15:14.112: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 10:15:14.112: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 10:15:14.112: INFO: update-demo-nautilus-phg76 is verified up and running
STEP: rolling-update to new replication controller
Apr  7 10:15:14.115: INFO: scanned /root for discovery docs: <nil>
Apr  7 10:15:14.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-770'
Apr  7 10:15:36.438: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  7 10:15:36.438: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 10:15:36.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-770'
Apr  7 10:15:36.527: INFO: stderr: ""
Apr  7 10:15:36.527: INFO: stdout: "update-demo-kitten-qrwqv update-demo-kitten-ssf6n "
Apr  7 10:15:36.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-kitten-qrwqv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:36.594: INFO: stderr: ""
Apr  7 10:15:36.594: INFO: stdout: "true"
Apr  7 10:15:36.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-kitten-qrwqv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:36.673: INFO: stderr: ""
Apr  7 10:15:36.673: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  7 10:15:36.673: INFO: validating pod update-demo-kitten-qrwqv
Apr  7 10:15:36.678: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  7 10:15:36.678: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  7 10:15:36.678: INFO: update-demo-kitten-qrwqv is verified up and running
Apr  7 10:15:36.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-kitten-ssf6n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:36.749: INFO: stderr: ""
Apr  7 10:15:36.749: INFO: stdout: "true"
Apr  7 10:15:36.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-kitten-ssf6n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-770'
Apr  7 10:15:36.813: INFO: stderr: ""
Apr  7 10:15:36.813: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  7 10:15:36.813: INFO: validating pod update-demo-kitten-ssf6n
Apr  7 10:15:36.818: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  7 10:15:36.818: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  7 10:15:36.818: INFO: update-demo-kitten-ssf6n is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:15:36.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-770" for this suite.
Apr  7 10:16:04.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:16:04.900: INFO: namespace kubectl-770 deletion completed in 28.079499021s

• [SLOW TEST:56.591 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:16:04.901: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:16:06.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9863" for this suite.
Apr  7 10:16:56.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:16:57.033: INFO: namespace kubelet-test-9863 deletion completed in 50.083198586s

• [SLOW TEST:52.133 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:16:57.033: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  7 10:16:59.581: INFO: Successfully updated pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2"
Apr  7 10:16:59.581: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2" in namespace "pods-4002" to be "terminated due to deadline exceeded"
Apr  7 10:16:59.584: INFO: Pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2": Phase="Running", Reason="", readiness=true. Elapsed: 2.205826ms
Apr  7 10:17:01.586: INFO: Pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005092067s
Apr  7 10:17:03.589: INFO: Pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007964854s
Apr  7 10:17:03.589: INFO: Pod "pod-update-activedeadlineseconds-460b4fff-591e-11e9-9aa1-1aed65326ff2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:17:03.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4002" for this suite.
Apr  7 10:17:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:17:09.666: INFO: namespace pods-4002 deletion completed in 6.074162166s

• [SLOW TEST:12.633 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:17:09.666: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  7 10:17:09.693: INFO: Waiting up to 5m0s for pod "pod-4d9319af-591e-11e9-9aa1-1aed65326ff2" in namespace "emptydir-6554" to be "success or failure"
Apr  7 10:17:09.696: INFO: Pod "pod-4d9319af-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.780412ms
Apr  7 10:17:11.699: INFO: Pod "pod-4d9319af-591e-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00559507s
STEP: Saw pod success
Apr  7 10:17:11.699: INFO: Pod "pod-4d9319af-591e-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:17:11.701: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-4d9319af-591e-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:17:11.712: INFO: Waiting for pod pod-4d9319af-591e-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:17:11.714: INFO: Pod pod-4d9319af-591e-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:17:11.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6554" for this suite.
Apr  7 10:17:17.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:17:17.790: INFO: namespace emptydir-6554 deletion completed in 6.073026313s

• [SLOW TEST:8.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:17:17.790: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  7 10:17:17.813: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 10:17:17.818: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 10:17:17.820: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-29-139 before test
Apr  7 10:17:17.825: INFO: calico-node-jc2tf from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 10:17:17.825: INFO: 	Container calico-node ready: true, restart count 0
Apr  7 10:17:17.825: INFO: kube-proxy-vcfnq from kube-system started at 2019-04-07 09:39:36 +0000 UTC (1 container statuses recorded)
Apr  7 10:17:17.825: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 10:17:17.825: INFO: sonobuoy-e2e-job-bd24bc4110464347 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 10:17:17.825: INFO: 	Container e2e ready: true, restart count 0
Apr  7 10:17:17.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 10:17:17.825: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-8b9mt from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 10:17:17.825: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 10:17:17.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 10:17:17.825: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-39-198 before test
Apr  7 10:17:17.830: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-07 09:48:57 +0000 UTC (1 container statuses recorded)
Apr  7 10:17:17.830: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 10:17:17.830: INFO: calico-node-tcp8p from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 10:17:17.830: INFO: 	Container calico-node ready: true, restart count 0
Apr  7 10:17:17.830: INFO: sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-lf7g7 from heptio-sonobuoy started at 2019-04-07 09:49:02 +0000 UTC (2 container statuses recorded)
Apr  7 10:17:17.830: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  7 10:17:17.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 10:17:17.830: INFO: kube-proxy-9zkg8 from kube-system started at 2019-04-07 09:39:33 +0000 UTC (1 container statuses recorded)
Apr  7 10:17:17.830: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-53a13307-591e-11e9-9aa1-1aed65326ff2 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-53a13307-591e-11e9-9aa1-1aed65326ff2 off the node ip-10-0-39-198
STEP: verifying the node doesn't have the label kubernetes.io/e2e-53a13307-591e-11e9-9aa1-1aed65326ff2
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:17:21.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2046" for this suite.
Apr  7 10:17:29.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:17:29.957: INFO: namespace sched-pred-2046 deletion completed in 8.073860857s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.167 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:17:29.958: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-59ac304f-591e-11e9-9aa1-1aed65326ff2
STEP: Creating secret with name s-test-opt-upd-59ac308a-591e-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-59ac304f-591e-11e9-9aa1-1aed65326ff2
STEP: Updating secret s-test-opt-upd-59ac308a-591e-11e9-9aa1-1aed65326ff2
STEP: Creating secret with name s-test-opt-create-59ac30a3-591e-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:18:54.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7623" for this suite.
Apr  7 10:19:16.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:16.449: INFO: namespace projected-7623 deletion completed in 22.073808403s

• [SLOW TEST:106.492 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:16.450: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-99250360-591e-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:19:16.482: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2" in namespace "projected-6917" to be "success or failure"
Apr  7 10:19:16.486: INFO: Pod "pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.915141ms
Apr  7 10:19:18.489: INFO: Pod "pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006798135s
STEP: Saw pod success
Apr  7 10:19:18.489: INFO: Pod "pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:19:18.492: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:19:18.506: INFO: Waiting for pod pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:19:18.508: INFO: Pod pod-projected-configmaps-99256be4-591e-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:19:18.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6917" for this suite.
Apr  7 10:19:24.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:24.586: INFO: namespace projected-6917 deletion completed in 6.076278007s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:24.587: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-f9dx5 in namespace proxy-8990
I0407 10:19:24.620257      16 runners.go:184] Created replication controller with name: proxy-service-f9dx5, namespace: proxy-8990, replica count: 1
I0407 10:19:25.671796      16 runners.go:184] proxy-service-f9dx5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0407 10:19:26.672118      16 runners.go:184] proxy-service-f9dx5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0407 10:19:27.672310      16 runners.go:184] proxy-service-f9dx5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 10:19:27.674: INFO: setup took 3.063738351s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  7 10:19:27.683: INFO: (0) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 8.855046ms)
Apr  7 10:19:27.684: INFO: (0) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.357513ms)
Apr  7 10:19:27.686: INFO: (0) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.661928ms)
Apr  7 10:19:27.694: INFO: (0) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 19.002772ms)
Apr  7 10:19:27.694: INFO: (0) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 19.049817ms)
Apr  7 10:19:27.699: INFO: (0) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 24.934266ms)
Apr  7 10:19:27.700: INFO: (0) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 24.554499ms)
Apr  7 10:19:27.700: INFO: (0) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 24.801305ms)
Apr  7 10:19:27.700: INFO: (0) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 24.739795ms)
Apr  7 10:19:27.700: INFO: (0) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 24.574864ms)
Apr  7 10:19:27.701: INFO: (0) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 26.040178ms)
Apr  7 10:19:27.702: INFO: (0) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 27.653085ms)
Apr  7 10:19:27.702: INFO: (0) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 27.5397ms)
Apr  7 10:19:27.704: INFO: (0) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 29.224981ms)
Apr  7 10:19:27.704: INFO: (0) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 29.534361ms)
Apr  7 10:19:27.711: INFO: (0) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 35.958305ms)
Apr  7 10:19:27.719: INFO: (1) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 8.407861ms)
Apr  7 10:19:27.720: INFO: (1) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 8.754691ms)
Apr  7 10:19:27.720: INFO: (1) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 8.764982ms)
Apr  7 10:19:27.722: INFO: (1) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.711307ms)
Apr  7 10:19:27.723: INFO: (1) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.744086ms)
Apr  7 10:19:27.723: INFO: (1) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 11.321052ms)
Apr  7 10:19:27.723: INFO: (1) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.924953ms)
Apr  7 10:19:27.724: INFO: (1) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 12.01012ms)
Apr  7 10:19:27.724: INFO: (1) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 11.777802ms)
Apr  7 10:19:27.724: INFO: (1) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.747989ms)
Apr  7 10:19:27.724: INFO: (1) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 11.805535ms)
Apr  7 10:19:27.725: INFO: (1) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 12.606814ms)
Apr  7 10:19:27.725: INFO: (1) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 12.776133ms)
Apr  7 10:19:27.725: INFO: (1) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 12.87093ms)
Apr  7 10:19:27.725: INFO: (1) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 12.712156ms)
Apr  7 10:19:27.725: INFO: (1) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 13.249673ms)
Apr  7 10:19:27.734: INFO: (2) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 8.084109ms)
Apr  7 10:19:27.734: INFO: (2) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 8.041163ms)
Apr  7 10:19:27.734: INFO: (2) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.978355ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.522063ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.39533ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.885939ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 10.827096ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.851496ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.779967ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.442349ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 10.528635ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 10.828576ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.683948ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 10.864602ms)
Apr  7 10:19:27.736: INFO: (2) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.795746ms)
Apr  7 10:19:27.737: INFO: (2) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.43614ms)
Apr  7 10:19:27.745: INFO: (3) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 7.856649ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.01763ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.319429ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.570906ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 10.505148ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.554971ms)
Apr  7 10:19:27.748: INFO: (3) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.917046ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 11.661011ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.181738ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.338435ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 11.215546ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.692846ms)
Apr  7 10:19:27.749: INFO: (3) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 11.475342ms)
Apr  7 10:19:27.750: INFO: (3) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 12.021584ms)
Apr  7 10:19:27.750: INFO: (3) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 12.482574ms)
Apr  7 10:19:27.751: INFO: (3) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 12.940089ms)
Apr  7 10:19:27.754: INFO: (4) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 3.671593ms)
Apr  7 10:19:27.758: INFO: (4) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 7.256493ms)
Apr  7 10:19:27.758: INFO: (4) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 7.221638ms)
Apr  7 10:19:27.758: INFO: (4) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.184342ms)
Apr  7 10:19:27.761: INFO: (4) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 9.728863ms)
Apr  7 10:19:27.763: INFO: (4) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 12.134192ms)
Apr  7 10:19:27.763: INFO: (4) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 12.705752ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 12.678398ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 12.740411ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 12.632223ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 12.866057ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 13.004797ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 13.008965ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 13.320248ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 13.453512ms)
Apr  7 10:19:27.764: INFO: (4) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 13.508171ms)
Apr  7 10:19:27.771: INFO: (5) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 6.274048ms)
Apr  7 10:19:27.771: INFO: (5) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 6.639551ms)
Apr  7 10:19:27.771: INFO: (5) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 6.822293ms)
Apr  7 10:19:27.772: INFO: (5) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.343463ms)
Apr  7 10:19:27.772: INFO: (5) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.449826ms)
Apr  7 10:19:27.773: INFO: (5) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 7.83034ms)
Apr  7 10:19:27.773: INFO: (5) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.772082ms)
Apr  7 10:19:27.774: INFO: (5) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 9.147673ms)
Apr  7 10:19:27.774: INFO: (5) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 9.083169ms)
Apr  7 10:19:27.776: INFO: (5) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.472024ms)
Apr  7 10:19:27.776: INFO: (5) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 10.109629ms)
Apr  7 10:19:27.776: INFO: (5) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.292812ms)
Apr  7 10:19:27.776: INFO: (5) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.551594ms)
Apr  7 10:19:27.776: INFO: (5) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.066044ms)
Apr  7 10:19:27.777: INFO: (5) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.666257ms)
Apr  7 10:19:27.777: INFO: (5) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 11.411454ms)
Apr  7 10:19:27.783: INFO: (6) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 6.252617ms)
Apr  7 10:19:27.785: INFO: (6) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.481609ms)
Apr  7 10:19:27.786: INFO: (6) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 8.492665ms)
Apr  7 10:19:27.786: INFO: (6) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 8.929767ms)
Apr  7 10:19:27.786: INFO: (6) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 9.084401ms)
Apr  7 10:19:27.787: INFO: (6) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 9.446063ms)
Apr  7 10:19:27.787: INFO: (6) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.832679ms)
Apr  7 10:19:27.787: INFO: (6) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.916389ms)
Apr  7 10:19:27.787: INFO: (6) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 9.867888ms)
Apr  7 10:19:27.788: INFO: (6) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 10.365165ms)
Apr  7 10:19:27.788: INFO: (6) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.45842ms)
Apr  7 10:19:27.788: INFO: (6) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.570062ms)
Apr  7 10:19:27.790: INFO: (6) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 12.101368ms)
Apr  7 10:19:27.790: INFO: (6) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 12.176181ms)
Apr  7 10:19:27.790: INFO: (6) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 12.917604ms)
Apr  7 10:19:27.790: INFO: (6) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 13.298255ms)
Apr  7 10:19:27.798: INFO: (7) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 7.544286ms)
Apr  7 10:19:27.798: INFO: (7) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 7.51929ms)
Apr  7 10:19:27.799: INFO: (7) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 8.221065ms)
Apr  7 10:19:27.800: INFO: (7) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 8.753671ms)
Apr  7 10:19:27.800: INFO: (7) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 8.619111ms)
Apr  7 10:19:27.800: INFO: (7) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.049483ms)
Apr  7 10:19:27.800: INFO: (7) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 9.649854ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.819027ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.29645ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.458045ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 10.257327ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.112974ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.884313ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.835569ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.705253ms)
Apr  7 10:19:27.802: INFO: (7) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.783842ms)
Apr  7 10:19:27.808: INFO: (8) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 5.733297ms)
Apr  7 10:19:27.812: INFO: (8) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 8.774826ms)
Apr  7 10:19:27.812: INFO: (8) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.687812ms)
Apr  7 10:19:27.812: INFO: (8) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 9.812969ms)
Apr  7 10:19:27.812: INFO: (8) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 9.768724ms)
Apr  7 10:19:27.812: INFO: (8) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 9.858677ms)
Apr  7 10:19:27.813: INFO: (8) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.105876ms)
Apr  7 10:19:27.813: INFO: (8) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.013519ms)
Apr  7 10:19:27.813: INFO: (8) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 10.242186ms)
Apr  7 10:19:27.813: INFO: (8) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 11.090801ms)
Apr  7 10:19:27.814: INFO: (8) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.726322ms)
Apr  7 10:19:27.814: INFO: (8) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 11.988228ms)
Apr  7 10:19:27.814: INFO: (8) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 12.340287ms)
Apr  7 10:19:27.815: INFO: (8) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 12.475676ms)
Apr  7 10:19:27.815: INFO: (8) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 12.583936ms)
Apr  7 10:19:27.815: INFO: (8) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 12.367903ms)
Apr  7 10:19:27.820: INFO: (9) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 5.343654ms)
Apr  7 10:19:27.822: INFO: (9) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.404353ms)
Apr  7 10:19:27.822: INFO: (9) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 7.236052ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 7.663466ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.861808ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 7.608237ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.875087ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 7.870005ms)
Apr  7 10:19:27.823: INFO: (9) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 8.15868ms)
Apr  7 10:19:27.824: INFO: (9) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 8.427119ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.505392ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.661496ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.607723ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 11.910155ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 12.170875ms)
Apr  7 10:19:27.827: INFO: (9) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.87322ms)
Apr  7 10:19:27.832: INFO: (10) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 4.48708ms)
Apr  7 10:19:27.835: INFO: (10) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 7.288124ms)
Apr  7 10:19:27.835: INFO: (10) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 7.94717ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 8.282981ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 8.778817ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 8.733325ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 8.449424ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.058605ms)
Apr  7 10:19:27.836: INFO: (10) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.087917ms)
Apr  7 10:19:27.837: INFO: (10) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.253225ms)
Apr  7 10:19:27.838: INFO: (10) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.522871ms)
Apr  7 10:19:27.838: INFO: (10) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.854569ms)
Apr  7 10:19:27.838: INFO: (10) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.814012ms)
Apr  7 10:19:27.838: INFO: (10) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.796357ms)
Apr  7 10:19:27.838: INFO: (10) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.01518ms)
Apr  7 10:19:27.839: INFO: (10) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.103763ms)
Apr  7 10:19:27.841: INFO: (11) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 2.664067ms)
Apr  7 10:19:27.849: INFO: (11) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.651381ms)
Apr  7 10:19:27.849: INFO: (11) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 9.418507ms)
Apr  7 10:19:27.849: INFO: (11) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.195787ms)
Apr  7 10:19:27.849: INFO: (11) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.977242ms)
Apr  7 10:19:27.850: INFO: (11) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.594225ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.464276ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 10.958448ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 10.942754ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 11.06636ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 11.95216ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 11.25516ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.855116ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 12.065654ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 11.848595ms)
Apr  7 10:19:27.851: INFO: (11) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 12.022297ms)
Apr  7 10:19:27.859: INFO: (12) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 7.731828ms)
Apr  7 10:19:27.859: INFO: (12) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 7.673791ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.658059ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.644219ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 10.710749ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.011754ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 10.875328ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.809921ms)
Apr  7 10:19:27.862: INFO: (12) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.965585ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.961764ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.968509ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 10.97522ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 11.184317ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.826772ms)
Apr  7 10:19:27.863: INFO: (12) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 11.890368ms)
Apr  7 10:19:27.864: INFO: (12) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 12.511543ms)
Apr  7 10:19:27.870: INFO: (13) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 5.675457ms)
Apr  7 10:19:27.870: INFO: (13) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 5.839342ms)
Apr  7 10:19:27.872: INFO: (13) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.277403ms)
Apr  7 10:19:27.874: INFO: (13) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.249348ms)
Apr  7 10:19:27.874: INFO: (13) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 8.444163ms)
Apr  7 10:19:27.874: INFO: (13) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 8.645845ms)
Apr  7 10:19:27.874: INFO: (13) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 9.613249ms)
Apr  7 10:19:27.874: INFO: (13) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 9.814205ms)
Apr  7 10:19:27.876: INFO: (13) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.152927ms)
Apr  7 10:19:27.876: INFO: (13) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.572901ms)
Apr  7 10:19:27.876: INFO: (13) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 10.665902ms)
Apr  7 10:19:27.876: INFO: (13) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 11.450664ms)
Apr  7 10:19:27.877: INFO: (13) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 11.90324ms)
Apr  7 10:19:27.877: INFO: (13) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 12.026319ms)
Apr  7 10:19:27.877: INFO: (13) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 12.427814ms)
Apr  7 10:19:27.877: INFO: (13) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 12.399473ms)
Apr  7 10:19:27.883: INFO: (14) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 5.249745ms)
Apr  7 10:19:27.887: INFO: (14) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 9.106017ms)
Apr  7 10:19:27.888: INFO: (14) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.165061ms)
Apr  7 10:19:27.888: INFO: (14) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.683593ms)
Apr  7 10:19:27.888: INFO: (14) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.233755ms)
Apr  7 10:19:27.889: INFO: (14) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.477166ms)
Apr  7 10:19:27.889: INFO: (14) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.461808ms)
Apr  7 10:19:27.890: INFO: (14) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 12.030575ms)
Apr  7 10:19:27.890: INFO: (14) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 12.003193ms)
Apr  7 10:19:27.890: INFO: (14) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 12.698198ms)
Apr  7 10:19:27.890: INFO: (14) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 12.063749ms)
Apr  7 10:19:27.891: INFO: (14) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 12.939043ms)
Apr  7 10:19:27.891: INFO: (14) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 12.585753ms)
Apr  7 10:19:27.891: INFO: (14) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 12.877536ms)
Apr  7 10:19:27.891: INFO: (14) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 13.079567ms)
Apr  7 10:19:27.891: INFO: (14) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 12.972207ms)
Apr  7 10:19:27.900: INFO: (15) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 8.401322ms)
Apr  7 10:19:27.900: INFO: (15) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 9.343003ms)
Apr  7 10:19:27.900: INFO: (15) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 9.291202ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.619059ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 9.282086ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.44758ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.838074ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 9.819191ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.818684ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 10.296541ms)
Apr  7 10:19:27.901: INFO: (15) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 10.174759ms)
Apr  7 10:19:27.902: INFO: (15) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.726926ms)
Apr  7 10:19:27.902: INFO: (15) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.759825ms)
Apr  7 10:19:27.902: INFO: (15) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 10.615574ms)
Apr  7 10:19:27.902: INFO: (15) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.065593ms)
Apr  7 10:19:27.902: INFO: (15) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 11.047023ms)
Apr  7 10:19:27.910: INFO: (16) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.047404ms)
Apr  7 10:19:27.910: INFO: (16) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 7.00947ms)
Apr  7 10:19:27.910: INFO: (16) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 7.90996ms)
Apr  7 10:19:27.910: INFO: (16) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 7.790718ms)
Apr  7 10:19:27.911: INFO: (16) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 8.441564ms)
Apr  7 10:19:27.911: INFO: (16) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 8.605715ms)
Apr  7 10:19:27.911: INFO: (16) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 8.921424ms)
Apr  7 10:19:27.911: INFO: (16) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 8.592533ms)
Apr  7 10:19:27.912: INFO: (16) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 8.927864ms)
Apr  7 10:19:27.912: INFO: (16) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 8.910783ms)
Apr  7 10:19:27.913: INFO: (16) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 10.267807ms)
Apr  7 10:19:27.913: INFO: (16) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 10.294251ms)
Apr  7 10:19:27.913: INFO: (16) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.390389ms)
Apr  7 10:19:27.913: INFO: (16) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.613172ms)
Apr  7 10:19:27.914: INFO: (16) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.949069ms)
Apr  7 10:19:27.914: INFO: (16) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.8735ms)
Apr  7 10:19:27.923: INFO: (17) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 8.477962ms)
Apr  7 10:19:27.923: INFO: (17) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.403154ms)
Apr  7 10:19:27.923: INFO: (17) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.002997ms)
Apr  7 10:19:27.923: INFO: (17) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 9.725551ms)
Apr  7 10:19:27.924: INFO: (17) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.596561ms)
Apr  7 10:19:27.924: INFO: (17) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 10.201376ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 10.024969ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 11.00975ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 10.961542ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 10.789485ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.913911ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 10.33564ms)
Apr  7 10:19:27.925: INFO: (17) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 10.461173ms)
Apr  7 10:19:27.926: INFO: (17) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.358597ms)
Apr  7 10:19:27.926: INFO: (17) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.3441ms)
Apr  7 10:19:27.926: INFO: (17) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 11.323182ms)
Apr  7 10:19:27.929: INFO: (18) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 3.127722ms)
Apr  7 10:19:27.934: INFO: (18) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 8.19377ms)
Apr  7 10:19:27.935: INFO: (18) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 8.749251ms)
Apr  7 10:19:27.935: INFO: (18) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 8.81939ms)
Apr  7 10:19:27.935: INFO: (18) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 8.806665ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 9.436051ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.658188ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 9.373917ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 9.808043ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 9.735636ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 9.774131ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.345827ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 9.955424ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.916491ms)
Apr  7 10:19:27.936: INFO: (18) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.878273ms)
Apr  7 10:19:27.937: INFO: (18) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 10.638466ms)
Apr  7 10:19:27.942: INFO: (19) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:443/proxy/tlsrewritem... (200; 4.949696ms)
Apr  7 10:19:27.942: INFO: (19) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 5.213445ms)
Apr  7 10:19:27.946: INFO: (19) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">test<... (200; 8.392561ms)
Apr  7 10:19:27.946: INFO: (19) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:460/proxy/: tls baz (200; 8.669265ms)
Apr  7 10:19:27.946: INFO: (19) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.052396ms)
Apr  7 10:19:27.947: INFO: (19) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:160/proxy/: foo (200; 9.399583ms)
Apr  7 10:19:27.947: INFO: (19) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl:162/proxy/: bar (200; 9.530013ms)
Apr  7 10:19:27.947: INFO: (19) /api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/proxy-service-f9dx5-hjcnl/proxy/rewriteme">test</a> (200; 9.942136ms)
Apr  7 10:19:27.947: INFO: (19) /api/v1/namespaces/proxy-8990/pods/https:proxy-service-f9dx5-hjcnl:462/proxy/: tls qux (200; 9.684452ms)
Apr  7 10:19:27.948: INFO: (19) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname2/proxy/: tls qux (200; 10.870912ms)
Apr  7 10:19:27.948: INFO: (19) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname2/proxy/: bar (200; 11.292507ms)
Apr  7 10:19:27.948: INFO: (19) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname2/proxy/: bar (200; 11.133261ms)
Apr  7 10:19:27.949: INFO: (19) /api/v1/namespaces/proxy-8990/services/proxy-service-f9dx5:portname1/proxy/: foo (200; 11.37294ms)
Apr  7 10:19:27.949: INFO: (19) /api/v1/namespaces/proxy-8990/services/https:proxy-service-f9dx5:tlsportname1/proxy/: tls baz (200; 11.341864ms)
Apr  7 10:19:27.949: INFO: (19) /api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/: <a href="/api/v1/namespaces/proxy-8990/pods/http:proxy-service-f9dx5-hjcnl:1080/proxy/rewriteme">... (200; 11.627884ms)
Apr  7 10:19:27.949: INFO: (19) /api/v1/namespaces/proxy-8990/services/http:proxy-service-f9dx5:portname1/proxy/: foo (200; 11.655435ms)
STEP: deleting ReplicationController proxy-service-f9dx5 in namespace proxy-8990, will wait for the garbage collector to delete the pods
Apr  7 10:19:28.006: INFO: Deleting ReplicationController proxy-service-f9dx5 took: 4.611176ms
Apr  7 10:19:28.306: INFO: Terminating ReplicationController proxy-service-f9dx5 pods took: 300.366364ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:19:31.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8990" for this suite.
Apr  7 10:19:37.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:37.487: INFO: namespace proxy-8990 deletion completed in 6.077750939s

• [SLOW TEST:12.900 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:37.487: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:19:39.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7876" for this suite.
Apr  7 10:19:45.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:45.624: INFO: namespace emptydir-wrapper-7876 deletion completed in 6.076385187s

• [SLOW TEST:8.137 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:45.625: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  7 10:19:45.660: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3906,SelfLink:/api/v1/namespaces/watch-3906/configmaps/e2e-watch-test-watch-closed,UID:aa84a8e0-591e-11e9-99b0-0225f4f52196,ResourceVersion:10725,Generation:0,CreationTimestamp:2019-04-07 10:19:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  7 10:19:45.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3906,SelfLink:/api/v1/namespaces/watch-3906/configmaps/e2e-watch-test-watch-closed,UID:aa84a8e0-591e-11e9-99b0-0225f4f52196,ResourceVersion:10726,Generation:0,CreationTimestamp:2019-04-07 10:19:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  7 10:19:45.669: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3906,SelfLink:/api/v1/namespaces/watch-3906/configmaps/e2e-watch-test-watch-closed,UID:aa84a8e0-591e-11e9-99b0-0225f4f52196,ResourceVersion:10727,Generation:0,CreationTimestamp:2019-04-07 10:19:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  7 10:19:45.669: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3906,SelfLink:/api/v1/namespaces/watch-3906/configmaps/e2e-watch-test-watch-closed,UID:aa84a8e0-591e-11e9-99b0-0225f4f52196,ResourceVersion:10728,Generation:0,CreationTimestamp:2019-04-07 10:19:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:19:45.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3906" for this suite.
Apr  7 10:19:51.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:51.750: INFO: namespace watch-3906 deletion completed in 6.078034635s

• [SLOW TEST:6.125 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:51.751: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ae2fb4b8-591e-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:19:51.784: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2" in namespace "configmap-19" to be "success or failure"
Apr  7 10:19:51.787: INFO: Pod "pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.934311ms
Apr  7 10:19:53.791: INFO: Pod "pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006714397s
STEP: Saw pod success
Apr  7 10:19:53.791: INFO: Pod "pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:19:53.793: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:19:53.809: INFO: Waiting for pod pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:19:53.811: INFO: Pod pod-configmaps-ae3015d6-591e-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:19:53.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-19" for this suite.
Apr  7 10:19:59.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:19:59.893: INFO: namespace configmap-19 deletion completed in 6.079352385s

• [SLOW TEST:8.142 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:19:59.893: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  7 10:20:03.945: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:03.949: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:05.949: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:05.952: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:07.949: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:07.952: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:09.957: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:09.960: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:11.949: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:11.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:13.949: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:13.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:15.950: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:15.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:17.950: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:17.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:19.950: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:19.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:21.949: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:21.953: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 10:20:23.950: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 10:20:23.952: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:20:23.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4228" for this suite.
Apr  7 10:20:45.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:20:46.050: INFO: namespace container-lifecycle-hook-4228 deletion completed in 22.084159505s

• [SLOW TEST:46.157 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:20:46.051: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-ce8d1026-591e-11e9-9aa1-1aed65326ff2
STEP: Creating secret with name s-test-opt-upd-ce8d1067-591e-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ce8d1026-591e-11e9-9aa1-1aed65326ff2
STEP: Updating secret s-test-opt-upd-ce8d1067-591e-11e9-9aa1-1aed65326ff2
STEP: Creating secret with name s-test-opt-create-ce8d1081-591e-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:20:50.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5241" for this suite.
Apr  7 10:21:12.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:21:12.228: INFO: namespace secrets-5241 deletion completed in 22.072988031s

• [SLOW TEST:26.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:21:12.231: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:21:12.252: INFO: Creating deployment "nginx-deployment"
Apr  7 10:21:12.255: INFO: Waiting for observed generation 1
Apr  7 10:21:14.263: INFO: Waiting for all required pods to come up
Apr  7 10:21:14.266: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  7 10:21:16.278: INFO: Waiting for deployment "nginx-deployment" to complete
Apr  7 10:21:16.283: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr  7 10:21:16.289: INFO: Updating deployment nginx-deployment
Apr  7 10:21:16.289: INFO: Waiting for observed generation 2
Apr  7 10:21:18.294: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  7 10:21:18.296: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  7 10:21:18.298: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  7 10:21:18.304: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  7 10:21:18.304: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  7 10:21:18.306: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  7 10:21:18.310: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr  7 10:21:18.310: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr  7 10:21:18.316: INFO: Updating deployment nginx-deployment
Apr  7 10:21:18.316: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr  7 10:21:18.326: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  7 10:21:18.331: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  7 10:21:18.352: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8790,SelfLink:/apis/apps/v1/namespaces/deployment-8790/deployments/nginx-deployment,UID:de229bff-591e-11e9-99b0-0225f4f52196,ResourceVersion:11289,Generation:3,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-04-07 10:21:16 +0000 UTC 2019-04-07 10:21:12 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-04-07 10:21:18 +0000 UTC 2019-04-07 10:21:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr  7 10:21:18.365: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8790,SelfLink:/apis/apps/v1/namespaces/deployment-8790/replicasets/nginx-deployment-5f9595f595,UID:e08a6921-591e-11e9-99b0-0225f4f52196,ResourceVersion:11279,Generation:3,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment de229bff-591e-11e9-99b0-0225f4f52196 0xc0013a1707 0xc0013a1708}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 10:21:18.365: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr  7 10:21:18.365: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-8790,SelfLink:/apis/apps/v1/namespaces/deployment-8790/replicasets/nginx-deployment-6f478d8d8,UID:de230c4c-591e-11e9-99b0-0225f4f52196,ResourceVersion:11277,Generation:3,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment de229bff-591e-11e9-99b0-0225f4f52196 0xc0013a17d7 0xc0013a17d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr  7 10:21:18.400: INFO: Pod "nginx-deployment-5f9595f595-4m5z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4m5z5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-4m5z5,UID:e1c23d04-591e-11e9-99b0-0225f4f52196,ResourceVersion:11292,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc0016e5d77 0xc0016e5d78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016e5e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016e5ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.400: INFO: Pod "nginx-deployment-5f9595f595-4ng9v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4ng9v,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-4ng9v,UID:e1c529e7-591e-11e9-99b0-0225f4f52196,ResourceVersion:11297,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc0016e5f90 0xc0016e5f91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-9x9zs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9x9zs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-9x9zs,UID:e1c48901-591e-11e9-99b0-0225f4f52196,ResourceVersion:11304,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e107 0xc000e9e108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-c6nps" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-c6nps,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-c6nps,UID:e1c8715e-591e-11e9-99b0-0225f4f52196,ResourceVersion:11303,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e240 0xc000e9e241}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-dh9tf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dh9tf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-dh9tf,UID:e08beb6d-591e-11e9-99b0-0225f4f52196,ResourceVersion:11257,Generation:0,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.74/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e347 0xc000e9e348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.74,StartTime:2019-04-07 10:21:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-gglkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-gglkr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-gglkr,UID:e08c319e-591e-11e9-99b0-0225f4f52196,ResourceVersion:11260,Generation:0,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.73/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e500 0xc000e9e501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.73,StartTime:2019-04-07 10:21:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-qmdqd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qmdqd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-qmdqd,UID:e1c89c87-591e-11e9-99b0-0225f4f52196,ResourceVersion:11305,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e690 0xc000e9e691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-v5nc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-v5nc6,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-v5nc6,UID:e08b053f-591e-11e9-99b0-0225f4f52196,ResourceVersion:11253,Generation:0,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.78/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e797 0xc000e9e798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:,StartTime:2019-04-07 10:21:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.401: INFO: Pod "nginx-deployment-5f9595f595-v9lqx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-v9lqx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-v9lqx,UID:e09505a2-591e-11e9-99b0-0225f4f52196,ResourceVersion:11254,Generation:0,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.79/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9e920 0xc000e9e921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9e9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9e9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:,StartTime:2019-04-07 10:21:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-5f9595f595-whhzx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-whhzx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-whhzx,UID:e1c8ae8a-591e-11e9-99b0-0225f4f52196,ResourceVersion:11307,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9ea90 0xc000e9ea91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9eb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9eb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-5f9595f595-xq2mb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xq2mb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-5f9595f595-xq2mb,UID:e0962814-591e-11e9-99b0-0225f4f52196,ResourceVersion:11269,Generation:0,CreationTimestamp:2019-04-07 10:21:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.77/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 e08a6921-591e-11e9-99b0-0225f4f52196 0xc000e9eb97 0xc000e9eb98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9ec10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9ec30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:16 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.77,StartTime:2019-04-07 10:21:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-6f478d8d8-42cpm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-42cpm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-42cpm,UID:de287437-591e-11e9-99b0-0225f4f52196,ResourceVersion:11142,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.74/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9ed30 0xc000e9ed31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9eda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9edc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.74,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://f3469370d236967e5338bdf33e58dd6b749b5267e056ee275b416321eda430c5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-6f478d8d8-5pmd6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-5pmd6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-5pmd6,UID:e1c51200-591e-11e9-99b0-0225f4f52196,ResourceVersion:11296,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9eeb0 0xc000e9eeb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9ef10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9ef30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-6f478d8d8-fhnsx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fhnsx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-fhnsx,UID:de2aab3d-591e-11e9-99b0-0225f4f52196,ResourceVersion:11154,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.70/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9efa7 0xc000e9efa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.70,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://fdba8a0610e60486350925e9f3f58725264d2000198a66029952814a2f441239}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.402: INFO: Pod "nginx-deployment-6f478d8d8-gq6zg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gq6zg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-gq6zg,UID:e1c1802d-591e-11e9-99b0-0225f4f52196,ResourceVersion:11290,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f130 0xc000e9f131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-hfx7g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hfx7g,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-hfx7g,UID:de28c304-591e-11e9-99b0-0225f4f52196,ResourceVersion:11149,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.72/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f290 0xc000e9f291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.72,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://2f7d5c5bc1bb62bbd41eff7732128455f16b48680e7eb0e774d956fd5693ee18}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-hxrjn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hxrjn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-hxrjn,UID:de26cb1f-591e-11e9-99b0-0225f4f52196,ResourceVersion:11151,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.69/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f420 0xc000e9f421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.69,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://6f2218be2783ba832f81d1f7e882419701f69d14245fd917cd520a86f96d2df5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-jx42s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jx42s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-jx42s,UID:de2880d7-591e-11e9-99b0-0225f4f52196,ResourceVersion:11130,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.75/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f590 0xc000e9f591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.75,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d40dbf940469b43ed363f2f7ff71a1a5397e85e28c2e84656953a8ed22782912}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-mhr7r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mhr7r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-mhr7r,UID:e1c49a53-591e-11e9-99b0-0225f4f52196,ResourceVersion:11306,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f6f0 0xc000e9f6f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-psfd2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-psfd2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-psfd2,UID:de2438ab-591e-11e9-99b0-0225f4f52196,ResourceVersion:11146,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.68/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f810 0xc000e9f811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9f8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.68,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://bdcb746034d92eff40321403a8603e8b86498634155479d240d34ff3f2b2dfc6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-qfl7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qfl7p,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-qfl7p,UID:e1c40d10-591e-11e9-99b0-0225f4f52196,ResourceVersion:11299,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9f970 0xc000e9f971}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9f9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9fa00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-qncmn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qncmn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-qncmn,UID:de2a95e6-591e-11e9-99b0-0225f4f52196,ResourceVersion:11158,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.210.71/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9fa90 0xc000e9fa91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-29-139,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9fb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9fb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.29.139,PodIP:10.2.210.71,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://cfea9dcd71ac875b39e4e233273d23c4802bd09f1df359a698cf436ffe89d4d2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-r2d5j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-r2d5j,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-r2d5j,UID:de2ab7bd-591e-11e9-99b0-0225f4f52196,ResourceVersion:11136,Generation:0,CreationTimestamp:2019-04-07 10:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.76/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9fc00 0xc000e9fc01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9fc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9fc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.76,StartTime:2019-04-07 10:21:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-07 10:21:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://aa04fc56223192a9e8da8c28662b9ccb090a28b65ee28120b95cf53f40b6760b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.403: INFO: Pod "nginx-deployment-6f478d8d8-tmdxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tmdxb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-tmdxb,UID:e1c159f5-591e-11e9-99b0-0225f4f52196,ResourceVersion:11285,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9fd80 0xc000e9fd81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9fe00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9fe20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.404: INFO: Pod "nginx-deployment-6f478d8d8-vv86q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vv86q,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-vv86q,UID:e1c51d4f-591e-11e9-99b0-0225f4f52196,ResourceVersion:11295,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9fea0 0xc000e9fea1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e9ff00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e9ff20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  7 10:21:18.404: INFO: Pod "nginx-deployment-6f478d8d8-zsrj6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zsrj6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8790,SelfLink:/api/v1/namespaces/deployment-8790/pods/nginx-deployment-6f478d8d8-zsrj6,UID:e1c05cbb-591e-11e9-99b0-0225f4f52196,ResourceVersion:11298,Generation:0,CreationTimestamp:2019-04-07 10:21:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 de230c4c-591e-11e9-99b0-0225f4f52196 0xc000e9ff87 0xc000e9ff88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r7knb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7knb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7knb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d40090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d400b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:21:18 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:,StartTime:2019-04-07 10:21:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:21:18.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8790" for this suite.
Apr  7 10:21:24.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:21:24.541: INFO: namespace deployment-8790 deletion completed in 6.123593326s

• [SLOW TEST:12.310 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:21:24.541: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0407 10:21:34.699713      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 10:21:34.699: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:21:34.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-489" for this suite.
Apr  7 10:21:40.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:21:40.781: INFO: namespace gc-489 deletion completed in 6.077050457s

• [SLOW TEST:16.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:21:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr  7 10:21:40.808: INFO: Waiting up to 5m0s for pod "client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2" in namespace "containers-1381" to be "success or failure"
Apr  7 10:21:40.811: INFO: Pod "client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.429054ms
Apr  7 10:21:42.814: INFO: Pod "client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006442945s
Apr  7 10:21:44.821: INFO: Pod "client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013236838s
STEP: Saw pod success
Apr  7 10:21:44.821: INFO: Pod "client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:21:44.824: INFO: Trying to get logs from node ip-10-0-29-139 pod client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:21:44.838: INFO: Waiting for pod client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:21:44.840: INFO: Pod client-containers-ef2c17d1-591e-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:21:44.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1381" for this suite.
Apr  7 10:21:50.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:21:50.917: INFO: namespace containers-1381 deletion completed in 6.073017179s

• [SLOW TEST:10.134 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:21:50.917: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr  7 10:21:50.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  7 10:21:50.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:51.222: INFO: stderr: ""
Apr  7 10:21:51.222: INFO: stdout: "service/redis-slave created\n"
Apr  7 10:21:51.222: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  7 10:21:51.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:51.401: INFO: stderr: ""
Apr  7 10:21:51.401: INFO: stdout: "service/redis-master created\n"
Apr  7 10:21:51.401: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  7 10:21:51.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:51.580: INFO: stderr: ""
Apr  7 10:21:51.580: INFO: stdout: "service/frontend created\n"
Apr  7 10:21:51.580: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  7 10:21:51.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:51.769: INFO: stderr: ""
Apr  7 10:21:51.769: INFO: stdout: "deployment.apps/frontend created\n"
Apr  7 10:21:51.770: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  7 10:21:51.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:51.935: INFO: stderr: ""
Apr  7 10:21:51.935: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  7 10:21:51.936: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  7 10:21:51.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8698'
Apr  7 10:21:52.091: INFO: stderr: ""
Apr  7 10:21:52.091: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  7 10:21:52.091: INFO: Waiting for all frontend pods to be Running.
Apr  7 10:22:07.141: INFO: Waiting for frontend to serve content.
Apr  7 10:22:12.157: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr  7 10:22:17.169: INFO: Trying to add a new entry to the guestbook.
Apr  7 10:22:17.178: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  7 10:22:17.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.275: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.275: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 10:22:17.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.381: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.381: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 10:22:17.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.484: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.484: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 10:22:17.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.594: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.594: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 10:22:17.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.660: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.660: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 10:22:17.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-8698'
Apr  7 10:22:17.740: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:22:17.740: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:22:17.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8698" for this suite.
Apr  7 10:22:55.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:22:55.827: INFO: namespace kubectl-8698 deletion completed in 38.080609843s

• [SLOW TEST:64.909 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:22:55.828: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  7 10:22:55.868: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12391,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  7 10:22:55.868: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12392,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  7 10:22:55.868: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12393,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  7 10:23:05.886: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12410,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  7 10:23:05.886: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12411,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  7 10:23:05.886: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6256,SelfLink:/api/v1/namespaces/watch-6256/configmaps/e2e-watch-test-label-changed,UID:1be32466-591f-11e9-99b0-0225f4f52196,ResourceVersion:12412,Generation:0,CreationTimestamp:2019-04-07 10:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:05.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6256" for this suite.
Apr  7 10:23:11.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:11.961: INFO: namespace watch-6256 deletion completed in 6.072427529s

• [SLOW TEST:16.132 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:11.961: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr  7 10:23:11.988: INFO: Waiting up to 5m0s for pod "client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2" in namespace "containers-8747" to be "success or failure"
Apr  7 10:23:11.992: INFO: Pod "client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.931709ms
Apr  7 10:23:13.995: INFO: Pod "client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006662077s
Apr  7 10:23:15.998: INFO: Pod "client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009659432s
STEP: Saw pod success
Apr  7 10:23:15.998: INFO: Pod "client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:23:16.000: INFO: Trying to get logs from node ip-10-0-39-198 pod client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:23:16.013: INFO: Waiting for pod client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:23:16.015: INFO: Pod client-containers-258501c3-591f-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:16.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8747" for this suite.
Apr  7 10:23:22.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:22.088: INFO: namespace containers-8747 deletion completed in 6.070662052s

• [SLOW TEST:10.127 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:22.089: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  7 10:23:22.120: INFO: Waiting up to 5m0s for pod "pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2" in namespace "emptydir-9385" to be "success or failure"
Apr  7 10:23:22.122: INFO: Pod "pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186948ms
Apr  7 10:23:24.125: INFO: Pod "pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005117102s
Apr  7 10:23:26.128: INFO: Pod "pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008032195s
STEP: Saw pod success
Apr  7 10:23:26.128: INFO: Pod "pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:23:26.130: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:23:26.142: INFO: Waiting for pod pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:23:26.144: INFO: Pod pod-2b8ea5c4-591f-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:26.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9385" for this suite.
Apr  7 10:23:32.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:32.225: INFO: namespace emptydir-9385 deletion completed in 6.077981267s

• [SLOW TEST:10.136 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:32.225: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr  7 10:23:32.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-4325'
Apr  7 10:23:32.405: INFO: stderr: ""
Apr  7 10:23:32.405: INFO: stdout: "pod/pause created\n"
Apr  7 10:23:32.405: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  7 10:23:32.405: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4325" to be "running and ready"
Apr  7 10:23:32.413: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167817ms
Apr  7 10:23:34.416: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011079667s
Apr  7 10:23:34.416: INFO: Pod "pause" satisfied condition "running and ready"
Apr  7 10:23:34.416: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  7 10:23:34.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 label pods pause testing-label=testing-label-value --namespace=kubectl-4325'
Apr  7 10:23:34.501: INFO: stderr: ""
Apr  7 10:23:34.501: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  7 10:23:34.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pod pause -L testing-label --namespace=kubectl-4325'
Apr  7 10:23:34.569: INFO: stderr: ""
Apr  7 10:23:34.569: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  7 10:23:34.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 label pods pause testing-label- --namespace=kubectl-4325'
Apr  7 10:23:34.658: INFO: stderr: ""
Apr  7 10:23:34.658: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  7 10:23:34.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pod pause -L testing-label --namespace=kubectl-4325'
Apr  7 10:23:34.733: INFO: stderr: ""
Apr  7 10:23:34.733: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr  7 10:23:34.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-4325'
Apr  7 10:23:34.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:23:34.867: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  7 10:23:34.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=pause --no-headers --namespace=kubectl-4325'
Apr  7 10:23:34.944: INFO: stderr: "No resources found.\n"
Apr  7 10:23:34.944: INFO: stdout: ""
Apr  7 10:23:34.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=pause --namespace=kubectl-4325 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 10:23:35.026: INFO: stderr: ""
Apr  7 10:23:35.026: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:35.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4325" for this suite.
Apr  7 10:23:41.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:41.104: INFO: namespace kubectl-4325 deletion completed in 6.075056134s

• [SLOW TEST:8.879 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:41.105: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-36e3a7ca-591f-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:23:41.132: INFO: Waiting up to 5m0s for pod "pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2" in namespace "configmap-7487" to be "success or failure"
Apr  7 10:23:41.134: INFO: Pod "pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.506283ms
Apr  7 10:23:43.137: INFO: Pod "pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005393425s
STEP: Saw pod success
Apr  7 10:23:43.137: INFO: Pod "pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:23:43.140: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:23:43.151: INFO: Waiting for pod pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:23:43.153: INFO: Pod pod-configmaps-36e4073f-591f-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:43.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7487" for this suite.
Apr  7 10:23:49.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:49.228: INFO: namespace configmap-7487 deletion completed in 6.07259277s

• [SLOW TEST:8.124 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:49.228: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr  7 10:23:49.816: INFO: created pod pod-service-account-defaultsa
Apr  7 10:23:49.816: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  7 10:23:49.820: INFO: created pod pod-service-account-mountsa
Apr  7 10:23:49.820: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  7 10:23:49.825: INFO: created pod pod-service-account-nomountsa
Apr  7 10:23:49.825: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  7 10:23:49.829: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  7 10:23:49.829: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  7 10:23:49.840: INFO: created pod pod-service-account-mountsa-mountspec
Apr  7 10:23:49.840: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  7 10:23:49.844: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  7 10:23:49.845: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  7 10:23:49.849: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  7 10:23:49.849: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  7 10:23:49.852: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  7 10:23:49.852: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  7 10:23:49.866: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  7 10:23:49.866: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:23:49.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4937" for this suite.
Apr  7 10:23:55.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:23:55.962: INFO: namespace svcaccounts-4937 deletion completed in 6.090763095s

• [SLOW TEST:6.734 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:23:55.962: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:24:55.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8647" for this suite.
Apr  7 10:25:17.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:25:18.063: INFO: namespace container-probe-8647 deletion completed in 22.071984226s

• [SLOW TEST:82.101 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:25:18.064: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  7 10:25:18.105: INFO: Waiting up to 5m0s for pod "pod-70af0b91-591f-11e9-9aa1-1aed65326ff2" in namespace "emptydir-4275" to be "success or failure"
Apr  7 10:25:18.114: INFO: Pod "pod-70af0b91-591f-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.449589ms
Apr  7 10:25:20.117: INFO: Pod "pod-70af0b91-591f-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011492282s
STEP: Saw pod success
Apr  7 10:25:20.117: INFO: Pod "pod-70af0b91-591f-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:25:20.119: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-70af0b91-591f-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:25:20.132: INFO: Waiting for pod pod-70af0b91-591f-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:25:20.136: INFO: Pod pod-70af0b91-591f-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:25:20.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4275" for this suite.
Apr  7 10:25:26.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:25:26.212: INFO: namespace emptydir-4275 deletion completed in 6.073324163s

• [SLOW TEST:8.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:25:26.212: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:25:28.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3869" for this suite.
Apr  7 10:26:06.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:26:06.334: INFO: namespace kubelet-test-3869 deletion completed in 38.079985113s

• [SLOW TEST:40.122 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:26:06.334: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-3120
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3120 to expose endpoints map[]
Apr  7 10:26:06.374: INFO: successfully validated that service endpoint-test2 in namespace services-3120 exposes endpoints map[] (4.126574ms elapsed)
STEP: Creating pod pod1 in namespace services-3120
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3120 to expose endpoints map[pod1:[80]]
Apr  7 10:26:08.398: INFO: successfully validated that service endpoint-test2 in namespace services-3120 exposes endpoints map[pod1:[80]] (2.016187416s elapsed)
STEP: Creating pod pod2 in namespace services-3120
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3120 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  7 10:26:10.429: INFO: successfully validated that service endpoint-test2 in namespace services-3120 exposes endpoints map[pod1:[80] pod2:[80]] (2.025783215s elapsed)
STEP: Deleting pod pod1 in namespace services-3120
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3120 to expose endpoints map[pod2:[80]]
Apr  7 10:26:10.445: INFO: successfully validated that service endpoint-test2 in namespace services-3120 exposes endpoints map[pod2:[80]] (11.920348ms elapsed)
STEP: Deleting pod pod2 in namespace services-3120
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3120 to expose endpoints map[]
Apr  7 10:26:10.465: INFO: successfully validated that service endpoint-test2 in namespace services-3120 exposes endpoints map[] (2.578199ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:26:10.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3120" for this suite.
Apr  7 10:26:32.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:26:32.565: INFO: namespace services-3120 deletion completed in 22.083240665s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:26.231 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:26:32.565: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8881
Apr  7 10:26:34.599: INFO: Started pod liveness-exec in namespace container-probe-8881
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 10:26:34.602: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:30:35.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8881" for this suite.
Apr  7 10:30:41.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:30:41.115: INFO: namespace container-probe-8881 deletion completed in 6.084325666s

• [SLOW TEST:248.550 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:30:41.116: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  7 10:30:41.147: INFO: Waiting up to 5m0s for pod "pod-313d254a-5920-11e9-9aa1-1aed65326ff2" in namespace "emptydir-9442" to be "success or failure"
Apr  7 10:30:41.151: INFO: Pod "pod-313d254a-5920-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.781891ms
Apr  7 10:30:43.154: INFO: Pod "pod-313d254a-5920-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006511594s
STEP: Saw pod success
Apr  7 10:30:43.154: INFO: Pod "pod-313d254a-5920-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:30:43.156: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-313d254a-5920-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:30:43.183: INFO: Waiting for pod pod-313d254a-5920-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:30:43.185: INFO: Pod pod-313d254a-5920-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:30:43.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9442" for this suite.
Apr  7 10:30:49.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:30:49.266: INFO: namespace emptydir-9442 deletion completed in 6.077933601s

• [SLOW TEST:8.151 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:30:49.266: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-36207ed9-5920-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:30:51.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4000" for this suite.
Apr  7 10:31:13.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:31:13.452: INFO: namespace configmap-4000 deletion completed in 22.077254422s

• [SLOW TEST:24.186 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:31:13.452: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  7 10:31:13.478: INFO: Waiting up to 5m0s for pod "pod-4482730b-5920-11e9-9aa1-1aed65326ff2" in namespace "emptydir-2575" to be "success or failure"
Apr  7 10:31:13.482: INFO: Pod "pod-4482730b-5920-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077387ms
Apr  7 10:31:15.486: INFO: Pod "pod-4482730b-5920-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007559238s
STEP: Saw pod success
Apr  7 10:31:15.486: INFO: Pod "pod-4482730b-5920-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:31:15.488: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-4482730b-5920-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:31:15.513: INFO: Waiting for pod pod-4482730b-5920-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:31:15.517: INFO: Pod pod-4482730b-5920-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:31:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2575" for this suite.
Apr  7 10:31:21.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:31:21.601: INFO: namespace emptydir-2575 deletion completed in 6.081511992s

• [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:31:21.601: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3081
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-3081
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3081
Apr  7 10:31:21.636: INFO: Found 0 stateful pods, waiting for 1
Apr  7 10:31:31.639: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  7 10:31:31.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:31:31.809: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:31:31.809: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:31:31.809: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:31:31.812: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  7 10:31:41.815: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:31:41.815: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:31:41.825: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:31:41.825: INFO: ss-0  ip-10-0-39-198  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:31:41.825: INFO: 
Apr  7 10:31:41.825: INFO: StatefulSet ss has not reached scale 3, at 1
Apr  7 10:31:42.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997727202s
Apr  7 10:31:43.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995106928s
Apr  7 10:31:44.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991630873s
Apr  7 10:31:45.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988548981s
Apr  7 10:31:46.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98517009s
Apr  7 10:31:47.843: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982151165s
Apr  7 10:31:48.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979007751s
Apr  7 10:31:49.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976114707s
Apr  7 10:31:50.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.740681ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3081
Apr  7 10:31:51.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:31:52.030: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 10:31:52.030: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:31:52.030: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:31:52.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:31:52.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  7 10:31:52.219: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:31:52.219: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:31:52.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 10:31:52.408: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  7 10:31:52.408: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 10:31:52.408: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 10:31:52.411: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr  7 10:32:02.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 10:32:02.415: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 10:32:02.415: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  7 10:32:02.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:32:02.660: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:32:02.660: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:32:02.660: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:32:02.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:32:02.847: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:32:02.847: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:32:02.847: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:32:02.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-3081 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 10:32:03.033: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 10:32:03.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 10:32:03.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 10:32:03.034: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:32:03.036: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  7 10:32:13.044: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:32:13.044: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:32:13.044: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 10:32:13.055: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:13.055: INFO: ss-0  ip-10-0-39-198  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:13.055: INFO: ss-1  ip-10-0-29-139  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  }]
Apr  7 10:32:13.055: INFO: ss-2  ip-10-0-39-198  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  }]
Apr  7 10:32:13.055: INFO: 
Apr  7 10:32:13.055: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  7 10:32:14.058: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:14.058: INFO: ss-0  ip-10-0-39-198  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:14.058: INFO: ss-1  ip-10-0-29-139  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  }]
Apr  7 10:32:14.058: INFO: ss-2  ip-10-0-39-198  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  }]
Apr  7 10:32:14.058: INFO: 
Apr  7 10:32:14.058: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  7 10:32:15.062: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:15.062: INFO: ss-0  ip-10-0-39-198  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:15.062: INFO: ss-2  ip-10-0-39-198  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:41 +0000 UTC  }]
Apr  7 10:32:15.062: INFO: 
Apr  7 10:32:15.062: INFO: StatefulSet ss has not reached scale 0, at 2
Apr  7 10:32:16.065: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:16.065: INFO: ss-0  ip-10-0-39-198  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:16.065: INFO: 
Apr  7 10:32:16.065: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  7 10:32:17.068: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:17.069: INFO: ss-0  ip-10-0-39-198  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:17.069: INFO: 
Apr  7 10:32:17.069: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  7 10:32:18.072: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  7 10:32:18.072: INFO: ss-0  ip-10-0-39-198  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:32:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 10:31:21 +0000 UTC  }]
Apr  7 10:32:18.072: INFO: 
Apr  7 10:32:18.072: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  7 10:32:19.074: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.97841208s
Apr  7 10:32:20.077: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.975711979s
Apr  7 10:32:21.080: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.972988357s
Apr  7 10:32:22.082: INFO: Verifying statefulset ss doesn't scale past 0 for another 970.264796ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3081
Apr  7 10:32:23.085: INFO: Scaling statefulset ss to 0
Apr  7 10:32:23.092: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  7 10:32:23.094: INFO: Deleting all statefulset in ns statefulset-3081
Apr  7 10:32:23.096: INFO: Scaling statefulset ss to 0
Apr  7 10:32:23.102: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 10:32:23.104: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:32:23.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3081" for this suite.
Apr  7 10:32:29.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:32:29.199: INFO: namespace statefulset-3081 deletion completed in 6.084666842s

• [SLOW TEST:67.598 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:32:29.200: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-71a8aba7-5920-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:32:29.228: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2" in namespace "projected-5952" to be "success or failure"
Apr  7 10:32:29.233: INFO: Pod "pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.98173ms
Apr  7 10:32:31.236: INFO: Pod "pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008043011s
STEP: Saw pod success
Apr  7 10:32:31.237: INFO: Pod "pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:32:31.239: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:32:31.254: INFO: Waiting for pod pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:32:31.257: INFO: Pod pod-projected-secrets-71a8fe72-5920-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:32:31.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5952" for this suite.
Apr  7 10:32:37.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:32:37.336: INFO: namespace projected-5952 deletion completed in 6.075341894s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:32:37.337: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:32:37.379: INFO: (0) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.940049ms)
Apr  7 10:32:37.382: INFO: (1) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.091598ms)
Apr  7 10:32:37.385: INFO: (2) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.486045ms)
Apr  7 10:32:37.389: INFO: (3) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.944632ms)
Apr  7 10:32:37.392: INFO: (4) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.828999ms)
Apr  7 10:32:37.396: INFO: (5) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.639768ms)
Apr  7 10:32:37.400: INFO: (6) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.548671ms)
Apr  7 10:32:37.403: INFO: (7) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.771209ms)
Apr  7 10:32:37.407: INFO: (8) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.194278ms)
Apr  7 10:32:37.410: INFO: (9) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.952597ms)
Apr  7 10:32:37.413: INFO: (10) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.127113ms)
Apr  7 10:32:37.416: INFO: (11) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.080899ms)
Apr  7 10:32:37.420: INFO: (12) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.0153ms)
Apr  7 10:32:37.423: INFO: (13) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.79489ms)
Apr  7 10:32:37.426: INFO: (14) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.897198ms)
Apr  7 10:32:37.430: INFO: (15) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.885776ms)
Apr  7 10:32:37.433: INFO: (16) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.578749ms)
Apr  7 10:32:37.436: INFO: (17) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.860245ms)
Apr  7 10:32:37.440: INFO: (18) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.39044ms)
Apr  7 10:32:37.442: INFO: (19) /api/v1/nodes/ip-10-0-29-139:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.874419ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:32:37.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-639" for this suite.
Apr  7 10:32:43.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:32:43.521: INFO: namespace proxy-639 deletion completed in 6.076490921s

• [SLOW TEST:6.185 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:32:43.523: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:32:43.557: INFO: Create a RollingUpdate DaemonSet
Apr  7 10:32:43.560: INFO: Check that daemon pods launch on every node of the cluster
Apr  7 10:32:43.565: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:32:43.571: INFO: Number of nodes with available pods: 0
Apr  7 10:32:43.571: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:32:44.578: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:32:44.581: INFO: Number of nodes with available pods: 0
Apr  7 10:32:44.581: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:32:45.574: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:32:45.578: INFO: Number of nodes with available pods: 2
Apr  7 10:32:45.578: INFO: Number of running nodes: 2, number of available pods: 2
Apr  7 10:32:45.578: INFO: Update the DaemonSet to trigger a rollout
Apr  7 10:32:45.584: INFO: Updating DaemonSet daemon-set
Apr  7 10:32:59.591: INFO: Roll back the DaemonSet before rollout is complete
Apr  7 10:32:59.598: INFO: Updating DaemonSet daemon-set
Apr  7 10:32:59.598: INFO: Make sure DaemonSet rollback is complete
Apr  7 10:32:59.603: INFO: Wrong image for pod: daemon-set-vbsqx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  7 10:32:59.603: INFO: Pod daemon-set-vbsqx is not available
Apr  7 10:32:59.608: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:33:00.612: INFO: Wrong image for pod: daemon-set-vbsqx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  7 10:33:00.612: INFO: Pod daemon-set-vbsqx is not available
Apr  7 10:33:00.615: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:33:01.619: INFO: Wrong image for pod: daemon-set-vbsqx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  7 10:33:01.619: INFO: Pod daemon-set-vbsqx is not available
Apr  7 10:33:01.622: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:33:02.611: INFO: Pod daemon-set-bjg5q is not available
Apr  7 10:33:02.614: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6483, will wait for the garbage collector to delete the pods
Apr  7 10:33:02.676: INFO: Deleting DaemonSet.extensions daemon-set took: 5.428425ms
Apr  7 10:33:02.976: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.246243ms
Apr  7 10:33:10.678: INFO: Number of nodes with available pods: 0
Apr  7 10:33:10.678: INFO: Number of running nodes: 0, number of available pods: 0
Apr  7 10:33:10.680: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6483/daemonsets","resourceVersion":"14204"},"items":null}

Apr  7 10:33:10.682: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6483/pods","resourceVersion":"14204"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:33:10.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6483" for this suite.
Apr  7 10:33:16.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:33:16.767: INFO: namespace daemonsets-6483 deletion completed in 6.076371211s

• [SLOW TEST:33.244 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:33:16.767: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  7 10:33:16.794: INFO: Waiting up to 5m0s for pod "pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2" in namespace "emptydir-5134" to be "success or failure"
Apr  7 10:33:16.798: INFO: Pod "pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.747708ms
Apr  7 10:33:18.801: INFO: Pod "pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006845781s
STEP: Saw pod success
Apr  7 10:33:18.801: INFO: Pod "pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:33:18.803: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:33:18.818: INFO: Waiting for pod pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:33:18.820: INFO: Pod pod-8e0300f6-5920-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:33:18.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5134" for this suite.
Apr  7 10:33:24.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:33:24.900: INFO: namespace emptydir-5134 deletion completed in 6.077050382s

• [SLOW TEST:8.133 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:33:24.901: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:33:24.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8744'
Apr  7 10:33:25.151: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  7 10:33:25.151: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Apr  7 10:33:25.166: INFO: scanned /root for discovery docs: <nil>
Apr  7 10:33:25.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8744'
Apr  7 10:33:37.941: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  7 10:33:37.941: INFO: stdout: "Created e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807\nScaling up e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr  7 10:33:37.941: INFO: stdout: "Created e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807\nScaling up e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr  7 10:33:37.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8744'
Apr  7 10:33:38.027: INFO: stderr: ""
Apr  7 10:33:38.027: INFO: stdout: "e2e-test-nginx-rc-5hfzx e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807-ckn6f "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Apr  7 10:33:43.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8744'
Apr  7 10:33:43.108: INFO: stderr: ""
Apr  7 10:33:43.108: INFO: stdout: "e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807-ckn6f "
Apr  7 10:33:43.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807-ckn6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8744'
Apr  7 10:33:43.191: INFO: stderr: ""
Apr  7 10:33:43.191: INFO: stdout: "true"
Apr  7 10:33:43.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807-ckn6f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8744'
Apr  7 10:33:43.263: INFO: stderr: ""
Apr  7 10:33:43.263: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr  7 10:33:43.263: INFO: e2e-test-nginx-rc-f784fa97ff6a821e1d792179308bb807-ckn6f is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr  7 10:33:43.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete rc e2e-test-nginx-rc --namespace=kubectl-8744'
Apr  7 10:33:43.351: INFO: stderr: ""
Apr  7 10:33:43.351: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:33:43.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8744" for this suite.
Apr  7 10:33:49.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:33:49.430: INFO: namespace kubectl-8744 deletion completed in 6.075909876s

• [SLOW TEST:24.529 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:33:49.430: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:34:13.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2047" for this suite.
Apr  7 10:34:19.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:34:19.652: INFO: namespace namespaces-2047 deletion completed in 6.077944346s
STEP: Destroying namespace "nsdeletetest-2858" for this suite.
Apr  7 10:34:19.654: INFO: Namespace nsdeletetest-2858 was already deleted
STEP: Destroying namespace "nsdeletetest-4306" for this suite.
Apr  7 10:34:25.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:34:25.737: INFO: namespace nsdeletetest-4306 deletion completed in 6.082289183s

• [SLOW TEST:36.307 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:34:25.738: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6142.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6142.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6142.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6142.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6142.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6142.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 10:34:35.802: INFO: DNS probes using dns-6142/dns-test-b71f18a7-5920-11e9-9aa1-1aed65326ff2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:34:35.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6142" for this suite.
Apr  7 10:34:41.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:34:41.888: INFO: namespace dns-6142 deletion completed in 6.074868937s

• [SLOW TEST:16.149 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:34:41.888: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2
Apr  7 10:34:41.914: INFO: Pod name my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2: Found 0 pods out of 1
Apr  7 10:34:46.917: INFO: Pod name my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2: Found 1 pods out of 1
Apr  7 10:34:46.917: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2" are running
Apr  7 10:34:46.920: INFO: Pod "my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2-69q5q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:34:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:34:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:34:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:34:41 +0000 UTC Reason: Message:}])
Apr  7 10:34:46.920: INFO: Trying to dial the pod
Apr  7 10:34:51.930: INFO: Controller my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2: Got expected result from replica 1 [my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2-69q5q]: "my-hostname-basic-c0bf3233-5920-11e9-9aa1-1aed65326ff2-69q5q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:34:51.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1601" for this suite.
Apr  7 10:34:57.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:34:58.013: INFO: namespace replication-controller-1601 deletion completed in 6.081273751s

• [SLOW TEST:16.126 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:34:58.014: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  7 10:34:58.035: INFO: namespace kubectl-7576
Apr  7 10:34:58.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-7576'
Apr  7 10:34:58.200: INFO: stderr: ""
Apr  7 10:34:58.200: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  7 10:34:59.203: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:34:59.203: INFO: Found 0 / 1
Apr  7 10:35:00.204: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:35:00.204: INFO: Found 1 / 1
Apr  7 10:35:00.204: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  7 10:35:00.209: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 10:35:00.209: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 10:35:00.209: INFO: wait on redis-master startup in kubectl-7576 
Apr  7 10:35:00.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 logs redis-master-lk8z7 redis-master --namespace=kubectl-7576'
Apr  7 10:35:00.334: INFO: stderr: ""
Apr  7 10:35:00.334: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Apr 10:34:59.078 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Apr 10:34:59.078 # Server started, Redis version 3.2.12\n1:M 07 Apr 10:34:59.078 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Apr 10:34:59.079 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr  7 10:35:00.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7576'
Apr  7 10:35:00.433: INFO: stderr: ""
Apr  7 10:35:00.433: INFO: stdout: "service/rm2 exposed\n"
Apr  7 10:35:00.436: INFO: Service rm2 in namespace kubectl-7576 found.
STEP: exposing service
Apr  7 10:35:02.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7576'
Apr  7 10:35:02.584: INFO: stderr: ""
Apr  7 10:35:02.584: INFO: stdout: "service/rm3 exposed\n"
Apr  7 10:35:02.593: INFO: Service rm3 in namespace kubectl-7576 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:35:04.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7576" for this suite.
Apr  7 10:35:26.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:35:26.677: INFO: namespace kubectl-7576 deletion completed in 22.077541093s

• [SLOW TEST:28.664 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:35:26.682: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:35:32.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3047" for this suite.
Apr  7 10:35:38.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:35:38.890: INFO: namespace namespaces-3047 deletion completed in 6.076354609s
STEP: Destroying namespace "nsdeletetest-3806" for this suite.
Apr  7 10:35:38.892: INFO: Namespace nsdeletetest-3806 was already deleted
STEP: Destroying namespace "nsdeletetest-2336" for this suite.
Apr  7 10:35:44.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:35:44.967: INFO: namespace nsdeletetest-2336 deletion completed in 6.075132116s

• [SLOW TEST:18.286 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:35:44.968: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:35:44.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2" in namespace "projected-5013" to be "success or failure"
Apr  7 10:35:45.003: INFO: Pod "downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.136587ms
Apr  7 10:35:47.006: INFO: Pod "downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008152842s
STEP: Saw pod success
Apr  7 10:35:47.006: INFO: Pod "downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:35:47.008: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:35:47.035: INFO: Waiting for pod downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:35:47.040: INFO: Pod downwardapi-volume-e658f38e-5920-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:35:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5013" for this suite.
Apr  7 10:35:53.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:35:53.126: INFO: namespace projected-5013 deletion completed in 6.080273487s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:35:53.126: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2406
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 10:35:53.153: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  7 10:36:13.214: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.122.120 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2406 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:36:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:36:14.337: INFO: Found all expected endpoints: [netserver-0]
Apr  7 10:36:14.341: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.210.107 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2406 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:36:14.341: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:36:15.437: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:36:15.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2406" for this suite.
Apr  7 10:36:37.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:36:37.517: INFO: namespace pod-network-test-2406 deletion completed in 22.076964545s

• [SLOW TEST:44.391 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:36:37.517: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:36:37.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2" in namespace "downward-api-5768" to be "success or failure"
Apr  7 10:36:37.552: INFO: Pod "downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.773158ms
Apr  7 10:36:39.555: INFO: Pod "downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010007303s
STEP: Saw pod success
Apr  7 10:36:39.555: INFO: Pod "downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:36:39.558: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:36:39.573: INFO: Waiting for pod downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:36:39.575: INFO: Pod downwardapi-volume-05ab288e-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:36:39.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5768" for this suite.
Apr  7 10:36:45.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:36:45.651: INFO: namespace downward-api-5768 deletion completed in 6.074034024s

• [SLOW TEST:8.134 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:36:45.652: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  7 10:36:45.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-5137'
Apr  7 10:36:45.846: INFO: stderr: ""
Apr  7 10:36:45.846: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 10:36:45.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5137'
Apr  7 10:36:45.921: INFO: stderr: ""
Apr  7 10:36:45.921: INFO: stdout: "update-demo-nautilus-6jf6j update-demo-nautilus-z6j7c "
Apr  7 10:36:45.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-6jf6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5137'
Apr  7 10:36:45.992: INFO: stderr: ""
Apr  7 10:36:45.992: INFO: stdout: ""
Apr  7 10:36:45.992: INFO: update-demo-nautilus-6jf6j is created but not running
Apr  7 10:36:50.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5137'
Apr  7 10:36:51.073: INFO: stderr: ""
Apr  7 10:36:51.073: INFO: stdout: "update-demo-nautilus-6jf6j update-demo-nautilus-z6j7c "
Apr  7 10:36:51.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-6jf6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5137'
Apr  7 10:36:51.150: INFO: stderr: ""
Apr  7 10:36:51.150: INFO: stdout: "true"
Apr  7 10:36:51.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-6jf6j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5137'
Apr  7 10:36:51.232: INFO: stderr: ""
Apr  7 10:36:51.232: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 10:36:51.232: INFO: validating pod update-demo-nautilus-6jf6j
Apr  7 10:36:51.237: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 10:36:51.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 10:36:51.237: INFO: update-demo-nautilus-6jf6j is verified up and running
Apr  7 10:36:51.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-z6j7c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5137'
Apr  7 10:36:51.316: INFO: stderr: ""
Apr  7 10:36:51.316: INFO: stdout: "true"
Apr  7 10:36:51.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods update-demo-nautilus-z6j7c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5137'
Apr  7 10:36:51.382: INFO: stderr: ""
Apr  7 10:36:51.382: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  7 10:36:51.382: INFO: validating pod update-demo-nautilus-z6j7c
Apr  7 10:36:51.387: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 10:36:51.387: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 10:36:51.387: INFO: update-demo-nautilus-z6j7c is verified up and running
STEP: using delete to clean up resources
Apr  7 10:36:51.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete --grace-period=0 --force -f - --namespace=kubectl-5137'
Apr  7 10:36:51.461: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 10:36:51.461: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  7 10:36:51.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5137'
Apr  7 10:36:51.547: INFO: stderr: "No resources found.\n"
Apr  7 10:36:51.547: INFO: stdout: ""
Apr  7 10:36:51.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=update-demo --namespace=kubectl-5137 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 10:36:51.625: INFO: stderr: ""
Apr  7 10:36:51.625: INFO: stdout: "update-demo-nautilus-6jf6j\nupdate-demo-nautilus-z6j7c\n"
Apr  7 10:36:52.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5137'
Apr  7 10:36:52.204: INFO: stderr: "No resources found.\n"
Apr  7 10:36:52.204: INFO: stdout: ""
Apr  7 10:36:52.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pods -l name=update-demo --namespace=kubectl-5137 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 10:36:52.276: INFO: stderr: ""
Apr  7 10:36:52.276: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:36:52.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5137" for this suite.
Apr  7 10:37:14.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:37:14.362: INFO: namespace kubectl-5137 deletion completed in 22.082399984s

• [SLOW TEST:28.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:37:14.362: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-1ba1352b-5921-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:37:14.394: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2" in namespace "projected-9176" to be "success or failure"
Apr  7 10:37:14.399: INFO: Pod "pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.480494ms
Apr  7 10:37:16.401: INFO: Pod "pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00687138s
STEP: Saw pod success
Apr  7 10:37:16.401: INFO: Pod "pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:37:16.404: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:37:16.434: INFO: Waiting for pod pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:37:16.436: INFO: Pod pod-projected-secrets-1ba1ab78-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:37:16.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9176" for this suite.
Apr  7 10:37:22.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:37:22.529: INFO: namespace projected-9176 deletion completed in 6.090360387s

• [SLOW TEST:8.166 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:37:22.529: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  7 10:37:22.553: INFO: Waiting up to 5m0s for pod "pod-207f0e69-5921-11e9-9aa1-1aed65326ff2" in namespace "emptydir-2271" to be "success or failure"
Apr  7 10:37:22.556: INFO: Pod "pod-207f0e69-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241344ms
Apr  7 10:37:24.559: INFO: Pod "pod-207f0e69-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005080466s
STEP: Saw pod success
Apr  7 10:37:24.559: INFO: Pod "pod-207f0e69-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:37:24.561: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-207f0e69-5921-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:37:24.577: INFO: Waiting for pod pod-207f0e69-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:37:24.578: INFO: Pod pod-207f0e69-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:37:24.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2271" for this suite.
Apr  7 10:37:30.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:37:30.676: INFO: namespace emptydir-2271 deletion completed in 6.095389273s

• [SLOW TEST:8.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:37:30.677: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-255b2509-5921-11e9-9aa1-1aed65326ff2
STEP: Creating configMap with name cm-test-opt-upd-255b2543-5921-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-255b2509-5921-11e9-9aa1-1aed65326ff2
STEP: Updating configmap cm-test-opt-upd-255b2543-5921-11e9-9aa1-1aed65326ff2
STEP: Creating configMap with name cm-test-opt-create-255b2559-5921-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:38:53.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9528" for this suite.
Apr  7 10:39:15.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:39:15.181: INFO: namespace configmap-9528 deletion completed in 22.090455585s

• [SLOW TEST:104.505 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:39:15.183: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-63a51ace-5921-11e9-9aa1-1aed65326ff2
STEP: Creating configMap with name cm-test-opt-upd-63a51b10-5921-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-63a51ace-5921-11e9-9aa1-1aed65326ff2
STEP: Updating configmap cm-test-opt-upd-63a51b10-5921-11e9-9aa1-1aed65326ff2
STEP: Creating configMap with name cm-test-opt-create-63a51b29-5921-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:39:19.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8" for this suite.
Apr  7 10:39:41.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:39:41.373: INFO: namespace projected-8 deletion completed in 22.082515385s

• [SLOW TEST:26.189 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:39:41.373: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  7 10:39:43.927: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6865 pod-service-account-7390acd9-5921-11e9-9aa1-1aed65326ff2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  7 10:39:44.092: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6865 pod-service-account-7390acd9-5921-11e9-9aa1-1aed65326ff2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  7 10:39:44.253: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6865 pod-service-account-7390acd9-5921-11e9-9aa1-1aed65326ff2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:39:44.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6865" for this suite.
Apr  7 10:39:50.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:39:50.515: INFO: namespace svcaccounts-6865 deletion completed in 6.087970296s

• [SLOW TEST:9.143 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:39:50.517: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:39:50.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2" in namespace "projected-9221" to be "success or failure"
Apr  7 10:39:50.561: INFO: Pod "downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.364695ms
Apr  7 10:39:52.564: INFO: Pod "downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011690996s
STEP: Saw pod success
Apr  7 10:39:52.564: INFO: Pod "downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:39:52.567: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:39:52.582: INFO: Waiting for pod downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:39:52.584: INFO: Pod downwardapi-volume-78b56d3a-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:39:52.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9221" for this suite.
Apr  7 10:39:58.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:39:58.682: INFO: namespace projected-9221 deletion completed in 6.095257839s

• [SLOW TEST:8.165 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:39:58.682: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4079
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4079 to expose endpoints map[]
Apr  7 10:39:58.725: INFO: Get endpoints failed (10.220879ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr  7 10:39:59.728: INFO: successfully validated that service multi-endpoint-test in namespace services-4079 exposes endpoints map[] (1.01281427s elapsed)
STEP: Creating pod pod1 in namespace services-4079
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4079 to expose endpoints map[pod1:[100]]
Apr  7 10:40:01.750: INFO: successfully validated that service multi-endpoint-test in namespace services-4079 exposes endpoints map[pod1:[100]] (2.016285115s elapsed)
STEP: Creating pod pod2 in namespace services-4079
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4079 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  7 10:40:02.777: INFO: successfully validated that service multi-endpoint-test in namespace services-4079 exposes endpoints map[pod1:[100] pod2:[101]] (1.020442439s elapsed)
STEP: Deleting pod pod1 in namespace services-4079
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4079 to expose endpoints map[pod2:[101]]
Apr  7 10:40:02.788: INFO: successfully validated that service multi-endpoint-test in namespace services-4079 exposes endpoints map[pod2:[101]] (6.431396ms elapsed)
STEP: Deleting pod pod2 in namespace services-4079
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4079 to expose endpoints map[]
Apr  7 10:40:03.815: INFO: successfully validated that service multi-endpoint-test in namespace services-4079 exposes endpoints map[] (1.014125276s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:40:03.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4079" for this suite.
Apr  7 10:40:25.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:40:25.913: INFO: namespace services-4079 deletion completed in 22.076948675s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.231 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:40:25.913: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:40:25.933: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:40:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3052" for this suite.
Apr  7 10:41:15.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:41:16.043: INFO: namespace pods-3052 deletion completed in 48.075141424s

• [SLOW TEST:50.130 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:41:16.043: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:41:16.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3749'
Apr  7 10:41:16.143: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  7 10:41:16.143: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr  7 10:41:16.152: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-gvtd7]
Apr  7 10:41:16.152: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-gvtd7" in namespace "kubectl-3749" to be "running and ready"
Apr  7 10:41:16.155: INFO: Pod "e2e-test-nginx-rc-gvtd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861551ms
Apr  7 10:41:18.158: INFO: Pod "e2e-test-nginx-rc-gvtd7": Phase="Running", Reason="", readiness=true. Elapsed: 2.005822327s
Apr  7 10:41:18.158: INFO: Pod "e2e-test-nginx-rc-gvtd7" satisfied condition "running and ready"
Apr  7 10:41:18.158: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-gvtd7]
Apr  7 10:41:18.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 logs rc/e2e-test-nginx-rc --namespace=kubectl-3749'
Apr  7 10:41:18.252: INFO: stderr: ""
Apr  7 10:41:18.252: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr  7 10:41:18.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete rc e2e-test-nginx-rc --namespace=kubectl-3749'
Apr  7 10:41:18.323: INFO: stderr: ""
Apr  7 10:41:18.323: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:41:18.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3749" for this suite.
Apr  7 10:41:24.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:41:24.404: INFO: namespace kubectl-3749 deletion completed in 6.075855723s

• [SLOW TEST:8.361 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:41:24.404: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  7 10:41:28.456: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.456: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.543: INFO: Exec stderr: ""
Apr  7 10:41:28.543: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.543: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.624: INFO: Exec stderr: ""
Apr  7 10:41:28.625: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.625: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.714: INFO: Exec stderr: ""
Apr  7 10:41:28.714: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.714: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.814: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  7 10:41:28.815: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.815: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.898: INFO: Exec stderr: ""
Apr  7 10:41:28.898: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.898: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:28.993: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  7 10:41:28.993: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:28.994: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:29.093: INFO: Exec stderr: ""
Apr  7 10:41:29.093: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:29.093: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:29.185: INFO: Exec stderr: ""
Apr  7 10:41:29.185: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:29.185: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:29.276: INFO: Exec stderr: ""
Apr  7 10:41:29.276: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6305 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  7 10:41:29.276: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
Apr  7 10:41:29.367: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:41:29.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6305" for this suite.
Apr  7 10:42:13.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:42:13.454: INFO: namespace e2e-kubelet-etc-hosts-6305 deletion completed in 44.084270476s

• [SLOW TEST:49.050 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:42:13.454: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-cde6bcda-5921-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:42:13.481: INFO: Waiting up to 5m0s for pod "pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2" in namespace "secrets-6793" to be "success or failure"
Apr  7 10:42:13.486: INFO: Pod "pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.478251ms
Apr  7 10:42:15.489: INFO: Pod "pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007254042s
STEP: Saw pod success
Apr  7 10:42:15.489: INFO: Pod "pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:42:15.491: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:42:15.507: INFO: Waiting for pod pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:42:15.509: INFO: Pod pod-secrets-cde71299-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:42:15.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6793" for this suite.
Apr  7 10:42:21.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:42:21.586: INFO: namespace secrets-6793 deletion completed in 6.074647033s

• [SLOW TEST:8.132 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:42:21.587: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 10:42:21.627: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:21.629: INFO: Number of nodes with available pods: 0
Apr  7 10:42:21.629: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:22.633: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:22.635: INFO: Number of nodes with available pods: 0
Apr  7 10:42:22.635: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:23.634: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:23.637: INFO: Number of nodes with available pods: 2
Apr  7 10:42:23.637: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  7 10:42:23.648: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:23.650: INFO: Number of nodes with available pods: 1
Apr  7 10:42:23.650: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:24.655: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:24.659: INFO: Number of nodes with available pods: 1
Apr  7 10:42:24.660: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:25.653: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:25.655: INFO: Number of nodes with available pods: 1
Apr  7 10:42:25.655: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:26.653: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:26.656: INFO: Number of nodes with available pods: 1
Apr  7 10:42:26.656: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:27.653: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:27.656: INFO: Number of nodes with available pods: 1
Apr  7 10:42:27.656: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 10:42:28.653: INFO: DaemonSet pods can't tolerate node ip-10-0-14-179 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  7 10:42:28.655: INFO: Number of nodes with available pods: 2
Apr  7 10:42:28.655: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2977, will wait for the garbage collector to delete the pods
Apr  7 10:42:28.716: INFO: Deleting DaemonSet.extensions daemon-set took: 4.17312ms
Apr  7 10:42:29.016: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.288255ms
Apr  7 10:42:40.718: INFO: Number of nodes with available pods: 0
Apr  7 10:42:40.718: INFO: Number of running nodes: 0, number of available pods: 0
Apr  7 10:42:40.720: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2977/daemonsets","resourceVersion":"16163"},"items":null}

Apr  7 10:42:40.722: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2977/pods","resourceVersion":"16163"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:42:40.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2977" for this suite.
Apr  7 10:42:46.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:42:46.810: INFO: namespace daemonsets-2977 deletion completed in 6.078427925s

• [SLOW TEST:25.223 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:42:46.810: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  7 10:42:49.405: INFO: Successfully updated pod "annotationupdatee1c86b79-5921-11e9-9aa1-1aed65326ff2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:42:51.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4008" for this suite.
Apr  7 10:43:13.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:13.493: INFO: namespace projected-4008 deletion completed in 22.072113899s

• [SLOW TEST:26.683 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:13.493: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr  7 10:43:13.528: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-872" to be "success or failure"
Apr  7 10:43:13.534: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.129401ms
Apr  7 10:43:15.537: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00813472s
STEP: Saw pod success
Apr  7 10:43:15.537: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  7 10:43:15.540: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  7 10:43:15.554: INFO: Waiting for pod pod-host-path-test to disappear
Apr  7 10:43:15.556: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:15.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-872" for this suite.
Apr  7 10:43:21.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:21.641: INFO: namespace hostpath-872 deletion completed in 6.082325771s

• [SLOW TEST:8.148 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:21.642: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  7 10:43:21.677: INFO: Pod name pod-release: Found 0 pods out of 1
Apr  7 10:43:26.680: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:26.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8464" for this suite.
Apr  7 10:43:32.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:32.787: INFO: namespace replication-controller-8464 deletion completed in 6.091958565s

• [SLOW TEST:11.146 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:32.788: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:43:32.814: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2" in namespace "projected-3416" to be "success or failure"
Apr  7 10:43:32.816: INFO: Pod "downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.338531ms
Apr  7 10:43:34.819: INFO: Pod "downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005335381s
STEP: Saw pod success
Apr  7 10:43:34.820: INFO: Pod "downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:43:34.822: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:43:34.837: INFO: Waiting for pod downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:43:34.838: INFO: Pod downwardapi-volume-fd302d2e-5921-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:34.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3416" for this suite.
Apr  7 10:43:40.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:40.922: INFO: namespace projected-3416 deletion completed in 6.081271135s

• [SLOW TEST:8.134 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:40.922: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-020982b7-5922-11e9-9aa1-1aed65326ff2
STEP: Creating secret with name secret-projected-all-test-volume-0209829f-5922-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  7 10:43:40.956: INFO: Waiting up to 5m0s for pod "projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2" in namespace "projected-287" to be "success or failure"
Apr  7 10:43:40.959: INFO: Pod "projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.257697ms
Apr  7 10:43:42.962: INFO: Pod "projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006036731s
STEP: Saw pod success
Apr  7 10:43:42.962: INFO: Pod "projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:43:42.965: INFO: Trying to get logs from node ip-10-0-29-139 pod projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  7 10:43:42.979: INFO: Waiting for pod projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:43:42.981: INFO: Pod projected-volume-02098254-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:42.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-287" for this suite.
Apr  7 10:43:48.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:49.074: INFO: namespace projected-287 deletion completed in 6.090781115s

• [SLOW TEST:8.152 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:49.074: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4865.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4865.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 10:43:51.191: INFO: DNS probes using dns-4865/dns-test-06ed94a9-5922-11e9-9aa1-1aed65326ff2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:51.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4865" for this suite.
Apr  7 10:43:57.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:43:57.279: INFO: namespace dns-4865 deletion completed in 6.076124331s

• [SLOW TEST:8.205 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:43:57.280: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  7 10:43:57.309: INFO: Waiting up to 5m0s for pod "pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2" in namespace "emptydir-7830" to be "success or failure"
Apr  7 10:43:57.312: INFO: Pod "pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.383901ms
Apr  7 10:43:59.315: INFO: Pod "pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006111608s
STEP: Saw pod success
Apr  7 10:43:59.315: INFO: Pod "pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:43:59.318: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:43:59.332: INFO: Waiting for pod pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:43:59.333: INFO: Pod pod-0bc9c313-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:43:59.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7830" for this suite.
Apr  7 10:44:05.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:44:05.410: INFO: namespace emptydir-7830 deletion completed in 6.073938815s

• [SLOW TEST:8.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:44:05.410: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-10a2050e-5922-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:44:05.440: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2" in namespace "projected-622" to be "success or failure"
Apr  7 10:44:05.444: INFO: Pod "pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07562ms
Apr  7 10:44:07.446: INFO: Pod "pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006815805s
STEP: Saw pod success
Apr  7 10:44:07.446: INFO: Pod "pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:44:07.449: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:44:07.461: INFO: Waiting for pod pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:44:07.464: INFO: Pod pod-projected-secrets-10a26a18-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:44:07.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-622" for this suite.
Apr  7 10:44:13.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:44:13.541: INFO: namespace projected-622 deletion completed in 6.07441777s

• [SLOW TEST:8.130 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:44:13.541: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:44:13.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2" in namespace "projected-8266" to be "success or failure"
Apr  7 10:44:13.568: INFO: Pod "downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.567679ms
Apr  7 10:44:15.571: INFO: Pod "downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005723944s
STEP: Saw pod success
Apr  7 10:44:15.571: INFO: Pod "downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:44:15.574: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:44:15.587: INFO: Waiting for pod downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:44:15.590: INFO: Pod downwardapi-volume-157a734b-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:44:15.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8266" for this suite.
Apr  7 10:44:21.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:44:21.665: INFO: namespace projected-8266 deletion completed in 6.07227611s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:44:21.665: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  7 10:44:21.744: INFO: Waiting up to 5m0s for pod "downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2" in namespace "downward-api-7264" to be "success or failure"
Apr  7 10:44:21.749: INFO: Pod "downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.49575ms
Apr  7 10:44:23.752: INFO: Pod "downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007663478s
STEP: Saw pod success
Apr  7 10:44:23.752: INFO: Pod "downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:44:23.754: INFO: Trying to get logs from node ip-10-0-39-198 pod downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 10:44:23.768: INFO: Waiting for pod downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:44:23.770: INFO: Pod downward-api-1a5a12d8-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:44:23.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7264" for this suite.
Apr  7 10:44:29.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:44:29.862: INFO: namespace downward-api-7264 deletion completed in 6.089274528s

• [SLOW TEST:8.197 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:44:29.862: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:44:29.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 version'
Apr  7 10:44:29.981: INFO: stderr: ""
Apr  7 10:44:29.981: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:44:29.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6274" for this suite.
Apr  7 10:44:35.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:44:36.059: INFO: namespace kubectl-6274 deletion completed in 6.074498541s

• [SLOW TEST:6.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:44:36.059: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  7 10:44:38.606: INFO: Successfully updated pod "labelsupdate22e69cd7-5922-11e9-9aa1-1aed65326ff2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:44:42.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4150" for this suite.
Apr  7 10:45:04.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:45:04.717: INFO: namespace projected-4150 deletion completed in 22.081845579s

• [SLOW TEST:28.658 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:45:04.718: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-33fb8d65-5922-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:45:04.746: INFO: Waiting up to 5m0s for pod "pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2" in namespace "configmap-3986" to be "success or failure"
Apr  7 10:45:04.749: INFO: Pod "pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.966332ms
Apr  7 10:45:06.752: INFO: Pod "pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005708837s
STEP: Saw pod success
Apr  7 10:45:06.752: INFO: Pod "pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:45:06.755: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 10:45:06.767: INFO: Waiting for pod pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:45:06.769: INFO: Pod pod-configmaps-33fbf52f-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:45:06.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3986" for this suite.
Apr  7 10:45:12.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:45:12.849: INFO: namespace configmap-3986 deletion completed in 6.075495308s

• [SLOW TEST:8.131 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:45:12.852: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:45:12.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-1648'
Apr  7 10:45:13.104: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  7 10:45:13.104: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr  7 10:45:15.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1648'
Apr  7 10:45:15.257: INFO: stderr: ""
Apr  7 10:45:15.257: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:45:15.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1648" for this suite.
Apr  7 10:45:21.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:45:21.341: INFO: namespace kubectl-1648 deletion completed in 6.078616253s

• [SLOW TEST:8.489 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:45:21.342: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 10:45:21.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7139'
Apr  7 10:45:21.468: INFO: stderr: ""
Apr  7 10:45:21.468: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr  7 10:45:21.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete pods e2e-test-nginx-pod --namespace=kubectl-7139'
Apr  7 10:45:28.986: INFO: stderr: ""
Apr  7 10:45:28.986: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:45:28.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7139" for this suite.
Apr  7 10:45:34.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:45:35.074: INFO: namespace kubectl-7139 deletion completed in 6.08539118s

• [SLOW TEST:13.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:45:35.074: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-461c62e9-5922-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 10:45:35.160: INFO: Waiting up to 5m0s for pod "pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2" in namespace "secrets-9745" to be "success or failure"
Apr  7 10:45:35.163: INFO: Pod "pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.446891ms
Apr  7 10:45:37.166: INFO: Pod "pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00597453s
STEP: Saw pod success
Apr  7 10:45:37.166: INFO: Pod "pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:45:37.169: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 10:45:37.191: INFO: Waiting for pod pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:45:37.192: INFO: Pod pod-secrets-461ccf8b-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:45:37.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9745" for this suite.
Apr  7 10:45:43.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:45:43.273: INFO: namespace secrets-9745 deletion completed in 6.078047081s

• [SLOW TEST:8.199 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:45:43.275: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  7 10:45:43.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:16974,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  7 10:45:43.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:16974,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  7 10:45:53.307: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:16991,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  7 10:45:53.307: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:16991,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  7 10:46:03.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:17006,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  7 10:46:03.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:17006,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  7 10:46:13.319: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:17021,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  7 10:46:13.319: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-a,UID:4aeedd23-5922-11e9-99b0-0225f4f52196,ResourceVersion:17021,Generation:0,CreationTimestamp:2019-04-07 10:45:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  7 10:46:23.324: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-b,UID:62c9682d-5922-11e9-99b0-0225f4f52196,ResourceVersion:17036,Generation:0,CreationTimestamp:2019-04-07 10:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  7 10:46:23.324: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-b,UID:62c9682d-5922-11e9-99b0-0225f4f52196,ResourceVersion:17036,Generation:0,CreationTimestamp:2019-04-07 10:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  7 10:46:33.328: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-b,UID:62c9682d-5922-11e9-99b0-0225f4f52196,ResourceVersion:17050,Generation:0,CreationTimestamp:2019-04-07 10:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  7 10:46:33.328: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-138,SelfLink:/api/v1/namespaces/watch-138/configmaps/e2e-watch-test-configmap-b,UID:62c9682d-5922-11e9-99b0-0225f4f52196,ResourceVersion:17050,Generation:0,CreationTimestamp:2019-04-07 10:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:46:43.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-138" for this suite.
Apr  7 10:46:49.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:46:49.423: INFO: namespace watch-138 deletion completed in 6.089497072s

• [SLOW TEST:66.148 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:46:49.423: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-h9hb
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 10:46:49.453: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-h9hb" in namespace "subpath-1659" to be "success or failure"
Apr  7 10:46:49.456: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.769551ms
Apr  7 10:46:51.459: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005779465s
Apr  7 10:46:53.462: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 4.008553675s
Apr  7 10:46:55.465: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 6.011459832s
Apr  7 10:46:57.468: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 8.014610404s
Apr  7 10:46:59.471: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 10.017495983s
Apr  7 10:47:01.474: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 12.020237381s
Apr  7 10:47:03.477: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 14.023207898s
Apr  7 10:47:05.480: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 16.026219514s
Apr  7 10:47:07.482: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 18.028894811s
Apr  7 10:47:09.485: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Running", Reason="", readiness=true. Elapsed: 20.031905468s
Apr  7 10:47:11.490: INFO: Pod "pod-subpath-test-secret-h9hb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036785298s
STEP: Saw pod success
Apr  7 10:47:11.490: INFO: Pod "pod-subpath-test-secret-h9hb" satisfied condition "success or failure"
Apr  7 10:47:11.492: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-subpath-test-secret-h9hb container test-container-subpath-secret-h9hb: <nil>
STEP: delete the pod
Apr  7 10:47:11.511: INFO: Waiting for pod pod-subpath-test-secret-h9hb to disappear
Apr  7 10:47:11.513: INFO: Pod pod-subpath-test-secret-h9hb no longer exists
STEP: Deleting pod pod-subpath-test-secret-h9hb
Apr  7 10:47:11.513: INFO: Deleting pod "pod-subpath-test-secret-h9hb" in namespace "subpath-1659"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:11.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1659" for this suite.
Apr  7 10:47:17.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:47:17.595: INFO: namespace subpath-1659 deletion completed in 6.077686601s

• [SLOW TEST:28.172 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:47:17.595: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-1180/configmap-test-832f5499-5922-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 10:47:17.627: INFO: Waiting up to 5m0s for pod "pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2" in namespace "configmap-1180" to be "success or failure"
Apr  7 10:47:17.630: INFO: Pod "pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00202ms
Apr  7 10:47:19.633: INFO: Pod "pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005906573s
STEP: Saw pod success
Apr  7 10:47:19.633: INFO: Pod "pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:47:19.637: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2 container env-test: <nil>
STEP: delete the pod
Apr  7 10:47:19.650: INFO: Waiting for pod pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:47:19.652: INFO: Pod pod-configmaps-832fff84-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:19.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1180" for this suite.
Apr  7 10:47:25.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:47:25.727: INFO: namespace configmap-1180 deletion completed in 6.072338364s

• [SLOW TEST:8.132 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:47:25.727: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr  7 10:47:25.751: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030244346 proxy --unix-socket=/tmp/kubectl-proxy-unix006754065/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:25.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2698" for this suite.
Apr  7 10:47:31.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:47:31.900: INFO: namespace kubectl-2698 deletion completed in 6.075401509s

• [SLOW TEST:6.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:47:31.901: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  7 10:47:31.997: INFO: Waiting up to 5m0s for pod "pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2" in namespace "emptydir-769" to be "success or failure"
Apr  7 10:47:32.003: INFO: Pod "pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.073582ms
Apr  7 10:47:34.006: INFO: Pod "pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009165454s
STEP: Saw pod success
Apr  7 10:47:34.007: INFO: Pod "pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:47:34.009: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:47:34.023: INFO: Waiting for pod pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:47:34.025: INFO: Pod pod-8bc022c4-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:34.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-769" for this suite.
Apr  7 10:47:40.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:47:40.103: INFO: namespace emptydir-769 deletion completed in 6.075163651s

• [SLOW TEST:8.202 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:47:40.104: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr  7 10:47:40.130: INFO: Waiting up to 5m0s for pod "client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2" in namespace "containers-905" to be "success or failure"
Apr  7 10:47:40.133: INFO: Pod "client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.53307ms
Apr  7 10:47:42.136: INFO: Pod "client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006482202s
STEP: Saw pod success
Apr  7 10:47:42.136: INFO: Pod "client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:47:42.139: INFO: Trying to get logs from node ip-10-0-29-139 pod client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:47:42.155: INFO: Waiting for pod client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:47:42.158: INFO: Pod client-containers-90999ca2-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:42.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-905" for this suite.
Apr  7 10:47:48.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:47:48.232: INFO: namespace containers-905 deletion completed in 6.071888524s

• [SLOW TEST:8.129 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:47:48.233: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:47:48.255: INFO: Creating ReplicaSet my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2
Apr  7 10:47:48.260: INFO: Pod name my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2: Found 0 pods out of 1
Apr  7 10:47:53.263: INFO: Pod name my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2: Found 1 pods out of 1
Apr  7 10:47:53.263: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2" is running
Apr  7 10:47:53.266: INFO: Pod "my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2-drnps" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:47:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:47:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:47:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-07 10:47:48 +0000 UTC Reason: Message:}])
Apr  7 10:47:53.266: INFO: Trying to dial the pod
Apr  7 10:47:58.276: INFO: Controller my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2: Got expected result from replica 1 [my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2-drnps]: "my-hostname-basic-957216ea-5922-11e9-9aa1-1aed65326ff2-drnps", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:47:58.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9589" for this suite.
Apr  7 10:48:04.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:48:04.363: INFO: namespace replicaset-9589 deletion completed in 6.084595332s

• [SLOW TEST:16.130 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:48:04.365: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-zmc4
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 10:48:04.395: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zmc4" in namespace "subpath-6878" to be "success or failure"
Apr  7 10:48:04.399: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.657515ms
Apr  7 10:48:06.402: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006592933s
Apr  7 10:48:08.405: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 4.009764239s
Apr  7 10:48:10.408: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 6.0128667s
Apr  7 10:48:12.411: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 8.015755585s
Apr  7 10:48:14.418: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 10.022413584s
Apr  7 10:48:16.421: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 12.025304565s
Apr  7 10:48:18.424: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 14.028279455s
Apr  7 10:48:20.429: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 16.033241313s
Apr  7 10:48:22.432: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 18.036094898s
Apr  7 10:48:24.436: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Running", Reason="", readiness=true. Elapsed: 20.040617204s
Apr  7 10:48:26.439: INFO: Pod "pod-subpath-test-configmap-zmc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043675994s
STEP: Saw pod success
Apr  7 10:48:26.439: INFO: Pod "pod-subpath-test-configmap-zmc4" satisfied condition "success or failure"
Apr  7 10:48:26.441: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-subpath-test-configmap-zmc4 container test-container-subpath-configmap-zmc4: <nil>
STEP: delete the pod
Apr  7 10:48:26.460: INFO: Waiting for pod pod-subpath-test-configmap-zmc4 to disappear
Apr  7 10:48:26.461: INFO: Pod pod-subpath-test-configmap-zmc4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zmc4
Apr  7 10:48:26.462: INFO: Deleting pod "pod-subpath-test-configmap-zmc4" in namespace "subpath-6878"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:48:26.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6878" for this suite.
Apr  7 10:48:32.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:48:32.567: INFO: namespace subpath-6878 deletion completed in 6.098697445s

• [SLOW TEST:28.202 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:48:32.568: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:48:32.648: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2" in namespace "downward-api-3539" to be "success or failure"
Apr  7 10:48:32.651: INFO: Pod "downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.73483ms
Apr  7 10:48:34.654: INFO: Pod "downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006707868s
STEP: Saw pod success
Apr  7 10:48:34.654: INFO: Pod "downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:48:34.657: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:48:34.673: INFO: Waiting for pod downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:48:34.675: INFO: Pod downwardapi-volume-afe6f203-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:48:34.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3539" for this suite.
Apr  7 10:48:40.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:48:40.752: INFO: namespace downward-api-3539 deletion completed in 6.074897556s

• [SLOW TEST:8.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:48:40.752: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-b4c014f0-5922-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b4c014f0-5922-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:48:44.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2553" for this suite.
Apr  7 10:49:06.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:49:06.888: INFO: namespace configmap-2553 deletion completed in 22.073827836s

• [SLOW TEST:26.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:49:06.888: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  7 10:49:10.946: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:10.948: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:12.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:12.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:14.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:14.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:16.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:16.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:18.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:18.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:20.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:20.950: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:22.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:22.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:24.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:24.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:26.949: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:26.952: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:28.949: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:28.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:30.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:30.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:32.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:32.950: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:34.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:34.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:36.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:36.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:38.948: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:38.951: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 10:49:40.954: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 10:49:40.956: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:49:40.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2723" for this suite.
Apr  7 10:50:02.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:50:03.048: INFO: namespace container-lifecycle-hook-2723 deletion completed in 22.089393219s

• [SLOW TEST:56.161 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:50:03.049: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  7 10:50:03.069: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:50:05.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7073" for this suite.
Apr  7 10:50:11.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:50:11.872: INFO: namespace init-container-7073 deletion completed in 6.08052035s

• [SLOW TEST:8.823 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:50:11.872: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:50:11.957: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2" in namespace "downward-api-1476" to be "success or failure"
Apr  7 10:50:11.960: INFO: Pod "downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695089ms
Apr  7 10:50:13.963: INFO: Pod "downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00579854s
STEP: Saw pod success
Apr  7 10:50:13.963: INFO: Pod "downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:50:13.966: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:50:13.987: INFO: Waiting for pod downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:50:14.005: INFO: Pod downwardapi-volume-eb175bda-5922-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:50:14.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1476" for this suite.
Apr  7 10:50:20.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:50:20.087: INFO: namespace downward-api-1476 deletion completed in 6.078985146s

• [SLOW TEST:8.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:50:20.088: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0407 10:50:50.653349      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 10:50:50.653: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:50:50.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2886" for this suite.
Apr  7 10:50:56.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:50:56.750: INFO: namespace gc-2886 deletion completed in 6.094644577s

• [SLOW TEST:36.662 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:50:56.750: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2733
Apr  7 10:50:58.832: INFO: Started pod liveness-http in namespace container-probe-2733
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 10:50:58.834: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:54:59.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2733" for this suite.
Apr  7 10:55:05.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:55:05.308: INFO: namespace container-probe-2733 deletion completed in 6.07610061s

• [SLOW TEST:248.558 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:55:05.308: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr  7 10:55:05.337: INFO: Waiting up to 5m0s for pod "client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2" in namespace "containers-4693" to be "success or failure"
Apr  7 10:55:05.342: INFO: Pod "client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.885085ms
Apr  7 10:55:07.345: INFO: Pod "client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007619827s
STEP: Saw pod success
Apr  7 10:55:07.345: INFO: Pod "client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:55:07.347: INFO: Trying to get logs from node ip-10-0-29-139 pod client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 10:55:07.362: INFO: Waiting for pod client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:55:07.364: INFO: Pod client-containers-99f6d316-5923-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:55:07.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4693" for this suite.
Apr  7 10:55:13.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:55:13.444: INFO: namespace containers-4693 deletion completed in 6.076485169s

• [SLOW TEST:8.136 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:55:13.444: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6192.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6192.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6192.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6192.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 50.223.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.223.50_udp@PTR;check="$$(dig +tcp +noall +answer +search 50.223.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.223.50_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6192.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6192.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6192.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6192.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6192.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6192.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 50.223.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.223.50_udp@PTR;check="$$(dig +tcp +noall +answer +search 50.223.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.223.50_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 10:55:15.549: INFO: Unable to read wheezy_udp@dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.552: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.555: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.558: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.580: INFO: Unable to read jessie_udp@dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.583: INFO: Unable to read jessie_tcp@dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.586: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.589: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local from pod dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2: the server could not find the requested resource (get pods dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2)
Apr  7 10:55:15.608: INFO: Lookups using dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2 failed for: [wheezy_udp@dns-test-service.dns-6192.svc.cluster.local wheezy_tcp@dns-test-service.dns-6192.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local jessie_udp@dns-test-service.dns-6192.svc.cluster.local jessie_tcp@dns-test-service.dns-6192.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6192.svc.cluster.local]

Apr  7 10:55:20.674: INFO: DNS probes using dns-6192/dns-test-9ed96f11-5923-11e9-9aa1-1aed65326ff2 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:55:20.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6192" for this suite.
Apr  7 10:55:26.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:55:26.813: INFO: namespace dns-6192 deletion completed in 6.075223473s

• [SLOW TEST:13.369 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:55:26.814: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  7 10:55:26.844: INFO: Waiting up to 5m0s for pod "downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2" in namespace "downward-api-2165" to be "success or failure"
Apr  7 10:55:26.847: INFO: Pod "downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.911597ms
Apr  7 10:55:28.850: INFO: Pod "downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00601313s
STEP: Saw pod success
Apr  7 10:55:28.850: INFO: Pod "downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:55:28.853: INFO: Trying to get logs from node ip-10-0-39-198 pod downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 10:55:28.874: INFO: Waiting for pod downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:55:28.877: INFO: Pod downward-api-a6c8496f-5923-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:55:28.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2165" for this suite.
Apr  7 10:55:34.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:55:34.953: INFO: namespace downward-api-2165 deletion completed in 6.074207197s

• [SLOW TEST:8.139 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:55:34.956: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:55:55.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4748" for this suite.
Apr  7 10:56:01.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:56:01.201: INFO: namespace container-runtime-4748 deletion completed in 6.080273977s

• [SLOW TEST:26.246 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:56:01.202: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-t6tt
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 10:56:01.235: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t6tt" in namespace "subpath-4933" to be "success or failure"
Apr  7 10:56:01.241: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Pending", Reason="", readiness=false. Elapsed: 5.431573ms
Apr  7 10:56:03.244: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 2.008488156s
Apr  7 10:56:05.247: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 4.011519752s
Apr  7 10:56:07.250: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 6.014496543s
Apr  7 10:56:09.253: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 8.017470899s
Apr  7 10:56:11.256: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 10.020410041s
Apr  7 10:56:13.258: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 12.023021703s
Apr  7 10:56:15.261: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 14.025741477s
Apr  7 10:56:17.264: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 16.028572542s
Apr  7 10:56:19.267: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 18.031468697s
Apr  7 10:56:21.272: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Running", Reason="", readiness=true. Elapsed: 20.036289878s
Apr  7 10:56:23.275: INFO: Pod "pod-subpath-test-configmap-t6tt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.039819284s
STEP: Saw pod success
Apr  7 10:56:23.275: INFO: Pod "pod-subpath-test-configmap-t6tt" satisfied condition "success or failure"
Apr  7 10:56:23.277: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-subpath-test-configmap-t6tt container test-container-subpath-configmap-t6tt: <nil>
STEP: delete the pod
Apr  7 10:56:23.302: INFO: Waiting for pod pod-subpath-test-configmap-t6tt to disappear
Apr  7 10:56:23.304: INFO: Pod pod-subpath-test-configmap-t6tt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t6tt
Apr  7 10:56:23.304: INFO: Deleting pod "pod-subpath-test-configmap-t6tt" in namespace "subpath-4933"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:56:23.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4933" for this suite.
Apr  7 10:56:29.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:56:29.384: INFO: namespace subpath-4933 deletion completed in 6.075597272s

• [SLOW TEST:28.182 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:56:29.385: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:56:29.411: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2" in namespace "projected-3969" to be "success or failure"
Apr  7 10:56:29.415: INFO: Pod "downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.870333ms
Apr  7 10:56:31.419: INFO: Pod "downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00745105s
STEP: Saw pod success
Apr  7 10:56:31.419: INFO: Pod "downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:56:31.421: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:56:31.436: INFO: Waiting for pod downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:56:31.438: INFO: Pod downwardapi-volume-cc13a5b6-5923-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:56:31.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3969" for this suite.
Apr  7 10:56:37.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:56:37.517: INFO: namespace projected-3969 deletion completed in 6.075453493s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:56:37.518: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-6063
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6063
STEP: Deleting pre-stop pod
Apr  7 10:56:48.573: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:56:48.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6063" for this suite.
Apr  7 10:57:26.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:57:26.688: INFO: namespace prestop-6063 deletion completed in 38.090809753s

• [SLOW TEST:49.170 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:57:26.688: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 10:57:26.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2" in namespace "projected-1019" to be "success or failure"
Apr  7 10:57:26.725: INFO: Pod "downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.695736ms
Apr  7 10:57:28.733: INFO: Pod "downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016516275s
STEP: Saw pod success
Apr  7 10:57:28.733: INFO: Pod "downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 10:57:28.735: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 10:57:28.751: INFO: Waiting for pod downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 10:57:28.752: INFO: Pod downwardapi-volume-ee3b43c9-5923-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:57:28.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1019" for this suite.
Apr  7 10:57:34.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:57:34.830: INFO: namespace projected-1019 deletion completed in 6.075155234s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:57:34.830: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  7 10:57:34.855: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:57:38.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9969" for this suite.
Apr  7 10:57:44.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:57:44.796: INFO: namespace init-container-9969 deletion completed in 6.126990506s

• [SLOW TEST:9.966 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:57:44.796: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 10:57:44.831: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 10:57:46.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4600" for this suite.
Apr  7 10:58:36.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 10:58:37.026: INFO: namespace pods-4600 deletion completed in 50.09049043s

• [SLOW TEST:52.229 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 10:58:37.026: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5511
Apr  7 10:58:39.060: INFO: Started pod liveness-http in namespace container-probe-5511
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 10:58:39.062: INFO: Initial restart count of pod liveness-http is 0
Apr  7 10:58:51.079: INFO: Restart count of pod container-probe-5511/liveness-http is now 1 (12.01693128s elapsed)
Apr  7 10:59:11.106: INFO: Restart count of pod container-probe-5511/liveness-http is now 2 (32.043946076s elapsed)
Apr  7 10:59:29.131: INFO: Restart count of pod container-probe-5511/liveness-http is now 3 (50.068342101s elapsed)
Apr  7 10:59:49.163: INFO: Restart count of pod container-probe-5511/liveness-http is now 4 (1m10.100394172s elapsed)
Apr  7 11:00:53.269: INFO: Restart count of pod container-probe-5511/liveness-http is now 5 (2m14.206815229s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:00:53.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5511" for this suite.
Apr  7 11:00:59.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:00:59.371: INFO: namespace container-probe-5511 deletion completed in 6.090775854s

• [SLOW TEST:142.345 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:00:59.371: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 11:00:59.412: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  7 11:00:59.417: INFO: Number of nodes with available pods: 0
Apr  7 11:00:59.417: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  7 11:00:59.433: INFO: Number of nodes with available pods: 0
Apr  7 11:00:59.433: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:00.442: INFO: Number of nodes with available pods: 0
Apr  7 11:01:00.442: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:01.438: INFO: Number of nodes with available pods: 0
Apr  7 11:01:01.438: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:02.436: INFO: Number of nodes with available pods: 0
Apr  7 11:01:02.436: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:03.436: INFO: Number of nodes with available pods: 1
Apr  7 11:01:03.436: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  7 11:01:03.460: INFO: Number of nodes with available pods: 1
Apr  7 11:01:03.460: INFO: Number of running nodes: 0, number of available pods: 1
Apr  7 11:01:04.463: INFO: Number of nodes with available pods: 0
Apr  7 11:01:04.463: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  7 11:01:04.468: INFO: Number of nodes with available pods: 0
Apr  7 11:01:04.468: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:05.472: INFO: Number of nodes with available pods: 0
Apr  7 11:01:05.472: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:06.472: INFO: Number of nodes with available pods: 0
Apr  7 11:01:06.472: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:07.471: INFO: Number of nodes with available pods: 0
Apr  7 11:01:07.471: INFO: Node ip-10-0-29-139 is running more than one daemon pod
Apr  7 11:01:08.471: INFO: Number of nodes with available pods: 1
Apr  7 11:01:08.472: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9097, will wait for the garbage collector to delete the pods
Apr  7 11:01:08.538: INFO: Deleting DaemonSet.extensions daemon-set took: 9.130679ms
Apr  7 11:01:08.839: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.313799ms
Apr  7 11:01:20.751: INFO: Number of nodes with available pods: 0
Apr  7 11:01:20.752: INFO: Number of running nodes: 0, number of available pods: 0
Apr  7 11:01:20.761: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9097/daemonsets","resourceVersion":"19456"},"items":null}

Apr  7 11:01:20.765: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9097/pods","resourceVersion":"19456"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:01:20.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9097" for this suite.
Apr  7 11:01:26.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:01:26.861: INFO: namespace daemonsets-9097 deletion completed in 6.076035253s

• [SLOW TEST:27.490 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:01:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7d6acb85-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 11:01:26.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2" in namespace "configmap-1354" to be "success or failure"
Apr  7 11:01:26.947: INFO: Pod "pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068052ms
Apr  7 11:01:28.950: INFO: Pod "pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007299543s
STEP: Saw pod success
Apr  7 11:01:28.950: INFO: Pod "pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:01:28.952: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 11:01:28.972: INFO: Waiting for pod pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:01:28.974: INFO: Pod pod-configmaps-7d6b37cb-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:01:28.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1354" for this suite.
Apr  7 11:01:34.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:01:35.055: INFO: namespace configmap-1354 deletion completed in 6.07788676s

• [SLOW TEST:8.194 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:01:35.056: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  7 11:01:35.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7424'
Apr  7 11:01:35.330: INFO: stderr: ""
Apr  7 11:01:35.330: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr  7 11:01:40.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 get pod e2e-test-nginx-pod --namespace=kubectl-7424 -o json'
Apr  7 11:01:40.459: INFO: stderr: ""
Apr  7 11:01:40.459: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.122.158/32\"\n        },\n        \"creationTimestamp\": \"2019-04-07T11:01:35Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7424\",\n        \"resourceVersion\": \"19542\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7424/pods/e2e-test-nginx-pod\",\n        \"uid\": \"826b9ab4-5924-11e9-99b0-0225f4f52196\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mfbjk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-39-198\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mfbjk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mfbjk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-07T11:01:35Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-07T11:01:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-07T11:01:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-07T11:01:35Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://d68a551570f132f5b16f98a954419455ff830c8d048f876f67492675318a6a75\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-07T11:01:36Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.39.198\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.122.158\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-07T11:01:35Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  7 11:01:40.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 replace -f - --namespace=kubectl-7424'
Apr  7 11:01:40.653: INFO: stderr: ""
Apr  7 11:01:40.653: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr  7 11:01:40.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 delete pods e2e-test-nginx-pod --namespace=kubectl-7424'
Apr  7 11:01:48.990: INFO: stderr: ""
Apr  7 11:01:48.990: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:01:48.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7424" for this suite.
Apr  7 11:01:55.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:01:55.075: INFO: namespace kubectl-7424 deletion completed in 6.080736943s

• [SLOW TEST:20.019 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:01:55.075: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  7 11:01:55.106: INFO: Waiting up to 5m0s for pod "downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2" in namespace "downward-api-5673" to be "success or failure"
Apr  7 11:01:55.109: INFO: Pod "downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861263ms
Apr  7 11:01:57.112: INFO: Pod "downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005699502s
STEP: Saw pod success
Apr  7 11:01:57.112: INFO: Pod "downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:01:57.115: INFO: Trying to get logs from node ip-10-0-29-139 pod downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 11:01:57.139: INFO: Waiting for pod downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:01:57.141: INFO: Pod downward-api-8e34b070-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:01:57.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5673" for this suite.
Apr  7 11:02:03.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:03.219: INFO: namespace downward-api-5673 deletion completed in 6.075899298s

• [SLOW TEST:8.143 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:03.219: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 11:02:03.244: INFO: Waiting up to 5m0s for pod "downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2" in namespace "downward-api-9458" to be "success or failure"
Apr  7 11:02:03.246: INFO: Pod "downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.260671ms
Apr  7 11:02:05.249: INFO: Pod "downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00538603s
STEP: Saw pod success
Apr  7 11:02:05.249: INFO: Pod "downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:05.252: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 11:02:05.267: INFO: Waiting for pod downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:05.269: INFO: Pod downwardapi-volume-930e5233-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:05.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9458" for this suite.
Apr  7 11:02:11.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:11.347: INFO: namespace downward-api-9458 deletion completed in 6.075026187s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:11.347: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-97e6d579-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 11:02:11.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2" in namespace "configmap-3797" to be "success or failure"
Apr  7 11:02:11.378: INFO: Pod "pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152698ms
Apr  7 11:02:13.381: INFO: Pod "pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005224494s
STEP: Saw pod success
Apr  7 11:02:13.381: INFO: Pod "pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:13.383: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 11:02:13.396: INFO: Waiting for pod pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:13.398: INFO: Pod pod-configmaps-97e734b8-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:13.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3797" for this suite.
Apr  7 11:02:19.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:19.487: INFO: namespace configmap-3797 deletion completed in 6.086145596s

• [SLOW TEST:8.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:19.487: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr  7 11:02:19.509: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030244346 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:19.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5283" for this suite.
Apr  7 11:02:25.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:25.671: INFO: namespace kubectl-5283 deletion completed in 6.078340688s

• [SLOW TEST:6.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:25.671: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a07116f6-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:02:25.704: INFO: Waiting up to 5m0s for pod "pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2" in namespace "secrets-2093" to be "success or failure"
Apr  7 11:02:25.708: INFO: Pod "pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.469732ms
Apr  7 11:02:27.711: INFO: Pod "pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007377477s
STEP: Saw pod success
Apr  7 11:02:27.711: INFO: Pod "pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:27.714: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 11:02:27.728: INFO: Waiting for pod pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:27.730: INFO: Pod pod-secrets-a0717a6e-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:27.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2093" for this suite.
Apr  7 11:02:33.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:33.809: INFO: namespace secrets-2093 deletion completed in 6.076423672s

• [SLOW TEST:8.138 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:33.810: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-a54acdef-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 11:02:33.843: INFO: Waiting up to 5m0s for pod "pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2" in namespace "configmap-9178" to be "success or failure"
Apr  7 11:02:33.848: INFO: Pod "pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.439146ms
Apr  7 11:02:35.851: INFO: Pod "pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008454237s
STEP: Saw pod success
Apr  7 11:02:35.852: INFO: Pod "pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:35.854: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 11:02:35.881: INFO: Waiting for pod pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:35.883: INFO: Pod pod-configmaps-a54b52c7-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:35.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9178" for this suite.
Apr  7 11:02:41.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:41.967: INFO: namespace configmap-9178 deletion completed in 6.081591315s

• [SLOW TEST:8.157 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:41.967: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  7 11:02:41.993: INFO: Waiting up to 5m0s for pod "pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2" in namespace "emptydir-568" to be "success or failure"
Apr  7 11:02:41.996: INFO: Pod "pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.542829ms
Apr  7 11:02:44.001: INFO: Pod "pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007834054s
STEP: Saw pod success
Apr  7 11:02:44.001: INFO: Pod "pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:44.003: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2 container test-container: <nil>
STEP: delete the pod
Apr  7 11:02:44.017: INFO: Waiting for pod pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:44.020: INFO: Pod pod-aa26eba9-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:44.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-568" for this suite.
Apr  7 11:02:50.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:50.109: INFO: namespace emptydir-568 deletion completed in 6.085889019s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:50.110: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-af01a7aa-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:02:50.142: INFO: Waiting up to 5m0s for pod "pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2" in namespace "secrets-8368" to be "success or failure"
Apr  7 11:02:50.146: INFO: Pod "pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.481747ms
Apr  7 11:02:52.149: INFO: Pod "pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006529881s
STEP: Saw pod success
Apr  7 11:02:52.149: INFO: Pod "pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:02:52.152: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 11:02:52.163: INFO: Waiting for pod pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:02:52.173: INFO: Pod pod-secrets-af02874f-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:02:52.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8368" for this suite.
Apr  7 11:02:58.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:02:58.258: INFO: namespace secrets-8368 deletion completed in 6.082413849s

• [SLOW TEST:8.148 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:02:58.258: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr  7 11:02:58.286: INFO: Waiting up to 5m0s for pod "var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2" in namespace "var-expansion-3675" to be "success or failure"
Apr  7 11:02:58.292: INFO: Pod "var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.174682ms
Apr  7 11:03:00.295: INFO: Pod "var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008990847s
STEP: Saw pod success
Apr  7 11:03:00.295: INFO: Pod "var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:03:00.297: INFO: Trying to get logs from node ip-10-0-39-198 pod var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 11:03:00.311: INFO: Waiting for pod var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:03:00.313: INFO: Pod var-expansion-b3dd43a7-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:03:00.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3675" for this suite.
Apr  7 11:03:06.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:03:06.395: INFO: namespace var-expansion-3675 deletion completed in 6.07894413s

• [SLOW TEST:8.137 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:03:06.396: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b8b6dbb4-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:03:06.428: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2" in namespace "projected-8839" to be "success or failure"
Apr  7 11:03:06.431: INFO: Pod "pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.070374ms
Apr  7 11:03:08.437: INFO: Pod "pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008823662s
STEP: Saw pod success
Apr  7 11:03:08.437: INFO: Pod "pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:03:08.444: INFO: Trying to get logs from node ip-10-0-29-139 pod pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 11:03:08.481: INFO: Waiting for pod pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:03:08.494: INFO: Pod pod-projected-secrets-b8b74e41-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:03:08.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8839" for this suite.
Apr  7 11:03:14.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:03:14.602: INFO: namespace projected-8839 deletion completed in 6.103929954s

• [SLOW TEST:8.206 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:03:14.602: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:03:17.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-368" for this suite.
Apr  7 11:03:39.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:03:39.745: INFO: namespace replication-controller-368 deletion completed in 22.086127142s

• [SLOW TEST:25.143 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:03:39.745: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:03:41.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2361" for this suite.
Apr  7 11:04:19.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:04:19.866: INFO: namespace kubelet-test-2361 deletion completed in 38.07737855s

• [SLOW TEST:40.122 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:04:19.867: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0407 11:04:25.907306      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  7 11:04:25.907: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:04:25.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4155" for this suite.
Apr  7 11:04:31.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:04:31.987: INFO: namespace gc-4155 deletion completed in 6.077290139s

• [SLOW TEST:12.120 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:04:31.987: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 11:04:32.011: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2" in namespace "downward-api-7779" to be "success or failure"
Apr  7 11:04:32.014: INFO: Pod "downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277183ms
Apr  7 11:04:34.017: INFO: Pod "downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005741145s
STEP: Saw pod success
Apr  7 11:04:34.017: INFO: Pod "downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:04:34.020: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 11:04:34.036: INFO: Waiting for pod downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:04:34.038: INFO: Pod downwardapi-volume-ebba8837-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:04:34.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7779" for this suite.
Apr  7 11:04:40.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:04:40.187: INFO: namespace downward-api-7779 deletion completed in 6.146354297s

• [SLOW TEST:8.200 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:04:40.187: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 11:04:40.234: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f0a26527-5924-11e9-99b0-0225f4f52196", Controller:(*bool)(0xc0020bd796), BlockOwnerDeletion:(*bool)(0xc0020bd797)}}
Apr  7 11:04:40.243: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f0a09fa2-5924-11e9-99b0-0225f4f52196", Controller:(*bool)(0xc0020bd946), BlockOwnerDeletion:(*bool)(0xc0020bd947)}}
Apr  7 11:04:40.247: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f0a12044-5924-11e9-99b0-0225f4f52196", Controller:(*bool)(0xc00265c476), BlockOwnerDeletion:(*bool)(0xc00265c477)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:04:45.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7365" for this suite.
Apr  7 11:04:51.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:04:51.341: INFO: namespace gc-7365 deletion completed in 6.081991624s

• [SLOW TEST:11.154 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:04:51.341: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-7233/configmap-test-f743d424-5924-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume configMaps
Apr  7 11:04:51.369: INFO: Waiting up to 5m0s for pod "pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2" in namespace "configmap-7233" to be "success or failure"
Apr  7 11:04:51.373: INFO: Pod "pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.949001ms
Apr  7 11:04:53.376: INFO: Pod "pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006764024s
STEP: Saw pod success
Apr  7 11:04:53.376: INFO: Pod "pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:04:53.378: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2 container env-test: <nil>
STEP: delete the pod
Apr  7 11:04:53.394: INFO: Waiting for pod pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:04:53.396: INFO: Pod pod-configmaps-f744388a-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:04:53.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7233" for this suite.
Apr  7 11:04:59.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:04:59.476: INFO: namespace configmap-7233 deletion completed in 6.076216268s

• [SLOW TEST:8.136 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:04:59.477: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 11:04:59.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2" in namespace "downward-api-5088" to be "success or failure"
Apr  7 11:04:59.510: INFO: Pod "downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.243946ms
Apr  7 11:05:01.514: INFO: Pod "downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00842913s
STEP: Saw pod success
Apr  7 11:05:01.514: INFO: Pod "downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:05:01.521: INFO: Trying to get logs from node ip-10-0-29-139 pod downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 11:05:01.551: INFO: Waiting for pod downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:05:01.553: INFO: Pod downwardapi-volume-fc1d90bf-5924-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:05:01.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5088" for this suite.
Apr  7 11:05:07.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:05:07.642: INFO: namespace downward-api-5088 deletion completed in 6.08639704s

• [SLOW TEST:8.165 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:05:07.642: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  7 11:05:07.671: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2" in namespace "downward-api-9117" to be "success or failure"
Apr  7 11:05:07.674: INFO: Pod "downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.148216ms
Apr  7 11:05:09.677: INFO: Pod "downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005183859s
STEP: Saw pod success
Apr  7 11:05:09.677: INFO: Pod "downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:05:09.679: INFO: Trying to get logs from node ip-10-0-39-198 pod downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2 container client-container: <nil>
STEP: delete the pod
Apr  7 11:05:09.693: INFO: Waiting for pod downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:05:09.695: INFO: Pod downwardapi-volume-00fbdde7-5925-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:05:09.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9117" for this suite.
Apr  7 11:05:15.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:05:15.772: INFO: namespace downward-api-9117 deletion completed in 6.074329186s

• [SLOW TEST:8.130 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:05:15.772: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 11:05:15.796: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  7 11:05:15.802: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  7 11:05:20.805: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 11:05:20.805: INFO: Creating deployment "test-rolling-update-deployment"
Apr  7 11:05:20.808: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  7 11:05:20.814: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  7 11:05:22.820: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  7 11:05:22.822: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  7 11:05:22.828: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4960,SelfLink:/apis/apps/v1/namespaces/deployment-4960/deployments/test-rolling-update-deployment,UID:08d3326f-5925-11e9-99b0-0225f4f52196,ResourceVersion:20746,Generation:1,CreationTimestamp:2019-04-07 11:05:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-07 11:05:20 +0000 UTC 2019-04-07 11:05:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-07 11:05:21 +0000 UTC 2019-04-07 11:05:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 11:05:22.830: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-4960,SelfLink:/apis/apps/v1/namespaces/deployment-4960/replicasets/test-rolling-update-deployment-67599b4d9,UID:08d47de7-5925-11e9-99b0-0225f4f52196,ResourceVersion:20735,Generation:1,CreationTimestamp:2019-04-07 11:05:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 08d3326f-5925-11e9-99b0-0225f4f52196 0xc00269a690 0xc00269a691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  7 11:05:22.830: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  7 11:05:22.831: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4960,SelfLink:/apis/apps/v1/namespaces/deployment-4960/replicasets/test-rolling-update-controller,UID:05d6da27-5925-11e9-99b0-0225f4f52196,ResourceVersion:20745,Generation:2,CreationTimestamp:2019-04-07 11:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 08d3326f-5925-11e9-99b0-0225f4f52196 0xc00269a5c7 0xc00269a5c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  7 11:05:22.833: INFO: Pod "test-rolling-update-deployment-67599b4d9-hqpn2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-hqpn2,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-4960,SelfLink:/api/v1/namespaces/deployment-4960/pods/test-rolling-update-deployment-67599b4d9-hqpn2,UID:08d4f3ff-5925-11e9-99b0-0225f4f52196,ResourceVersion:20734,Generation:0,CreationTimestamp:2019-04-07 11:05:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.122.173/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 08d47de7-5925-11e9-99b0-0225f4f52196 0xc00269af40 0xc00269af41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ktdf6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ktdf6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ktdf6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-39-198,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269afc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269afe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 11:05:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 11:05:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 11:05:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-07 11:05:20 +0000 UTC  }],Message:,Reason:,HostIP:10.0.39.198,PodIP:10.2.122.173,StartTime:2019-04-07 11:05:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-07 11:05:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7bd62a1af81df1ecf101f782186426760487819e5e5bd937c87df17e5e3afa6a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:05:22.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4960" for this suite.
Apr  7 11:05:28.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:05:28.909: INFO: namespace deployment-4960 deletion completed in 6.074068172s

• [SLOW TEST:13.137 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:05:28.910: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7124
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  7 11:05:28.946: INFO: Found 0 stateful pods, waiting for 3
Apr  7 11:05:38.948: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 11:05:38.948: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 11:05:38.948: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 11:05:38.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-7124 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 11:05:39.139: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 11:05:39.139: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 11:05:39.139: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  7 11:05:39.164: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  7 11:05:49.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-7124 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 11:05:49.349: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 11:05:49.349: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 11:05:49.349: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 11:05:59.363: INFO: Waiting for StatefulSet statefulset-7124/ss2 to complete update
Apr  7 11:05:59.363: INFO: Waiting for Pod statefulset-7124/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  7 11:05:59.363: INFO: Waiting for Pod statefulset-7124/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  7 11:06:09.368: INFO: Waiting for StatefulSet statefulset-7124/ss2 to complete update
STEP: Rolling back to a previous revision
Apr  7 11:06:19.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-7124 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  7 11:06:19.529: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  7 11:06:19.529: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  7 11:06:19.529: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  7 11:06:29.555: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  7 11:06:39.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 exec --namespace=statefulset-7124 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  7 11:06:39.755: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  7 11:06:39.755: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  7 11:06:39.755: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  7 11:06:49.773: INFO: Waiting for StatefulSet statefulset-7124/ss2 to complete update
Apr  7 11:06:49.773: INFO: Waiting for Pod statefulset-7124/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr  7 11:06:59.778: INFO: Waiting for StatefulSet statefulset-7124/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  7 11:07:09.778: INFO: Deleting all statefulset in ns statefulset-7124
Apr  7 11:07:09.782: INFO: Scaling statefulset ss2 to 0
Apr  7 11:07:39.792: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 11:07:39.794: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:07:39.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7124" for this suite.
Apr  7 11:07:45.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:07:45.895: INFO: namespace statefulset-7124 deletion completed in 6.089592392s

• [SLOW TEST:136.986 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:07:45.896: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-2304/secret-test-5f500275-5925-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:07:45.931: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2" in namespace "secrets-2304" to be "success or failure"
Apr  7 11:07:45.935: INFO: Pod "pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330158ms
Apr  7 11:07:47.938: INFO: Pod "pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006363336s
STEP: Saw pod success
Apr  7 11:07:47.938: INFO: Pod "pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:07:47.941: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2 container env-test: <nil>
STEP: delete the pod
Apr  7 11:07:47.955: INFO: Waiting for pod pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:07:47.957: INFO: Pod pod-configmaps-5f50681a-5925-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:07:47.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2304" for this suite.
Apr  7 11:07:53.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:07:54.070: INFO: namespace secrets-2304 deletion completed in 6.11009265s

• [SLOW TEST:8.174 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:07:54.070: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-642f3407-5925-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:07:54.104: INFO: Waiting up to 5m0s for pod "pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2" in namespace "secrets-4720" to be "success or failure"
Apr  7 11:07:54.107: INFO: Pod "pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951505ms
Apr  7 11:07:56.110: INFO: Pod "pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005619992s
STEP: Saw pod success
Apr  7 11:07:56.110: INFO: Pod "pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:07:56.118: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 11:07:56.131: INFO: Waiting for pod pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:07:56.133: INFO: Pod pod-secrets-642f8bc3-5925-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:07:56.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4720" for this suite.
Apr  7 11:08:02.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:08:02.216: INFO: namespace secrets-4720 deletion completed in 6.079963554s

• [SLOW TEST:8.146 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:08:02.216: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr  7 11:08:02.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 cluster-info'
Apr  7 11:08:02.312: INFO: stderr: ""
Apr  7 11:08:02.312: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:08:02.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4533" for this suite.
Apr  7 11:08:08.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:08:08.398: INFO: namespace kubectl-4533 deletion completed in 6.081672937s

• [SLOW TEST:6.182 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:08:08.398: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6cb99ae0-5925-11e9-9aa1-1aed65326ff2
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6cb99ae0-5925-11e9-9aa1-1aed65326ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:08:12.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6568" for this suite.
Apr  7 11:08:34.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:08:34.544: INFO: namespace projected-6568 deletion completed in 22.073790994s

• [SLOW TEST:26.146 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:08:34.544: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:08:34.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3897" for this suite.
Apr  7 11:08:56.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:08:56.663: INFO: namespace kubelet-test-3897 deletion completed in 22.075922777s

• [SLOW TEST:22.119 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:08:56.663: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-897d0978-5925-11e9-9aa1-1aed65326ff2
STEP: Creating a pod to test consume secrets
Apr  7 11:08:56.692: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2" in namespace "projected-9529" to be "success or failure"
Apr  7 11:08:56.695: INFO: Pod "pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.011311ms
Apr  7 11:08:58.698: INFO: Pod "pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006389955s
STEP: Saw pod success
Apr  7 11:08:58.699: INFO: Pod "pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2" satisfied condition "success or failure"
Apr  7 11:08:58.701: INFO: Trying to get logs from node ip-10-0-39-198 pod pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 11:08:58.715: INFO: Waiting for pod pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2 to disappear
Apr  7 11:08:58.717: INFO: Pod pod-projected-secrets-897d742f-5925-11e9-9aa1-1aed65326ff2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:08:58.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9529" for this suite.
Apr  7 11:09:04.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:09:04.796: INFO: namespace projected-9529 deletion completed in 6.07720158s

• [SLOW TEST:8.134 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:09:04.797: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  7 11:09:04.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-3339'
Apr  7 11:09:05.026: INFO: stderr: ""
Apr  7 11:09:05.026: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  7 11:09:06.030: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:09:06.030: INFO: Found 0 / 1
Apr  7 11:09:07.029: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:09:07.029: INFO: Found 0 / 1
Apr  7 11:09:08.029: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:09:08.029: INFO: Found 1 / 1
Apr  7 11:09:08.029: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  7 11:09:08.031: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:09:08.031: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 11:09:08.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 patch pod redis-master-jl9fz --namespace=kubectl-3339 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  7 11:09:08.132: INFO: stderr: ""
Apr  7 11:09:08.132: INFO: stdout: "pod/redis-master-jl9fz patched\n"
STEP: checking annotations
Apr  7 11:09:08.142: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:09:08.142: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:09:08.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3339" for this suite.
Apr  7 11:09:30.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:09:30.238: INFO: namespace kubectl-3339 deletion completed in 22.085740703s

• [SLOW TEST:25.441 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:09:30.238: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  7 11:09:30.261: INFO: PodSpec: initContainers in spec.initContainers
Apr  7 11:10:16.553: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9d807d8e-5925-11e9-9aa1-1aed65326ff2", GenerateName:"", Namespace:"init-container-3186", SelfLink:"/api/v1/namespaces/init-container-3186/pods/pod-init-9d807d8e-5925-11e9-9aa1-1aed65326ff2", UID:"9d837c21-5925-11e9-99b0-0225f4f52196", ResourceVersion:"21822", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63690232170, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"261650780"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.122.184/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fhstw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001e25300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhstw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhstw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhstw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002d85ce8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-39-198", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002445e60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d85d70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002d85d90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002d85d98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002d85d9c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232170, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232170, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232170, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232170, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.39.198", PodIP:"10.2.122.184", StartTime:(*v1.Time)(0xc002ea8c40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025f8700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025f8770)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://9ec22f2d8a555a1611e41f5127bb4c81043cd2d761073b7372b34db30431d285"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ea8c80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ea8c60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:10:16.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3186" for this suite.
Apr  7 11:10:38.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:10:38.641: INFO: namespace init-container-3186 deletion completed in 22.084485377s

• [SLOW TEST:68.403 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:10:38.642: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  7 11:10:38.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 version --client'
Apr  7 11:10:38.723: INFO: stderr: ""
Apr  7 11:10:38.723: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr  7 11:10:38.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8904'
Apr  7 11:10:38.957: INFO: stderr: ""
Apr  7 11:10:38.957: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  7 11:10:38.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 create -f - --namespace=kubectl-8904'
Apr  7 11:10:39.151: INFO: stderr: ""
Apr  7 11:10:39.151: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  7 11:10:40.154: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:10:40.154: INFO: Found 0 / 1
Apr  7 11:10:41.154: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:10:41.154: INFO: Found 1 / 1
Apr  7 11:10:41.154: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  7 11:10:41.157: INFO: Selector matched 1 pods for map[app:redis]
Apr  7 11:10:41.157: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 11:10:41.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 describe pod redis-master-qtlqp --namespace=kubectl-8904'
Apr  7 11:10:41.252: INFO: stderr: ""
Apr  7 11:10:41.252: INFO: stdout: "Name:               redis-master-qtlqp\nNamespace:          kubectl-8904\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-29-139/10.0.29.139\nStart Time:         Sun, 07 Apr 2019 11:10:38 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.2.210.153/32\nStatus:             Running\nIP:                 10.2.210.153\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d221016d4ee8a4365515c3cda4dedbffabdd4a8fbe4848019791793d1d0a28dd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 07 Apr 2019 11:10:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-thl4n (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-thl4n:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-thl4n\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned kubectl-8904/redis-master-qtlqp to ip-10-0-29-139\n  Normal  Pulled     2s    kubelet, ip-10-0-29-139  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-0-29-139  Created container redis-master\n  Normal  Started    2s    kubelet, ip-10-0-29-139  Started container redis-master\n"
Apr  7 11:10:41.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 describe rc redis-master --namespace=kubectl-8904'
Apr  7 11:10:41.348: INFO: stderr: ""
Apr  7 11:10:41.348: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8904\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-qtlqp\n"
Apr  7 11:10:41.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 describe service redis-master --namespace=kubectl-8904'
Apr  7 11:10:41.434: INFO: stderr: ""
Apr  7 11:10:41.434: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8904\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.218.251\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.210.153:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  7 11:10:41.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 describe node ip-10-0-14-179'
Apr  7 11:10:41.595: INFO: stderr: ""
Apr  7 11:10:41.595: INFO: stdout: "Name:               ip-10-0-14-179\nRoles:              controller,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-14-179\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/controller=true\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.14.179/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.39.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 07 Apr 2019 09:39:32 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 07 Apr 2019 09:39:39 +0000   Sun, 07 Apr 2019 09:39:39 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sun, 07 Apr 2019 11:09:50 +0000   Sun, 07 Apr 2019 09:39:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 07 Apr 2019 11:09:50 +0000   Sun, 07 Apr 2019 09:39:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 07 Apr 2019 11:09:50 +0000   Sun, 07 Apr 2019 09:39:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 07 Apr 2019 11:09:50 +0000   Sun, 07 Apr 2019 09:39:42 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.14.179\n  Hostname:    ip-10-0-14-179\nCapacity:\n cpu:                2\n ephemeral-storage:  17897500Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2004008Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  16494335973\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1901608Ki\n pods:               110\nSystem Info:\n Machine ID:                 ec28e98e01257d735945de7f1385f6e3\n System UUID:                ec28e98e-0125-7d73-5945-de7f1385f6e3\n Boot ID:                    c89f94bc-1132-48d4-9cbd-ec59bc47a339\n Kernel Version:             4.19.25-coreos\n OS Image:                   Container Linux by CoreOS 2023.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nPodCIDR:                     10.2.0.0/24\nNon-terminated Pods:         (12 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e8e6e381860c47b5-g42fb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                calico-node-ks89t                                          150m (7%)     0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                coredns-5644c585c9-gfhc5                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     91m\n  kube-system                coredns-5644c585c9-mt564                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     91m\n  kube-system                kube-apiserver-w2ddx                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         90m\n  kube-system                kube-controller-manager-7c844bbd77-dnbv7                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                kube-controller-manager-7c844bbd77-j5zvc                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                kube-proxy-p8pjq                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                kube-scheduler-7b8c76994f-p6j64                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                kube-scheduler-7b8c76994f-qdplf                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  kube-system                pod-checkpointer-vvqjd                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         90m\n  kube-system                pod-checkpointer-vvqjd-ip-10-0-14-179                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         90m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                350m (17%)  0 (0%)\n  memory             140Mi (7%)  340Mi (18%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr  7 11:10:41.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030244346 describe namespace kubectl-8904'
Apr  7 11:10:41.733: INFO: stderr: ""
Apr  7 11:10:41.733: INFO: stdout: "Name:         kubectl-8904\nLabels:       e2e-framework=kubectl\n              e2e-run=6a4f7e49-591a-11e9-9aa1-1aed65326ff2\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:10:41.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8904" for this suite.
Apr  7 11:11:03.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:11:03.814: INFO: namespace kubectl-8904 deletion completed in 22.078101715s

• [SLOW TEST:25.172 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:11:03.815: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-794
Apr  7 11:11:05.849: INFO: Started pod liveness-exec in namespace container-probe-794
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 11:11:05.851: INFO: Initial restart count of pod liveness-exec is 0
Apr  7 11:11:53.928: INFO: Restart count of pod container-probe-794/liveness-exec is now 1 (48.077328668s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:11:53.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-794" for this suite.
Apr  7 11:11:59.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:12:00.016: INFO: namespace container-probe-794 deletion completed in 6.073883483s

• [SLOW TEST:56.201 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:12:00.020: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:12:00.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-269" for this suite.
Apr  7 11:12:06.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:12:06.130: INFO: namespace services-269 deletion completed in 6.081096238s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.110 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  7 11:12:06.130: INFO: >>> kubeConfig: /tmp/kubeconfig-030244346
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr  7 11:12:06.489: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr  7 11:12:08.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 11:12:10.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 11:12:12.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690232326, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 11:12:15.351: INFO: Waited 825.635865ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  7 11:12:15.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5855" for this suite.
Apr  7 11:12:21.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  7 11:12:22.043: INFO: namespace aggregator-5855 deletion completed in 6.179250622s

• [SLOW TEST:15.913 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSApr  7 11:12:22.044: INFO: Running AfterSuite actions on all nodes
Apr  7 11:12:22.045: INFO: Running AfterSuite actions on node 1
Apr  7 11:12:22.045: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 4980.251 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h23m2.206574155s
Test Suite Passed
