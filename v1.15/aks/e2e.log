I0115 21:02:03.183641      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-089408705
I0115 21:02:03.183743      16 e2e.go:243] Starting e2e run "8c058764-af84-44ad-bba3-c3dc1852a329" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1579122121 - Will randomize all specs
Will run 215 of 4412 specs

Jan 15 21:02:03.373: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:02:03.376: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 15 21:02:03.410: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 15 21:02:03.439: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 15 21:02:03.439: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Jan 15 21:02:03.439: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 15 21:02:03.446: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan 15 21:02:03.446: INFO: e2e test version: v1.15.7
Jan 15 21:02:03.447: INFO: kube-apiserver version: v1.15.7
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:02:03.447: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
Jan 15 21:02:03.499: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0115 21:02:09.539708      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 21:02:09.539: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:02:09.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5002" for this suite.
Jan 15 21:02:15.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:02:15.701: INFO: namespace gc-5002 deletion completed in 6.156680407s

• [SLOW TEST:12.254 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:02:15.701: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Jan 15 21:02:16.279: INFO: created pod pod-service-account-defaultsa
Jan 15 21:02:16.279: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 15 21:02:16.286: INFO: created pod pod-service-account-mountsa
Jan 15 21:02:16.286: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 15 21:02:16.294: INFO: created pod pod-service-account-nomountsa
Jan 15 21:02:16.294: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 15 21:02:16.301: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 15 21:02:16.301: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 15 21:02:16.307: INFO: created pod pod-service-account-mountsa-mountspec
Jan 15 21:02:16.307: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 15 21:02:16.314: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 15 21:02:16.314: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 15 21:02:16.321: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 15 21:02:16.321: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 15 21:02:16.327: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 15 21:02:16.327: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 15 21:02:16.332: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 15 21:02:16.332: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:02:16.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5091" for this suite.
Jan 15 21:02:38.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:02:38.507: INFO: namespace svcaccounts-5091 deletion completed in 22.168841925s

• [SLOW TEST:22.805 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:02:38.507: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:02:38.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599" in namespace "projected-4613" to be "success or failure"
Jan 15 21:02:38.578: INFO: Pod "downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599": Phase="Pending", Reason="", readiness=false. Elapsed: 5.474151ms
Jan 15 21:02:40.583: INFO: Pod "downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009545606s
Jan 15 21:02:42.587: INFO: Pod "downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014115255s
STEP: Saw pod success
Jan 15 21:02:42.587: INFO: Pod "downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599" satisfied condition "success or failure"
Jan 15 21:02:42.590: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599 container client-container: <nil>
STEP: delete the pod
Jan 15 21:02:42.612: INFO: Waiting for pod downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599 to disappear
Jan 15 21:02:42.615: INFO: Pod downwardapi-volume-276b365f-95f2-4576-981e-decc9c161599 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:02:42.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4613" for this suite.
Jan 15 21:02:48.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:02:48.811: INFO: namespace projected-4613 deletion completed in 6.190961669s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:02:48.812: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:02:48.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-6321'
Jan 15 21:02:49.844: INFO: stderr: ""
Jan 15 21:02:49.844: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 15 21:02:49.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-6321'
Jan 15 21:02:50.075: INFO: stderr: ""
Jan 15 21:02:50.075: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 21:02:51.081: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:02:51.081: INFO: Found 0 / 1
Jan 15 21:02:52.079: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:02:52.079: INFO: Found 0 / 1
Jan 15 21:02:53.079: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:02:53.079: INFO: Found 0 / 1
Jan 15 21:02:54.079: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:02:54.079: INFO: Found 1 / 1
Jan 15 21:02:54.079: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 21:02:54.083: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:02:54.083: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 21:02:54.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 describe pod redis-master-h76wl --namespace=kubectl-6321'
Jan 15 21:02:54.183: INFO: stderr: ""
Jan 15 21:02:54.183: INFO: stdout: "Name:           redis-master-h76wl\nNamespace:      kubectl-6321\nPriority:       0\nNode:           aks-nodepool1-25266157-vmss000001/10.240.0.5\nStart Time:     Wed, 15 Jan 2020 21:02:49 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.2.13\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://88e929035ade45c49f9dc5e29e67504eaef7c36e8fefcaf2805f48ed8fe7c308\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 15 Jan 2020 21:02:53 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-bhmvn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-bhmvn:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-bhmvn\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                        Message\n  ----    ------     ----  ----                                        -------\n  Normal  Scheduled  5s    default-scheduler                           Successfully assigned kubectl-6321/redis-master-h76wl to aks-nodepool1-25266157-vmss000001\n  Normal  Pulling    3s    kubelet, aks-nodepool1-25266157-vmss000001  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, aks-nodepool1-25266157-vmss000001  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, aks-nodepool1-25266157-vmss000001  Created container redis-master\n  Normal  Started    1s    kubelet, aks-nodepool1-25266157-vmss000001  Started container redis-master\n"
Jan 15 21:02:54.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 describe rc redis-master --namespace=kubectl-6321'
Jan 15 21:02:54.289: INFO: stderr: ""
Jan 15 21:02:54.289: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6321\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-h76wl\n"
Jan 15 21:02:54.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 describe service redis-master --namespace=kubectl-6321'
Jan 15 21:02:54.388: INFO: stderr: ""
Jan 15 21:02:54.388: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6321\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.186.40\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.13:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 15 21:02:54.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 describe node aks-nodepool1-25266157-vmss000000'
Jan 15 21:02:54.515: INFO: stderr: ""
Jan 15 21:02:54.515: INFO: stdout: "Name:               aks-nodepool1-25266157-vmss000000\nRoles:              agent\nLabels:             agentpool=nodepool1\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westus2\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/cluster=MC_levo-aks-westus2_levo-wus2-06_westus2\n                    kubernetes.azure.com/role=agent\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=aks-nodepool1-25266157-vmss000000\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    storageprofile=managed\n                    storagetier=Premium_LRS\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 15 Jan 2020 20:57:44 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 15 Jan 2020 20:58:04 +0000   Wed, 15 Jan 2020 20:58:04 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Wed, 15 Jan 2020 21:02:45 +0000   Wed, 15 Jan 2020 20:57:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 15 Jan 2020 21:02:45 +0000   Wed, 15 Jan 2020 20:57:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 15 Jan 2020 21:02:45 +0000   Wed, 15 Jan 2020 20:57:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 15 Jan 2020 21:02:45 +0000   Wed, 15 Jan 2020 20:57:44 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    aks-nodepool1-25266157-vmss000000\n  InternalIP:  10.240.0.4\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              101445900Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7114148Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            1900m\n ephemeral-storage:              93492541286\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         4668836Ki\n pods:                           110\nSystem Info:\n Machine ID:                 3f45f58eff254295b709a965a3dad0b4\n System UUID:                89E661D6-BB58-3E44-B73D-FCCAFF909FFA\n Boot ID:                    9d183e69-46e8-46ad-a160-3c57a9d9f6f5\n Kernel Version:             4.15.0-1064-azure\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://3.0.8\n Kubelet Version:            v1.15.7\n Kube-Proxy Version:         v1.15.7\nPodCIDR:                     10.244.0.0/24\nProviderID:                  azure:///subscriptions/01db32b1-e169-43b0-a791-de0e1ca5d8cd/resourceGroups/mc_levo-aks-westus2_levo-wus2-06_westus2/providers/Microsoft.Compute/virtualMachineScaleSets/aks-nodepool1-25266157-vmss/virtualMachines/0\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-68c85fc5d4-7jtpf                                   100m (5%)     0 (0%)      70Mi (1%)        170Mi (3%)     7m55s\n  kube-system                coredns-autoscaler-875fb445c-tvwfg                         20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         7m54s\n  kube-system                kube-proxy-k6zsd                                           100m (5%)     0 (0%)      0 (0%)           0 (0%)         5m10s\n  kube-system                kubernetes-dashboard-5758d48c87-k6r2c                      100m (5%)     100m (5%)   50Mi (1%)        500Mi (10%)    7m54s\n  kube-system                metrics-server-957757c9f-hvw4p                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m55s\n  kube-system                tunnelfront-6558768cb7-qpdxq                               10m (0%)      0 (0%)      64Mi (1%)        0 (0%)         7m54s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-1924fb744c904971-bmwhb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         78s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            330m (17%)  100m (5%)\n  memory                         194Mi (4%)  670Mi (14%)\n  ephemeral-storage              0 (0%)      0 (0%)\n  attachable-volumes-azure-disk  0           0\nEvents:\n  Type    Reason                   Age    From                                           Message\n  ----    ------                   ----   ----                                           -------\n  Normal  Starting                 5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Starting kubelet.\n  Normal  NodeHasSufficientMemory  5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Node aks-nodepool1-25266157-vmss000000 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Node aks-nodepool1-25266157-vmss000000 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Node aks-nodepool1-25266157-vmss000000 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Updated Node Allocatable limit across pods\n  Normal  NodeReady                5m10s  kubelet, aks-nodepool1-25266157-vmss000000     Node aks-nodepool1-25266157-vmss000000 status is now: NodeReady\n  Normal  Starting                 4m55s  kube-proxy, aks-nodepool1-25266157-vmss000000  Starting kube-proxy.\n"
Jan 15 21:02:54.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 describe namespace kubectl-6321'
Jan 15 21:02:54.621: INFO: stderr: ""
Jan 15 21:02:54.621: INFO: stdout: "Name:         kubectl-6321\nLabels:       e2e-framework=kubectl\n              e2e-run=8c058764-af84-44ad-bba3-c3dc1852a329\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:02:54.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6321" for this suite.
Jan 15 21:03:16.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:03:16.774: INFO: namespace kubectl-6321 deletion completed in 22.146463059s

• [SLOW TEST:27.962 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:03:16.775: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Jan 15 21:03:16.831: INFO: Waiting up to 5m0s for pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703" in namespace "downward-api-5691" to be "success or failure"
Jan 15 21:03:16.834: INFO: Pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703": Phase="Pending", Reason="", readiness=false. Elapsed: 2.96432ms
Jan 15 21:03:18.839: INFO: Pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007069238s
Jan 15 21:03:20.843: INFO: Pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011236686s
Jan 15 21:03:22.847: INFO: Pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015178769s
STEP: Saw pod success
Jan 15 21:03:22.847: INFO: Pod "downward-api-3fb54739-3f92-4635-9a16-e05ddd536703" satisfied condition "success or failure"
Jan 15 21:03:22.849: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downward-api-3fb54739-3f92-4635-9a16-e05ddd536703 container dapi-container: <nil>
STEP: delete the pod
Jan 15 21:03:22.874: INFO: Waiting for pod downward-api-3fb54739-3f92-4635-9a16-e05ddd536703 to disappear
Jan 15 21:03:22.877: INFO: Pod downward-api-3fb54739-3f92-4635-9a16-e05ddd536703 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:03:22.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5691" for this suite.
Jan 15 21:03:28.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:03:29.057: INFO: namespace downward-api-5691 deletion completed in 6.175196455s

• [SLOW TEST:12.283 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:03:29.058: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jan 15 21:03:32.366: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:03:32.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3995" for this suite.
Jan 15 21:03:38.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:03:38.637: INFO: namespace container-runtime-3995 deletion completed in 6.247542231s

• [SLOW TEST:9.579 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:03:38.637: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Jan 15 21:03:38.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8192'
Jan 15 21:03:39.597: INFO: stderr: ""
Jan 15 21:03:39.597: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 21:03:39.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:03:39.707: INFO: stderr: ""
Jan 15 21:03:39.707: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-n8fm5 "
Jan 15 21:03:39.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:03:39.789: INFO: stderr: ""
Jan 15 21:03:39.789: INFO: stdout: ""
Jan 15 21:03:39.789: INFO: update-demo-nautilus-c2ngd is created but not running
Jan 15 21:03:44.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:03:44.887: INFO: stderr: ""
Jan 15 21:03:44.887: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-n8fm5 "
Jan 15 21:03:44.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:03:44.975: INFO: stderr: ""
Jan 15 21:03:44.975: INFO: stdout: "true"
Jan 15 21:03:44.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:03:45.073: INFO: stderr: ""
Jan 15 21:03:45.073: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:03:45.073: INFO: validating pod update-demo-nautilus-c2ngd
Jan 15 21:03:45.168: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:03:45.168: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:03:45.168: INFO: update-demo-nautilus-c2ngd is verified up and running
Jan 15 21:03:45.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-n8fm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:03:45.261: INFO: stderr: ""
Jan 15 21:03:45.261: INFO: stdout: "true"
Jan 15 21:03:45.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-n8fm5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:03:45.355: INFO: stderr: ""
Jan 15 21:03:45.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:03:45.355: INFO: validating pod update-demo-nautilus-n8fm5
Jan 15 21:03:45.449: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:03:45.449: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:03:45.449: INFO: update-demo-nautilus-n8fm5 is verified up and running
STEP: scaling down the replication controller
Jan 15 21:03:45.451: INFO: scanned /root for discovery docs: <nil>
Jan 15 21:03:45.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8192'
Jan 15 21:03:46.587: INFO: stderr: ""
Jan 15 21:03:46.587: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 21:03:46.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:03:46.673: INFO: stderr: ""
Jan 15 21:03:46.673: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-n8fm5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 21:03:51.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:03:51.779: INFO: stderr: ""
Jan 15 21:03:51.779: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-n8fm5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 21:03:56.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:03:56.867: INFO: stderr: ""
Jan 15 21:03:56.867: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-n8fm5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 21:04:01.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:04:01.957: INFO: stderr: ""
Jan 15 21:04:01.957: INFO: stdout: "update-demo-nautilus-c2ngd "
Jan 15 21:04:01.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:02.042: INFO: stderr: ""
Jan 15 21:04:02.042: INFO: stdout: "true"
Jan 15 21:04:02.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:02.123: INFO: stderr: ""
Jan 15 21:04:02.123: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:04:02.123: INFO: validating pod update-demo-nautilus-c2ngd
Jan 15 21:04:02.134: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:04:02.134: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:04:02.134: INFO: update-demo-nautilus-c2ngd is verified up and running
STEP: scaling up the replication controller
Jan 15 21:04:02.136: INFO: scanned /root for discovery docs: <nil>
Jan 15 21:04:02.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8192'
Jan 15 21:04:03.255: INFO: stderr: ""
Jan 15 21:04:03.255: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 21:04:03.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:04:03.341: INFO: stderr: ""
Jan 15 21:04:03.341: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-qv9q7 "
Jan 15 21:04:03.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:03.426: INFO: stderr: ""
Jan 15 21:04:03.426: INFO: stdout: "true"
Jan 15 21:04:03.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:03.509: INFO: stderr: ""
Jan 15 21:04:03.509: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:04:03.509: INFO: validating pod update-demo-nautilus-c2ngd
Jan 15 21:04:03.514: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:04:03.514: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:04:03.514: INFO: update-demo-nautilus-c2ngd is verified up and running
Jan 15 21:04:03.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qv9q7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:03.604: INFO: stderr: ""
Jan 15 21:04:03.604: INFO: stdout: ""
Jan 15 21:04:03.604: INFO: update-demo-nautilus-qv9q7 is created but not running
Jan 15 21:04:08.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8192'
Jan 15 21:04:08.709: INFO: stderr: ""
Jan 15 21:04:08.710: INFO: stdout: "update-demo-nautilus-c2ngd update-demo-nautilus-qv9q7 "
Jan 15 21:04:08.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:08.800: INFO: stderr: ""
Jan 15 21:04:08.800: INFO: stdout: "true"
Jan 15 21:04:08.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c2ngd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:08.882: INFO: stderr: ""
Jan 15 21:04:08.882: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:04:08.882: INFO: validating pod update-demo-nautilus-c2ngd
Jan 15 21:04:08.889: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:04:08.889: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:04:08.889: INFO: update-demo-nautilus-c2ngd is verified up and running
Jan 15 21:04:08.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qv9q7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:08.977: INFO: stderr: ""
Jan 15 21:04:08.977: INFO: stdout: "true"
Jan 15 21:04:08.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qv9q7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8192'
Jan 15 21:04:09.061: INFO: stderr: ""
Jan 15 21:04:09.061: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 21:04:09.062: INFO: validating pod update-demo-nautilus-qv9q7
Jan 15 21:04:09.156: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 21:04:09.156: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 21:04:09.156: INFO: update-demo-nautilus-qv9q7 is verified up and running
STEP: using delete to clean up resources
Jan 15 21:04:09.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8192'
Jan 15 21:04:09.245: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:04:09.246: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 21:04:09.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8192'
Jan 15 21:04:09.337: INFO: stderr: "No resources found.\n"
Jan 15 21:04:09.337: INFO: stdout: ""
Jan 15 21:04:09.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=update-demo --namespace=kubectl-8192 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 21:04:09.417: INFO: stderr: ""
Jan 15 21:04:09.417: INFO: stdout: "update-demo-nautilus-c2ngd\nupdate-demo-nautilus-qv9q7\n"
Jan 15 21:04:09.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8192'
Jan 15 21:04:10.019: INFO: stderr: "No resources found.\n"
Jan 15 21:04:10.019: INFO: stdout: ""
Jan 15 21:04:10.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=update-demo --namespace=kubectl-8192 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 21:04:10.119: INFO: stderr: ""
Jan 15 21:04:10.119: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:04:10.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8192" for this suite.
Jan 15 21:04:32.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:04:32.278: INFO: namespace kubectl-8192 deletion completed in 22.151466257s

• [SLOW TEST:53.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:04:32.278: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 21:04:32.334: INFO: Waiting up to 5m0s for pod "pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e" in namespace "emptydir-5476" to be "success or failure"
Jan 15 21:04:32.337: INFO: Pod "pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.959415ms
Jan 15 21:04:34.341: INFO: Pod "pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007266118s
Jan 15 21:04:36.345: INFO: Pod "pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011400768s
STEP: Saw pod success
Jan 15 21:04:36.345: INFO: Pod "pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e" satisfied condition "success or failure"
Jan 15 21:04:36.348: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e container test-container: <nil>
STEP: delete the pod
Jan 15 21:04:36.371: INFO: Waiting for pod pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e to disappear
Jan 15 21:04:36.374: INFO: Pod pod-660f1128-d0d1-4c0b-b6b1-ee437af2731e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:04:36.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5476" for this suite.
Jan 15 21:04:42.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:04:42.521: INFO: namespace emptydir-5476 deletion completed in 6.142281086s

• [SLOW TEST:10.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:04:42.521: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:04:42.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664" in namespace "downward-api-1894" to be "success or failure"
Jan 15 21:04:42.591: INFO: Pod "downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664": Phase="Pending", Reason="", readiness=false. Elapsed: 3.296916ms
Jan 15 21:04:44.596: INFO: Pod "downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008452474s
STEP: Saw pod success
Jan 15 21:04:44.596: INFO: Pod "downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664" satisfied condition "success or failure"
Jan 15 21:04:44.599: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664 container client-container: <nil>
STEP: delete the pod
Jan 15 21:04:44.620: INFO: Waiting for pod downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664 to disappear
Jan 15 21:04:44.624: INFO: Pod downwardapi-volume-95d29147-712e-4a50-b7d9-394e35606664 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:04:44.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1894" for this suite.
Jan 15 21:04:50.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:04:50.779: INFO: namespace downward-api-1894 deletion completed in 6.149837956s

• [SLOW TEST:8.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:04:50.780: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 21:04:50.846: INFO: Waiting up to 5m0s for pod "pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece" in namespace "emptydir-9970" to be "success or failure"
Jan 15 21:04:50.849: INFO: Pod "pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece": Phase="Pending", Reason="", readiness=false. Elapsed: 3.464416ms
Jan 15 21:04:52.858: INFO: Pod "pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012393918s
Jan 15 21:04:54.862: INFO: Pod "pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016497858s
STEP: Saw pod success
Jan 15 21:04:54.862: INFO: Pod "pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece" satisfied condition "success or failure"
Jan 15 21:04:54.865: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece container test-container: <nil>
STEP: delete the pod
Jan 15 21:04:54.887: INFO: Waiting for pod pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece to disappear
Jan 15 21:04:54.891: INFO: Pod pod-d5e6131f-cc63-4c30-ad70-47ce95b14ece no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:04:54.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9970" for this suite.
Jan 15 21:05:00.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:05:01.049: INFO: namespace emptydir-9970 deletion completed in 6.152480957s

• [SLOW TEST:10.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:05:01.049: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7287
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-7287
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7287
Jan 15 21:05:01.119: INFO: Found 0 stateful pods, waiting for 1
Jan 15 21:05:11.125: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 15 21:05:11.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:05:11.673: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:05:11.673: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:05:11.673: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:05:11.678: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 21:05:21.683: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:05:21.683: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:05:21.711: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:21.711: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:21.711: INFO: 
Jan 15 21:05:21.711: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 15 21:05:22.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993902572s
Jan 15 21:05:23.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989318619s
Jan 15 21:05:24.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984992641s
Jan 15 21:05:25.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979876838s
Jan 15 21:05:26.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974849511s
Jan 15 21:05:27.739: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970397861s
Jan 15 21:05:28.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966173785s
Jan 15 21:05:29.748: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961721186s
Jan 15 21:05:30.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.842363ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7287
Jan 15 21:05:31.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:05:32.188: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:05:32.188: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:05:32.188: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:05:32.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:05:32.793: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 15 21:05:32.793: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:05:32.793: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:05:32.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:05:33.405: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 15 21:05:33.405: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:05:33.405: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:05:33.410: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:05:33.410: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:05:33.410: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 15 21:05:33.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:05:33.945: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:05:33.945: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:05:33.945: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:05:33.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:05:34.817: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:05:34.817: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:05:34.817: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:05:34.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:05:35.774: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:05:35.774: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:05:35.774: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:05:35.774: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:05:35.779: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 15 21:05:45.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:05:45.787: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:05:45.787: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:05:45.800: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:45.800: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:45.800: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:45.800: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:45.800: INFO: 
Jan 15 21:05:45.800: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:46.804: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:46.805: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:46.805: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:46.805: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:46.805: INFO: 
Jan 15 21:05:46.805: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:47.810: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:47.810: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:47.810: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:47.810: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:47.810: INFO: 
Jan 15 21:05:47.810: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:48.814: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:48.814: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:48.815: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:48.815: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:48.815: INFO: 
Jan 15 21:05:48.815: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:49.819: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:49.819: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:49.819: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:49.819: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:49.819: INFO: 
Jan 15 21:05:49.819: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:50.823: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:50.823: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:50.823: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:50.823: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:50.823: INFO: 
Jan 15 21:05:50.823: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:51.828: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:51.828: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:51.828: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:51.828: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:51.828: INFO: 
Jan 15 21:05:51.828: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:52.832: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:52.832: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:52.833: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:52.833: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:52.833: INFO: 
Jan 15 21:05:52.833: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:53.837: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:53.837: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:53.837: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:53.837: INFO: ss-2  aks-nodepool1-25266157-vmss000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:53.837: INFO: 
Jan 15 21:05:53.837: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 21:05:54.843: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Jan 15 21:05:54.843: INFO: ss-0  aks-nodepool1-25266157-vmss000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:01 +0000 UTC  }]
Jan 15 21:05:54.843: INFO: ss-1  aks-nodepool1-25266157-vmss000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:05:21 +0000 UTC  }]
Jan 15 21:05:54.843: INFO: 
Jan 15 21:05:54.843: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7287
Jan 15 21:05:55.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:05:56.189: INFO: rc: 1
Jan 15 21:05:56.189: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001d852f0 exit status 1 <nil> <nil> true [0xc0018bcde0 0xc0018bce30 0xc0018bce60] [0xc0018bcde0 0xc0018bce30 0xc0018bce60] [0xc0018bce20 0xc0018bce50] [0xba6c10 0xba6c10] 0xc002c879e0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Jan 15 21:06:06.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:06.275: INFO: rc: 1
Jan 15 21:06:06.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d856b0 exit status 1 <nil> <nil> true [0xc0018bce68 0xc0018bce88 0xc0018bcf00] [0xc0018bce68 0xc0018bce88 0xc0018bcf00] [0xc0018bce78 0xc0018bcef0] [0xba6c10 0xba6c10] 0xc002c87d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:06:16.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:16.361: INFO: rc: 1
Jan 15 21:06:16.361: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85a70 exit status 1 <nil> <nil> true [0xc0018bcf08 0xc0018bcf30 0xc0018bcf80] [0xc0018bcf08 0xc0018bcf30 0xc0018bcf80] [0xc0018bcf20 0xc0018bcf60] [0xba6c10 0xba6c10] 0xc00391e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:06:26.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:26.454: INFO: rc: 1
Jan 15 21:06:26.454: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85e60 exit status 1 <nil> <nil> true [0xc0018bcf90 0xc0018bcfd0 0xc0018bd008] [0xc0018bcf90 0xc0018bcfd0 0xc0018bd008] [0xc0018bcfb0 0xc0018bcff8] [0xba6c10 0xba6c10] 0xc00391e420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:06:36.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:36.545: INFO: rc: 1
Jan 15 21:06:36.545: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af7f50 exit status 1 <nil> <nil> true [0xc0028aa1d8 0xc0028aa1f0 0xc0028aa208] [0xc0028aa1d8 0xc0028aa1f0 0xc0028aa208] [0xc0028aa1e8 0xc0028aa200] [0xba6c10 0xba6c10] 0xc00276a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:06:46.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:46.633: INFO: rc: 1
Jan 15 21:06:46.633: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a2a2a0 exit status 1 <nil> <nil> true [0xc0018bd020 0xc0018bd060 0xc0018bd0a0] [0xc0018bd020 0xc0018bd060 0xc0018bd0a0] [0xc0018bd058 0xc0018bd078] [0xba6c10 0xba6c10] 0xc00391e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:06:56.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:06:56.715: INFO: rc: 1
Jan 15 21:06:56.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00219e390 exit status 1 <nil> <nil> true [0xc0028aa210 0xc0028aa228 0xc0028aa240] [0xc0028aa210 0xc0028aa228 0xc0028aa240] [0xc0028aa220 0xc0028aa238] [0xba6c10 0xba6c10] 0xc00276a4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:06.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:06.806: INFO: rc: 1
Jan 15 21:07:06.806: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a2a630 exit status 1 <nil> <nil> true [0xc0018bd0d0 0xc0018bd0f0 0xc0018bd178] [0xc0018bd0d0 0xc0018bd0f0 0xc0018bd178] [0xc0018bd0e8 0xc0018bd138] [0xba6c10 0xba6c10] 0xc00391eae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:16.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:16.897: INFO: rc: 1
Jan 15 21:07:16.897: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00219e750 exit status 1 <nil> <nil> true [0xc0028aa248 0xc0028aa260 0xc0028aa278] [0xc0028aa248 0xc0028aa260 0xc0028aa278] [0xc0028aa258 0xc0028aa270] [0xba6c10 0xba6c10] 0xc00276a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:26.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:27.004: INFO: rc: 1
Jan 15 21:07:27.005: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00219eb10 exit status 1 <nil> <nil> true [0xc0028aa280 0xc0028aa298 0xc0028aa2b0] [0xc0028aa280 0xc0028aa298 0xc0028aa2b0] [0xc0028aa290 0xc0028aa2a8] [0xba6c10 0xba6c10] 0xc00276ab40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:37.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:37.100: INFO: rc: 1
Jan 15 21:07:37.100: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d843c0 exit status 1 <nil> <nil> true [0xc0028aa008 0xc0028aa020 0xc0028aa038] [0xc0028aa008 0xc0028aa020 0xc0028aa038] [0xc0028aa018 0xc0028aa030] [0xba6c10 0xba6c10] 0xc002c862a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:47.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:47.196: INFO: rc: 1
Jan 15 21:07:47.196: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002114570 exit status 1 <nil> <nil> true [0xc0018bc010 0xc0018bc040 0xc0018bc170] [0xc0018bc010 0xc0018bc040 0xc0018bc170] [0xc0018bc030 0xc0018bc120] [0xba6c10 0xba6c10] 0xc003a562a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:07:57.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:07:57.291: INFO: rc: 1
Jan 15 21:07:57.291: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d84780 exit status 1 <nil> <nil> true [0xc0028aa040 0xc0028aa058 0xc0028aa070] [0xc0028aa040 0xc0028aa058 0xc0028aa070] [0xc0028aa050 0xc0028aa068] [0xba6c10 0xba6c10] 0xc002c86600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:07.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:07.378: INFO: rc: 1
Jan 15 21:08:07.378: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002114960 exit status 1 <nil> <nil> true [0xc0018bc178 0xc0018bc1d0 0xc0018bc240] [0xc0018bc178 0xc0018bc1d0 0xc0018bc240] [0xc0018bc1b0 0xc0018bc228] [0xba6c10 0xba6c10] 0xc003a56600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:17.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:17.478: INFO: rc: 1
Jan 15 21:08:17.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d84b40 exit status 1 <nil> <nil> true [0xc0028aa078 0xc0028aa090 0xc0028aa0a8] [0xc0028aa078 0xc0028aa090 0xc0028aa0a8] [0xc0028aa088 0xc0028aa0a0] [0xba6c10 0xba6c10] 0xc002c86960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:27.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:27.559: INFO: rc: 1
Jan 15 21:08:27.559: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85290 exit status 1 <nil> <nil> true [0xc0028aa0b0 0xc0028aa0c8 0xc0028aa0e0] [0xc0028aa0b0 0xc0028aa0c8 0xc0028aa0e0] [0xc0028aa0c0 0xc0028aa0d8] [0xba6c10 0xba6c10] 0xc002c86d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:37.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:37.645: INFO: rc: 1
Jan 15 21:08:37.645: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85680 exit status 1 <nil> <nil> true [0xc0028aa0e8 0xc0028aa100 0xc0028aa118] [0xc0028aa0e8 0xc0028aa100 0xc0028aa118] [0xc0028aa0f8 0xc0028aa110] [0xba6c10 0xba6c10] 0xc002c870e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:47.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:47.739: INFO: rc: 1
Jan 15 21:08:47.739: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85aa0 exit status 1 <nil> <nil> true [0xc0028aa120 0xc0028aa138 0xc0028aa150] [0xc0028aa120 0xc0028aa138 0xc0028aa150] [0xc0028aa130 0xc0028aa148] [0xba6c10 0xba6c10] 0xc002c87440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:08:57.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:08:57.841: INFO: rc: 1
Jan 15 21:08:57.841: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85ec0 exit status 1 <nil> <nil> true [0xc0028aa158 0xc0028aa170 0xc0028aa190] [0xc0028aa158 0xc0028aa170 0xc0028aa190] [0xc0028aa168 0xc0028aa188] [0xba6c10 0xba6c10] 0xc002c87860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:07.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:07.931: INFO: rc: 1
Jan 15 21:09:07.931: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af6300 exit status 1 <nil> <nil> true [0xc0028aa198 0xc0028aa1b0 0xc0028aa1c8] [0xc0028aa198 0xc0028aa1b0 0xc0028aa1c8] [0xc0028aa1a8 0xc0028aa1c0] [0xba6c10 0xba6c10] 0xc002c87bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:17.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:18.021: INFO: rc: 1
Jan 15 21:09:18.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af66c0 exit status 1 <nil> <nil> true [0xc0028aa1d0 0xc0028aa1e8 0xc0028aa200] [0xc0028aa1d0 0xc0028aa1e8 0xc0028aa200] [0xc0028aa1e0 0xc0028aa1f8] [0xba6c10 0xba6c10] 0xc002c87f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:28.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:28.107: INFO: rc: 1
Jan 15 21:09:28.107: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d84390 exit status 1 <nil> <nil> true [0xc0028aa008 0xc0028aa020 0xc0028aa038] [0xc0028aa008 0xc0028aa020 0xc0028aa038] [0xc0028aa018 0xc0028aa030] [0xba6c10 0xba6c10] 0xc002c862a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:38.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:38.196: INFO: rc: 1
Jan 15 21:09:38.196: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d847b0 exit status 1 <nil> <nil> true [0xc0028aa040 0xc0028aa058 0xc0028aa070] [0xc0028aa040 0xc0028aa058 0xc0028aa070] [0xc0028aa050 0xc0028aa068] [0xba6c10 0xba6c10] 0xc002c86600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:48.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:48.293: INFO: rc: 1
Jan 15 21:09:48.293: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d84bd0 exit status 1 <nil> <nil> true [0xc0028aa078 0xc0028aa090 0xc0028aa0a8] [0xc0028aa078 0xc0028aa090 0xc0028aa0a8] [0xc0028aa088 0xc0028aa0a0] [0xba6c10 0xba6c10] 0xc002c86960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:09:58.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:09:58.385: INFO: rc: 1
Jan 15 21:09:58.385: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85350 exit status 1 <nil> <nil> true [0xc0028aa0b0 0xc0028aa0c8 0xc0028aa0e0] [0xc0028aa0b0 0xc0028aa0c8 0xc0028aa0e0] [0xc0028aa0c0 0xc0028aa0d8] [0xba6c10 0xba6c10] 0xc002c86d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:08.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:08.477: INFO: rc: 1
Jan 15 21:10:08.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85740 exit status 1 <nil> <nil> true [0xc0028aa0e8 0xc0028aa100 0xc0028aa118] [0xc0028aa0e8 0xc0028aa100 0xc0028aa118] [0xc0028aa0f8 0xc0028aa110] [0xba6c10 0xba6c10] 0xc002c870e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:18.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:18.580: INFO: rc: 1
Jan 15 21:10:18.580: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af6420 exit status 1 <nil> <nil> true [0xc0018bc010 0xc0018bc040 0xc0018bc170] [0xc0018bc010 0xc0018bc040 0xc0018bc170] [0xc0018bc030 0xc0018bc120] [0xba6c10 0xba6c10] 0xc003a562a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:28.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:28.668: INFO: rc: 1
Jan 15 21:10:28.668: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af6810 exit status 1 <nil> <nil> true [0xc0018bc178 0xc0018bc1d0 0xc0018bc240] [0xc0018bc178 0xc0018bc1d0 0xc0018bc240] [0xc0018bc1b0 0xc0018bc228] [0xba6c10 0xba6c10] 0xc003a56600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:38.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:38.757: INFO: rc: 1
Jan 15 21:10:38.757: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d85b00 exit status 1 <nil> <nil> true [0xc0028aa120 0xc0028aa138 0xc0028aa150] [0xc0028aa120 0xc0028aa138 0xc0028aa150] [0xc0028aa130 0xc0028aa148] [0xba6c10 0xba6c10] 0xc002c87440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:48.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:48.845: INFO: rc: 1
Jan 15 21:10:48.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000af6c30 exit status 1 <nil> <nil> true [0xc0018bc248 0xc0018bc288 0xc0018bc308] [0xc0018bc248 0xc0018bc288 0xc0018bc308] [0xc0018bc270 0xc0018bc2e0] [0xba6c10 0xba6c10] 0xc003a56960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jan 15 21:10:58.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-7287 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:10:58.931: INFO: rc: 1
Jan 15 21:10:58.931: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Jan 15 21:10:58.931: INFO: Scaling statefulset ss to 0
Jan 15 21:10:58.944: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Jan 15 21:10:58.949: INFO: Deleting all statefulset in ns statefulset-7287
Jan 15 21:10:58.953: INFO: Scaling statefulset ss to 0
Jan 15 21:10:58.967: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:10:58.970: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:10:58.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7287" for this suite.
Jan 15 21:11:05.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:11:05.140: INFO: namespace statefulset-7287 deletion completed in 6.145734019s

• [SLOW TEST:364.091 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:11:05.140: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:11:09.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5842" for this suite.
Jan 15 21:11:51.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:11:51.417: INFO: namespace kubelet-test-5842 deletion completed in 42.178448227s

• [SLOW TEST:46.277 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:11:51.417: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:11:57.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3314" for this suite.
Jan 15 21:12:03.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:12:03.312: INFO: namespace watch-3314 deletion completed in 6.237232645s

• [SLOW TEST:11.895 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:12:03.312: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-8e0712b8-e0e6-4f0c-8e21-346d8d61581c
STEP: Creating a pod to test consume secrets
Jan 15 21:12:03.378: INFO: Waiting up to 5m0s for pod "pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e" in namespace "secrets-8798" to be "success or failure"
Jan 15 21:12:03.381: INFO: Pod "pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.192911ms
Jan 15 21:12:05.385: INFO: Pod "pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007767369s
Jan 15 21:12:07.389: INFO: Pod "pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011324428s
STEP: Saw pod success
Jan 15 21:12:07.389: INFO: Pod "pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e" satisfied condition "success or failure"
Jan 15 21:12:07.392: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:12:07.414: INFO: Waiting for pod pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e to disappear
Jan 15 21:12:07.417: INFO: Pod pod-secrets-787b0400-061e-4ba7-b92e-5d882e0f436e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:12:07.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8798" for this suite.
Jan 15 21:12:13.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:12:13.562: INFO: namespace secrets-8798 deletion completed in 6.140762367s

• [SLOW TEST:10.250 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:12:13.563: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-e97519b6-dd07-4282-839e-e79f08de4466
STEP: Creating a pod to test consume configMaps
Jan 15 21:12:13.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15" in namespace "configmap-4658" to be "success or failure"
Jan 15 21:12:13.630: INFO: Pod "pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15": Phase="Pending", Reason="", readiness=false. Elapsed: 3.984614ms
Jan 15 21:12:15.634: INFO: Pod "pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008466093s
Jan 15 21:12:17.638: INFO: Pod "pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012314774s
STEP: Saw pod success
Jan 15 21:12:17.638: INFO: Pod "pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15" satisfied condition "success or failure"
Jan 15 21:12:17.641: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:12:17.661: INFO: Waiting for pod pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15 to disappear
Jan 15 21:12:17.665: INFO: Pod pod-configmaps-04299962-c1dd-426b-a9f8-39050ad32b15 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:12:17.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4658" for this suite.
Jan 15 21:12:23.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:12:23.809: INFO: namespace configmap-4658 deletion completed in 6.139668724s

• [SLOW TEST:10.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:12:23.809: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:12:27.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4560" for this suite.
Jan 15 21:13:05.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:13:06.106: INFO: namespace kubelet-test-4560 deletion completed in 38.201013871s

• [SLOW TEST:42.297 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:13:06.106: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-0e60b48c-0e68-41b0-8d5a-7459f2aff54c
STEP: Creating a pod to test consume configMaps
Jan 15 21:13:06.170: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb" in namespace "projected-2011" to be "success or failure"
Jan 15 21:13:06.174: INFO: Pod "pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.246712ms
Jan 15 21:13:08.178: INFO: Pod "pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007500274s
Jan 15 21:13:10.182: INFO: Pod "pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011431739s
STEP: Saw pod success
Jan 15 21:13:10.182: INFO: Pod "pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb" satisfied condition "success or failure"
Jan 15 21:13:10.185: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:13:10.206: INFO: Waiting for pod pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb to disappear
Jan 15 21:13:10.209: INFO: Pod pod-projected-configmaps-9566f3eb-f160-48a1-a0c4-62255d9110fb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:13:10.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2011" for this suite.
Jan 15 21:13:16.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:13:16.350: INFO: namespace projected-2011 deletion completed in 6.13617066s

• [SLOW TEST:10.244 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:13:16.351: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-05235241-963f-4607-b52e-a43b32caf645
STEP: Creating secret with name secret-projected-all-test-volume-d0b6c413-f889-417b-b08c-190bea108b18
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 15 21:13:16.420: INFO: Waiting up to 5m0s for pod "projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331" in namespace "projected-200" to be "success or failure"
Jan 15 21:13:16.423: INFO: Pod "projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331": Phase="Pending", Reason="", readiness=false. Elapsed: 3.267311ms
Jan 15 21:13:18.427: INFO: Pod "projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007124286s
Jan 15 21:13:20.432: INFO: Pod "projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012022366s
STEP: Saw pod success
Jan 15 21:13:20.432: INFO: Pod "projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331" satisfied condition "success or failure"
Jan 15 21:13:20.436: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 15 21:13:20.474: INFO: Waiting for pod projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331 to disappear
Jan 15 21:13:20.478: INFO: Pod projected-volume-f9995547-0f9e-43e7-8e79-77967fb72331 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:13:20.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-200" for this suite.
Jan 15 21:13:26.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:13:26.682: INFO: namespace projected-200 deletion completed in 6.198241823s

• [SLOW TEST:10.331 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:13:26.683: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:13:26.743: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516" in namespace "projected-37" to be "success or failure"
Jan 15 21:13:26.747: INFO: Pod "downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516": Phase="Pending", Reason="", readiness=false. Elapsed: 4.851017ms
Jan 15 21:13:28.753: INFO: Pod "downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009887408s
Jan 15 21:13:30.757: INFO: Pod "downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014124697s
STEP: Saw pod success
Jan 15 21:13:30.757: INFO: Pod "downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516" satisfied condition "success or failure"
Jan 15 21:13:30.760: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516 container client-container: <nil>
STEP: delete the pod
Jan 15 21:13:30.789: INFO: Waiting for pod downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516 to disappear
Jan 15 21:13:30.792: INFO: Pod downwardapi-volume-0901d18e-544c-40bf-ac70-671ccc53a516 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:13:30.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-37" for this suite.
Jan 15 21:13:36.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:13:36.949: INFO: namespace projected-37 deletion completed in 6.143412158s

• [SLOW TEST:10.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:13:36.950: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-44e1e7b3-06a7-467d-8b30-719538bc424d
STEP: Creating a pod to test consume configMaps
Jan 15 21:13:37.014: INFO: Waiting up to 5m0s for pod "pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b" in namespace "configmap-2029" to be "success or failure"
Jan 15 21:13:37.017: INFO: Pod "pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.118611ms
Jan 15 21:13:39.021: INFO: Pod "pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007113152s
Jan 15 21:13:41.027: INFO: Pod "pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013368461s
STEP: Saw pod success
Jan 15 21:13:41.027: INFO: Pod "pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b" satisfied condition "success or failure"
Jan 15 21:13:41.031: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:13:41.059: INFO: Waiting for pod pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b to disappear
Jan 15 21:13:41.064: INFO: Pod pod-configmaps-aff64676-3363-4fda-a765-1b905d727c3b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:13:41.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2029" for this suite.
Jan 15 21:13:47.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:13:47.220: INFO: namespace configmap-2029 deletion completed in 6.150720219s

• [SLOW TEST:10.270 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:13:47.221: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 21:13:55.324: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:13:55.330: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:13:57.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:13:57.334: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:13:59.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:13:59.334: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:01.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:01.337: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:03.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:03.334: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:05.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:05.334: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:07.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:07.335: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:09.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:09.334: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:11.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:11.335: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:13.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:13.335: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:15.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:15.335: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 21:14:17.330: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 21:14:17.334: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:14:17.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2379" for this suite.
Jan 15 21:14:39.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:14:39.488: INFO: namespace container-lifecycle-hook-2379 deletion completed in 22.135933318s

• [SLOW TEST:52.268 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:14:39.489: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Jan 15 21:14:39.554: INFO: Waiting up to 5m0s for pod "client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165" in namespace "containers-5782" to be "success or failure"
Jan 15 21:14:39.557: INFO: Pod "client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165": Phase="Pending", Reason="", readiness=false. Elapsed: 3.114829ms
Jan 15 21:14:41.561: INFO: Pod "client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006775973s
Jan 15 21:14:43.565: INFO: Pod "client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011219648s
STEP: Saw pod success
Jan 15 21:14:43.565: INFO: Pod "client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165" satisfied condition "success or failure"
Jan 15 21:14:43.568: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165 container test-container: <nil>
STEP: delete the pod
Jan 15 21:14:43.590: INFO: Waiting for pod client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165 to disappear
Jan 15 21:14:43.593: INFO: Pod client-containers-c48e3c39-0d92-4d5b-8904-a5d1af8c6165 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:14:43.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5782" for this suite.
Jan 15 21:14:49.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:14:49.745: INFO: namespace containers-5782 deletion completed in 6.145864189s

• [SLOW TEST:10.256 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:14:49.746: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jan 15 21:14:59.838: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0115 21:14:59.838202      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 21:14:59.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2526" for this suite.
Jan 15 21:15:05.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:15:06.027: INFO: namespace gc-2526 deletion completed in 6.183927612s

• [SLOW TEST:16.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:15:06.029: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-408e7aa9-f5e5-4a6c-8d78-9d4a6c4b3448
STEP: Creating configMap with name cm-test-opt-upd-a973ddc4-ba3d-4484-ad9a-05d101975336
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-408e7aa9-f5e5-4a6c-8d78-9d4a6c4b3448
STEP: Updating configmap cm-test-opt-upd-a973ddc4-ba3d-4484-ad9a-05d101975336
STEP: Creating configMap with name cm-test-opt-create-655acef7-e232-41d3-8158-3aa0567d2ad3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:15:12.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4061" for this suite.
Jan 15 21:15:40.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:15:40.826: INFO: namespace projected-4061 deletion completed in 28.190185978s

• [SLOW TEST:34.798 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:15:40.828: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:15:40.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae" in namespace "downward-api-3878" to be "success or failure"
Jan 15 21:15:40.897: INFO: Pod "downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.414029ms
Jan 15 21:15:42.907: INFO: Pod "downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013681726s
Jan 15 21:15:44.911: INFO: Pod "downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017467508s
STEP: Saw pod success
Jan 15 21:15:44.911: INFO: Pod "downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae" satisfied condition "success or failure"
Jan 15 21:15:44.914: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae container client-container: <nil>
STEP: delete the pod
Jan 15 21:15:44.934: INFO: Waiting for pod downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae to disappear
Jan 15 21:15:44.937: INFO: Pod downwardapi-volume-560e17b0-377f-4143-9f56-0667ad9341ae no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:15:44.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3878" for this suite.
Jan 15 21:15:50.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:15:51.126: INFO: namespace downward-api-3878 deletion completed in 6.182535093s

• [SLOW TEST:10.298 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:15:51.126: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 21:15:51.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4451'
Jan 15 21:15:52.586: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 21:15:52.586: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 15 21:15:52.593: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 15 21:15:52.595: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 15 21:15:52.605: INFO: scanned /root for discovery docs: <nil>
Jan 15 21:15:52.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4451'
Jan 15 21:16:08.401: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 21:16:08.401: INFO: stdout: "Created e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2\nScaling up e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 15 21:16:08.401: INFO: stdout: "Created e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2\nScaling up e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 15 21:16:08.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4451'
Jan 15 21:16:08.493: INFO: stderr: ""
Jan 15 21:16:08.493: INFO: stdout: "e2e-test-nginx-rc-5zkbw e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2-hdtgd "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan 15 21:16:13.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4451'
Jan 15 21:16:13.576: INFO: stderr: ""
Jan 15 21:16:13.576: INFO: stdout: "e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2-hdtgd "
Jan 15 21:16:13.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2-hdtgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4451'
Jan 15 21:16:13.658: INFO: stderr: ""
Jan 15 21:16:13.658: INFO: stdout: "true"
Jan 15 21:16:13.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2-hdtgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4451'
Jan 15 21:16:13.736: INFO: stderr: ""
Jan 15 21:16:13.736: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 15 21:16:13.736: INFO: e2e-test-nginx-rc-e0030544e254d1ff197d6387d22991c2-hdtgd is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Jan 15 21:16:13.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete rc e2e-test-nginx-rc --namespace=kubectl-4451'
Jan 15 21:16:13.825: INFO: stderr: ""
Jan 15 21:16:13.825: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:16:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4451" for this suite.
Jan 15 21:16:35.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:16:36.027: INFO: namespace kubectl-4451 deletion completed in 22.196359081s

• [SLOW TEST:44.901 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:16:36.027: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-aab78cb6-b137-4a1f-91a0-8ebb993961bb
STEP: Creating a pod to test consume configMaps
Jan 15 21:16:36.101: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b" in namespace "configmap-9909" to be "success or failure"
Jan 15 21:16:36.105: INFO: Pod "pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012631ms
Jan 15 21:16:38.109: INFO: Pod "pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007978969s
Jan 15 21:16:40.114: INFO: Pod "pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012500862s
STEP: Saw pod success
Jan 15 21:16:40.114: INFO: Pod "pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b" satisfied condition "success or failure"
Jan 15 21:16:40.117: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:16:40.146: INFO: Waiting for pod pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b to disappear
Jan 15 21:16:40.151: INFO: Pod pod-configmaps-b5b595c7-17e8-4b12-a96c-ccb26ea29b5b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:16:40.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9909" for this suite.
Jan 15 21:16:46.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:16:46.333: INFO: namespace configmap-9909 deletion completed in 6.175147899s

• [SLOW TEST:10.306 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:16:46.333: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2919
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 21:16:46.389: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 21:17:08.492: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.38:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:17:08.492: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:17:08.988: INFO: Found all expected endpoints: [netserver-0]
Jan 15 21:17:08.991: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:17:08.992: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:17:09.449: INFO: Found all expected endpoints: [netserver-1]
Jan 15 21:17:09.452: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.13:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:17:09.452: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:17:09.864: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:17:09.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2919" for this suite.
Jan 15 21:17:31.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:17:32.043: INFO: namespace pod-network-test-2919 deletion completed in 22.17327273s

• [SLOW TEST:45.710 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:17:32.044: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 21:17:32.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9981'
Jan 15 21:17:32.201: INFO: stderr: ""
Jan 15 21:17:32.201: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 15 21:17:37.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pod e2e-test-nginx-pod --namespace=kubectl-9981 -o json'
Jan 15 21:17:37.334: INFO: stderr: ""
Jan 15 21:17:37.334: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-01-15T21:17:32Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9981\",\n        \"resourceVersion\": \"4133\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9981/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2cd6ba62-1ffa-4df7-8287-bc6e41d14b26\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-trnhk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"aks-nodepool1-25266157-vmss000001\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-trnhk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-trnhk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-01-15T21:17:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-01-15T21:17:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-01-15T21:17:34Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-01-15T21:17:32Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b4c844c7bdcd5524e5e18e20673ffeee661560b96cef6bf81aa03386b468e1a6\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-01-15T21:17:33Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.240.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.2.40\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-01-15T21:17:32Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 15 21:17:37.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 replace -f - --namespace=kubectl-9981'
Jan 15 21:17:37.573: INFO: stderr: ""
Jan 15 21:17:37.573: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Jan 15 21:17:37.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete pods e2e-test-nginx-pod --namespace=kubectl-9981'
Jan 15 21:17:49.126: INFO: stderr: ""
Jan 15 21:17:49.126: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:17:49.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9981" for this suite.
Jan 15 21:17:55.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:17:55.281: INFO: namespace kubectl-9981 deletion completed in 6.14817227s

• [SLOW TEST:23.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:17:55.281: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2665
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2665
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2665
Jan 15 21:17:55.362: INFO: Found 0 stateful pods, waiting for 1
Jan 15 21:18:05.366: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 15 21:18:05.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:18:05.796: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:18:05.796: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:18:05.796: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:18:05.800: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 21:18:15.804: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:18:15.804: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:18:15.825: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999997s
Jan 15 21:18:16.830: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996378175s
Jan 15 21:18:17.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991709052s
Jan 15 21:18:18.838: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987341439s
Jan 15 21:18:19.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983057634s
Jan 15 21:18:20.850: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978757838s
Jan 15 21:18:21.855: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971250329s
Jan 15 21:18:22.859: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.966664747s
Jan 15 21:18:23.863: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.962007173s
Jan 15 21:18:24.869: INFO: Verifying statefulset ss doesn't scale past 1 for another 957.998311ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2665
Jan 15 21:18:25.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:18:26.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:18:26.399: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:18:26.399: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:18:26.403: INFO: Found 1 stateful pods, waiting for 3
Jan 15 21:18:36.407: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:18:36.407: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:18:36.407: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 15 21:18:36.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:18:36.931: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:18:36.931: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:18:36.931: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:18:36.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:18:37.523: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:18:37.523: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:18:37.523: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:18:37.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:18:38.048: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:18:38.048: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:18:38.048: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:18:38.048: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:18:38.054: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 15 21:18:48.064: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:18:48.064: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:18:48.064: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 21:18:48.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999997s
Jan 15 21:18:49.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995997824s
Jan 15 21:18:50.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990820048s
Jan 15 21:18:51.100: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983820368s
Jan 15 21:18:52.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974596481s
Jan 15 21:18:53.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970431134s
Jan 15 21:18:54.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966584795s
Jan 15 21:18:55.117: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962164161s
Jan 15 21:18:56.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95721313s
Jan 15 21:18:57.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.265006ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2665
Jan 15 21:18:58.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:18:58.542: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:18:58.542: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:18:58.543: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:18:58.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:18:59.086: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:18:59.086: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:18:59.086: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:18:59.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-2665 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:18:59.679: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:18:59.679: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:18:59.679: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:18:59.679: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Jan 15 21:19:29.698: INFO: Deleting all statefulset in ns statefulset-2665
Jan 15 21:19:29.702: INFO: Scaling statefulset ss to 0
Jan 15 21:19:29.715: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:19:29.719: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:19:29.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2665" for this suite.
Jan 15 21:19:35.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:19:35.899: INFO: namespace statefulset-2665 deletion completed in 6.155669468s

• [SLOW TEST:100.618 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:19:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Jan 15 21:19:35.968: INFO: Waiting up to 5m0s for pod "var-expansion-069c2140-e1d0-421d-8944-5c996425e28d" in namespace "var-expansion-66" to be "success or failure"
Jan 15 21:19:35.972: INFO: Pod "var-expansion-069c2140-e1d0-421d-8944-5c996425e28d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090525ms
Jan 15 21:19:37.976: INFO: Pod "var-expansion-069c2140-e1d0-421d-8944-5c996425e28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007564203s
Jan 15 21:19:39.980: INFO: Pod "var-expansion-069c2140-e1d0-421d-8944-5c996425e28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011560461s
STEP: Saw pod success
Jan 15 21:19:39.980: INFO: Pod "var-expansion-069c2140-e1d0-421d-8944-5c996425e28d" satisfied condition "success or failure"
Jan 15 21:19:39.983: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod var-expansion-069c2140-e1d0-421d-8944-5c996425e28d container dapi-container: <nil>
STEP: delete the pod
Jan 15 21:19:40.005: INFO: Waiting for pod var-expansion-069c2140-e1d0-421d-8944-5c996425e28d to disappear
Jan 15 21:19:40.008: INFO: Pod var-expansion-069c2140-e1d0-421d-8944-5c996425e28d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:19:40.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-66" for this suite.
Jan 15 21:19:46.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:19:46.168: INFO: namespace var-expansion-66 deletion completed in 6.15442918s

• [SLOW TEST:10.269 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:19:46.168: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Jan 15 21:19:46.231: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 15 21:19:46.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:46.585: INFO: stderr: ""
Jan 15 21:19:46.585: INFO: stdout: "service/redis-slave created\n"
Jan 15 21:19:46.586: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 15 21:19:46.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:46.829: INFO: stderr: ""
Jan 15 21:19:46.829: INFO: stdout: "service/redis-master created\n"
Jan 15 21:19:46.829: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 15 21:19:46.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:47.070: INFO: stderr: ""
Jan 15 21:19:47.071: INFO: stdout: "service/frontend created\n"
Jan 15 21:19:47.071: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 15 21:19:47.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:47.355: INFO: stderr: ""
Jan 15 21:19:47.355: INFO: stdout: "deployment.apps/frontend created\n"
Jan 15 21:19:47.355: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 15 21:19:47.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:47.594: INFO: stderr: ""
Jan 15 21:19:47.594: INFO: stdout: "deployment.apps/redis-master created\n"
Jan 15 21:19:47.595: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 15 21:19:47.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8679'
Jan 15 21:19:47.909: INFO: stderr: ""
Jan 15 21:19:47.909: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jan 15 21:19:47.909: INFO: Waiting for all frontend pods to be Running.
Jan 15 21:20:07.960: INFO: Waiting for frontend to serve content.
Jan 15 21:20:09.037: INFO: Trying to add a new entry to the guestbook.
Jan 15 21:20:09.167: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 15 21:20:09.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.322: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.322: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 21:20:09.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.439: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.439: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 21:20:09.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.570: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.570: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 21:20:09.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.665: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.665: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 21:20:09.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.759: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.759: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 21:20:09.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-8679'
Jan 15 21:20:09.851: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 21:20:09.851: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:20:09.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8679" for this suite.
Jan 15 21:21:05.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:21:06.009: INFO: namespace kubectl-8679 deletion completed in 56.151950495s

• [SLOW TEST:79.840 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:21:06.009: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:21:06.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6873" for this suite.
Jan 15 21:21:12.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:21:12.249: INFO: namespace kubelet-test-6873 deletion completed in 6.147171189s

• [SLOW TEST:6.240 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:21:12.250: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan 15 21:21:17.332: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:21:18.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9577" for this suite.
Jan 15 21:21:40.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:21:40.510: INFO: namespace replicaset-9577 deletion completed in 22.156453124s

• [SLOW TEST:28.261 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:21:40.511: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Jan 15 21:21:45.094: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8360 pod-service-account-c5275857-5f16-46b5-ac40-9704da23442c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jan 15 21:21:45.623: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8360 pod-service-account-c5275857-5f16-46b5-ac40-9704da23442c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jan 15 21:21:46.047: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8360 pod-service-account-c5275857-5f16-46b5-ac40-9704da23442c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:21:46.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8360" for this suite.
Jan 15 21:21:52.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:21:52.765: INFO: namespace svcaccounts-8360 deletion completed in 6.137728871s

• [SLOW TEST:12.255 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:21:52.766: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jan 15 21:22:02.896: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0115 21:22:02.896297      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:22:02.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7295" for this suite.
Jan 15 21:22:10.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:22:11.069: INFO: namespace gc-7295 deletion completed in 8.168130454s

• [SLOW TEST:18.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:22:11.069: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:22:11.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28" in namespace "projected-5686" to be "success or failure"
Jan 15 21:22:11.152: INFO: Pod "downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28": Phase="Pending", Reason="", readiness=false. Elapsed: 9.025848ms
Jan 15 21:22:13.156: INFO: Pod "downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013292825s
Jan 15 21:22:15.161: INFO: Pod "downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01765929s
STEP: Saw pod success
Jan 15 21:22:15.161: INFO: Pod "downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28" satisfied condition "success or failure"
Jan 15 21:22:15.164: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28 container client-container: <nil>
STEP: delete the pod
Jan 15 21:22:15.211: INFO: Waiting for pod downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28 to disappear
Jan 15 21:22:15.218: INFO: Pod downwardapi-volume-cef21a54-bbee-4873-864d-72a7a1cddd28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:22:15.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5686" for this suite.
Jan 15 21:22:21.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:22:21.388: INFO: namespace projected-5686 deletion completed in 6.164192315s

• [SLOW TEST:10.319 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:22:21.388: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-c4485475-5fb9-4da7-9330-27245c45372c
STEP: Creating secret with name s-test-opt-upd-35e043e7-4942-4dcc-b880-6c7c5028e729
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c4485475-5fb9-4da7-9330-27245c45372c
STEP: Updating secret s-test-opt-upd-35e043e7-4942-4dcc-b880-6c7c5028e729
STEP: Creating secret with name s-test-opt-create-26b8e441-d75b-4299-a2f1-f5441245f7a0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:22:27.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3345" for this suite.
Jan 15 21:22:49.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:22:50.094: INFO: namespace projected-3345 deletion completed in 22.148960339s

• [SLOW TEST:28.706 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:22:50.095: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-cc313417-bc41-435b-9ae4-9bc32f528b0e
STEP: Creating a pod to test consume configMaps
Jan 15 21:22:50.162: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04" in namespace "projected-2334" to be "success or failure"
Jan 15 21:22:50.167: INFO: Pod "pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133321ms
Jan 15 21:22:52.171: INFO: Pod "pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00840206s
Jan 15 21:22:54.175: INFO: Pod "pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012160084s
STEP: Saw pod success
Jan 15 21:22:54.175: INFO: Pod "pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04" satisfied condition "success or failure"
Jan 15 21:22:54.177: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:22:54.242: INFO: Waiting for pod pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04 to disappear
Jan 15 21:22:54.245: INFO: Pod pod-projected-configmaps-8040d0ac-bafa-4e80-9021-2177f0371a04 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:22:54.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2334" for this suite.
Jan 15 21:23:00.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:00.464: INFO: namespace projected-2334 deletion completed in 6.213073152s

• [SLOW TEST:10.369 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:00.464: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Jan 15 21:23:00.550: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1225" to be "success or failure"
Jan 15 21:23:00.559: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 9.390449ms
Jan 15 21:23:02.563: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013318228s
Jan 15 21:23:04.569: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019200807s
STEP: Saw pod success
Jan 15 21:23:04.569: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 15 21:23:04.572: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 15 21:23:04.633: INFO: Waiting for pod pod-host-path-test to disappear
Jan 15 21:23:04.637: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:04.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1225" for this suite.
Jan 15 21:23:10.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:10.795: INFO: namespace hostpath-1225 deletion completed in 6.152796067s

• [SLOW TEST:10.331 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:10.796: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 15 21:23:10.862: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-54,SelfLink:/api/v1/namespaces/watch-54/configmaps/e2e-watch-test-watch-closed,UID:8a742340-2c08-4841-aff1-709a4fab3a86,ResourceVersion:5504,Generation:0,CreationTimestamp:2020-01-15 21:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 21:23:10.862: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-54,SelfLink:/api/v1/namespaces/watch-54/configmaps/e2e-watch-test-watch-closed,UID:8a742340-2c08-4841-aff1-709a4fab3a86,ResourceVersion:5505,Generation:0,CreationTimestamp:2020-01-15 21:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 15 21:23:10.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-54,SelfLink:/api/v1/namespaces/watch-54/configmaps/e2e-watch-test-watch-closed,UID:8a742340-2c08-4841-aff1-709a4fab3a86,ResourceVersion:5506,Generation:0,CreationTimestamp:2020-01-15 21:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 21:23:10.884: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-54,SelfLink:/api/v1/namespaces/watch-54/configmaps/e2e-watch-test-watch-closed,UID:8a742340-2c08-4841-aff1-709a4fab3a86,ResourceVersion:5507,Generation:0,CreationTimestamp:2020-01-15 21:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:10.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-54" for this suite.
Jan 15 21:23:16.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:17.033: INFO: namespace watch-54 deletion completed in 6.143358118s

• [SLOW TEST:6.237 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:17.033: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:23:17.089: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 15 21:23:22.096: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 21:23:22.096: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Jan 15 21:23:22.120: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-519,SelfLink:/apis/apps/v1/namespaces/deployment-519/deployments/test-cleanup-deployment,UID:819b5d1a-e5f4-4021-9657-bad21d4b637b,ResourceVersion:5549,Generation:1,CreationTimestamp:2020-01-15 21:23:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 21:23:22.125: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 15 21:23:22.125: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 15 21:23:22.125: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-519,SelfLink:/apis/apps/v1/namespaces/deployment-519/replicasets/test-cleanup-controller,UID:3d6ba602-0ad4-42b1-84a4-9a8114e53f14,ResourceVersion:5550,Generation:1,CreationTimestamp:2020-01-15 21:23:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 819b5d1a-e5f4-4021-9657-bad21d4b637b 0xc003dc49df 0xc003dc49f0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 21:23:22.129: INFO: Pod "test-cleanup-controller-g9nqh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-g9nqh,GenerateName:test-cleanup-controller-,Namespace:deployment-519,SelfLink:/api/v1/namespaces/deployment-519/pods/test-cleanup-controller-g9nqh,UID:502bf36a-91fa-409d-9a66-4e00232a44e6,ResourceVersion:5542,Generation:0,CreationTimestamp:2020-01-15 21:23:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 3d6ba602-0ad4-42b1-84a4-9a8114e53f14 0xc003dc4f5f 0xc003dc4f70}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-88mp9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-88mp9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-88mp9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:23:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:23:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:23:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:23:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.56,StartTime:2020-01-15 21:23:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:23:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://eb2dd0e2d5106bdbf82f3417dbf6a8ff9f3d34fe04db8619439fc6b517f80b20}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:22.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-519" for this suite.
Jan 15 21:23:28.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:28.317: INFO: namespace deployment-519 deletion completed in 6.182368943s

• [SLOW TEST:11.284 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:28.317: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Jan 15 21:23:28.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 api-versions'
Jan 15 21:23:28.503: INFO: stderr: ""
Jan 15 21:23:28.503: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:28.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7413" for this suite.
Jan 15 21:23:34.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:34.691: INFO: namespace kubectl-7413 deletion completed in 6.180695939s

• [SLOW TEST:6.374 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:34.691: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:23:34.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 version'
Jan 15 21:23:34.849: INFO: stderr: ""
Jan 15 21:23:34.849: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:42:56Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:34:17Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:34.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6785" for this suite.
Jan 15 21:23:40.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:41.016: INFO: namespace kubectl-6785 deletion completed in 6.160358542s

• [SLOW TEST:6.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:41.017: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:23:41.095: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41" in namespace "downward-api-8010" to be "success or failure"
Jan 15 21:23:41.099: INFO: Pod "downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263622ms
Jan 15 21:23:43.103: INFO: Pod "downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008269498s
Jan 15 21:23:45.107: INFO: Pod "downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012670967s
STEP: Saw pod success
Jan 15 21:23:45.107: INFO: Pod "downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41" satisfied condition "success or failure"
Jan 15 21:23:45.110: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41 container client-container: <nil>
STEP: delete the pod
Jan 15 21:23:45.173: INFO: Waiting for pod downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41 to disappear
Jan 15 21:23:45.176: INFO: Pod downwardapi-volume-5162769c-de53-4cf7-9265-23e37787bd41 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:23:45.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8010" for this suite.
Jan 15 21:23:51.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:23:51.394: INFO: namespace downward-api-8010 deletion completed in 6.211928956s

• [SLOW TEST:10.377 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:23:51.394: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jan 15 21:23:51.450: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:24:09.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8410" for this suite.
Jan 15 21:24:15.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:24:15.295: INFO: namespace pods-8410 deletion completed in 6.156659959s

• [SLOW TEST:23.901 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:24:15.295: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:24:15.359: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9" in namespace "downward-api-8076" to be "success or failure"
Jan 15 21:24:15.362: INFO: Pod "downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258116ms
Jan 15 21:24:17.366: INFO: Pod "downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007483845s
Jan 15 21:24:19.371: INFO: Pod "downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012035867s
STEP: Saw pod success
Jan 15 21:24:19.371: INFO: Pod "downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9" satisfied condition "success or failure"
Jan 15 21:24:19.374: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9 container client-container: <nil>
STEP: delete the pod
Jan 15 21:24:19.394: INFO: Waiting for pod downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9 to disappear
Jan 15 21:24:19.398: INFO: Pod downwardapi-volume-66e88cf6-14bb-4d91-93db-208e27cf39c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:24:19.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8076" for this suite.
Jan 15 21:24:25.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:24:25.615: INFO: namespace downward-api-8076 deletion completed in 6.212180808s

• [SLOW TEST:10.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:24:25.616: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Jan 15 21:24:30.243: INFO: Successfully updated pod "labelsupdate554c5da2-2f9e-4be0-9f85-a9e155484930"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:24:32.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7070" for this suite.
Jan 15 21:24:54.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:24:54.463: INFO: namespace downward-api-7070 deletion completed in 22.149035684s

• [SLOW TEST:28.847 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:24:54.464: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-7135e03a-8c96-42ea-897f-744993f6a292
STEP: Creating a pod to test consume secrets
Jan 15 21:24:54.534: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb" in namespace "projected-4655" to be "success or failure"
Jan 15 21:24:54.537: INFO: Pod "pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.912214ms
Jan 15 21:24:56.541: INFO: Pod "pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006683594s
Jan 15 21:24:58.546: INFO: Pod "pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012118774s
STEP: Saw pod success
Jan 15 21:24:58.546: INFO: Pod "pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb" satisfied condition "success or failure"
Jan 15 21:24:58.549: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:24:58.570: INFO: Waiting for pod pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb to disappear
Jan 15 21:24:58.574: INFO: Pod pod-projected-secrets-fe7450a0-e8e5-40f8-a077-a599c4afa1bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:24:58.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4655" for this suite.
Jan 15 21:25:04.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:25:04.739: INFO: namespace projected-4655 deletion completed in 6.159696006s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:25:04.739: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Jan 15 21:25:04.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 cluster-info'
Jan 15 21:25:04.906: INFO: stderr: ""
Jan 15 21:25:04.906: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:25:04.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9560" for this suite.
Jan 15 21:25:10.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:25:11.071: INFO: namespace kubectl-9560 deletion completed in 6.158593835s

• [SLOW TEST:6.332 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:25:11.071: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-stmms in namespace proxy-2836
I0115 21:25:11.151427      16 runners.go:180] Created replication controller with name: proxy-service-stmms, namespace: proxy-2836, replica count: 1
I0115 21:25:12.201986      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 21:25:13.202187      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 21:25:14.202414      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 21:25:15.202637      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 21:25:16.202828      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 21:25:17.203088      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 21:25:18.203279      16 runners.go:180] proxy-service-stmms Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 21:25:18.208: INFO: setup took 7.072769745s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 15 21:25:18.220: INFO: (0) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 11.645157ms)
Jan 15 21:25:18.222: INFO: (0) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 13.388765ms)
Jan 15 21:25:18.222: INFO: (0) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 13.592266ms)
Jan 15 21:25:18.222: INFO: (0) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 13.765167ms)
Jan 15 21:25:18.223: INFO: (0) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 14.920473ms)
Jan 15 21:25:18.224: INFO: (0) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 14.881673ms)
Jan 15 21:25:18.224: INFO: (0) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 15.068574ms)
Jan 15 21:25:18.268: INFO: (0) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 59.687492ms)
Jan 15 21:25:18.268: INFO: (0) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 59.533992ms)
Jan 15 21:25:18.268: INFO: (0) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 59.609392ms)
Jan 15 21:25:18.268: INFO: (0) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 59.912293ms)
Jan 15 21:25:18.348: INFO: (0) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 139.820684ms)
Jan 15 21:25:18.348: INFO: (0) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 139.994785ms)
Jan 15 21:25:18.349: INFO: (0) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 139.808184ms)
Jan 15 21:25:18.349: INFO: (0) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 140.148885ms)
Jan 15 21:25:18.357: INFO: (0) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 147.849523ms)
Jan 15 21:25:18.366: INFO: (1) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.232345ms)
Jan 15 21:25:18.367: INFO: (1) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 9.848148ms)
Jan 15 21:25:18.367: INFO: (1) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 9.973149ms)
Jan 15 21:25:18.367: INFO: (1) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 9.946148ms)
Jan 15 21:25:18.368: INFO: (1) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 10.701952ms)
Jan 15 21:25:18.368: INFO: (1) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 11.578856ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 15.633576ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 15.864977ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 15.765378ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 16.33148ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 16.664982ms)
Jan 15 21:25:18.373: INFO: (1) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 16.725782ms)
Jan 15 21:25:18.374: INFO: (1) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 16.905482ms)
Jan 15 21:25:18.374: INFO: (1) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 17.306284ms)
Jan 15 21:25:18.375: INFO: (1) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 18.040089ms)
Jan 15 21:25:18.376: INFO: (1) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 19.167194ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 13.534667ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 13.481066ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 13.564366ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 13.796967ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 14.092769ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 14.163869ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 14.544672ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 14.556071ms)
Jan 15 21:25:18.390: INFO: (2) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 14.35907ms)
Jan 15 21:25:18.392: INFO: (2) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 16.054579ms)
Jan 15 21:25:18.393: INFO: (2) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 16.866783ms)
Jan 15 21:25:18.398: INFO: (2) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 21.589505ms)
Jan 15 21:25:18.398: INFO: (2) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 21.628105ms)
Jan 15 21:25:18.398: INFO: (2) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 21.867007ms)
Jan 15 21:25:18.398: INFO: (2) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 21.629106ms)
Jan 15 21:25:18.398: INFO: (2) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 22.076808ms)
Jan 15 21:25:18.423: INFO: (3) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 24.146918ms)
Jan 15 21:25:18.423: INFO: (3) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 24.50272ms)
Jan 15 21:25:18.424: INFO: (3) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 25.859026ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 25.756026ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 26.062828ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 26.005028ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 26.291929ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 26.010327ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 26.68273ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 26.835831ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 26.763431ms)
Jan 15 21:25:18.425: INFO: (3) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 26.56303ms)
Jan 15 21:25:18.426: INFO: (3) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 27.287834ms)
Jan 15 21:25:18.426: INFO: (3) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 27.419134ms)
Jan 15 21:25:18.426: INFO: (3) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 27.630335ms)
Jan 15 21:25:18.427: INFO: (3) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 28.57484ms)
Jan 15 21:25:18.471: INFO: (4) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 43.897915ms)
Jan 15 21:25:18.471: INFO: (4) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 43.858914ms)
Jan 15 21:25:18.471: INFO: (4) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 43.619513ms)
Jan 15 21:25:18.471: INFO: (4) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 43.677813ms)
Jan 15 21:25:18.471: INFO: (4) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 44.091616ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 44.460418ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 44.344617ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 44.626519ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 44.627818ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 45.063921ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 44.93852ms)
Jan 15 21:25:18.472: INFO: (4) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 44.750919ms)
Jan 15 21:25:18.515: INFO: (4) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 87.181027ms)
Jan 15 21:25:18.515: INFO: (4) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 87.273727ms)
Jan 15 21:25:18.515: INFO: (4) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 87.461628ms)
Jan 15 21:25:18.515: INFO: (4) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 88.05403ms)
Jan 15 21:25:18.571: INFO: (5) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 55.871573ms)
Jan 15 21:25:18.572: INFO: (5) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 56.536977ms)
Jan 15 21:25:18.572: INFO: (5) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 56.729477ms)
Jan 15 21:25:18.572: INFO: (5) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 56.896278ms)
Jan 15 21:25:18.572: INFO: (5) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 57.13518ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 57.35808ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 57.448581ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 57.542082ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 57.834283ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 57.461381ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 57.533782ms)
Jan 15 21:25:18.573: INFO: (5) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 57.747282ms)
Jan 15 21:25:18.576: INFO: (5) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 60.299095ms)
Jan 15 21:25:18.576: INFO: (5) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 60.160394ms)
Jan 15 21:25:18.578: INFO: (5) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 62.263305ms)
Jan 15 21:25:18.578: INFO: (5) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 62.218705ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 20.851302ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 21.314404ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 20.997503ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 21.638006ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 20.997303ms)
Jan 15 21:25:18.600: INFO: (6) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 21.709907ms)
Jan 15 21:25:18.601: INFO: (6) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 21.640806ms)
Jan 15 21:25:18.601: INFO: (6) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 22.987913ms)
Jan 15 21:25:18.601: INFO: (6) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 22.643111ms)
Jan 15 21:25:18.601: INFO: (6) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 22.142209ms)
Jan 15 21:25:18.601: INFO: (6) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 22.53911ms)
Jan 15 21:25:18.602: INFO: (6) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 23.491915ms)
Jan 15 21:25:18.646: INFO: (6) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 67.888632ms)
Jan 15 21:25:18.646: INFO: (6) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 67.38263ms)
Jan 15 21:25:18.646: INFO: (6) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 68.035833ms)
Jan 15 21:25:18.646: INFO: (6) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 68.344634ms)
Jan 15 21:25:18.660: INFO: (7) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 13.302265ms)
Jan 15 21:25:18.660: INFO: (7) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 13.134664ms)
Jan 15 21:25:18.660: INFO: (7) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 13.224565ms)
Jan 15 21:25:18.660: INFO: (7) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 13.698267ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 14.186869ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 14.34087ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 13.951068ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 14.499171ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 14.709572ms)
Jan 15 21:25:18.661: INFO: (7) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 14.427271ms)
Jan 15 21:25:18.662: INFO: (7) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 15.749377ms)
Jan 15 21:25:18.663: INFO: (7) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 16.570581ms)
Jan 15 21:25:18.664: INFO: (7) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 17.217984ms)
Jan 15 21:25:18.664: INFO: (7) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 17.133484ms)
Jan 15 21:25:18.664: INFO: (7) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 17.218184ms)
Jan 15 21:25:18.664: INFO: (7) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 17.398785ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 8.226141ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 8.555342ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 8.347141ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 8.440641ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 8.320341ms)
Jan 15 21:25:18.673: INFO: (8) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 8.650643ms)
Jan 15 21:25:18.674: INFO: (8) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 9.678247ms)
Jan 15 21:25:18.674: INFO: (8) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 9.672947ms)
Jan 15 21:25:18.675: INFO: (8) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 9.976749ms)
Jan 15 21:25:18.674: INFO: (8) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.777048ms)
Jan 15 21:25:18.675: INFO: (8) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 10.503152ms)
Jan 15 21:25:18.676: INFO: (8) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 11.438156ms)
Jan 15 21:25:18.687: INFO: (8) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 22.61061ms)
Jan 15 21:25:18.687: INFO: (8) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 22.413409ms)
Jan 15 21:25:18.687: INFO: (8) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 22.52071ms)
Jan 15 21:25:18.717: INFO: (8) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 51.731153ms)
Jan 15 21:25:18.728: INFO: (9) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 10.869153ms)
Jan 15 21:25:18.729: INFO: (9) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 11.866058ms)
Jan 15 21:25:18.729: INFO: (9) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 12.221659ms)
Jan 15 21:25:18.729: INFO: (9) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 12.755362ms)
Jan 15 21:25:18.729: INFO: (9) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 11.613457ms)
Jan 15 21:25:18.729: INFO: (9) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 11.912358ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 12.331661ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 12.406561ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 12.17986ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 13.077364ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 12.499861ms)
Jan 15 21:25:18.730: INFO: (9) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 13.300765ms)
Jan 15 21:25:18.732: INFO: (9) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 14.40577ms)
Jan 15 21:25:18.733: INFO: (9) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 15.723877ms)
Jan 15 21:25:18.734: INFO: (9) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 16.830683ms)
Jan 15 21:25:18.734: INFO: (9) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 15.960678ms)
Jan 15 21:25:18.746: INFO: (10) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 12.109259ms)
Jan 15 21:25:18.746: INFO: (10) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 12.045759ms)
Jan 15 21:25:18.746: INFO: (10) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 12.36816ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 12.21576ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 12.565762ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 12.853463ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 13.341666ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 13.044964ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 12.719762ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 12.517261ms)
Jan 15 21:25:18.747: INFO: (10) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 12.955263ms)
Jan 15 21:25:18.748: INFO: (10) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 13.036764ms)
Jan 15 21:25:18.750: INFO: (10) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 15.332375ms)
Jan 15 21:25:18.750: INFO: (10) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 15.494976ms)
Jan 15 21:25:18.751: INFO: (10) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 15.756277ms)
Jan 15 21:25:18.751: INFO: (10) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 16.737982ms)
Jan 15 21:25:18.759: INFO: (11) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 8.570142ms)
Jan 15 21:25:18.760: INFO: (11) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 8.679042ms)
Jan 15 21:25:18.760: INFO: (11) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 8.231441ms)
Jan 15 21:25:18.760: INFO: (11) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 8.696542ms)
Jan 15 21:25:18.761: INFO: (11) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 8.700742ms)
Jan 15 21:25:18.761: INFO: (11) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 9.642847ms)
Jan 15 21:25:18.761: INFO: (11) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 9.424346ms)
Jan 15 21:25:18.761: INFO: (11) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 9.851248ms)
Jan 15 21:25:18.761: INFO: (11) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 9.454146ms)
Jan 15 21:25:18.762: INFO: (11) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 10.362851ms)
Jan 15 21:25:18.764: INFO: (11) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 12.689362ms)
Jan 15 21:25:18.765: INFO: (11) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 13.643567ms)
Jan 15 21:25:18.765: INFO: (11) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 13.483766ms)
Jan 15 21:25:18.765: INFO: (11) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 13.568366ms)
Jan 15 21:25:18.765: INFO: (11) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 14.44197ms)
Jan 15 21:25:18.803: INFO: (11) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 51.514852ms)
Jan 15 21:25:18.810: INFO: (12) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 7.188935ms)
Jan 15 21:25:18.811: INFO: (12) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 8.32444ms)
Jan 15 21:25:18.811: INFO: (12) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 8.361341ms)
Jan 15 21:25:18.811: INFO: (12) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 8.250541ms)
Jan 15 21:25:18.812: INFO: (12) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 8.902843ms)
Jan 15 21:25:18.812: INFO: (12) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.162345ms)
Jan 15 21:25:18.812: INFO: (12) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 9.387446ms)
Jan 15 21:25:18.812: INFO: (12) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 9.276046ms)
Jan 15 21:25:18.812: INFO: (12) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 9.209445ms)
Jan 15 21:25:18.813: INFO: (12) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 9.751348ms)
Jan 15 21:25:18.813: INFO: (12) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 9.760948ms)
Jan 15 21:25:18.816: INFO: (12) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 12.511361ms)
Jan 15 21:25:18.816: INFO: (12) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 13.079764ms)
Jan 15 21:25:18.816: INFO: (12) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 13.070064ms)
Jan 15 21:25:18.816: INFO: (12) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 13.441365ms)
Jan 15 21:25:18.858: INFO: (12) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 55.13337ms)
Jan 15 21:25:18.868: INFO: (13) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 9.467747ms)
Jan 15 21:25:18.869: INFO: (13) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 10.29115ms)
Jan 15 21:25:18.870: INFO: (13) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 10.780952ms)
Jan 15 21:25:18.870: INFO: (13) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 10.669652ms)
Jan 15 21:25:18.870: INFO: (13) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 11.506356ms)
Jan 15 21:25:18.870: INFO: (13) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 11.402656ms)
Jan 15 21:25:18.871: INFO: (13) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 12.498661ms)
Jan 15 21:25:18.871: INFO: (13) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 12.612562ms)
Jan 15 21:25:18.871: INFO: (13) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 12.37336ms)
Jan 15 21:25:18.871: INFO: (13) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 12.30346ms)
Jan 15 21:25:18.872: INFO: (13) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 13.849868ms)
Jan 15 21:25:18.875: INFO: (13) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 15.724377ms)
Jan 15 21:25:18.919: INFO: (13) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 60.193695ms)
Jan 15 21:25:18.919: INFO: (13) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 60.182894ms)
Jan 15 21:25:18.919: INFO: (13) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 59.989794ms)
Jan 15 21:25:18.919: INFO: (13) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 60.308495ms)
Jan 15 21:25:18.927: INFO: (14) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 7.377136ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.902149ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 10.28365ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 10.610051ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 10.40075ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 10.516652ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 10.594152ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 10.548651ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 10.869753ms)
Jan 15 21:25:18.930: INFO: (14) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 11.491757ms)
Jan 15 21:25:18.932: INFO: (14) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 12.27216ms)
Jan 15 21:25:18.932: INFO: (14) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 12.110659ms)
Jan 15 21:25:18.932: INFO: (14) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 12.476061ms)
Jan 15 21:25:18.971: INFO: (14) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 51.221051ms)
Jan 15 21:25:18.971: INFO: (14) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 50.666548ms)
Jan 15 21:25:18.971: INFO: (14) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 50.941249ms)
Jan 15 21:25:18.978: INFO: (15) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 6.830633ms)
Jan 15 21:25:18.978: INFO: (15) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 7.141635ms)
Jan 15 21:25:18.979: INFO: (15) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 7.832738ms)
Jan 15 21:25:18.979: INFO: (15) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 8.046439ms)
Jan 15 21:25:18.980: INFO: (15) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 8.614443ms)
Jan 15 21:25:18.980: INFO: (15) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 9.081145ms)
Jan 15 21:25:18.980: INFO: (15) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 8.927843ms)
Jan 15 21:25:18.981: INFO: (15) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 9.651147ms)
Jan 15 21:25:18.981: INFO: (15) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.703347ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 55.301171ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 55.661073ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 55.413571ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 55.888374ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 56.009474ms)
Jan 15 21:25:19.027: INFO: (15) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 55.858673ms)
Jan 15 21:25:19.071: INFO: (15) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 99.676087ms)
Jan 15 21:25:19.078: INFO: (16) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 6.505032ms)
Jan 15 21:25:19.079: INFO: (16) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 7.548337ms)
Jan 15 21:25:19.079: INFO: (16) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 8.025339ms)
Jan 15 21:25:19.079: INFO: (16) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 7.784538ms)
Jan 15 21:25:19.079: INFO: (16) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 8.04874ms)
Jan 15 21:25:19.080: INFO: (16) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 8.10294ms)
Jan 15 21:25:19.079: INFO: (16) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 7.719938ms)
Jan 15 21:25:19.080: INFO: (16) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 8.18914ms)
Jan 15 21:25:19.080: INFO: (16) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 8.425342ms)
Jan 15 21:25:19.080: INFO: (16) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 8.840543ms)
Jan 15 21:25:19.089: INFO: (16) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 17.244584ms)
Jan 15 21:25:19.131: INFO: (16) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 59.920794ms)
Jan 15 21:25:19.131: INFO: (16) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 60.043094ms)
Jan 15 21:25:19.131: INFO: (16) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 59.718392ms)
Jan 15 21:25:19.132: INFO: (16) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 60.124294ms)
Jan 15 21:25:19.132: INFO: (16) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 59.980293ms)
Jan 15 21:25:19.142: INFO: (17) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 9.830349ms)
Jan 15 21:25:19.148: INFO: (17) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 15.529076ms)
Jan 15 21:25:19.149: INFO: (17) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 16.955983ms)
Jan 15 21:25:19.150: INFO: (17) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 18.134489ms)
Jan 15 21:25:19.150: INFO: (17) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 18.141389ms)
Jan 15 21:25:19.150: INFO: (17) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 18.235389ms)
Jan 15 21:25:19.150: INFO: (17) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 18.23909ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 18.833792ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 18.812892ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 18.730591ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 18.853292ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 19.018493ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 19.236594ms)
Jan 15 21:25:19.151: INFO: (17) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 19.398395ms)
Jan 15 21:25:19.159: INFO: (17) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 27.433034ms)
Jan 15 21:25:19.160: INFO: (17) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 27.455134ms)
Jan 15 21:25:19.171: INFO: (18) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 11.123555ms)
Jan 15 21:25:19.171: INFO: (18) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 11.334855ms)
Jan 15 21:25:19.172: INFO: (18) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 11.566957ms)
Jan 15 21:25:19.172: INFO: (18) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 11.452656ms)
Jan 15 21:25:19.172: INFO: (18) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 12.27546ms)
Jan 15 21:25:19.172: INFO: (18) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 12.39906ms)
Jan 15 21:25:19.173: INFO: (18) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 13.378565ms)
Jan 15 21:25:19.173: INFO: (18) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 13.233365ms)
Jan 15 21:25:19.175: INFO: (18) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 14.898973ms)
Jan 15 21:25:19.175: INFO: (18) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 14.37117ms)
Jan 15 21:25:19.175: INFO: (18) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 14.43497ms)
Jan 15 21:25:19.177: INFO: (18) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 17.039583ms)
Jan 15 21:25:19.185: INFO: (18) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 24.58722ms)
Jan 15 21:25:19.185: INFO: (18) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 24.53922ms)
Jan 15 21:25:19.185: INFO: (18) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 24.45802ms)
Jan 15 21:25:19.215: INFO: (18) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 54.685167ms)
Jan 15 21:25:19.224: INFO: (19) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:162/proxy/: bar (200; 8.720742ms)
Jan 15 21:25:19.225: INFO: (19) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:162/proxy/: bar (200; 9.260545ms)
Jan 15 21:25:19.225: INFO: (19) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:160/proxy/: foo (200; 9.817648ms)
Jan 15 21:25:19.226: INFO: (19) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:1080/proxy/rewriteme">test<... (200; 10.422551ms)
Jan 15 21:25:19.226: INFO: (19) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:460/proxy/: tls baz (200; 10.734453ms)
Jan 15 21:25:19.226: INFO: (19) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:462/proxy/: tls qux (200; 10.897254ms)
Jan 15 21:25:19.227: INFO: (19) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf/proxy/rewriteme">test</a> (200; 11.078654ms)
Jan 15 21:25:19.227: INFO: (19) /api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/http:proxy-service-stmms-xmqjf:1080/proxy/rewriteme">... (200; 11.369155ms)
Jan 15 21:25:19.227: INFO: (19) /api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/: <a href="/api/v1/namespaces/proxy-2836/pods/https:proxy-service-stmms-xmqjf:443/proxy/tlsrewritem... (200; 11.779458ms)
Jan 15 21:25:19.227: INFO: (19) /api/v1/namespaces/proxy-2836/pods/proxy-service-stmms-xmqjf:160/proxy/: foo (200; 11.750757ms)
Jan 15 21:25:19.228: INFO: (19) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname2/proxy/: bar (200; 12.755562ms)
Jan 15 21:25:19.231: INFO: (19) /api/v1/namespaces/proxy-2836/services/http:proxy-service-stmms:portname1/proxy/: foo (200; 16.055079ms)
Jan 15 21:25:19.231: INFO: (19) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname2/proxy/: tls qux (200; 15.636776ms)
Jan 15 21:25:19.231: INFO: (19) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname1/proxy/: foo (200; 15.754677ms)
Jan 15 21:25:19.231: INFO: (19) /api/v1/namespaces/proxy-2836/services/proxy-service-stmms:portname2/proxy/: bar (200; 15.996679ms)
Jan 15 21:25:19.231: INFO: (19) /api/v1/namespaces/proxy-2836/services/https:proxy-service-stmms:tlsportname1/proxy/: tls baz (200; 16.135979ms)
STEP: deleting ReplicationController proxy-service-stmms in namespace proxy-2836, will wait for the garbage collector to delete the pods
Jan 15 21:25:19.299: INFO: Deleting ReplicationController proxy-service-stmms took: 11.706857ms
Jan 15 21:25:19.599: INFO: Terminating ReplicationController proxy-service-stmms pods took: 300.192068ms
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:25:21.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2836" for this suite.
Jan 15 21:25:27.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:25:27.666: INFO: namespace proxy-2836 deletion completed in 6.159134674s

• [SLOW TEST:16.594 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:25:27.666: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:25:27.712: INFO: Creating deployment "nginx-deployment"
Jan 15 21:25:27.719: INFO: Waiting for observed generation 1
Jan 15 21:25:29.737: INFO: Waiting for all required pods to come up
Jan 15 21:25:29.742: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 15 21:25:31.763: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 15 21:25:31.778: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 15 21:25:31.791: INFO: Updating deployment nginx-deployment
Jan 15 21:25:31.791: INFO: Waiting for observed generation 2
Jan 15 21:25:33.812: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 15 21:25:33.817: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 15 21:25:33.821: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 21:25:33.833: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 15 21:25:33.833: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 15 21:25:33.837: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 21:25:33.845: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 15 21:25:33.845: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 15 21:25:33.855: INFO: Updating deployment nginx-deployment
Jan 15 21:25:33.855: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 15 21:25:33.863: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 15 21:25:33.868: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Jan 15 21:25:33.887: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6655,SelfLink:/apis/apps/v1/namespaces/deployment-6655/deployments/nginx-deployment,UID:475538e0-8918-4331-b428-71cbbf250632,ResourceVersion:6169,Generation:3,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2020-01-15 21:25:31 +0000 UTC 2020-01-15 21:25:27 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2020-01-15 21:25:33 +0000 UTC 2020-01-15 21:25:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 15 21:25:33.907: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-6655,SelfLink:/apis/apps/v1/namespaces/deployment-6655/replicasets/nginx-deployment-55fb7cb77f,UID:6a2226d0-ab58-438b-9748-788cc73562b0,ResourceVersion:6165,Generation:3,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 475538e0-8918-4331-b428-71cbbf250632 0xc003cda5a7 0xc003cda5a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 21:25:33.908: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 15 21:25:33.908: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-6655,SelfLink:/apis/apps/v1/namespaces/deployment-6655/replicasets/nginx-deployment-7b8c6f4498,UID:297f7c20-b07a-4037-a325-86b9b87dbc15,ResourceVersion:6163,Generation:3,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 475538e0-8918-4331-b428-71cbbf250632 0xc003cda677 0xc003cda678}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 15 21:25:33.943: INFO: Pod "nginx-deployment-55fb7cb77f-4l7ms" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4l7ms,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-4l7ms,UID:c28bdde2-1722-4e13-9aea-2c4a9f7917e6,ResourceVersion:6198,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdaff0 0xc003cdaff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-5gq5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5gq5h,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-5gq5h,UID:f6e39662-6561-4195-9359-86f082d0a3ad,ResourceVersion:6188,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb0e7 0xc003cdb0e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-6kkbb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6kkbb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-6kkbb,UID:03ba2752-3435-4c3e-ab1c-2ee2dee848a9,ResourceVersion:6197,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb1f0 0xc003cdb1f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-6tvkh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6tvkh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-6tvkh,UID:305f3f94-a0ee-419b-a63d-4f8ea740c342,ResourceVersion:6153,Generation:0,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb2e7 0xc003cdb2e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2020-01-15 21:25:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-8dmsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8dmsc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-8dmsc,UID:ef2b3be6-40e8-4ece-a40a-48b1a73537a7,ResourceVersion:6176,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb440 0xc003cdb441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb4b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb4d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-b2qrw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b2qrw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-b2qrw,UID:4511b979-8b61-42bc-a6d3-b9cb3cabe2e6,ResourceVersion:6194,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb550 0xc003cdb551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.944: INFO: Pod "nginx-deployment-55fb7cb77f-h5kfc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-h5kfc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-h5kfc,UID:da68741b-99df-41a0-a81c-916a96896860,ResourceVersion:6133,Generation:0,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb647 0xc003cdb648}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:,StartTime:2020-01-15 21:25:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-55fb7cb77f-hqd42" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hqd42,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-hqd42,UID:fa850bc5-77a5-4eb4-9ee1-c31c3f8f0306,ResourceVersion:6129,Generation:0,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb7a0 0xc003cdb7a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2020-01-15 21:25:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-55fb7cb77f-k69sj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-k69sj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-k69sj,UID:f59c7773-9634-42e1-a841-d00257655eba,ResourceVersion:6155,Generation:0,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdb900 0xc003cdb901}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdb970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdb990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2020-01-15 21:25:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-55fb7cb77f-mb855" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mb855,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-mb855,UID:9b2cb4b8-f18e-458a-90db-28ae4fe2f7f1,ResourceVersion:6193,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdba60 0xc003cdba61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdbad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdbaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-55fb7cb77f-rh6nh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rh6nh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-rh6nh,UID:17b2806c-3d9f-48d4-b72e-84cc8f04b239,ResourceVersion:6186,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdbb57 0xc003cdbb58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdbbc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdbbe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-55fb7cb77f-z5kht" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-z5kht,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-55fb7cb77f-z5kht,UID:2858a5f8-4d24-49b8-a823-543079470e0e,ResourceVersion:6142,Generation:0,CreationTimestamp:2020-01-15 21:25:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 6a2226d0-ab58-438b-9748-788cc73562b0 0xc003cdbc60 0xc003cdbc61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdbcd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdbcf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:31 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2020-01-15 21:25:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-7b8c6f4498-4npr4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4npr4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-4npr4,UID:ad4a98da-6bfb-4b5f-8d26-3dd1ef51cbe4,ResourceVersion:6199,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003cdbdc0 0xc003cdbdc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdbe20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdbe50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.945: INFO: Pod "nginx-deployment-7b8c6f4498-627k5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-627k5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-627k5,UID:cf39d371-87db-413b-9d70-e3c1fdd4f4f6,ResourceVersion:6089,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003cdbed0 0xc003cdbed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cdbf30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cdbf50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.65,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://12105e648b73f2e27531b13322370a32ad290cd595b1263a3d1e4bded30383db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-8nh2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8nh2w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-8nh2w,UID:ceefa7f0-b6fb-40c6-8d5a-6a8f4b0ffdac,ResourceVersion:6167,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4020 0xc003dc4021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc40a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-f5f9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f5f9h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-f5f9h,UID:3bdb05ff-2e8e-4ef5-86c6-81aca8c5a310,ResourceVersion:6203,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4120 0xc003dc4121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc41a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-gn55v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gn55v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-gn55v,UID:9a956525-9ea0-497b-9289-058c72e8a891,ResourceVersion:6183,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4207 0xc003dc4208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-hh9g6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hh9g6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-hh9g6,UID:b82463b2-f47b-4795-b6ad-fe1199302b75,ResourceVersion:6182,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4320 0xc003dc4321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc43a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-k6wgs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k6wgs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-k6wgs,UID:dde7c0bb-07f1-458f-b7d5-d02b855c7130,ResourceVersion:6072,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4420 0xc003dc4421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc44a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.1.22,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://58b16b5eb5d4f1ac24480156da6422ce61ad25d6f62714d273a92b40b23de403}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-kjwtb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kjwtb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-kjwtb,UID:845d0118-0514-429d-a23a-092885f05be0,ResourceVersion:6195,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4570 0xc003dc4571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc45d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc45f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-l7vmt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l7vmt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-l7vmt,UID:980f4342-9988-427d-873f-0e5b8d288799,ResourceVersion:6091,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4670 0xc003dc4671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc46d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc46f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.66,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2eadc091b10604c295fba895a2e3a125f1912a4cfa5e37208b5b8fdf34cfa757}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-l8g4l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l8g4l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-l8g4l,UID:7fa90869-c121-4dc2-88a4-751606384841,ResourceVersion:6094,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc47c0 0xc003dc47c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.67,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://883a28b0510329d05e8878e5d2ba75fcd7136faecf742792dccef99b65d1b268}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-lp5tw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lp5tw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-lp5tw,UID:bb8216e1-3199-4bd0-8a20-fc6659d6a521,ResourceVersion:6200,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4910 0xc003dc4911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.946: INFO: Pod "nginx-deployment-7b8c6f4498-nvwf8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nvwf8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-nvwf8,UID:beb85a5c-0c83-40d4-bb26-7cc53d2161bb,ResourceVersion:6080,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4a10 0xc003dc4a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.22,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0efd64ab7c67e3294a9b155712aa00610d41b6eafce01f7add574fc97d981991}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.947: INFO: Pod "nginx-deployment-7b8c6f4498-p8xcj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p8xcj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-p8xcj,UID:8cb81d10-639c-4fa0-bb22-7afcad13456f,ResourceVersion:6070,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4b60 0xc003dc4b61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.1.21,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b7c328e27745fe7c7f3975b0b57bf7a3b40cdc2a329c4e3aef2b36d6164fd9ce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.947: INFO: Pod "nginx-deployment-7b8c6f4498-pqgz4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pqgz4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-pqgz4,UID:1f9ffa4a-9d96-42d6-a9af-e0c1d9eed9ac,ResourceVersion:6196,Generation:0,CreationTimestamp:2020-01-15 21:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4cb0 0xc003dc4cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.947: INFO: Pod "nginx-deployment-7b8c6f4498-rvh22" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rvh22,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-rvh22,UID:8817764b-7fba-41ef-9e14-eec6ee71a4b8,ResourceVersion:6097,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4db0 0xc003dc4db1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.64,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c07b7c23c1331ce8b03568195d9babfdf5fa6fb1fdf109bc9b786b1f276b35f8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 21:25:33.947: INFO: Pod "nginx-deployment-7b8c6f4498-xqlpc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xqlpc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-6655,SelfLink:/api/v1/namespaces/deployment-6655/pods/nginx-deployment-7b8c6f4498-xqlpc,UID:052b6492-6f2d-4185-aa95-dd8115819e82,ResourceVersion:6082,Generation:0,CreationTimestamp:2020-01-15 21:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 297f7c20-b07a-4037-a325-86b9b87dbc15 0xc003dc4f00 0xc003dc4f01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ds77f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ds77f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ds77f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc4f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc4f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:25:27 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.21,StartTime:2020-01-15 21:25:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-01-15 21:25:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ef9219d8f48c5150ae347b64f1d2dea04d1a374fc8eac0259e7e672f8c6df605}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:25:33.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6655" for this suite.
Jan 15 21:25:42.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:25:42.213: INFO: namespace deployment-6655 deletion completed in 8.225688496s

• [SLOW TEST:14.547 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:25:42.213: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-90dc0734-a94f-44f1-8a16-43c038da4041
STEP: Creating a pod to test consume configMaps
Jan 15 21:25:42.288: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7" in namespace "projected-6647" to be "success or failure"
Jan 15 21:25:42.291: INFO: Pod "pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517817ms
Jan 15 21:25:44.295: INFO: Pod "pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007285845s
Jan 15 21:25:46.299: INFO: Pod "pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011013167s
STEP: Saw pod success
Jan 15 21:25:46.299: INFO: Pod "pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7" satisfied condition "success or failure"
Jan 15 21:25:46.302: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:25:46.322: INFO: Waiting for pod pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7 to disappear
Jan 15 21:25:46.325: INFO: Pod pod-projected-configmaps-b4d8d62d-c7d8-4452-a16a-ba23f8df72c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:25:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6647" for this suite.
Jan 15 21:25:52.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:25:52.503: INFO: namespace projected-6647 deletion completed in 6.173407718s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:25:52.504: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:25:52.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1" in namespace "downward-api-2332" to be "success or failure"
Jan 15 21:25:52.572: INFO: Pod "downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.833118ms
Jan 15 21:25:54.576: INFO: Pod "downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00815132s
Jan 15 21:25:56.580: INFO: Pod "downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012392016s
STEP: Saw pod success
Jan 15 21:25:56.580: INFO: Pod "downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1" satisfied condition "success or failure"
Jan 15 21:25:56.583: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1 container client-container: <nil>
STEP: delete the pod
Jan 15 21:25:56.606: INFO: Waiting for pod downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1 to disappear
Jan 15 21:25:56.610: INFO: Pod downwardapi-volume-6019fd04-7de6-439a-9081-728e168af4c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:25:56.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2332" for this suite.
Jan 15 21:26:02.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:26:02.762: INFO: namespace downward-api-2332 deletion completed in 6.145967497s

• [SLOW TEST:10.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:26:02.762: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9a422346-67b4-4c79-b466-27a15030dd1d in namespace container-probe-833
Jan 15 21:26:06.828: INFO: Started pod liveness-9a422346-67b4-4c79-b466-27a15030dd1d in namespace container-probe-833
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 21:26:06.831: INFO: Initial restart count of pod liveness-9a422346-67b4-4c79-b466-27a15030dd1d is 0
Jan 15 21:26:20.863: INFO: Restart count of pod container-probe-833/liveness-9a422346-67b4-4c79-b466-27a15030dd1d is now 1 (14.031664141s elapsed)
Jan 15 21:26:40.908: INFO: Restart count of pod container-probe-833/liveness-9a422346-67b4-4c79-b466-27a15030dd1d is now 2 (34.077277209s elapsed)
Jan 15 21:27:00.955: INFO: Restart count of pod container-probe-833/liveness-9a422346-67b4-4c79-b466-27a15030dd1d is now 3 (54.124513023s elapsed)
Jan 15 21:27:21.002: INFO: Restart count of pod container-probe-833/liveness-9a422346-67b4-4c79-b466-27a15030dd1d is now 4 (1m14.170912606s elapsed)
Jan 15 21:28:21.142: INFO: Restart count of pod container-probe-833/liveness-9a422346-67b4-4c79-b466-27a15030dd1d is now 5 (2m14.310726709s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:28:21.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-833" for this suite.
Jan 15 21:28:27.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:28:27.357: INFO: namespace container-probe-833 deletion completed in 6.185185165s

• [SLOW TEST:144.595 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:28:27.358: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:28:31.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1532" for this suite.
Jan 15 21:28:37.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:28:37.578: INFO: namespace kubelet-test-1532 deletion completed in 6.138072898s

• [SLOW TEST:10.220 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:28:37.579: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-7dcdbe10-a322-4c6d-8619-3a1f9344a1de
STEP: Creating secret with name s-test-opt-upd-7c256ad1-40c0-4174-b023-2aa6f17ba34b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7dcdbe10-a322-4c6d-8619-3a1f9344a1de
STEP: Updating secret s-test-opt-upd-7c256ad1-40c0-4174-b023-2aa6f17ba34b
STEP: Creating secret with name s-test-opt-create-4b27d004-8ca8-4470-9853-f5b8d1e1ec34
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:28:46.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5583" for this suite.
Jan 15 21:29:08.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:29:08.363: INFO: namespace secrets-5583 deletion completed in 22.207888176s

• [SLOW TEST:30.785 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:29:08.364: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:29:08.429: INFO: Creating ReplicaSet my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d
Jan 15 21:29:08.438: INFO: Pod name my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d: Found 0 pods out of 1
Jan 15 21:29:13.443: INFO: Pod name my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d: Found 1 pods out of 1
Jan 15 21:29:13.443: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d" is running
Jan 15 21:29:13.446: INFO: Pod "my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d-4vpdh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:29:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:29:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:29:11 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:29:08 +0000 UTC Reason: Message:}])
Jan 15 21:29:13.446: INFO: Trying to dial the pod
Jan 15 21:29:18.550: INFO: Controller my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d: Got expected result from replica 1 [my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d-4vpdh]: "my-hostname-basic-d3d1404d-b532-4463-bfe1-01363829bf3d-4vpdh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:29:18.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1336" for this suite.
Jan 15 21:29:24.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:29:24.703: INFO: namespace replicaset-1336 deletion completed in 6.147437046s

• [SLOW TEST:16.340 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:29:24.704: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-3ba835c5-2a1a-4715-a3e7-f575119f1b68
STEP: Creating a pod to test consume configMaps
Jan 15 21:29:24.772: INFO: Waiting up to 5m0s for pod "pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b" in namespace "configmap-8275" to be "success or failure"
Jan 15 21:29:24.775: INFO: Pod "pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.888013ms
Jan 15 21:29:26.779: INFO: Pod "pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006899714s
STEP: Saw pod success
Jan 15 21:29:26.779: INFO: Pod "pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b" satisfied condition "success or failure"
Jan 15 21:29:26.783: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:29:26.806: INFO: Waiting for pod pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b to disappear
Jan 15 21:29:26.809: INFO: Pod pod-configmaps-af09bb8d-9f12-4b41-9236-b0fa91be1b4b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:29:26.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8275" for this suite.
Jan 15 21:29:32.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:29:33.028: INFO: namespace configmap-8275 deletion completed in 6.212842019s

• [SLOW TEST:8.324 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:29:33.029: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Jan 15 21:29:33.079: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 21:29:33.090: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 21:29:33.095: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000000 before test
Jan 15 21:29:33.108: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-bmwhb from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:29:33.108: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:29:33.108: INFO: coredns-68c85fc5d4-7jtpf from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:29:33.108: INFO: metrics-server-957757c9f-hvw4p from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container metrics-server ready: true, restart count 1
Jan 15 21:29:33.108: INFO: tunnelfront-6558768cb7-qpdxq from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 15 21:29:33.108: INFO: kube-proxy-k6zsd from kube-system started at 2020-01-15 20:57:45 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:29:33.108: INFO: coredns-autoscaler-875fb445c-tvwfg from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 21:29:33.108: INFO: kubernetes-dashboard-5758d48c87-k6r2c from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.108: INFO: 	Container main ready: true, restart count 0
Jan 15 21:29:33.108: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000001 before test
Jan 15 21:29:33.117: INFO: sonobuoy from sonobuoy started at 2020-01-15 21:01:28 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.117: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 21:29:33.117: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-wz2pp from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:29:33.117: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:29:33.118: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:29:33.118: INFO: kube-proxy-qpcxm from kube-system started at 2020-01-15 20:57:49 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.118: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:29:33.118: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000002 before test
Jan 15 21:29:33.168: INFO: kube-proxy-7sm85 from kube-system started at 2020-01-15 20:57:47 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.168: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:29:33.168: INFO: coredns-68c85fc5d4-49g8n from kube-system started at 2020-01-15 20:58:10 +0000 UTC (1 container statuses recorded)
Jan 15 21:29:33.168: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:29:33.168: INFO: sonobuoy-e2e-job-547910a8bd894eaf from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:29:33.168: INFO: 	Container e2e ready: true, restart count 0
Jan 15 21:29:33.168: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:29:33.168: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-79lmz from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:29:33.168: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:29:33.168: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node aks-nodepool1-25266157-vmss000000
STEP: verifying the node has the label node aks-nodepool1-25266157-vmss000001
STEP: verifying the node has the label node aks-nodepool1-25266157-vmss000002
Jan 15 21:29:33.229: INFO: Pod coredns-68c85fc5d4-49g8n requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000002
Jan 15 21:29:33.229: INFO: Pod coredns-68c85fc5d4-7jtpf requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod coredns-autoscaler-875fb445c-tvwfg requesting resource cpu=20m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod kube-proxy-7sm85 requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000002
Jan 15 21:29:33.229: INFO: Pod kube-proxy-k6zsd requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod kube-proxy-qpcxm requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000001
Jan 15 21:29:33.229: INFO: Pod kubernetes-dashboard-5758d48c87-k6r2c requesting resource cpu=100m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod metrics-server-957757c9f-hvw4p requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod tunnelfront-6558768cb7-qpdxq requesting resource cpu=10m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod sonobuoy requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000001
Jan 15 21:29:33.229: INFO: Pod sonobuoy-e2e-job-547910a8bd894eaf requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000002
Jan 15 21:29:33.229: INFO: Pod sonobuoy-systemd-logs-daemon-set-1924fb744c904971-79lmz requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000002
Jan 15 21:29:33.229: INFO: Pod sonobuoy-systemd-logs-daemon-set-1924fb744c904971-bmwhb requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000000
Jan 15 21:29:33.229: INFO: Pod sonobuoy-systemd-logs-daemon-set-1924fb744c904971-wz2pp requesting resource cpu=0m on Node aks-nodepool1-25266157-vmss000001
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-402e3b95-ae90-4842-a917-960fa54b38da.15ea2cb48923186d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5090/filler-pod-402e3b95-ae90-4842-a917-960fa54b38da to aks-nodepool1-25266157-vmss000002]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-402e3b95-ae90-4842-a917-960fa54b38da.15ea2cb4cb7b2209], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-402e3b95-ae90-4842-a917-960fa54b38da.15ea2cb4ea1a86bb], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-402e3b95-ae90-4842-a917-960fa54b38da.15ea2cb4f9d4706a], Reason = [Created], Message = [Created container filler-pod-402e3b95-ae90-4842-a917-960fa54b38da]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-402e3b95-ae90-4842-a917-960fa54b38da.15ea2cb507e87e49], Reason = [Started], Message = [Started container filler-pod-402e3b95-ae90-4842-a917-960fa54b38da]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245.15ea2cb4885aea7f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5090/filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245 to aks-nodepool1-25266157-vmss000000]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245.15ea2cb4c93e93d5], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245.15ea2cb4ed4389d6], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245.15ea2cb4fde8e112], Reason = [Created], Message = [Created container filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245.15ea2cb50f679da0], Reason = [Started], Message = [Started container filler-pod-4d6c464e-9d49-40e3-8c4a-5f10f6e67245]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228.15ea2cb488b9bbd6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5090/filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228 to aks-nodepool1-25266157-vmss000001]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228.15ea2cb4cb4e75c0], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228.15ea2cb4e8e875d2], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228.15ea2cb4f8de32bd], Reason = [Created], Message = [Created container filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228.15ea2cb50750bcb1], Reason = [Started], Message = [Started container filler-pod-ef3ed3bf-85b4-46cd-af91-22b32a903228]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15ea2cb578ca8c29], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node aks-nodepool1-25266157-vmss000000
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-nodepool1-25266157-vmss000001
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-nodepool1-25266157-vmss000002
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:29:38.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5090" for this suite.
Jan 15 21:29:44.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:29:44.488: INFO: namespace sched-pred-5090 deletion completed in 6.148510481s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.460 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:29:44.489: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-8723eed8-d6ab-4d8f-9b3f-08a715a1b631
STEP: Creating a pod to test consume secrets
Jan 15 21:29:44.558: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6" in namespace "projected-9457" to be "success or failure"
Jan 15 21:29:44.561: INFO: Pod "pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.024514ms
Jan 15 21:29:46.566: INFO: Pod "pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008339698s
Jan 15 21:29:48.570: INFO: Pod "pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012898776s
STEP: Saw pod success
Jan 15 21:29:48.570: INFO: Pod "pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6" satisfied condition "success or failure"
Jan 15 21:29:48.574: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:29:48.596: INFO: Waiting for pod pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6 to disappear
Jan 15 21:29:48.600: INFO: Pod pod-projected-secrets-eea19f22-ce52-4ea8-86c9-eab41d1ee7d6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:29:48.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9457" for this suite.
Jan 15 21:29:54.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:29:54.771: INFO: namespace projected-9457 deletion completed in 6.165125922s

• [SLOW TEST:10.283 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:29:54.773: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Jan 15 21:29:59.380: INFO: Successfully updated pod "annotationupdatebd0a92e4-c073-48cb-a90e-2b02574edb2e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:30:01.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9287" for this suite.
Jan 15 21:30:23.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:30:23.580: INFO: namespace downward-api-9287 deletion completed in 22.161550787s

• [SLOW TEST:28.807 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:30:23.581: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Jan 15 21:30:23.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-2142'
Jan 15 21:30:24.555: INFO: stderr: ""
Jan 15 21:30:24.555: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 21:30:25.560: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:30:25.560: INFO: Found 0 / 1
Jan 15 21:30:26.560: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:30:26.560: INFO: Found 0 / 1
Jan 15 21:30:27.560: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:30:27.560: INFO: Found 1 / 1
Jan 15 21:30:27.560: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 15 21:30:27.564: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:30:27.564: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 21:30:27.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 patch pod redis-master-p5nwb --namespace=kubectl-2142 -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 15 21:30:27.658: INFO: stderr: ""
Jan 15 21:30:27.658: INFO: stdout: "pod/redis-master-p5nwb patched\n"
STEP: checking annotations
Jan 15 21:30:27.661: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 21:30:27.661: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:30:27.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2142" for this suite.
Jan 15 21:30:49.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:30:49.831: INFO: namespace kubectl-2142 deletion completed in 22.163653162s

• [SLOW TEST:26.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:30:49.831: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9974/configmap-test-7126578d-29d3-4f4f-837f-d79edce60252
STEP: Creating a pod to test consume configMaps
Jan 15 21:30:49.894: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf" in namespace "configmap-9974" to be "success or failure"
Jan 15 21:30:49.900: INFO: Pod "pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.853719ms
Jan 15 21:30:51.907: INFO: Pod "pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013097624s
Jan 15 21:30:53.912: INFO: Pod "pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017224827s
STEP: Saw pod success
Jan 15 21:30:53.912: INFO: Pod "pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf" satisfied condition "success or failure"
Jan 15 21:30:53.914: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf container env-test: <nil>
STEP: delete the pod
Jan 15 21:30:53.937: INFO: Waiting for pod pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf to disappear
Jan 15 21:30:53.940: INFO: Pod pod-configmaps-cbbebd1c-13b8-464e-8c89-00c518737edf no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:30:53.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9974" for this suite.
Jan 15 21:30:59.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:31:00.127: INFO: namespace configmap-9974 deletion completed in 6.180128414s

• [SLOW TEST:10.296 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:31:00.127: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 21:31:00.216: INFO: Waiting up to 5m0s for pod "pod-cc140b94-5fce-4e9b-bcf9-86178844f01d" in namespace "emptydir-470" to be "success or failure"
Jan 15 21:31:00.223: INFO: Pod "pod-cc140b94-5fce-4e9b-bcf9-86178844f01d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.250624ms
Jan 15 21:31:02.227: INFO: Pod "pod-cc140b94-5fce-4e9b-bcf9-86178844f01d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011243261s
Jan 15 21:31:04.231: INFO: Pod "pod-cc140b94-5fce-4e9b-bcf9-86178844f01d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015194706s
STEP: Saw pod success
Jan 15 21:31:04.231: INFO: Pod "pod-cc140b94-5fce-4e9b-bcf9-86178844f01d" satisfied condition "success or failure"
Jan 15 21:31:04.243: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-cc140b94-5fce-4e9b-bcf9-86178844f01d container test-container: <nil>
STEP: delete the pod
Jan 15 21:31:04.266: INFO: Waiting for pod pod-cc140b94-5fce-4e9b-bcf9-86178844f01d to disappear
Jan 15 21:31:04.270: INFO: Pod pod-cc140b94-5fce-4e9b-bcf9-86178844f01d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:31:04.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-470" for this suite.
Jan 15 21:31:10.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:31:10.474: INFO: namespace emptydir-470 deletion completed in 6.198523905s

• [SLOW TEST:10.347 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:31:10.474: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Jan 15 21:31:10.534: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:31:14.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6278" for this suite.
Jan 15 21:31:36.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:31:36.809: INFO: namespace init-container-6278 deletion completed in 22.172643008s

• [SLOW TEST:26.336 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:31:36.810: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Jan 15 21:31:36.863: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 21:31:36.872: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 21:31:36.877: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000000 before test
Jan 15 21:31:36.888: INFO: tunnelfront-6558768cb7-qpdxq from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 15 21:31:36.888: INFO: kube-proxy-k6zsd from kube-system started at 2020-01-15 20:57:45 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:31:36.888: INFO: coredns-autoscaler-875fb445c-tvwfg from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 21:31:36.888: INFO: kubernetes-dashboard-5758d48c87-k6r2c from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container main ready: true, restart count 0
Jan 15 21:31:36.888: INFO: metrics-server-957757c9f-hvw4p from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container metrics-server ready: true, restart count 1
Jan 15 21:31:36.888: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-bmwhb from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:31:36.888: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:31:36.888: INFO: coredns-68c85fc5d4-7jtpf from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.888: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:31:36.888: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000001 before test
Jan 15 21:31:36.910: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-wz2pp from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:31:36.910: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:31:36.910: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:31:36.910: INFO: sonobuoy from sonobuoy started at 2020-01-15 21:01:28 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.910: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 21:31:36.910: INFO: kube-proxy-qpcxm from kube-system started at 2020-01-15 20:57:49 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.910: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:31:36.910: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000002 before test
Jan 15 21:31:36.932: INFO: kube-proxy-7sm85 from kube-system started at 2020-01-15 20:57:47 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.932: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:31:36.932: INFO: coredns-68c85fc5d4-49g8n from kube-system started at 2020-01-15 20:58:10 +0000 UTC (1 container statuses recorded)
Jan 15 21:31:36.932: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:31:36.932: INFO: sonobuoy-e2e-job-547910a8bd894eaf from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:31:36.932: INFO: 	Container e2e ready: true, restart count 0
Jan 15 21:31:36.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:31:36.932: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-79lmz from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:31:36.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:31:36.932: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ea2cd155ebdf71], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:31:37.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7606" for this suite.
Jan 15 21:31:43.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:31:44.109: INFO: namespace sched-pred-7606 deletion completed in 6.149271644s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.299 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:31:44.110: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 21:31:44.172: INFO: Waiting up to 5m0s for pod "pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af" in namespace "emptydir-695" to be "success or failure"
Jan 15 21:31:44.175: INFO: Pod "pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204411ms
Jan 15 21:31:46.183: INFO: Pod "pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010837232s
Jan 15 21:31:48.188: INFO: Pod "pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016493254s
STEP: Saw pod success
Jan 15 21:31:48.189: INFO: Pod "pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af" satisfied condition "success or failure"
Jan 15 21:31:48.192: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af container test-container: <nil>
STEP: delete the pod
Jan 15 21:31:48.217: INFO: Waiting for pod pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af to disappear
Jan 15 21:31:48.221: INFO: Pod pod-99e64a5a-9b61-4ac0-a8b6-1047ea6584af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:31:48.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-695" for this suite.
Jan 15 21:31:54.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:31:54.381: INFO: namespace emptydir-695 deletion completed in 6.155112782s

• [SLOW TEST:10.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:31:54.381: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:31:54.434: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 15 21:31:54.446: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 15 21:31:59.450: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 21:31:59.450: INFO: Creating deployment "test-rolling-update-deployment"
Jan 15 21:31:59.455: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 15 21:31:59.464: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 15 21:32:01.472: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 15 21:32:01.476: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714720719, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714720719, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714720719, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714720719, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 21:32:03.481: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Jan 15 21:32:03.494: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1810,SelfLink:/apis/apps/v1/namespaces/deployment-1810/deployments/test-rolling-update-deployment,UID:0d3db6db-e014-40cd-b13d-e249103b13e4,ResourceVersion:7595,Generation:1,CreationTimestamp:2020-01-15 21:31:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-01-15 21:31:59 +0000 UTC 2020-01-15 21:31:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-01-15 21:32:02 +0000 UTC 2020-01-15 21:31:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 21:32:03.498: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-1810,SelfLink:/apis/apps/v1/namespaces/deployment-1810/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:0925d664-3926-44b2-8185-cfbcba197875,ResourceVersion:7584,Generation:1,CreationTimestamp:2020-01-15 21:31:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0d3db6db-e014-40cd-b13d-e249103b13e4 0xc003952e17 0xc003952e18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 21:32:03.498: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 15 21:32:03.498: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1810,SelfLink:/apis/apps/v1/namespaces/deployment-1810/replicasets/test-rolling-update-controller,UID:2e4c53c0-aefa-4468-96e4-6f6cce0eb292,ResourceVersion:7594,Generation:2,CreationTimestamp:2020-01-15 21:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0d3db6db-e014-40cd-b13d-e249103b13e4 0xc003952d3f 0xc003952d50}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 21:32:03.502: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-qzckt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-qzckt,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-1810,SelfLink:/api/v1/namespaces/deployment-1810/pods/test-rolling-update-deployment-79f6b9d75c-qzckt,UID:20aeb22f-d236-4b23-b700-2a7e5ddd6482,ResourceVersion:7583,Generation:0,CreationTimestamp:2020-01-15 21:31:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 0925d664-3926-44b2-8185-cfbcba197875 0xc003953717 0xc003953718}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-q9zfk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q9zfk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-q9zfk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003953780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039537a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:31:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:32:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:32:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:31:59 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.1.36,StartTime:2020-01-15 21:31:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-01-15 21:32:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e7261fc7c544eab8279f90148552ee5fef0579661226ca49c42815839bb405e2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:32:03.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1810" for this suite.
Jan 15 21:32:09.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:32:09.660: INFO: namespace deployment-1810 deletion completed in 6.152693945s

• [SLOW TEST:15.279 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:32:09.661: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-d03efa46-1b17-4454-ac9a-d7712da727a0
STEP: Creating a pod to test consume secrets
Jan 15 21:32:09.724: INFO: Waiting up to 5m0s for pod "pod-secrets-50148ba2-3e33-4437-8425-750a2541480b" in namespace "secrets-4572" to be "success or failure"
Jan 15 21:32:09.727: INFO: Pod "pod-secrets-50148ba2-3e33-4437-8425-750a2541480b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.91861ms
Jan 15 21:32:11.731: INFO: Pod "pod-secrets-50148ba2-3e33-4437-8425-750a2541480b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007526114s
Jan 15 21:32:13.735: INFO: Pod "pod-secrets-50148ba2-3e33-4437-8425-750a2541480b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011049821s
STEP: Saw pod success
Jan 15 21:32:13.735: INFO: Pod "pod-secrets-50148ba2-3e33-4437-8425-750a2541480b" satisfied condition "success or failure"
Jan 15 21:32:13.738: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-50148ba2-3e33-4437-8425-750a2541480b container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:32:13.758: INFO: Waiting for pod pod-secrets-50148ba2-3e33-4437-8425-750a2541480b to disappear
Jan 15 21:32:13.761: INFO: Pod pod-secrets-50148ba2-3e33-4437-8425-750a2541480b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:32:13.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4572" for this suite.
Jan 15 21:32:19.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:32:19.920: INFO: namespace secrets-4572 deletion completed in 6.153342559s

• [SLOW TEST:10.259 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:32:19.921: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:32:19.973: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:32:24.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9928" for this suite.
Jan 15 21:33:02.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:33:02.407: INFO: namespace pods-9928 deletion completed in 38.159199654s

• [SLOW TEST:42.486 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:33:02.407: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:34:02.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6953" for this suite.
Jan 15 21:34:24.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:34:24.636: INFO: namespace container-probe-6953 deletion completed in 22.149687778s

• [SLOW TEST:82.229 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:34:24.636: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 15 21:34:28.717: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0c262aa4-a0ad-4dc2-b0b3-1381b8e13604,GenerateName:,Namespace:events-3770,SelfLink:/api/v1/namespaces/events-3770/pods/send-events-0c262aa4-a0ad-4dc2-b0b3-1381b8e13604,UID:f8d2a6fc-6318-4183-94e6-7a666d2f0f2d,ResourceVersion:7926,Generation:0,CreationTimestamp:2020-01-15 21:34:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 693066561,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2s8pt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2s8pt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-2s8pt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003e36290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003e362b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:34:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:34:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:34:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 21:34:24 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.94,StartTime:2020-01-15 21:34:24 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-01-15 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://5d6f9bc8cfc2ad401401449a289a5c97c318dfc4c0b2f55a4c317a298a871a29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 15 21:34:30.722: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 15 21:34:32.728: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:34:32.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3770" for this suite.
Jan 15 21:35:10.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:35:10.889: INFO: namespace events-3770 deletion completed in 38.147408938s

• [SLOW TEST:46.253 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:35:10.890: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:35:10.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7" in namespace "projected-2197" to be "success or failure"
Jan 15 21:35:10.959: INFO: Pod "downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.583714ms
Jan 15 21:35:12.963: INFO: Pod "downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007770559s
Jan 15 21:35:14.967: INFO: Pod "downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01188061s
STEP: Saw pod success
Jan 15 21:35:14.967: INFO: Pod "downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7" satisfied condition "success or failure"
Jan 15 21:35:14.970: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7 container client-container: <nil>
STEP: delete the pod
Jan 15 21:35:14.998: INFO: Waiting for pod downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7 to disappear
Jan 15 21:35:15.001: INFO: Pod downwardapi-volume-24e57c56-3d14-473d-b2ac-60e52608f9a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:35:15.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2197" for this suite.
Jan 15 21:35:21.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:35:21.194: INFO: namespace projected-2197 deletion completed in 6.187929536s

• [SLOW TEST:10.305 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:35:21.195: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:35:21.290: INFO: Create a RollingUpdate DaemonSet
Jan 15 21:35:21.295: INFO: Check that daemon pods launch on every node of the cluster
Jan 15 21:35:21.303: INFO: Number of nodes with available pods: 0
Jan 15 21:35:21.303: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:35:22.312: INFO: Number of nodes with available pods: 0
Jan 15 21:35:22.312: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:35:23.312: INFO: Number of nodes with available pods: 0
Jan 15 21:35:23.312: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:35:24.313: INFO: Number of nodes with available pods: 3
Jan 15 21:35:24.313: INFO: Number of running nodes: 3, number of available pods: 3
Jan 15 21:35:24.313: INFO: Update the DaemonSet to trigger a rollout
Jan 15 21:35:24.321: INFO: Updating DaemonSet daemon-set
Jan 15 21:35:37.339: INFO: Roll back the DaemonSet before rollout is complete
Jan 15 21:35:37.347: INFO: Updating DaemonSet daemon-set
Jan 15 21:35:37.347: INFO: Make sure DaemonSet rollback is complete
Jan 15 21:35:37.350: INFO: Wrong image for pod: daemon-set-b9t7f. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jan 15 21:35:37.350: INFO: Pod daemon-set-b9t7f is not available
Jan 15 21:35:38.362: INFO: Wrong image for pod: daemon-set-b9t7f. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jan 15 21:35:38.362: INFO: Pod daemon-set-b9t7f is not available
Jan 15 21:35:39.360: INFO: Wrong image for pod: daemon-set-b9t7f. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Jan 15 21:35:39.360: INFO: Pod daemon-set-b9t7f is not available
Jan 15 21:35:40.360: INFO: Pod daemon-set-gx6nw is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7036, will wait for the garbage collector to delete the pods
Jan 15 21:35:40.435: INFO: Deleting DaemonSet.extensions daemon-set took: 9.124334ms
Jan 15 21:35:40.735: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.212926ms
Jan 15 21:35:54.539: INFO: Number of nodes with available pods: 0
Jan 15 21:35:54.539: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 21:35:54.543: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7036/daemonsets","resourceVersion":"8188"},"items":null}

Jan 15 21:35:54.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7036/pods","resourceVersion":"8188"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:35:54.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7036" for this suite.
Jan 15 21:36:00.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:36:00.721: INFO: namespace daemonsets-7036 deletion completed in 6.149448081s

• [SLOW TEST:39.526 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:36:00.721: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a27aaba4-4a07-490c-ac7d-3fe3434959a3
STEP: Creating a pod to test consume secrets
Jan 15 21:36:00.789: INFO: Waiting up to 5m0s for pod "pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951" in namespace "secrets-7131" to be "success or failure"
Jan 15 21:36:00.794: INFO: Pod "pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951": Phase="Pending", Reason="", readiness=false. Elapsed: 5.653122ms
Jan 15 21:36:02.798: INFO: Pod "pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008914483s
Jan 15 21:36:04.802: INFO: Pod "pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013013051s
STEP: Saw pod success
Jan 15 21:36:04.802: INFO: Pod "pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951" satisfied condition "success or failure"
Jan 15 21:36:04.807: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951 container secret-env-test: <nil>
STEP: delete the pod
Jan 15 21:36:04.833: INFO: Waiting for pod pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951 to disappear
Jan 15 21:36:04.836: INFO: Pod pod-secrets-d7a6fc16-1701-4b20-b93b-9a3c3c81f951 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:36:04.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7131" for this suite.
Jan 15 21:36:10.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:36:11.012: INFO: namespace secrets-7131 deletion completed in 6.171044934s

• [SLOW TEST:10.291 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:36:11.012: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Jan 15 21:36:11.087: INFO: Waiting up to 5m0s for pod "downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1" in namespace "downward-api-5636" to be "success or failure"
Jan 15 21:36:11.098: INFO: Pod "downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.79814ms
Jan 15 21:36:13.102: INFO: Pod "downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015204829s
Jan 15 21:36:15.106: INFO: Pod "downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019557721s
STEP: Saw pod success
Jan 15 21:36:15.106: INFO: Pod "downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1" satisfied condition "success or failure"
Jan 15 21:36:15.109: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1 container dapi-container: <nil>
STEP: delete the pod
Jan 15 21:36:15.134: INFO: Waiting for pod downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1 to disappear
Jan 15 21:36:15.137: INFO: Pod downward-api-70c8a11c-8cab-4f0d-a193-f382b55d22d1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:36:15.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5636" for this suite.
Jan 15 21:36:21.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:36:21.330: INFO: namespace downward-api-5636 deletion completed in 6.187402366s

• [SLOW TEST:10.318 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:36:21.330: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:36:21.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7" in namespace "downward-api-3632" to be "success or failure"
Jan 15 21:36:21.402: INFO: Pod "downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.301232ms
Jan 15 21:36:23.407: INFO: Pod "downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013112244s
STEP: Saw pod success
Jan 15 21:36:23.407: INFO: Pod "downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7" satisfied condition "success or failure"
Jan 15 21:36:23.411: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7 container client-container: <nil>
STEP: delete the pod
Jan 15 21:36:23.435: INFO: Waiting for pod downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7 to disappear
Jan 15 21:36:23.439: INFO: Pod downwardapi-volume-9d14d27a-ff88-44f9-ba1d-c60ca0ae0db7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:36:23.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3632" for this suite.
Jan 15 21:36:29.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:36:29.595: INFO: namespace downward-api-3632 deletion completed in 6.149310977s

• [SLOW TEST:8.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:36:29.596: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:36:29.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7" in namespace "projected-5982" to be "success or failure"
Jan 15 21:36:29.669: INFO: Pod "downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.285116ms
Jan 15 21:36:31.674: INFO: Pod "downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008987646s
Jan 15 21:36:33.678: INFO: Pod "downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012905677s
STEP: Saw pod success
Jan 15 21:36:33.678: INFO: Pod "downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7" satisfied condition "success or failure"
Jan 15 21:36:33.681: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7 container client-container: <nil>
STEP: delete the pod
Jan 15 21:36:33.703: INFO: Waiting for pod downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7 to disappear
Jan 15 21:36:33.706: INFO: Pod downwardapi-volume-dd1fbe24-02d1-42d4-9ae1-c2ad6f0b46d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:36:33.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5982" for this suite.
Jan 15 21:36:39.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:36:39.899: INFO: namespace projected-5982 deletion completed in 6.189093496s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:36:39.900: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 21:36:39.951: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:36:44.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2374" for this suite.
Jan 15 21:37:32.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:37:32.159: INFO: namespace pods-2374 deletion completed in 48.152132916s

• [SLOW TEST:52.260 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:37:32.160: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-46fe9b96-1562-449f-a9da-6349cc926460
STEP: Creating a pod to test consume secrets
Jan 15 21:37:32.225: INFO: Waiting up to 5m0s for pod "pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2" in namespace "secrets-9223" to be "success or failure"
Jan 15 21:37:32.230: INFO: Pod "pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.377821ms
Jan 15 21:37:34.239: INFO: Pod "pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014166893s
Jan 15 21:37:36.246: INFO: Pod "pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021282662s
STEP: Saw pod success
Jan 15 21:37:36.246: INFO: Pod "pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2" satisfied condition "success or failure"
Jan 15 21:37:36.249: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:37:36.285: INFO: Waiting for pod pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2 to disappear
Jan 15 21:37:36.289: INFO: Pod pod-secrets-f496ca6c-319d-457e-a6a7-d42de2edb7c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:37:36.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9223" for this suite.
Jan 15 21:37:42.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:37:42.492: INFO: namespace secrets-9223 deletion completed in 6.196064308s

• [SLOW TEST:10.332 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:37:42.493: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 21:37:42.564: INFO: Waiting up to 5m0s for pod "pod-6c48b60c-e62b-41ae-8632-8a43c4b63092" in namespace "emptydir-7905" to be "success or failure"
Jan 15 21:37:42.569: INFO: Pod "pod-6c48b60c-e62b-41ae-8632-8a43c4b63092": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551218ms
Jan 15 21:37:44.576: INFO: Pod "pod-6c48b60c-e62b-41ae-8632-8a43c4b63092": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012118305s
Jan 15 21:37:46.581: INFO: Pod "pod-6c48b60c-e62b-41ae-8632-8a43c4b63092": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016781284s
STEP: Saw pod success
Jan 15 21:37:46.581: INFO: Pod "pod-6c48b60c-e62b-41ae-8632-8a43c4b63092" satisfied condition "success or failure"
Jan 15 21:37:46.585: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-6c48b60c-e62b-41ae-8632-8a43c4b63092 container test-container: <nil>
STEP: delete the pod
Jan 15 21:37:46.607: INFO: Waiting for pod pod-6c48b60c-e62b-41ae-8632-8a43c4b63092 to disappear
Jan 15 21:37:46.610: INFO: Pod pod-6c48b60c-e62b-41ae-8632-8a43c4b63092 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:37:46.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7905" for this suite.
Jan 15 21:37:52.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:37:52.766: INFO: namespace emptydir-7905 deletion completed in 6.150845991s

• [SLOW TEST:10.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:37:52.766: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-02f3bd69-cc66-45e5-adb0-a7e15cc0ad14
STEP: Creating a pod to test consume configMaps
Jan 15 21:37:52.837: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b" in namespace "projected-9925" to be "success or failure"
Jan 15 21:37:52.841: INFO: Pod "pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.497113ms
Jan 15 21:37:54.845: INFO: Pod "pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007562305s
STEP: Saw pod success
Jan 15 21:37:54.845: INFO: Pod "pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b" satisfied condition "success or failure"
Jan 15 21:37:54.849: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:37:54.876: INFO: Waiting for pod pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b to disappear
Jan 15 21:37:54.879: INFO: Pod pod-projected-configmaps-5761ca54-27ec-48f9-8ff8-d2f7b3d3be9b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:37:54.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9925" for this suite.
Jan 15 21:38:00.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:38:01.028: INFO: namespace projected-9925 deletion completed in 6.142891107s

• [SLOW TEST:8.261 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:38:01.028: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Jan 15 21:38:01.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 --namespace=kubectl-1396 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 15 21:38:04.849: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 15 21:38:04.849: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:38:06.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1396" for this suite.
Jan 15 21:38:12.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:38:13.000: INFO: namespace kubectl-1396 deletion completed in 6.136133746s

• [SLOW TEST:11.972 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:38:13.001: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 21:38:13.097: INFO: Number of nodes with available pods: 0
Jan 15 21:38:13.097: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:38:14.107: INFO: Number of nodes with available pods: 0
Jan 15 21:38:14.107: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:38:15.111: INFO: Number of nodes with available pods: 0
Jan 15 21:38:15.111: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:38:16.107: INFO: Number of nodes with available pods: 3
Jan 15 21:38:16.108: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 15 21:38:16.136: INFO: Number of nodes with available pods: 2
Jan 15 21:38:16.136: INFO: Node aks-nodepool1-25266157-vmss000002 is running more than one daemon pod
Jan 15 21:38:17.145: INFO: Number of nodes with available pods: 2
Jan 15 21:38:17.145: INFO: Node aks-nodepool1-25266157-vmss000002 is running more than one daemon pod
Jan 15 21:38:18.145: INFO: Number of nodes with available pods: 2
Jan 15 21:38:18.145: INFO: Node aks-nodepool1-25266157-vmss000002 is running more than one daemon pod
Jan 15 21:38:19.147: INFO: Number of nodes with available pods: 3
Jan 15 21:38:19.147: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8544, will wait for the garbage collector to delete the pods
Jan 15 21:38:19.214: INFO: Deleting DaemonSet.extensions daemon-set took: 8.207732ms
Jan 15 21:38:19.514: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.253875ms
Jan 15 21:38:29.218: INFO: Number of nodes with available pods: 0
Jan 15 21:38:29.218: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 21:38:29.221: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8544/daemonsets","resourceVersion":"8752"},"items":null}

Jan 15 21:38:29.224: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8544/pods","resourceVersion":"8752"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:38:29.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8544" for this suite.
Jan 15 21:38:35.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:38:35.473: INFO: namespace daemonsets-8544 deletion completed in 6.222445703s

• [SLOW TEST:22.473 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:38:35.474: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Jan 15 21:38:35.529: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-089408705 proxy --unix-socket=/tmp/kubectl-proxy-unix335355180/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:38:35.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6926" for this suite.
Jan 15 21:38:41.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:38:41.769: INFO: namespace kubectl-6926 deletion completed in 6.180698371s

• [SLOW TEST:6.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:38:41.769: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jan 15 21:38:44.906: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:38:44.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7451" for this suite.
Jan 15 21:38:50.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:38:51.087: INFO: namespace container-runtime-7451 deletion completed in 6.16290935s

• [SLOW TEST:9.318 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:38:51.087: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 21:38:59.205: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 21:38:59.208: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 21:39:01.208: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 21:39:01.213: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 21:39:03.208: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 21:39:03.213: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:39:03.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-419" for this suite.
Jan 15 21:39:25.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:39:25.426: INFO: namespace container-lifecycle-hook-419 deletion completed in 22.190075377s

• [SLOW TEST:34.339 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:39:25.427: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-b6f9fd35-8cb2-4a9e-9a08-563ce96735cf
STEP: Creating a pod to test consume configMaps
Jan 15 21:39:25.497: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725" in namespace "projected-1876" to be "success or failure"
Jan 15 21:39:25.502: INFO: Pod "pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725": Phase="Pending", Reason="", readiness=false. Elapsed: 5.04192ms
Jan 15 21:39:27.507: INFO: Pod "pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009601368s
Jan 15 21:39:29.511: INFO: Pod "pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013418516s
STEP: Saw pod success
Jan 15 21:39:29.511: INFO: Pod "pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725" satisfied condition "success or failure"
Jan 15 21:39:29.514: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 21:39:29.536: INFO: Waiting for pod pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725 to disappear
Jan 15 21:39:29.539: INFO: Pod pod-projected-configmaps-aeed8392-72dc-4ac6-8112-8a3ce9414725 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:39:29.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1876" for this suite.
Jan 15 21:39:35.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:39:35.739: INFO: namespace projected-1876 deletion completed in 6.194901391s

• [SLOW TEST:10.312 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:39:35.740: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Jan 15 21:39:40.346: INFO: Successfully updated pod "annotationupdate3cbd444c-dc80-461f-aa2d-11d55c978f24"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:39:42.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7425" for this suite.
Jan 15 21:40:04.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:40:04.610: INFO: namespace projected-7425 deletion completed in 22.189200523s

• [SLOW TEST:28.871 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:40:04.611: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Jan 15 21:40:04.666: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-089408705 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:40:04.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2374" for this suite.
Jan 15 21:40:10.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:40:10.918: INFO: namespace kubectl-2374 deletion completed in 6.155453391s

• [SLOW TEST:6.308 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:40:10.919: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Jan 15 21:40:10.970: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:40:15.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8917" for this suite.
Jan 15 21:40:21.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:40:21.282: INFO: namespace init-container-8917 deletion completed in 6.157483444s

• [SLOW TEST:10.364 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:40:21.283: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-55d4633c-967b-4cde-9d46-dbe66a8601cd
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-55d4633c-967b-4cde-9d46-dbe66a8601cd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:40:27.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5258" for this suite.
Jan 15 21:40:49.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:40:49.641: INFO: namespace configmap-5258 deletion completed in 22.150378955s

• [SLOW TEST:28.358 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:40:49.641: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 21:40:49.794: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441" in namespace "downward-api-432" to be "success or failure"
Jan 15 21:40:49.798: INFO: Pod "downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441": Phase="Pending", Reason="", readiness=false. Elapsed: 3.269013ms
Jan 15 21:40:51.803: INFO: Pod "downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008809183s
Jan 15 21:40:53.815: INFO: Pod "downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02027508s
STEP: Saw pod success
Jan 15 21:40:53.815: INFO: Pod "downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441" satisfied condition "success or failure"
Jan 15 21:40:53.818: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441 container client-container: <nil>
STEP: delete the pod
Jan 15 21:40:53.842: INFO: Waiting for pod downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441 to disappear
Jan 15 21:40:53.845: INFO: Pod downwardapi-volume-a9e1e496-a642-4201-a2f6-30fefa47e441 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:40:53.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-432" for this suite.
Jan 15 21:40:59.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:41:00.006: INFO: namespace downward-api-432 deletion completed in 6.156072395s

• [SLOW TEST:10.365 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:41:00.007: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 15 21:41:00.066: INFO: Waiting up to 5m0s for pod "pod-c269d493-b91b-4bda-a35c-5fd879babffb" in namespace "emptydir-1292" to be "success or failure"
Jan 15 21:41:00.070: INFO: Pod "pod-c269d493-b91b-4bda-a35c-5fd879babffb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.790215ms
Jan 15 21:41:02.074: INFO: Pod "pod-c269d493-b91b-4bda-a35c-5fd879babffb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007386591s
Jan 15 21:41:04.078: INFO: Pod "pod-c269d493-b91b-4bda-a35c-5fd879babffb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011503571s
STEP: Saw pod success
Jan 15 21:41:04.078: INFO: Pod "pod-c269d493-b91b-4bda-a35c-5fd879babffb" satisfied condition "success or failure"
Jan 15 21:41:04.081: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-c269d493-b91b-4bda-a35c-5fd879babffb container test-container: <nil>
STEP: delete the pod
Jan 15 21:41:04.105: INFO: Waiting for pod pod-c269d493-b91b-4bda-a35c-5fd879babffb to disappear
Jan 15 21:41:04.108: INFO: Pod pod-c269d493-b91b-4bda-a35c-5fd879babffb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:41:04.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1292" for this suite.
Jan 15 21:41:10.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:41:10.281: INFO: namespace emptydir-1292 deletion completed in 6.167507782s

• [SLOW TEST:10.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:41:10.282: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-e0a46ba5-493b-48e3-aeb9-6d87c03ba100 in namespace container-probe-4831
Jan 15 21:41:14.352: INFO: Started pod liveness-e0a46ba5-493b-48e3-aeb9-6d87c03ba100 in namespace container-probe-4831
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 21:41:14.355: INFO: Initial restart count of pod liveness-e0a46ba5-493b-48e3-aeb9-6d87c03ba100 is 0
Jan 15 21:41:36.407: INFO: Restart count of pod container-probe-4831/liveness-e0a46ba5-493b-48e3-aeb9-6d87c03ba100 is now 1 (22.052098709s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:41:36.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4831" for this suite.
Jan 15 21:41:42.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:41:42.563: INFO: namespace container-probe-4831 deletion completed in 6.141244895s

• [SLOW TEST:32.282 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:41:42.564: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan 15 21:41:42.632: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 15 21:41:47.636: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:41:48.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2314" for this suite.
Jan 15 21:41:54.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:41:54.846: INFO: namespace replication-controller-2314 deletion completed in 6.186581123s

• [SLOW TEST:12.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:41:54.847: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 15 21:41:54.905: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9422,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 21:41:54.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9422,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 15 21:42:04.916: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9439,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 21:42:04.916: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9439,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 15 21:42:14.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9455,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 21:42:14.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9455,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 15 21:42:24.938: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9470,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 21:42:24.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-a,UID:148d0d3f-12f2-4932-af0b-8662baf01cb5,ResourceVersion:9470,Generation:0,CreationTimestamp:2020-01-15 21:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 15 21:42:34.949: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-b,UID:460f5ce7-e316-4984-88e7-6669378a9fdf,ResourceVersion:9487,Generation:0,CreationTimestamp:2020-01-15 21:42:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 21:42:34.949: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-b,UID:460f5ce7-e316-4984-88e7-6669378a9fdf,ResourceVersion:9487,Generation:0,CreationTimestamp:2020-01-15 21:42:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 15 21:42:44.969: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-b,UID:460f5ce7-e316-4984-88e7-6669378a9fdf,ResourceVersion:9503,Generation:0,CreationTimestamp:2020-01-15 21:42:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 21:42:44.969: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7693,SelfLink:/api/v1/namespaces/watch-7693/configmaps/e2e-watch-test-configmap-b,UID:460f5ce7-e316-4984-88e7-6669378a9fdf,ResourceVersion:9503,Generation:0,CreationTimestamp:2020-01-15 21:42:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:42:54.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7693" for this suite.
Jan 15 21:43:00.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:43:01.134: INFO: namespace watch-7693 deletion completed in 6.158032525s

• [SLOW TEST:66.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:43:01.135: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:43:05.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7992" for this suite.
Jan 15 21:43:53.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:43:53.389: INFO: namespace kubelet-test-7992 deletion completed in 48.145913449s

• [SLOW TEST:52.255 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:43:53.391: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Jan 15 21:43:53.442: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 21:43:53.453: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 21:43:53.457: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000000 before test
Jan 15 21:43:53.472: INFO: coredns-68c85fc5d4-7jtpf from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:43:53.472: INFO: kubernetes-dashboard-5758d48c87-k6r2c from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container main ready: true, restart count 0
Jan 15 21:43:53.472: INFO: metrics-server-957757c9f-hvw4p from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container metrics-server ready: true, restart count 1
Jan 15 21:43:53.472: INFO: tunnelfront-6558768cb7-qpdxq from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 15 21:43:53.472: INFO: kube-proxy-k6zsd from kube-system started at 2020-01-15 20:57:45 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:43:53.472: INFO: coredns-autoscaler-875fb445c-tvwfg from kube-system started at 2020-01-15 20:57:48 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 21:43:53.472: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-bmwhb from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:43:53.472: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:43:53.472: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:43:53.472: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000001 before test
Jan 15 21:43:53.499: INFO: sonobuoy from sonobuoy started at 2020-01-15 21:01:28 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.499: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 21:43:53.499: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-wz2pp from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:43:53.499: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:43:53.499: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:43:53.499: INFO: kube-proxy-qpcxm from kube-system started at 2020-01-15 20:57:49 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.499: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 15 21:43:53.499: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-vmss000002 before test
Jan 15 21:43:53.554: INFO: sonobuoy-e2e-job-547910a8bd894eaf from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:43:53.554: INFO: 	Container e2e ready: true, restart count 0
Jan 15 21:43:53.554: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:43:53.554: INFO: sonobuoy-systemd-logs-daemon-set-1924fb744c904971-79lmz from sonobuoy started at 2020-01-15 21:01:36 +0000 UTC (2 container statuses recorded)
Jan 15 21:43:53.554: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 21:43:53.554: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 15 21:43:53.554: INFO: coredns-68c85fc5d4-49g8n from kube-system started at 2020-01-15 20:58:10 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.554: INFO: 	Container coredns ready: true, restart count 0
Jan 15 21:43:53.554: INFO: kube-proxy-7sm85 from kube-system started at 2020-01-15 20:57:47 +0000 UTC (1 container statuses recorded)
Jan 15 21:43:53.554: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e171d1f8-a566-45c5-9b20-e4aa6fa9ea6f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e171d1f8-a566-45c5-9b20-e4aa6fa9ea6f off the node aks-nodepool1-25266157-vmss000001
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e171d1f8-a566-45c5-9b20-e4aa6fa9ea6f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:44:01.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5820" for this suite.
Jan 15 21:44:21.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:44:21.810: INFO: namespace sched-pred-5820 deletion completed in 20.170091717s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:28.420 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:44:21.811: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-069b5f4b-6d0b-4149-bf91-8dc7b0190272
STEP: Creating a pod to test consume secrets
Jan 15 21:44:21.891: INFO: Waiting up to 5m0s for pod "pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189" in namespace "secrets-8319" to be "success or failure"
Jan 15 21:44:21.896: INFO: Pod "pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095421ms
Jan 15 21:44:23.900: INFO: Pod "pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008930608s
Jan 15 21:44:25.903: INFO: Pod "pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012896297s
STEP: Saw pod success
Jan 15 21:44:25.904: INFO: Pod "pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189" satisfied condition "success or failure"
Jan 15 21:44:25.906: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 21:44:25.935: INFO: Waiting for pod pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189 to disappear
Jan 15 21:44:25.941: INFO: Pod pod-secrets-2fe035c4-7fb1-43a6-990e-25b1797bb189 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:44:25.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8319" for this suite.
Jan 15 21:44:31.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:44:32.097: INFO: namespace secrets-8319 deletion completed in 6.148382042s

• [SLOW TEST:10.286 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:44:32.097: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-7727
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7727
STEP: Deleting pre-stop pod
Jan 15 21:44:47.287: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:44:47.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7727" for this suite.
Jan 15 21:45:25.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:45:25.488: INFO: namespace prestop-7727 deletion completed in 38.185222989s

• [SLOW TEST:53.391 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:45:25.488: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Jan 15 21:45:25.570: INFO: Waiting up to 5m0s for pod "client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8" in namespace "containers-8259" to be "success or failure"
Jan 15 21:45:25.589: INFO: Pod "client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.272176ms
Jan 15 21:45:27.605: INFO: Pod "client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034419865s
Jan 15 21:45:29.609: INFO: Pod "client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038846706s
STEP: Saw pod success
Jan 15 21:45:29.609: INFO: Pod "client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8" satisfied condition "success or failure"
Jan 15 21:45:29.615: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8 container test-container: <nil>
STEP: delete the pod
Jan 15 21:45:29.639: INFO: Waiting for pod client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8 to disappear
Jan 15 21:45:29.642: INFO: Pod client-containers-02b6dfc8-38e3-4cf1-a620-971ac0e8cbc8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:45:29.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8259" for this suite.
Jan 15 21:45:35.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:45:35.792: INFO: namespace containers-8259 deletion completed in 6.144656582s

• [SLOW TEST:10.304 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:45:35.793: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-9059e061-4042-4738-9f65-678192261eb3
STEP: Creating configMap with name cm-test-opt-upd-bcb25c5d-bb25-4e7b-9c26-adeaaa2d7530
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9059e061-4042-4738-9f65-678192261eb3
STEP: Updating configmap cm-test-opt-upd-bcb25c5d-bb25-4e7b-9c26-adeaaa2d7530
STEP: Creating configMap with name cm-test-opt-create-cc64cee8-11b7-4c75-9d07-568a516b8b64
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:47:07.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5766" for this suite.
Jan 15 21:47:29.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:47:29.673: INFO: namespace configmap-5766 deletion completed in 22.150453201s

• [SLOW TEST:113.881 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:47:29.674: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 21:47:29.779: INFO: Number of nodes with available pods: 0
Jan 15 21:47:29.779: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:47:30.789: INFO: Number of nodes with available pods: 0
Jan 15 21:47:30.789: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:47:31.789: INFO: Number of nodes with available pods: 0
Jan 15 21:47:31.790: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 21:47:32.789: INFO: Number of nodes with available pods: 3
Jan 15 21:47:32.789: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 15 21:47:32.812: INFO: Number of nodes with available pods: 2
Jan 15 21:47:32.812: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:33.824: INFO: Number of nodes with available pods: 2
Jan 15 21:47:33.824: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:34.822: INFO: Number of nodes with available pods: 2
Jan 15 21:47:34.822: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:35.822: INFO: Number of nodes with available pods: 2
Jan 15 21:47:35.822: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:36.822: INFO: Number of nodes with available pods: 2
Jan 15 21:47:36.822: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:37.826: INFO: Number of nodes with available pods: 2
Jan 15 21:47:37.826: INFO: Node aks-nodepool1-25266157-vmss000001 is running more than one daemon pod
Jan 15 21:47:38.823: INFO: Number of nodes with available pods: 3
Jan 15 21:47:38.823: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7497, will wait for the garbage collector to delete the pods
Jan 15 21:47:38.887: INFO: Deleting DaemonSet.extensions daemon-set took: 8.195735ms
Jan 15 21:47:39.187: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.255462ms
Jan 15 21:47:49.192: INFO: Number of nodes with available pods: 0
Jan 15 21:47:49.192: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 21:47:49.195: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7497/daemonsets","resourceVersion":"10244"},"items":null}

Jan 15 21:47:49.198: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7497/pods","resourceVersion":"10244"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:47:49.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7497" for this suite.
Jan 15 21:47:55.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:47:55.413: INFO: namespace daemonsets-7497 deletion completed in 6.185516732s

• [SLOW TEST:25.740 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:47:55.414: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 21:48:03.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:03.544: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:05.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:05.551: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:07.545: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:07.548: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:09.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:09.548: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:11.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:11.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:13.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:13.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:15.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:15.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:17.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:17.551: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:19.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:19.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:21.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:21.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:23.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:23.549: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:25.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:25.551: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:27.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:27.548: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 21:48:29.544: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 21:48:29.549: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:48:29.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8475" for this suite.
Jan 15 21:48:51.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:48:51.720: INFO: namespace container-lifecycle-hook-8475 deletion completed in 22.164804168s

• [SLOW TEST:56.306 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:48:51.720: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Jan 15 21:48:51.795: INFO: Waiting up to 5m0s for pod "downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8" in namespace "downward-api-2316" to be "success or failure"
Jan 15 21:48:51.799: INFO: Pod "downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720416ms
Jan 15 21:48:53.803: INFO: Pod "downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007758482s
Jan 15 21:48:55.806: INFO: Pod "downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011467348s
STEP: Saw pod success
Jan 15 21:48:55.806: INFO: Pod "downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8" satisfied condition "success or failure"
Jan 15 21:48:55.809: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8 container dapi-container: <nil>
STEP: delete the pod
Jan 15 21:48:55.836: INFO: Waiting for pod downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8 to disappear
Jan 15 21:48:55.839: INFO: Pod downward-api-5c43eed3-7cac-481a-b3a8-40a0841be0a8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:48:55.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2316" for this suite.
Jan 15 21:49:01.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:49:02.004: INFO: namespace downward-api-2316 deletion completed in 6.159655732s

• [SLOW TEST:10.285 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:49:02.005: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-110b9e54-6dcc-400f-9ead-3a129fd38a52
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:49:02.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5991" for this suite.
Jan 15 21:49:08.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:49:08.209: INFO: namespace secrets-5991 deletion completed in 6.143902374s

• [SLOW TEST:6.204 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:49:08.210: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9815
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Jan 15 21:49:08.292: INFO: Found 0 stateful pods, waiting for 3
Jan 15 21:49:18.296: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:49:18.296: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:49:18.296: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 21:49:18.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-9815 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:49:19.762: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:49:19.762: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:49:19.762: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 21:49:29.800: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 15 21:49:39.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-9815 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:49:40.294: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:49:40.294: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:49:40.294: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:49:50.347: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:49:50.347: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:49:50.347: INFO: Waiting for Pod statefulset-9815/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:49:50.347: INFO: Waiting for Pod statefulset-9815/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:50:00.361: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:50:00.361: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:50:00.361: INFO: Waiting for Pod statefulset-9815/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:50:10.359: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:50:10.359: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 21:50:20.357: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
STEP: Rolling back to a previous revision
Jan 15 21:50:30.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-9815 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 21:50:30.973: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Jan 15 21:50:30.973: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 21:50:30.973: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 21:50:41.013: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 15 21:50:51.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec --namespace=statefulset-9815 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 21:50:51.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Jan 15 21:50:51.476: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 21:50:51.476: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 21:51:01.510: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:51:01.510: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jan 15 21:51:01.510: INFO: Waiting for Pod statefulset-9815/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jan 15 21:51:01.510: INFO: Waiting for Pod statefulset-9815/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jan 15 21:51:11.520: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:51:11.520: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jan 15 21:51:11.520: INFO: Waiting for Pod statefulset-9815/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Jan 15 21:51:21.521: INFO: Waiting for StatefulSet statefulset-9815/ss2 to complete update
Jan 15 21:51:21.521: INFO: Waiting for Pod statefulset-9815/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Jan 15 21:51:31.522: INFO: Deleting all statefulset in ns statefulset-9815
Jan 15 21:51:31.526: INFO: Scaling statefulset ss2 to 0
Jan 15 21:52:11.547: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 21:52:11.551: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:52:11.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9815" for this suite.
Jan 15 21:52:17.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:52:17.734: INFO: namespace statefulset-9815 deletion completed in 6.155699162s

• [SLOW TEST:189.525 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:52:17.734: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3477
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 21:52:17.796: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 21:52:41.894: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.136:8080/dial?request=hostName&protocol=http&host=10.244.2.135&port=8080&tries=1'] Namespace:pod-network-test-3477 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:52:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:52:42.351: INFO: Waiting for endpoints: map[]
Jan 15 21:52:42.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.136:8080/dial?request=hostName&protocol=http&host=10.244.0.38&port=8080&tries=1'] Namespace:pod-network-test-3477 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:52:42.356: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:52:42.807: INFO: Waiting for endpoints: map[]
Jan 15 21:52:42.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.136:8080/dial?request=hostName&protocol=http&host=10.244.1.47&port=8080&tries=1'] Namespace:pod-network-test-3477 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 21:52:42.811: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 21:52:43.272: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:52:43.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3477" for this suite.
Jan 15 21:53:07.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:53:07.439: INFO: namespace pod-network-test-3477 deletion completed in 24.16160604s

• [SLOW TEST:49.705 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:53:07.440: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 21:53:07.497: INFO: Waiting up to 5m0s for pod "pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98" in namespace "emptydir-333" to be "success or failure"
Jan 15 21:53:07.500: INFO: Pod "pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.185113ms
Jan 15 21:53:09.504: INFO: Pod "pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006947279s
Jan 15 21:53:11.508: INFO: Pod "pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01178455s
STEP: Saw pod success
Jan 15 21:53:11.509: INFO: Pod "pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98" satisfied condition "success or failure"
Jan 15 21:53:11.511: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98 container test-container: <nil>
STEP: delete the pod
Jan 15 21:53:11.538: INFO: Waiting for pod pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98 to disappear
Jan 15 21:53:11.542: INFO: Pod pod-ea8ec33c-1d14-4753-bad1-243fdc1ffb98 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:53:11.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-333" for this suite.
Jan 15 21:53:17.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:53:17.715: INFO: namespace emptydir-333 deletion completed in 6.167637072s

• [SLOW TEST:10.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:53:17.715: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-1531/configmap-test-8eda1f57-0f89-4bc1-8565-960c26e1d7bc
STEP: Creating a pod to test consume configMaps
Jan 15 21:53:17.793: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa" in namespace "configmap-1531" to be "success or failure"
Jan 15 21:53:17.797: INFO: Pod "pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.540315ms
Jan 15 21:53:19.801: INFO: Pod "pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007439785s
Jan 15 21:53:21.805: INFO: Pod "pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011534756s
STEP: Saw pod success
Jan 15 21:53:21.805: INFO: Pod "pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa" satisfied condition "success or failure"
Jan 15 21:53:21.808: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa container env-test: <nil>
STEP: delete the pod
Jan 15 21:53:21.834: INFO: Waiting for pod pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa to disappear
Jan 15 21:53:21.839: INFO: Pod pod-configmaps-1ae92f1a-44fb-401f-b3fe-699f97f8b8aa no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:53:21.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1531" for this suite.
Jan 15 21:53:27.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:53:28.003: INFO: namespace configmap-1531 deletion completed in 6.15793254s

• [SLOW TEST:10.288 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:53:28.003: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ccf0fa78-3ccc-45ad-b72d-c5098a62d855
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ccf0fa78-3ccc-45ad-b72d-c5098a62d855
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:53:34.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9673" for this suite.
Jan 15 21:53:56.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:53:56.488: INFO: namespace projected-9673 deletion completed in 22.194041398s

• [SLOW TEST:28.485 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:53:56.489: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 15 21:53:56.572: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3271,SelfLink:/api/v1/namespaces/watch-3271/configmaps/e2e-watch-test-resource-version,UID:46cdcac6-ebea-402e-a569-8e04c7086420,ResourceVersion:11405,Generation:0,CreationTimestamp:2020-01-15 21:53:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 21:53:56.572: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3271,SelfLink:/api/v1/namespaces/watch-3271/configmaps/e2e-watch-test-resource-version,UID:46cdcac6-ebea-402e-a569-8e04c7086420,ResourceVersion:11406,Generation:0,CreationTimestamp:2020-01-15 21:53:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:53:56.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3271" for this suite.
Jan 15 21:54:02.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:54:02.732: INFO: namespace watch-3271 deletion completed in 6.154169654s

• [SLOW TEST:6.244 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:54:02.733: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62
Jan 15 21:54:02.805: INFO: Pod name my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62: Found 0 pods out of 1
Jan 15 21:54:07.809: INFO: Pod name my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62: Found 1 pods out of 1
Jan 15 21:54:07.809: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62" are running
Jan 15 21:54:07.812: INFO: Pod "my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62-9tss9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:54:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:54:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:54:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-01-15 21:54:02 +0000 UTC Reason: Message:}])
Jan 15 21:54:07.813: INFO: Trying to dial the pod
Jan 15 21:54:12.913: INFO: Controller my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62: Got expected result from replica 1 [my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62-9tss9]: "my-hostname-basic-b52ae866-1e3f-4949-b971-292e6f342f62-9tss9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:54:12.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-703" for this suite.
Jan 15 21:54:18.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:54:19.086: INFO: namespace replication-controller-703 deletion completed in 6.167540525s

• [SLOW TEST:16.353 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:54:19.086: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jan 15 21:54:49.684: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0115 21:54:49.684031      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:54:49.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3964" for this suite.
Jan 15 21:54:55.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:54:55.829: INFO: namespace gc-3964 deletion completed in 6.140335137s

• [SLOW TEST:36.743 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:54:55.830: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan 15 21:54:56.169: INFO: Pod name wrapped-volume-race-52935ef5-092d-4929-af9c-4e06dd8f4ff8: Found 0 pods out of 5
Jan 15 21:55:01.178: INFO: Pod name wrapped-volume-race-52935ef5-092d-4929-af9c-4e06dd8f4ff8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-52935ef5-092d-4929-af9c-4e06dd8f4ff8 in namespace emptydir-wrapper-4834, will wait for the garbage collector to delete the pods
Jan 15 21:55:19.268: INFO: Deleting ReplicationController wrapped-volume-race-52935ef5-092d-4929-af9c-4e06dd8f4ff8 took: 11.803051ms
Jan 15 21:55:19.568: INFO: Terminating ReplicationController wrapped-volume-race-52935ef5-092d-4929-af9c-4e06dd8f4ff8 pods took: 300.179188ms
STEP: Creating RC which spawns configmap-volume pods
Jan 15 21:56:04.892: INFO: Pod name wrapped-volume-race-315ebfba-be79-4c7b-8bf0-331bb34186c5: Found 0 pods out of 5
Jan 15 21:56:09.898: INFO: Pod name wrapped-volume-race-315ebfba-be79-4c7b-8bf0-331bb34186c5: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-315ebfba-be79-4c7b-8bf0-331bb34186c5 in namespace emptydir-wrapper-4834, will wait for the garbage collector to delete the pods
Jan 15 21:56:21.985: INFO: Deleting ReplicationController wrapped-volume-race-315ebfba-be79-4c7b-8bf0-331bb34186c5 took: 12.624155ms
Jan 15 21:56:22.286: INFO: Terminating ReplicationController wrapped-volume-race-315ebfba-be79-4c7b-8bf0-331bb34186c5 pods took: 300.254691ms
STEP: Creating RC which spawns configmap-volume pods
Jan 15 21:57:05.512: INFO: Pod name wrapped-volume-race-feb7a2b8-4667-4646-b01e-9bff26f1370d: Found 0 pods out of 5
Jan 15 21:57:10.522: INFO: Pod name wrapped-volume-race-feb7a2b8-4667-4646-b01e-9bff26f1370d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-feb7a2b8-4667-4646-b01e-9bff26f1370d in namespace emptydir-wrapper-4834, will wait for the garbage collector to delete the pods
Jan 15 21:57:22.617: INFO: Deleting ReplicationController wrapped-volume-race-feb7a2b8-4667-4646-b01e-9bff26f1370d took: 14.060061ms
Jan 15 21:57:22.917: INFO: Terminating ReplicationController wrapped-volume-race-feb7a2b8-4667-4646-b01e-9bff26f1370d pods took: 300.191792ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:58:06.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4834" for this suite.
Jan 15 21:58:14.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:58:14.236: INFO: namespace emptydir-wrapper-4834 deletion completed in 8.151227028s

• [SLOW TEST:198.406 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:58:14.236: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6537
I0115 21:58:14.295164      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6537, replica count: 1
I0115 21:58:15.345925      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 21:58:16.346186      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 21:58:17.346389      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 21:58:17.457: INFO: Created: latency-svc-nk6kb
Jan 15 21:58:17.463: INFO: Got endpoints: latency-svc-nk6kb [17.141274ms]
Jan 15 21:58:17.474: INFO: Created: latency-svc-6944v
Jan 15 21:58:17.486: INFO: Got endpoints: latency-svc-6944v [23.0091ms]
Jan 15 21:58:17.489: INFO: Created: latency-svc-fcd2b
Jan 15 21:58:17.494: INFO: Got endpoints: latency-svc-fcd2b [30.22993ms]
Jan 15 21:58:17.498: INFO: Created: latency-svc-p2p2h
Jan 15 21:58:17.503: INFO: Got endpoints: latency-svc-p2p2h [39.088269ms]
Jan 15 21:58:17.505: INFO: Created: latency-svc-t6wsd
Jan 15 21:58:17.510: INFO: Got endpoints: latency-svc-t6wsd [45.482396ms]
Jan 15 21:58:17.512: INFO: Created: latency-svc-7z9q8
Jan 15 21:58:17.517: INFO: Created: latency-svc-vcqxf
Jan 15 21:58:17.526: INFO: Got endpoints: latency-svc-vcqxf [62.366869ms]
Jan 15 21:58:17.527: INFO: Got endpoints: latency-svc-7z9q8 [62.902271ms]
Jan 15 21:58:17.527: INFO: Created: latency-svc-8l8sf
Jan 15 21:58:17.531: INFO: Created: latency-svc-kv7k5
Jan 15 21:58:17.533: INFO: Got endpoints: latency-svc-8l8sf [68.805196ms]
Jan 15 21:58:17.536: INFO: Got endpoints: latency-svc-kv7k5 [71.221607ms]
Jan 15 21:58:17.536: INFO: Created: latency-svc-2mj7c
Jan 15 21:58:17.542: INFO: Got endpoints: latency-svc-2mj7c [77.416834ms]
Jan 15 21:58:17.543: INFO: Created: latency-svc-zrtmt
Jan 15 21:58:17.548: INFO: Got endpoints: latency-svc-zrtmt [83.59126ms]
Jan 15 21:58:17.550: INFO: Created: latency-svc-ddfz8
Jan 15 21:58:17.555: INFO: Created: latency-svc-2lbsb
Jan 15 21:58:17.560: INFO: Got endpoints: latency-svc-ddfz8 [95.275111ms]
Jan 15 21:58:17.561: INFO: Got endpoints: latency-svc-2lbsb [96.958918ms]
Jan 15 21:58:17.564: INFO: Created: latency-svc-m6j8m
Jan 15 21:58:17.567: INFO: Got endpoints: latency-svc-m6j8m [101.359737ms]
Jan 15 21:58:17.569: INFO: Created: latency-svc-jssqm
Jan 15 21:58:17.573: INFO: Got endpoints: latency-svc-jssqm [107.825565ms]
Jan 15 21:58:17.574: INFO: Created: latency-svc-w7ztj
Jan 15 21:58:17.577: INFO: Got endpoints: latency-svc-w7ztj [112.283784ms]
Jan 15 21:58:17.579: INFO: Created: latency-svc-mnmzg
Jan 15 21:58:17.584: INFO: Got endpoints: latency-svc-mnmzg [97.554221ms]
Jan 15 21:58:17.587: INFO: Created: latency-svc-p56f9
Jan 15 21:58:17.594: INFO: Got endpoints: latency-svc-p56f9 [99.473929ms]
Jan 15 21:58:17.598: INFO: Created: latency-svc-khth4
Jan 15 21:58:17.607: INFO: Got endpoints: latency-svc-khth4 [103.845147ms]
Jan 15 21:58:17.607: INFO: Created: latency-svc-mv4ts
Jan 15 21:58:17.614: INFO: Created: latency-svc-wg4c8
Jan 15 21:58:17.614: INFO: Got endpoints: latency-svc-mv4ts [104.28535ms]
Jan 15 21:58:17.618: INFO: Got endpoints: latency-svc-wg4c8 [91.738396ms]
Jan 15 21:58:17.619: INFO: Created: latency-svc-w776j
Jan 15 21:58:17.624: INFO: Got endpoints: latency-svc-w776j [97.24402ms]
Jan 15 21:58:17.626: INFO: Created: latency-svc-nq4sp
Jan 15 21:58:17.630: INFO: Got endpoints: latency-svc-nq4sp [96.654517ms]
Jan 15 21:58:17.632: INFO: Created: latency-svc-vx7z6
Jan 15 21:58:17.639: INFO: Got endpoints: latency-svc-vx7z6 [103.410546ms]
Jan 15 21:58:17.639: INFO: Created: latency-svc-7rnpg
Jan 15 21:58:17.642: INFO: Got endpoints: latency-svc-7rnpg [100.264932ms]
Jan 15 21:58:17.644: INFO: Created: latency-svc-jxxf2
Jan 15 21:58:17.649: INFO: Got endpoints: latency-svc-jxxf2 [99.88463ms]
Jan 15 21:58:17.651: INFO: Created: latency-svc-rmlzs
Jan 15 21:58:17.655: INFO: Created: latency-svc-m2pzs
Jan 15 21:58:17.657: INFO: Got endpoints: latency-svc-rmlzs [17.615176ms]
Jan 15 21:58:17.659: INFO: Got endpoints: latency-svc-m2pzs [98.177723ms]
Jan 15 21:58:17.659: INFO: Created: latency-svc-xrmgs
Jan 15 21:58:17.664: INFO: Got endpoints: latency-svc-xrmgs [101.746639ms]
Jan 15 21:58:17.665: INFO: Created: latency-svc-zvxph
Jan 15 21:58:17.675: INFO: Created: latency-svc-snpl7
Jan 15 21:58:17.675: INFO: Got endpoints: latency-svc-zvxph [108.649868ms]
Jan 15 21:58:17.681: INFO: Got endpoints: latency-svc-snpl7 [107.461563ms]
Jan 15 21:58:17.682: INFO: Created: latency-svc-25w46
Jan 15 21:58:17.689: INFO: Got endpoints: latency-svc-25w46 [111.34948ms]
Jan 15 21:58:17.690: INFO: Created: latency-svc-44vl7
Jan 15 21:58:17.694: INFO: Got endpoints: latency-svc-44vl7 [109.545872ms]
Jan 15 21:58:17.697: INFO: Created: latency-svc-692jr
Jan 15 21:58:17.700: INFO: Got endpoints: latency-svc-692jr [106.190058ms]
Jan 15 21:58:17.704: INFO: Created: latency-svc-bvh4r
Jan 15 21:58:17.710: INFO: Created: latency-svc-7fq75
Jan 15 21:58:17.719: INFO: Got endpoints: latency-svc-bvh4r [112.088083ms]
Jan 15 21:58:17.720: INFO: Created: latency-svc-9n8r8
Jan 15 21:58:17.729: INFO: Created: latency-svc-wsqgr
Jan 15 21:58:17.738: INFO: Created: latency-svc-gn6dh
Jan 15 21:58:17.745: INFO: Created: latency-svc-l2jdf
Jan 15 21:58:17.751: INFO: Created: latency-svc-mrhq9
Jan 15 21:58:17.766: INFO: Got endpoints: latency-svc-7fq75 [149.942747ms]
Jan 15 21:58:17.766: INFO: Created: latency-svc-clnkc
Jan 15 21:58:17.766: INFO: Created: latency-svc-kqwkz
Jan 15 21:58:17.770: INFO: Created: latency-svc-6tvt6
Jan 15 21:58:17.774: INFO: Created: latency-svc-9tl79
Jan 15 21:58:17.780: INFO: Created: latency-svc-fzzll
Jan 15 21:58:17.785: INFO: Created: latency-svc-r8l7n
Jan 15 21:58:17.791: INFO: Created: latency-svc-ktvwc
Jan 15 21:58:17.796: INFO: Created: latency-svc-s9r4d
Jan 15 21:58:17.810: INFO: Created: latency-svc-c26jm
Jan 15 21:58:17.812: INFO: Created: latency-svc-hjjr4
Jan 15 21:58:17.813: INFO: Got endpoints: latency-svc-9n8r8 [194.203438ms]
Jan 15 21:58:17.841: INFO: Created: latency-svc-z75fv
Jan 15 21:58:17.863: INFO: Got endpoints: latency-svc-wsqgr [238.99663ms]
Jan 15 21:58:17.874: INFO: Created: latency-svc-r8tqp
Jan 15 21:58:17.914: INFO: Got endpoints: latency-svc-gn6dh [283.940924ms]
Jan 15 21:58:17.927: INFO: Created: latency-svc-w2pkp
Jan 15 21:58:17.963: INFO: Got endpoints: latency-svc-l2jdf [320.411081ms]
Jan 15 21:58:17.973: INFO: Created: latency-svc-l9dgq
Jan 15 21:58:18.014: INFO: Got endpoints: latency-svc-mrhq9 [364.967573ms]
Jan 15 21:58:18.023: INFO: Created: latency-svc-2xrrv
Jan 15 21:58:18.065: INFO: Got endpoints: latency-svc-clnkc [408.119159ms]
Jan 15 21:58:18.076: INFO: Created: latency-svc-hdn4b
Jan 15 21:58:18.114: INFO: Got endpoints: latency-svc-kqwkz [455.481863ms]
Jan 15 21:58:18.124: INFO: Created: latency-svc-v9zhb
Jan 15 21:58:18.164: INFO: Got endpoints: latency-svc-6tvt6 [500.972859ms]
Jan 15 21:58:18.178: INFO: Created: latency-svc-pnlfx
Jan 15 21:58:18.213: INFO: Got endpoints: latency-svc-9tl79 [537.436616ms]
Jan 15 21:58:18.223: INFO: Created: latency-svc-l87v7
Jan 15 21:58:18.265: INFO: Got endpoints: latency-svc-fzzll [583.746516ms]
Jan 15 21:58:18.275: INFO: Created: latency-svc-84s86
Jan 15 21:58:18.318: INFO: Got endpoints: latency-svc-r8l7n [629.248912ms]
Jan 15 21:58:18.328: INFO: Created: latency-svc-hlpzs
Jan 15 21:58:18.365: INFO: Got endpoints: latency-svc-ktvwc [670.912192ms]
Jan 15 21:58:18.374: INFO: Created: latency-svc-25z6t
Jan 15 21:58:18.417: INFO: Got endpoints: latency-svc-s9r4d [716.550689ms]
Jan 15 21:58:18.428: INFO: Created: latency-svc-jhd5z
Jan 15 21:58:18.463: INFO: Got endpoints: latency-svc-c26jm [744.166607ms]
Jan 15 21:58:18.475: INFO: Created: latency-svc-ftn9x
Jan 15 21:58:18.515: INFO: Got endpoints: latency-svc-hjjr4 [749.43463ms]
Jan 15 21:58:18.527: INFO: Created: latency-svc-vgvhc
Jan 15 21:58:18.568: INFO: Got endpoints: latency-svc-z75fv [755.036055ms]
Jan 15 21:58:18.582: INFO: Created: latency-svc-b4xf6
Jan 15 21:58:18.613: INFO: Got endpoints: latency-svc-r8tqp [749.940132ms]
Jan 15 21:58:18.626: INFO: Created: latency-svc-wwgmt
Jan 15 21:58:18.664: INFO: Got endpoints: latency-svc-w2pkp [749.600231ms]
Jan 15 21:58:18.675: INFO: Created: latency-svc-wfxhd
Jan 15 21:58:18.714: INFO: Got endpoints: latency-svc-l9dgq [750.656936ms]
Jan 15 21:58:18.725: INFO: Created: latency-svc-s8svp
Jan 15 21:58:18.763: INFO: Got endpoints: latency-svc-2xrrv [749.139329ms]
Jan 15 21:58:18.777: INFO: Created: latency-svc-lrzcf
Jan 15 21:58:18.814: INFO: Got endpoints: latency-svc-hdn4b [748.912228ms]
Jan 15 21:58:18.825: INFO: Created: latency-svc-nt2k6
Jan 15 21:58:18.863: INFO: Got endpoints: latency-svc-v9zhb [748.764628ms]
Jan 15 21:58:18.874: INFO: Created: latency-svc-xmdr2
Jan 15 21:58:18.913: INFO: Got endpoints: latency-svc-pnlfx [748.282525ms]
Jan 15 21:58:18.922: INFO: Created: latency-svc-x6lzh
Jan 15 21:58:18.965: INFO: Got endpoints: latency-svc-l87v7 [752.540743ms]
Jan 15 21:58:18.977: INFO: Created: latency-svc-ddc8g
Jan 15 21:58:19.013: INFO: Got endpoints: latency-svc-84s86 [747.461022ms]
Jan 15 21:58:19.022: INFO: Created: latency-svc-6zssz
Jan 15 21:58:19.063: INFO: Got endpoints: latency-svc-hlpzs [744.60711ms]
Jan 15 21:58:19.074: INFO: Created: latency-svc-669nv
Jan 15 21:58:19.114: INFO: Got endpoints: latency-svc-25z6t [749.46953ms]
Jan 15 21:58:19.124: INFO: Created: latency-svc-qxjlt
Jan 15 21:58:19.168: INFO: Got endpoints: latency-svc-jhd5z [750.486535ms]
Jan 15 21:58:19.181: INFO: Created: latency-svc-66wjb
Jan 15 21:58:19.215: INFO: Got endpoints: latency-svc-ftn9x [750.265034ms]
Jan 15 21:58:19.225: INFO: Created: latency-svc-t9pqq
Jan 15 21:58:19.264: INFO: Got endpoints: latency-svc-vgvhc [748.350225ms]
Jan 15 21:58:19.276: INFO: Created: latency-svc-xj8fh
Jan 15 21:58:19.315: INFO: Got endpoints: latency-svc-b4xf6 [747.643822ms]
Jan 15 21:58:19.330: INFO: Created: latency-svc-rr5rg
Jan 15 21:58:19.364: INFO: Got endpoints: latency-svc-wwgmt [750.305334ms]
Jan 15 21:58:19.377: INFO: Created: latency-svc-mr95s
Jan 15 21:58:19.487: INFO: Got endpoints: latency-svc-wfxhd [823.075347ms]
Jan 15 21:58:19.542: INFO: Got endpoints: latency-svc-s8svp [828.891573ms]
Jan 15 21:58:19.547: INFO: Got endpoints: latency-svc-lrzcf [783.497177ms]
Jan 15 21:58:19.643: INFO: Got endpoints: latency-svc-xmdr2 [779.874261ms]
Jan 15 21:58:19.644: INFO: Got endpoints: latency-svc-nt2k6 [829.628476ms]
Jan 15 21:58:19.664: INFO: Created: latency-svc-j97r6
Jan 15 21:58:19.668: INFO: Got endpoints: latency-svc-x6lzh [755.108855ms]
Jan 15 21:58:19.689: INFO: Created: latency-svc-x25tv
Jan 15 21:58:19.695: INFO: Created: latency-svc-t88p9
Jan 15 21:58:19.702: INFO: Created: latency-svc-q5phd
Jan 15 21:58:19.713: INFO: Got endpoints: latency-svc-ddc8g [745.152712ms]
Jan 15 21:58:19.714: INFO: Created: latency-svc-qn955
Jan 15 21:58:19.719: INFO: Created: latency-svc-wfctb
Jan 15 21:58:19.729: INFO: Created: latency-svc-tbl2l
Jan 15 21:58:19.763: INFO: Got endpoints: latency-svc-6zssz [750.450835ms]
Jan 15 21:58:19.773: INFO: Created: latency-svc-6llwp
Jan 15 21:58:19.815: INFO: Got endpoints: latency-svc-669nv [750.386634ms]
Jan 15 21:58:19.825: INFO: Created: latency-svc-frgqw
Jan 15 21:58:19.862: INFO: Got endpoints: latency-svc-qxjlt [747.779923ms]
Jan 15 21:58:19.873: INFO: Created: latency-svc-fhfbc
Jan 15 21:58:19.913: INFO: Got endpoints: latency-svc-66wjb [744.517409ms]
Jan 15 21:58:19.924: INFO: Created: latency-svc-74gnl
Jan 15 21:58:19.963: INFO: Got endpoints: latency-svc-t9pqq [748.665927ms]
Jan 15 21:58:19.974: INFO: Created: latency-svc-rlb9g
Jan 15 21:58:20.016: INFO: Got endpoints: latency-svc-xj8fh [752.651744ms]
Jan 15 21:58:20.026: INFO: Created: latency-svc-jc5xm
Jan 15 21:58:20.063: INFO: Got endpoints: latency-svc-rr5rg [747.504622ms]
Jan 15 21:58:20.081: INFO: Created: latency-svc-rwjsj
Jan 15 21:58:20.113: INFO: Got endpoints: latency-svc-mr95s [749.001029ms]
Jan 15 21:58:20.124: INFO: Created: latency-svc-bf9kg
Jan 15 21:58:20.164: INFO: Got endpoints: latency-svc-j97r6 [676.348315ms]
Jan 15 21:58:20.175: INFO: Created: latency-svc-b5pqv
Jan 15 21:58:20.214: INFO: Got endpoints: latency-svc-x25tv [671.825996ms]
Jan 15 21:58:20.226: INFO: Created: latency-svc-8bx74
Jan 15 21:58:20.264: INFO: Got endpoints: latency-svc-t88p9 [716.593689ms]
Jan 15 21:58:20.279: INFO: Created: latency-svc-wzfb8
Jan 15 21:58:20.314: INFO: Got endpoints: latency-svc-q5phd [670.841991ms]
Jan 15 21:58:20.326: INFO: Created: latency-svc-sqvz8
Jan 15 21:58:20.365: INFO: Got endpoints: latency-svc-qn955 [721.52671ms]
Jan 15 21:58:20.376: INFO: Created: latency-svc-4krf7
Jan 15 21:58:20.416: INFO: Got endpoints: latency-svc-wfctb [747.764023ms]
Jan 15 21:58:20.427: INFO: Created: latency-svc-fpht9
Jan 15 21:58:20.472: INFO: Got endpoints: latency-svc-tbl2l [758.793871ms]
Jan 15 21:58:20.543: INFO: Got endpoints: latency-svc-6llwp [779.125159ms]
Jan 15 21:58:20.549: INFO: Created: latency-svc-gfglr
Jan 15 21:58:20.566: INFO: Created: latency-svc-kr7j7
Jan 15 21:58:20.566: INFO: Got endpoints: latency-svc-frgqw [751.200838ms]
Jan 15 21:58:20.578: INFO: Created: latency-svc-s9dkf
Jan 15 21:58:20.621: INFO: Got endpoints: latency-svc-fhfbc [757.694566ms]
Jan 15 21:58:20.634: INFO: Created: latency-svc-mv8xc
Jan 15 21:58:20.665: INFO: Got endpoints: latency-svc-74gnl [751.549739ms]
Jan 15 21:58:20.677: INFO: Created: latency-svc-n4wjj
Jan 15 21:58:20.714: INFO: Got endpoints: latency-svc-rlb9g [750.443835ms]
Jan 15 21:58:20.734: INFO: Created: latency-svc-wwbmv
Jan 15 21:58:20.788: INFO: Got endpoints: latency-svc-jc5xm [771.240624ms]
Jan 15 21:58:20.800: INFO: Created: latency-svc-9pq7p
Jan 15 21:58:20.814: INFO: Got endpoints: latency-svc-rwjsj [750.538135ms]
Jan 15 21:58:20.826: INFO: Created: latency-svc-kml6x
Jan 15 21:58:20.864: INFO: Got endpoints: latency-svc-bf9kg [751.469739ms]
Jan 15 21:58:20.874: INFO: Created: latency-svc-rqjmw
Jan 15 21:58:20.914: INFO: Got endpoints: latency-svc-b5pqv [749.478931ms]
Jan 15 21:58:20.925: INFO: Created: latency-svc-v75tl
Jan 15 21:58:20.966: INFO: Got endpoints: latency-svc-8bx74 [751.101038ms]
Jan 15 21:58:20.976: INFO: Created: latency-svc-dx5ck
Jan 15 21:58:21.014: INFO: Got endpoints: latency-svc-wzfb8 [749.506131ms]
Jan 15 21:58:21.023: INFO: Created: latency-svc-hcx4p
Jan 15 21:58:21.065: INFO: Got endpoints: latency-svc-sqvz8 [750.900637ms]
Jan 15 21:58:21.076: INFO: Created: latency-svc-974rv
Jan 15 21:58:21.114: INFO: Got endpoints: latency-svc-4krf7 [749.010528ms]
Jan 15 21:58:21.126: INFO: Created: latency-svc-256xk
Jan 15 21:58:21.165: INFO: Got endpoints: latency-svc-fpht9 [748.651227ms]
Jan 15 21:58:21.185: INFO: Created: latency-svc-j79ll
Jan 15 21:58:21.213: INFO: Got endpoints: latency-svc-gfglr [740.759693ms]
Jan 15 21:58:21.224: INFO: Created: latency-svc-wlb7c
Jan 15 21:58:21.264: INFO: Got endpoints: latency-svc-kr7j7 [721.095408ms]
Jan 15 21:58:21.277: INFO: Created: latency-svc-4bbbg
Jan 15 21:58:21.314: INFO: Got endpoints: latency-svc-s9dkf [747.293421ms]
Jan 15 21:58:21.324: INFO: Created: latency-svc-6jjhd
Jan 15 21:58:21.363: INFO: Got endpoints: latency-svc-mv8xc [742.3832ms]
Jan 15 21:58:21.372: INFO: Created: latency-svc-4n5c9
Jan 15 21:58:21.413: INFO: Got endpoints: latency-svc-n4wjj [748.572926ms]
Jan 15 21:58:21.425: INFO: Created: latency-svc-gm4l9
Jan 15 21:58:21.467: INFO: Got endpoints: latency-svc-wwbmv [752.710244ms]
Jan 15 21:58:21.477: INFO: Created: latency-svc-54cgk
Jan 15 21:58:21.517: INFO: Got endpoints: latency-svc-9pq7p [728.019538ms]
Jan 15 21:58:21.528: INFO: Created: latency-svc-lcdxd
Jan 15 21:58:21.567: INFO: Got endpoints: latency-svc-kml6x [753.102747ms]
Jan 15 21:58:21.583: INFO: Created: latency-svc-684q8
Jan 15 21:58:21.614: INFO: Got endpoints: latency-svc-rqjmw [749.121929ms]
Jan 15 21:58:21.623: INFO: Created: latency-svc-7m572
Jan 15 21:58:21.668: INFO: Got endpoints: latency-svc-v75tl [753.280147ms]
Jan 15 21:58:21.678: INFO: Created: latency-svc-lm4qx
Jan 15 21:58:21.715: INFO: Got endpoints: latency-svc-dx5ck [749.36593ms]
Jan 15 21:58:21.729: INFO: Created: latency-svc-zxqkw
Jan 15 21:58:21.766: INFO: Got endpoints: latency-svc-hcx4p [752.612645ms]
Jan 15 21:58:21.783: INFO: Created: latency-svc-s2gx6
Jan 15 21:58:21.813: INFO: Got endpoints: latency-svc-974rv [747.622723ms]
Jan 15 21:58:21.823: INFO: Created: latency-svc-6b68r
Jan 15 21:58:21.864: INFO: Got endpoints: latency-svc-256xk [749.693631ms]
Jan 15 21:58:21.882: INFO: Created: latency-svc-4w9hv
Jan 15 21:58:21.913: INFO: Got endpoints: latency-svc-j79ll [748.134725ms]
Jan 15 21:58:21.924: INFO: Created: latency-svc-5b9zg
Jan 15 21:58:21.975: INFO: Got endpoints: latency-svc-wlb7c [761.494282ms]
Jan 15 21:58:21.985: INFO: Created: latency-svc-mftzw
Jan 15 21:58:22.012: INFO: Got endpoints: latency-svc-4bbbg [748.517927ms]
Jan 15 21:58:22.025: INFO: Created: latency-svc-4dszv
Jan 15 21:58:22.071: INFO: Got endpoints: latency-svc-6jjhd [756.982263ms]
Jan 15 21:58:22.080: INFO: Created: latency-svc-qkqjf
Jan 15 21:58:22.114: INFO: Got endpoints: latency-svc-4n5c9 [750.893737ms]
Jan 15 21:58:22.124: INFO: Created: latency-svc-dj7br
Jan 15 21:58:22.164: INFO: Got endpoints: latency-svc-gm4l9 [750.476135ms]
Jan 15 21:58:22.174: INFO: Created: latency-svc-9vxn4
Jan 15 21:58:22.213: INFO: Got endpoints: latency-svc-54cgk [746.679319ms]
Jan 15 21:58:22.225: INFO: Created: latency-svc-lr25r
Jan 15 21:58:22.268: INFO: Got endpoints: latency-svc-lcdxd [750.508235ms]
Jan 15 21:58:22.287: INFO: Created: latency-svc-kpvlv
Jan 15 21:58:22.315: INFO: Got endpoints: latency-svc-684q8 [748.435126ms]
Jan 15 21:58:22.327: INFO: Created: latency-svc-nts4v
Jan 15 21:58:22.368: INFO: Got endpoints: latency-svc-7m572 [754.616253ms]
Jan 15 21:58:22.379: INFO: Created: latency-svc-qsqlz
Jan 15 21:58:22.413: INFO: Got endpoints: latency-svc-lm4qx [745.390213ms]
Jan 15 21:58:22.424: INFO: Created: latency-svc-2cz85
Jan 15 21:58:22.464: INFO: Got endpoints: latency-svc-zxqkw [748.594527ms]
Jan 15 21:58:22.476: INFO: Created: latency-svc-vt44l
Jan 15 21:58:22.513: INFO: Got endpoints: latency-svc-s2gx6 [747.07432ms]
Jan 15 21:58:22.526: INFO: Created: latency-svc-pb7pk
Jan 15 21:58:22.563: INFO: Got endpoints: latency-svc-6b68r [749.32163ms]
Jan 15 21:58:22.572: INFO: Created: latency-svc-h5fts
Jan 15 21:58:22.614: INFO: Got endpoints: latency-svc-4w9hv [749.684232ms]
Jan 15 21:58:22.625: INFO: Created: latency-svc-lfx46
Jan 15 21:58:22.663: INFO: Got endpoints: latency-svc-5b9zg [750.036833ms]
Jan 15 21:58:22.673: INFO: Created: latency-svc-447tz
Jan 15 21:58:22.718: INFO: Got endpoints: latency-svc-mftzw [743.065803ms]
Jan 15 21:58:22.729: INFO: Created: latency-svc-rpv4f
Jan 15 21:58:22.764: INFO: Got endpoints: latency-svc-4dszv [751.574239ms]
Jan 15 21:58:22.773: INFO: Created: latency-svc-zjdb4
Jan 15 21:58:22.813: INFO: Got endpoints: latency-svc-qkqjf [742.3055ms]
Jan 15 21:58:22.823: INFO: Created: latency-svc-hnfsk
Jan 15 21:58:22.863: INFO: Got endpoints: latency-svc-dj7br [749.089729ms]
Jan 15 21:58:22.871: INFO: Created: latency-svc-qfvgn
Jan 15 21:58:22.914: INFO: Got endpoints: latency-svc-9vxn4 [749.555231ms]
Jan 15 21:58:22.923: INFO: Created: latency-svc-vh7tn
Jan 15 21:58:22.963: INFO: Got endpoints: latency-svc-lr25r [749.685031ms]
Jan 15 21:58:22.972: INFO: Created: latency-svc-5xhkc
Jan 15 21:58:23.015: INFO: Got endpoints: latency-svc-kpvlv [747.695623ms]
Jan 15 21:58:23.025: INFO: Created: latency-svc-bqp6g
Jan 15 21:58:23.064: INFO: Got endpoints: latency-svc-nts4v [748.723228ms]
Jan 15 21:58:23.074: INFO: Created: latency-svc-98s7g
Jan 15 21:58:23.113: INFO: Got endpoints: latency-svc-qsqlz [744.220408ms]
Jan 15 21:58:23.121: INFO: Created: latency-svc-gq8tz
Jan 15 21:58:23.163: INFO: Got endpoints: latency-svc-2cz85 [749.879132ms]
Jan 15 21:58:23.173: INFO: Created: latency-svc-q2sm8
Jan 15 21:58:23.213: INFO: Got endpoints: latency-svc-vt44l [748.295325ms]
Jan 15 21:58:23.223: INFO: Created: latency-svc-lkqzh
Jan 15 21:58:23.263: INFO: Got endpoints: latency-svc-pb7pk [748.927629ms]
Jan 15 21:58:23.272: INFO: Created: latency-svc-4fd48
Jan 15 21:58:23.313: INFO: Got endpoints: latency-svc-h5fts [750.057833ms]
Jan 15 21:58:23.323: INFO: Created: latency-svc-6fph5
Jan 15 21:58:23.367: INFO: Got endpoints: latency-svc-lfx46 [752.756645ms]
Jan 15 21:58:23.377: INFO: Created: latency-svc-lqp5k
Jan 15 21:58:23.414: INFO: Got endpoints: latency-svc-447tz [750.786536ms]
Jan 15 21:58:23.423: INFO: Created: latency-svc-6vskd
Jan 15 21:58:23.463: INFO: Got endpoints: latency-svc-rpv4f [745.101612ms]
Jan 15 21:58:23.473: INFO: Created: latency-svc-9sbg7
Jan 15 21:58:23.513: INFO: Got endpoints: latency-svc-zjdb4 [749.29943ms]
Jan 15 21:58:23.523: INFO: Created: latency-svc-82rgc
Jan 15 21:58:23.564: INFO: Got endpoints: latency-svc-hnfsk [751.018737ms]
Jan 15 21:58:23.576: INFO: Created: latency-svc-b6pvv
Jan 15 21:58:23.615: INFO: Got endpoints: latency-svc-qfvgn [752.174442ms]
Jan 15 21:58:23.624: INFO: Created: latency-svc-l898b
Jan 15 21:58:23.663: INFO: Got endpoints: latency-svc-vh7tn [748.759228ms]
Jan 15 21:58:23.672: INFO: Created: latency-svc-62p54
Jan 15 21:58:23.714: INFO: Got endpoints: latency-svc-5xhkc [750.350935ms]
Jan 15 21:58:23.723: INFO: Created: latency-svc-hw9q2
Jan 15 21:58:23.763: INFO: Got endpoints: latency-svc-bqp6g [747.760524ms]
Jan 15 21:58:23.773: INFO: Created: latency-svc-468lj
Jan 15 21:58:23.813: INFO: Got endpoints: latency-svc-98s7g [748.928528ms]
Jan 15 21:58:23.823: INFO: Created: latency-svc-m2wl6
Jan 15 21:58:23.863: INFO: Got endpoints: latency-svc-gq8tz [750.668936ms]
Jan 15 21:58:23.872: INFO: Created: latency-svc-jvm2k
Jan 15 21:58:23.913: INFO: Got endpoints: latency-svc-q2sm8 [749.832033ms]
Jan 15 21:58:23.923: INFO: Created: latency-svc-7rkl5
Jan 15 21:58:23.963: INFO: Got endpoints: latency-svc-lkqzh [749.22063ms]
Jan 15 21:58:23.972: INFO: Created: latency-svc-xwjkj
Jan 15 21:58:24.021: INFO: Got endpoints: latency-svc-4fd48 [757.627566ms]
Jan 15 21:58:24.030: INFO: Created: latency-svc-pvtfb
Jan 15 21:58:24.068: INFO: Got endpoints: latency-svc-6fph5 [755.270156ms]
Jan 15 21:58:24.078: INFO: Created: latency-svc-bkzhf
Jan 15 21:58:24.113: INFO: Got endpoints: latency-svc-lqp5k [745.499413ms]
Jan 15 21:58:24.122: INFO: Created: latency-svc-pdq49
Jan 15 21:58:24.164: INFO: Got endpoints: latency-svc-6vskd [750.343335ms]
Jan 15 21:58:24.174: INFO: Created: latency-svc-k4cp7
Jan 15 21:58:24.215: INFO: Got endpoints: latency-svc-9sbg7 [751.675841ms]
Jan 15 21:58:24.224: INFO: Created: latency-svc-sm6tf
Jan 15 21:58:24.263: INFO: Got endpoints: latency-svc-82rgc [749.33963ms]
Jan 15 21:58:24.273: INFO: Created: latency-svc-8pjbw
Jan 15 21:58:24.313: INFO: Got endpoints: latency-svc-b6pvv [748.177025ms]
Jan 15 21:58:24.322: INFO: Created: latency-svc-qw9bn
Jan 15 21:58:24.364: INFO: Got endpoints: latency-svc-l898b [748.214926ms]
Jan 15 21:58:24.374: INFO: Created: latency-svc-tz4cm
Jan 15 21:58:24.414: INFO: Got endpoints: latency-svc-62p54 [750.241934ms]
Jan 15 21:58:24.422: INFO: Created: latency-svc-xc67p
Jan 15 21:58:24.466: INFO: Got endpoints: latency-svc-hw9q2 [752.293843ms]
Jan 15 21:58:24.475: INFO: Created: latency-svc-nqxrm
Jan 15 21:58:24.514: INFO: Got endpoints: latency-svc-468lj [750.287734ms]
Jan 15 21:58:24.523: INFO: Created: latency-svc-rt75g
Jan 15 21:58:24.565: INFO: Got endpoints: latency-svc-m2wl6 [751.398739ms]
Jan 15 21:58:24.574: INFO: Created: latency-svc-8tdtx
Jan 15 21:58:24.613: INFO: Got endpoints: latency-svc-jvm2k [749.696432ms]
Jan 15 21:58:24.622: INFO: Created: latency-svc-hfhb8
Jan 15 21:58:24.663: INFO: Got endpoints: latency-svc-7rkl5 [750.281934ms]
Jan 15 21:58:24.672: INFO: Created: latency-svc-nldz8
Jan 15 21:58:24.713: INFO: Got endpoints: latency-svc-xwjkj [750.219734ms]
Jan 15 21:58:24.724: INFO: Created: latency-svc-jzl9t
Jan 15 21:58:24.764: INFO: Got endpoints: latency-svc-pvtfb [742.5245ms]
Jan 15 21:58:24.775: INFO: Created: latency-svc-b7ml6
Jan 15 21:58:24.817: INFO: Got endpoints: latency-svc-bkzhf [749.101629ms]
Jan 15 21:58:24.836: INFO: Created: latency-svc-qtbzr
Jan 15 21:58:24.865: INFO: Got endpoints: latency-svc-pdq49 [752.528244ms]
Jan 15 21:58:24.877: INFO: Created: latency-svc-9qpc7
Jan 15 21:58:24.913: INFO: Got endpoints: latency-svc-k4cp7 [749.087629ms]
Jan 15 21:58:24.923: INFO: Created: latency-svc-l25xq
Jan 15 21:58:24.964: INFO: Got endpoints: latency-svc-sm6tf [749.559631ms]
Jan 15 21:58:24.977: INFO: Created: latency-svc-hq8pp
Jan 15 21:58:25.015: INFO: Got endpoints: latency-svc-8pjbw [751.750641ms]
Jan 15 21:58:25.025: INFO: Created: latency-svc-5n7dt
Jan 15 21:58:25.063: INFO: Got endpoints: latency-svc-qw9bn [750.523235ms]
Jan 15 21:58:25.079: INFO: Created: latency-svc-zn4t4
Jan 15 21:58:25.113: INFO: Got endpoints: latency-svc-tz4cm [749.597331ms]
Jan 15 21:58:25.123: INFO: Created: latency-svc-62mtx
Jan 15 21:58:25.167: INFO: Got endpoints: latency-svc-xc67p [752.828346ms]
Jan 15 21:58:25.200: INFO: Created: latency-svc-r27rd
Jan 15 21:58:25.214: INFO: Got endpoints: latency-svc-nqxrm [746.646619ms]
Jan 15 21:58:25.232: INFO: Created: latency-svc-r97m2
Jan 15 21:58:25.264: INFO: Got endpoints: latency-svc-rt75g [750.140634ms]
Jan 15 21:58:25.278: INFO: Created: latency-svc-p8x5d
Jan 15 21:58:25.316: INFO: Got endpoints: latency-svc-8tdtx [750.817536ms]
Jan 15 21:58:25.370: INFO: Got endpoints: latency-svc-hfhb8 [756.570362ms]
Jan 15 21:58:25.415: INFO: Got endpoints: latency-svc-nldz8 [751.55424ms]
Jan 15 21:58:25.466: INFO: Got endpoints: latency-svc-jzl9t [752.105142ms]
Jan 15 21:58:25.513: INFO: Got endpoints: latency-svc-b7ml6 [748.924828ms]
Jan 15 21:58:25.566: INFO: Got endpoints: latency-svc-qtbzr [748.323926ms]
Jan 15 21:58:25.614: INFO: Got endpoints: latency-svc-9qpc7 [748.082125ms]
Jan 15 21:58:25.664: INFO: Got endpoints: latency-svc-l25xq [750.168134ms]
Jan 15 21:58:25.713: INFO: Got endpoints: latency-svc-hq8pp [748.523727ms]
Jan 15 21:58:25.765: INFO: Got endpoints: latency-svc-5n7dt [749.820133ms]
Jan 15 21:58:25.820: INFO: Got endpoints: latency-svc-zn4t4 [756.315961ms]
Jan 15 21:58:25.864: INFO: Got endpoints: latency-svc-62mtx [750.886837ms]
Jan 15 21:58:25.913: INFO: Got endpoints: latency-svc-r27rd [746.614018ms]
Jan 15 21:58:25.965: INFO: Got endpoints: latency-svc-r97m2 [750.728937ms]
Jan 15 21:58:26.016: INFO: Got endpoints: latency-svc-p8x5d [752.035642ms]
Jan 15 21:58:26.017: INFO: Latencies: [17.615176ms 23.0091ms 30.22993ms 39.088269ms 45.482396ms 62.366869ms 62.902271ms 68.805196ms 71.221607ms 77.416834ms 83.59126ms 91.738396ms 95.275111ms 96.654517ms 96.958918ms 97.24402ms 97.554221ms 98.177723ms 99.473929ms 99.88463ms 100.264932ms 101.359737ms 101.746639ms 103.410546ms 103.845147ms 104.28535ms 106.190058ms 107.461563ms 107.825565ms 108.649868ms 109.545872ms 111.34948ms 112.088083ms 112.283784ms 149.942747ms 194.203438ms 238.99663ms 283.940924ms 320.411081ms 364.967573ms 408.119159ms 455.481863ms 500.972859ms 537.436616ms 583.746516ms 629.248912ms 670.841991ms 670.912192ms 671.825996ms 676.348315ms 716.550689ms 716.593689ms 721.095408ms 721.52671ms 728.019538ms 740.759693ms 742.3055ms 742.3832ms 742.5245ms 743.065803ms 744.166607ms 744.220408ms 744.517409ms 744.60711ms 745.101612ms 745.152712ms 745.390213ms 745.499413ms 746.614018ms 746.646619ms 746.679319ms 747.07432ms 747.293421ms 747.461022ms 747.504622ms 747.622723ms 747.643822ms 747.695623ms 747.760524ms 747.764023ms 747.779923ms 748.082125ms 748.134725ms 748.177025ms 748.214926ms 748.282525ms 748.295325ms 748.323926ms 748.350225ms 748.435126ms 748.517927ms 748.523727ms 748.572926ms 748.594527ms 748.651227ms 748.665927ms 748.723228ms 748.759228ms 748.764628ms 748.912228ms 748.924828ms 748.927629ms 748.928528ms 749.001029ms 749.010528ms 749.087629ms 749.089729ms 749.101629ms 749.121929ms 749.139329ms 749.22063ms 749.29943ms 749.32163ms 749.33963ms 749.36593ms 749.43463ms 749.46953ms 749.478931ms 749.506131ms 749.555231ms 749.559631ms 749.597331ms 749.600231ms 749.684232ms 749.685031ms 749.693631ms 749.696432ms 749.820133ms 749.832033ms 749.879132ms 749.940132ms 750.036833ms 750.057833ms 750.140634ms 750.168134ms 750.219734ms 750.241934ms 750.265034ms 750.281934ms 750.287734ms 750.305334ms 750.343335ms 750.350935ms 750.386634ms 750.443835ms 750.450835ms 750.476135ms 750.486535ms 750.508235ms 750.523235ms 750.538135ms 750.656936ms 750.668936ms 750.728937ms 750.786536ms 750.817536ms 750.886837ms 750.893737ms 750.900637ms 751.018737ms 751.101038ms 751.200838ms 751.398739ms 751.469739ms 751.549739ms 751.55424ms 751.574239ms 751.675841ms 751.750641ms 752.035642ms 752.105142ms 752.174442ms 752.293843ms 752.528244ms 752.540743ms 752.612645ms 752.651744ms 752.710244ms 752.756645ms 752.828346ms 753.102747ms 753.280147ms 754.616253ms 755.036055ms 755.108855ms 755.270156ms 756.315961ms 756.570362ms 756.982263ms 757.627566ms 757.694566ms 758.793871ms 761.494282ms 771.240624ms 779.125159ms 779.874261ms 783.497177ms 823.075347ms 828.891573ms 829.628476ms]
Jan 15 21:58:26.017: INFO: 50 %ile: 748.924828ms
Jan 15 21:58:26.017: INFO: 90 %ile: 753.102747ms
Jan 15 21:58:26.017: INFO: 99 %ile: 828.891573ms
Jan 15 21:58:26.017: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 21:58:26.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6537" for this suite.
Jan 15 21:58:50.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 21:58:50.206: INFO: namespace svc-latency-6537 deletion completed in 24.181844868s

• [SLOW TEST:35.970 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 21:58:50.206: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-6f431b27-3fe5-400e-9e16-7b00ab7b9f31 in namespace container-probe-6211
Jan 15 21:58:54.371: INFO: Started pod test-webserver-6f431b27-3fe5-400e-9e16-7b00ab7b9f31 in namespace container-probe-6211
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 21:58:54.374: INFO: Initial restart count of pod test-webserver-6f431b27-3fe5-400e-9e16-7b00ab7b9f31 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:02:54.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6211" for this suite.
Jan 15 22:03:00.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:03:01.110: INFO: namespace container-probe-6211 deletion completed in 6.173049318s

• [SLOW TEST:250.904 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:03:01.110: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Jan 15 22:03:03.238: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-089408705 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 15 22:03:08.355: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:03:08.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-119" for this suite.
Jan 15 22:03:14.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:03:14.516: INFO: namespace pods-119 deletion completed in 6.149579919s

• [SLOW TEST:13.407 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:03:14.518: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Jan 15 22:03:14.576: INFO: namespace kubectl-3209
Jan 15 22:03:14.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-3209'
Jan 15 22:03:15.636: INFO: stderr: ""
Jan 15 22:03:15.636: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 22:03:16.640: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:03:16.640: INFO: Found 0 / 1
Jan 15 22:03:17.640: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:03:17.640: INFO: Found 0 / 1
Jan 15 22:03:18.641: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:03:18.641: INFO: Found 1 / 1
Jan 15 22:03:18.641: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 22:03:18.648: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:03:18.648: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 22:03:18.648: INFO: wait on redis-master startup in kubectl-3209 
Jan 15 22:03:18.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-dwrmr redis-master --namespace=kubectl-3209'
Jan 15 22:03:18.769: INFO: stderr: ""
Jan 15 22:03:18.769: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:03:17.413 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:03:17.413 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:03:17.413 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:03:17.414 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 15 22:03:18.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3209'
Jan 15 22:03:18.893: INFO: stderr: ""
Jan 15 22:03:18.893: INFO: stdout: "service/rm2 exposed\n"
Jan 15 22:03:18.897: INFO: Service rm2 in namespace kubectl-3209 found.
STEP: exposing service
Jan 15 22:03:20.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3209'
Jan 15 22:03:21.012: INFO: stderr: ""
Jan 15 22:03:21.012: INFO: stdout: "service/rm3 exposed\n"
Jan 15 22:03:21.017: INFO: Service rm3 in namespace kubectl-3209 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:03:23.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3209" for this suite.
Jan 15 22:03:45.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:03:45.219: INFO: namespace kubectl-3209 deletion completed in 22.189398475s

• [SLOW TEST:30.702 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:03:45.220: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-44602303-4972-497c-94d7-90084ec6c1c8
STEP: Creating a pod to test consume secrets
Jan 15 22:03:45.303: INFO: Waiting up to 5m0s for pod "pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da" in namespace "secrets-9092" to be "success or failure"
Jan 15 22:03:45.312: INFO: Pod "pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.08504ms
Jan 15 22:03:47.316: INFO: Pod "pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013044117s
Jan 15 22:03:49.320: INFO: Pod "pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017355097s
STEP: Saw pod success
Jan 15 22:03:49.320: INFO: Pod "pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da" satisfied condition "success or failure"
Jan 15 22:03:49.323: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:03:49.355: INFO: Waiting for pod pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da to disappear
Jan 15 22:03:49.360: INFO: Pod pod-secrets-8b07378f-3759-4cbf-afca-996dde4c37da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:03:49.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9092" for this suite.
Jan 15 22:03:55.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:03:55.528: INFO: namespace secrets-9092 deletion completed in 6.163393891s

• [SLOW TEST:10.309 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:03:55.529: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:03:55.626: INFO: (0) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.533319ms)
Jan 15 22:03:55.711: INFO: (1) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 84.919568ms)
Jan 15 22:03:55.800: INFO: (2) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.531983ms)
Jan 15 22:03:55.887: INFO: (3) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.574279ms)
Jan 15 22:03:55.975: INFO: (4) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.007381ms)
Jan 15 22:03:56.064: INFO: (5) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.179581ms)
Jan 15 22:03:56.152: INFO: (6) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.86008ms)
Jan 15 22:03:56.239: INFO: (7) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.822781ms)
Jan 15 22:03:56.331: INFO: (8) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 91.993598ms)
Jan 15 22:03:56.419: INFO: (9) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.70388ms)
Jan 15 22:03:56.508: INFO: (10) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.478883ms)
Jan 15 22:03:56.596: INFO: (11) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.002881ms)
Jan 15 22:03:56.684: INFO: (12) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.137882ms)
Jan 15 22:03:56.771: INFO: (13) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.330878ms)
Jan 15 22:03:56.859: INFO: (14) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.92278ms)
Jan 15 22:03:56.947: INFO: (15) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.823881ms)
Jan 15 22:03:57.035: INFO: (16) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.313182ms)
Jan 15 22:03:57.123: INFO: (17) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.80248ms)
Jan 15 22:03:57.211: INFO: (18) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.984881ms)
Jan 15 22:03:57.258: INFO: (19) /api/v1/nodes/aks-nodepool1-25266157-vmss000000/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 46.025299ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:03:57.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9433" for this suite.
Jan 15 22:04:03.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:04:03.467: INFO: namespace proxy-9433 deletion completed in 6.203271366s

• [SLOW TEST:7.938 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:04:03.467: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:04:03.544: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 15 22:04:03.551: INFO: Number of nodes with available pods: 0
Jan 15 22:04:03.551: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 15 22:04:03.571: INFO: Number of nodes with available pods: 0
Jan 15 22:04:03.571: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:04.575: INFO: Number of nodes with available pods: 0
Jan 15 22:04:04.575: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:05.575: INFO: Number of nodes with available pods: 0
Jan 15 22:04:05.575: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:06.576: INFO: Number of nodes with available pods: 1
Jan 15 22:04:06.576: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 15 22:04:06.596: INFO: Number of nodes with available pods: 1
Jan 15 22:04:06.596: INFO: Number of running nodes: 0, number of available pods: 1
Jan 15 22:04:07.600: INFO: Number of nodes with available pods: 0
Jan 15 22:04:07.600: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 15 22:04:07.612: INFO: Number of nodes with available pods: 0
Jan 15 22:04:07.612: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:08.617: INFO: Number of nodes with available pods: 0
Jan 15 22:04:08.617: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:09.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:09.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:10.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:10.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:11.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:11.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:12.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:12.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:13.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:13.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:14.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:14.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:15.616: INFO: Number of nodes with available pods: 0
Jan 15 22:04:15.616: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:16.617: INFO: Number of nodes with available pods: 0
Jan 15 22:04:16.617: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:04:17.616: INFO: Number of nodes with available pods: 1
Jan 15 22:04:17.616: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1196, will wait for the garbage collector to delete the pods
Jan 15 22:04:17.685: INFO: Deleting DaemonSet.extensions daemon-set took: 9.204339ms
Jan 15 22:04:17.985: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.249501ms
Jan 15 22:04:20.789: INFO: Number of nodes with available pods: 0
Jan 15 22:04:20.789: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 22:04:20.796: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1196/daemonsets","resourceVersion":"14742"},"items":null}

Jan 15 22:04:20.799: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1196/pods","resourceVersion":"14742"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:04:20.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1196" for this suite.
Jan 15 22:04:26.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:04:26.977: INFO: namespace daemonsets-1196 deletion completed in 6.145504122s

• [SLOW TEST:23.510 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:04:26.978: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 22:04:27.037: INFO: Waiting up to 5m0s for pod "pod-cf86e964-f85a-4559-8689-6ed6984639a7" in namespace "emptydir-2303" to be "success or failure"
Jan 15 22:04:27.041: INFO: Pod "pod-cf86e964-f85a-4559-8689-6ed6984639a7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210914ms
Jan 15 22:04:29.045: INFO: Pod "pod-cf86e964-f85a-4559-8689-6ed6984639a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008053199s
STEP: Saw pod success
Jan 15 22:04:29.045: INFO: Pod "pod-cf86e964-f85a-4559-8689-6ed6984639a7" satisfied condition "success or failure"
Jan 15 22:04:29.048: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-cf86e964-f85a-4559-8689-6ed6984639a7 container test-container: <nil>
STEP: delete the pod
Jan 15 22:04:29.073: INFO: Waiting for pod pod-cf86e964-f85a-4559-8689-6ed6984639a7 to disappear
Jan 15 22:04:29.075: INFO: Pod pod-cf86e964-f85a-4559-8689-6ed6984639a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:04:29.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2303" for this suite.
Jan 15 22:04:35.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:04:35.239: INFO: namespace emptydir-2303 deletion completed in 6.158032878s

• [SLOW TEST:8.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:04:35.239: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 22:04:35.308: INFO: Waiting up to 5m0s for pod "pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f" in namespace "emptydir-8100" to be "success or failure"
Jan 15 22:04:35.315: INFO: Pod "pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.579933ms
Jan 15 22:04:37.319: INFO: Pod "pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011916717s
Jan 15 22:04:39.323: INFO: Pod "pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015895599s
STEP: Saw pod success
Jan 15 22:04:39.323: INFO: Pod "pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f" satisfied condition "success or failure"
Jan 15 22:04:39.326: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f container test-container: <nil>
STEP: delete the pod
Jan 15 22:04:39.350: INFO: Waiting for pod pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f to disappear
Jan 15 22:04:39.353: INFO: Pod pod-f4150175-13b0-4bc3-9ad9-39ea3daed60f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:04:39.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8100" for this suite.
Jan 15 22:04:45.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:04:45.514: INFO: namespace emptydir-8100 deletion completed in 6.154917667s

• [SLOW TEST:10.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:04:45.515: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jan 15 22:05:25.619: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0115 22:05:25.619087      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:05:25.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6881" for this suite.
Jan 15 22:05:33.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:05:33.778: INFO: namespace gc-6881 deletion completed in 8.150980941s

• [SLOW TEST:48.264 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:05:33.779: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:05:38.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9847" for this suite.
Jan 15 22:06:00.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:06:01.035: INFO: namespace replication-controller-9847 deletion completed in 22.159376577s

• [SLOW TEST:27.256 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:06:01.036: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:06:05.146: INFO: Waiting up to 5m0s for pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853" in namespace "pods-5532" to be "success or failure"
Jan 15 22:06:05.149: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Pending", Reason="", readiness=false. Elapsed: 2.821325ms
Jan 15 22:06:07.153: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006489629s
Jan 15 22:06:09.157: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010182601s
Jan 15 22:06:11.162: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015242253s
Jan 15 22:06:13.166: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019417364s
Jan 15 22:06:15.170: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023709945s
STEP: Saw pod success
Jan 15 22:06:15.170: INFO: Pod "client-envvars-6accec20-71cf-4eec-acbb-d4d664528853" satisfied condition "success or failure"
Jan 15 22:06:15.173: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000002 pod client-envvars-6accec20-71cf-4eec-acbb-d4d664528853 container env3cont: <nil>
STEP: delete the pod
Jan 15 22:06:15.207: INFO: Waiting for pod client-envvars-6accec20-71cf-4eec-acbb-d4d664528853 to disappear
Jan 15 22:06:15.210: INFO: Pod client-envvars-6accec20-71cf-4eec-acbb-d4d664528853 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:06:15.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5532" for this suite.
Jan 15 22:07:03.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:07:03.405: INFO: namespace pods-5532 deletion completed in 48.189924277s

• [SLOW TEST:62.369 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:07:03.406: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7310
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7310
STEP: Creating statefulset with conflicting port in namespace statefulset-7310
STEP: Waiting until pod test-pod will start running in namespace statefulset-7310
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7310
Jan 15 22:07:07.508: INFO: Observed stateful pod in namespace: statefulset-7310, name: ss-0, uid: 51d95cc6-055e-4ce4-ac0b-5c5b5c0c753d, status phase: Pending. Waiting for statefulset controller to delete.
Jan 15 22:07:07.694: INFO: Observed stateful pod in namespace: statefulset-7310, name: ss-0, uid: 51d95cc6-055e-4ce4-ac0b-5c5b5c0c753d, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 22:07:07.699: INFO: Observed stateful pod in namespace: statefulset-7310, name: ss-0, uid: 51d95cc6-055e-4ce4-ac0b-5c5b5c0c753d, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 22:07:07.704: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7310
STEP: Removing pod with conflicting port in namespace statefulset-7310
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7310 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Jan 15 22:07:11.728: INFO: Deleting all statefulset in ns statefulset-7310
Jan 15 22:07:11.732: INFO: Scaling statefulset ss to 0
Jan 15 22:07:21.749: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:07:21.755: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:07:21.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7310" for this suite.
Jan 15 22:07:27.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:07:27.973: INFO: namespace statefulset-7310 deletion completed in 6.192950712s

• [SLOW TEST:24.568 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:07:27.973: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 22:07:28.038: INFO: Waiting up to 5m0s for pod "pod-66268323-9b09-4459-a967-bae2a79051df" in namespace "emptydir-7438" to be "success or failure"
Jan 15 22:07:28.041: INFO: Pod "pod-66268323-9b09-4459-a967-bae2a79051df": Phase="Pending", Reason="", readiness=false. Elapsed: 3.100126ms
Jan 15 22:07:30.044: INFO: Pod "pod-66268323-9b09-4459-a967-bae2a79051df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00670729s
STEP: Saw pod success
Jan 15 22:07:30.044: INFO: Pod "pod-66268323-9b09-4459-a967-bae2a79051df" satisfied condition "success or failure"
Jan 15 22:07:30.048: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-66268323-9b09-4459-a967-bae2a79051df container test-container: <nil>
STEP: delete the pod
Jan 15 22:07:30.072: INFO: Waiting for pod pod-66268323-9b09-4459-a967-bae2a79051df to disappear
Jan 15 22:07:30.075: INFO: Pod pod-66268323-9b09-4459-a967-bae2a79051df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:07:30.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7438" for this suite.
Jan 15 22:07:36.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:07:36.246: INFO: namespace emptydir-7438 deletion completed in 6.165511927s

• [SLOW TEST:8.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:07:36.246: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:07:36.314: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9" in namespace "downward-api-1141" to be "success or failure"
Jan 15 22:07:36.317: INFO: Pod "downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.871224ms
Jan 15 22:07:38.322: INFO: Pod "downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008361591s
Jan 15 22:07:40.335: INFO: Pod "downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020447986s
STEP: Saw pod success
Jan 15 22:07:40.335: INFO: Pod "downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9" satisfied condition "success or failure"
Jan 15 22:07:40.338: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9 container client-container: <nil>
STEP: delete the pod
Jan 15 22:07:40.367: INFO: Waiting for pod downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9 to disappear
Jan 15 22:07:40.370: INFO: Pod downwardapi-volume-17432de1-88b1-4fcf-bbba-7e40110ad1f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:07:40.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1141" for this suite.
Jan 15 22:07:46.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:07:46.561: INFO: namespace downward-api-1141 deletion completed in 6.185219064s

• [SLOW TEST:10.315 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:07:46.561: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jan 15 22:07:49.649: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:07:49.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4470" for this suite.
Jan 15 22:07:55.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:07:55.830: INFO: namespace container-runtime-4470 deletion completed in 6.150920598s

• [SLOW TEST:9.269 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:07:55.831: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-849af3b9-8948-41a3-bf71-ac3e44abc61a
STEP: Creating a pod to test consume configMaps
Jan 15 22:07:55.907: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0" in namespace "configmap-5575" to be "success or failure"
Jan 15 22:07:55.911: INFO: Pod "pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116734ms
Jan 15 22:07:57.916: INFO: Pod "pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008810634s
STEP: Saw pod success
Jan 15 22:07:57.916: INFO: Pod "pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0" satisfied condition "success or failure"
Jan 15 22:07:57.920: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:07:57.941: INFO: Waiting for pod pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0 to disappear
Jan 15 22:07:57.944: INFO: Pod pod-configmaps-fe1bb176-e8f5-4e52-918b-99a4fa117af0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:07:57.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5575" for this suite.
Jan 15 22:08:03.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:08:04.146: INFO: namespace configmap-5575 deletion completed in 6.197639351s

• [SLOW TEST:8.316 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:08:04.147: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-ab610b98-1e03-467d-b880-a7e989f58275
STEP: Creating a pod to test consume configMaps
Jan 15 22:08:04.213: INFO: Waiting up to 5m0s for pod "pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787" in namespace "configmap-6592" to be "success or failure"
Jan 15 22:08:04.217: INFO: Pod "pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.973724ms
Jan 15 22:08:06.221: INFO: Pod "pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00698211s
Jan 15 22:08:08.224: INFO: Pod "pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010753569s
STEP: Saw pod success
Jan 15 22:08:08.224: INFO: Pod "pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787" satisfied condition "success or failure"
Jan 15 22:08:08.227: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:08:08.257: INFO: Waiting for pod pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787 to disappear
Jan 15 22:08:08.260: INFO: Pod pod-configmaps-cda972be-b70b-4f84-bf0a-afa2c5de3787 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:08:08.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6592" for this suite.
Jan 15 22:08:14.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:08:14.429: INFO: namespace configmap-6592 deletion completed in 6.161068744s

• [SLOW TEST:10.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:08:14.429: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:08:14.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2" in namespace "projected-3699" to be "success or failure"
Jan 15 22:08:14.494: INFO: Pod "downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.516628ms
Jan 15 22:08:16.497: INFO: Pod "downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007356783s
Jan 15 22:08:18.501: INFO: Pod "downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011334213s
STEP: Saw pod success
Jan 15 22:08:18.502: INFO: Pod "downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2" satisfied condition "success or failure"
Jan 15 22:08:18.505: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2 container client-container: <nil>
STEP: delete the pod
Jan 15 22:08:18.532: INFO: Waiting for pod downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2 to disappear
Jan 15 22:08:18.535: INFO: Pod downwardapi-volume-edec763e-da03-4583-ba29-0b78d189bbe2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:08:18.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3699" for this suite.
Jan 15 22:08:24.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:08:24.687: INFO: namespace projected-3699 deletion completed in 6.146109227s

• [SLOW TEST:10.258 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:08:24.688: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b72085c9-3c70-43a5-8c24-98855b033f21
STEP: Creating a pod to test consume secrets
Jan 15 22:08:24.772: INFO: Waiting up to 5m0s for pod "pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179" in namespace "secrets-5050" to be "success or failure"
Jan 15 22:08:24.777: INFO: Pod "pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.305735ms
Jan 15 22:08:26.781: INFO: Pod "pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008491564s
Jan 15 22:08:28.785: INFO: Pod "pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012592668s
STEP: Saw pod success
Jan 15 22:08:28.785: INFO: Pod "pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179" satisfied condition "success or failure"
Jan 15 22:08:28.789: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:08:28.817: INFO: Waiting for pod pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179 to disappear
Jan 15 22:08:28.820: INFO: Pod pod-secrets-684e405c-ec74-4342-aff6-92e02ecf6179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:08:28.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5050" for this suite.
Jan 15 22:08:34.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:08:35.038: INFO: namespace secrets-5050 deletion completed in 6.212360072s

• [SLOW TEST:10.351 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:08:35.039: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5438
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 22:08:35.102: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 22:08:55.254: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.61 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5438 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:08:55.254: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:08:56.735: INFO: Found all expected endpoints: [netserver-0]
Jan 15 22:08:56.738: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.162 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5438 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:08:56.738: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:08:58.213: INFO: Found all expected endpoints: [netserver-1]
Jan 15 22:08:58.220: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.53 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5438 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:08:58.221: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:08:59.556: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:08:59.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5438" for this suite.
Jan 15 22:09:21.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:09:21.784: INFO: namespace pod-network-test-5438 deletion completed in 22.221395968s

• [SLOW TEST:46.745 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:09:21.785: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:09:47.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-162" for this suite.
Jan 15 22:09:54.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:09:54.154: INFO: namespace namespaces-162 deletion completed in 6.142381369s
STEP: Destroying namespace "nsdeletetest-209" for this suite.
Jan 15 22:09:54.158: INFO: Namespace nsdeletetest-209 was already deleted
STEP: Destroying namespace "nsdeletetest-9225" for this suite.
Jan 15 22:10:00.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:10:00.325: INFO: namespace nsdeletetest-9225 deletion completed in 6.166458156s

• [SLOW TEST:38.540 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:10:00.325: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-klmr
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:10:00.400: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-klmr" in namespace "subpath-9177" to be "success or failure"
Jan 15 22:10:00.403: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.432326ms
Jan 15 22:10:02.408: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008088783s
Jan 15 22:10:04.412: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 4.012329616s
Jan 15 22:10:06.417: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 6.017338535s
Jan 15 22:10:08.429: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 8.02985619s
Jan 15 22:10:10.434: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 10.033959862s
Jan 15 22:10:12.437: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 12.037037705s
Jan 15 22:10:14.441: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 14.041445039s
Jan 15 22:10:16.444: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 16.044917046s
Jan 15 22:10:18.449: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 18.04945554s
Jan 15 22:10:20.453: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 20.053726513s
Jan 15 22:10:22.457: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Running", Reason="", readiness=true. Elapsed: 22.057825765s
Jan 15 22:10:24.461: INFO: Pod "pod-subpath-test-configmap-klmr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061739496s
STEP: Saw pod success
Jan 15 22:10:24.461: INFO: Pod "pod-subpath-test-configmap-klmr" satisfied condition "success or failure"
Jan 15 22:10:24.464: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-subpath-test-configmap-klmr container test-container-subpath-configmap-klmr: <nil>
STEP: delete the pod
Jan 15 22:10:24.487: INFO: Waiting for pod pod-subpath-test-configmap-klmr to disappear
Jan 15 22:10:24.490: INFO: Pod pod-subpath-test-configmap-klmr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-klmr
Jan 15 22:10:24.490: INFO: Deleting pod "pod-subpath-test-configmap-klmr" in namespace "subpath-9177"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:10:24.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9177" for this suite.
Jan 15 22:10:30.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:10:30.677: INFO: namespace subpath-9177 deletion completed in 6.179574819s

• [SLOW TEST:30.352 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:10:30.678: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 15 22:10:38.764: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:38.764: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:39.265: INFO: Exec stderr: ""
Jan 15 22:10:39.265: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:39.265: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:39.745: INFO: Exec stderr: ""
Jan 15 22:10:39.745: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:39.745: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:40.191: INFO: Exec stderr: ""
Jan 15 22:10:40.191: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:40.191: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:40.544: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 15 22:10:40.544: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:40.544: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:40.984: INFO: Exec stderr: ""
Jan 15 22:10:40.984: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:40.984: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:41.427: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 15 22:10:41.427: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:41.427: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:41.909: INFO: Exec stderr: ""
Jan 15 22:10:41.909: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:41.909: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:42.342: INFO: Exec stderr: ""
Jan 15 22:10:42.342: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:42.343: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:42.873: INFO: Exec stderr: ""
Jan 15 22:10:42.873: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5480 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:10:42.873: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:10:43.293: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:10:43.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5480" for this suite.
Jan 15 22:11:31.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:11:31.457: INFO: namespace e2e-kubelet-etc-hosts-5480 deletion completed in 48.158850957s

• [SLOW TEST:60.779 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:11:31.457: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 22:11:39.570: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:11:39.573: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:11:41.573: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:11:41.578: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:11:43.573: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:11:43.577: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:11:45.573: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:11:45.579: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:11:47.573: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:11:47.577: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:11:47.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6663" for this suite.
Jan 15 22:12:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:12:09.726: INFO: namespace container-lifecycle-hook-6663 deletion completed in 22.14364809s

• [SLOW TEST:38.269 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:12:09.726: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:12:09.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6775" for this suite.
Jan 15 22:12:15.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:12:15.973: INFO: namespace services-6775 deletion completed in 6.18121578s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.246 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:12:15.974: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-dea8fcce-25f9-4480-85a5-9baf71990549 in namespace container-probe-3793
Jan 15 22:12:20.044: INFO: Started pod busybox-dea8fcce-25f9-4480-85a5-9baf71990549 in namespace container-probe-3793
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:12:20.047: INFO: Initial restart count of pod busybox-dea8fcce-25f9-4480-85a5-9baf71990549 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:16:20.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3793" for this suite.
Jan 15 22:16:26.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:16:26.766: INFO: namespace container-probe-3793 deletion completed in 6.14834654s

• [SLOW TEST:250.792 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:16:26.766: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:16:26.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7108'
Jan 15 22:16:27.813: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 22:16:27.813: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Jan 15 22:16:27.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete jobs e2e-test-nginx-job --namespace=kubectl-7108'
Jan 15 22:16:27.907: INFO: stderr: ""
Jan 15 22:16:27.907: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:16:27.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7108" for this suite.
Jan 15 22:16:49.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:16:50.082: INFO: namespace kubectl-7108 deletion completed in 22.169368353s

• [SLOW TEST:23.316 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:16:50.083: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:16:50.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1381'
Jan 15 22:16:50.262: INFO: stderr: ""
Jan 15 22:16:50.262: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Jan 15 22:16:50.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete pods e2e-test-nginx-pod --namespace=kubectl-1381'
Jan 15 22:16:59.127: INFO: stderr: ""
Jan 15 22:16:59.127: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:16:59.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1381" for this suite.
Jan 15 22:17:05.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:17:05.308: INFO: namespace kubectl-1381 deletion completed in 6.165497293s

• [SLOW TEST:15.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:17:05.309: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:17:05.395: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"aaa79092-0be1-4712-8c2d-1158f026f966", Controller:(*bool)(0xc002cbf926), BlockOwnerDeletion:(*bool)(0xc002cbf927)}}
Jan 15 22:17:05.400: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b08b9d9f-83df-4fbb-a973-64a50ae31e5e", Controller:(*bool)(0xc0038658de), BlockOwnerDeletion:(*bool)(0xc0038658df)}}
Jan 15 22:17:05.404: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bfcda135-a046-4c37-83c3-578f497d6846", Controller:(*bool)(0xc002cbfaee), BlockOwnerDeletion:(*bool)(0xc002cbfaef)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:17:10.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7954" for this suite.
Jan 15 22:17:16.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:17:16.579: INFO: namespace gc-7954 deletion completed in 6.158638596s

• [SLOW TEST:11.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:17:16.579: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1b33e326-05ab-40e1-8667-fe98afcd3617
STEP: Creating a pod to test consume configMaps
Jan 15 22:17:16.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c" in namespace "configmap-6224" to be "success or failure"
Jan 15 22:17:16.655: INFO: Pod "pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.051218ms
Jan 15 22:17:18.660: INFO: Pod "pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007435071s
Jan 15 22:17:20.664: INFO: Pod "pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011934016s
STEP: Saw pod success
Jan 15 22:17:20.664: INFO: Pod "pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c" satisfied condition "success or failure"
Jan 15 22:17:20.667: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:17:20.692: INFO: Waiting for pod pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c to disappear
Jan 15 22:17:20.695: INFO: Pod pod-configmaps-4fa34818-bea7-4274-9bcd-287333da386c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:17:20.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6224" for this suite.
Jan 15 22:17:26.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:17:26.860: INFO: namespace configmap-6224 deletion completed in 6.156199945s

• [SLOW TEST:10.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:17:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6751.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6751.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6751.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6751.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6751.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6751.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:17:43.607: INFO: DNS probes using dns-6751/dns-test-92ab0faa-9303-49ba-9214-915f3756f622 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:17:43.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6751" for this suite.
Jan 15 22:17:49.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:17:49.772: INFO: namespace dns-6751 deletion completed in 6.147388595s

• [SLOW TEST:22.912 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:17:49.773: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:17:49.851: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 22:17:49.864: INFO: Number of nodes with available pods: 0
Jan 15 22:17:49.864: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:17:50.874: INFO: Number of nodes with available pods: 0
Jan 15 22:17:50.874: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:17:51.874: INFO: Number of nodes with available pods: 0
Jan 15 22:17:51.874: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:17:52.878: INFO: Number of nodes with available pods: 3
Jan 15 22:17:52.878: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 15 22:17:52.907: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:52.907: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:52.907: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:53.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:53.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:53.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:54.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:54.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:54.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:55.917: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:55.917: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:17:55.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:55.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:56.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:56.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:17:56.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:56.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:57.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:57.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:17:57.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:57.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:58.915: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:58.915: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:17:58.915: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:58.915: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:59.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:59.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:17:59.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:17:59.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:00.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:00.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:00.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:00.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:01.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:01.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:01.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:01.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:02.918: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:02.919: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:02.919: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:02.919: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:03.917: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:03.917: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:03.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:03.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:04.921: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:04.921: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:04.921: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:04.921: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:05.916: INFO: Wrong image for pod: daemon-set-bzcj7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:05.916: INFO: Pod daemon-set-bzcj7 is not available
Jan 15 22:18:05.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:05.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:06.918: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:06.918: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:06.918: INFO: Pod daemon-set-j7qxn is not available
Jan 15 22:18:07.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:07.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:07.916: INFO: Pod daemon-set-j7qxn is not available
Jan 15 22:18:08.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:08.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:08.917: INFO: Pod daemon-set-j7qxn is not available
Jan 15 22:18:09.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:09.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:09.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:10.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:10.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:10.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:11.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:11.917: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:11.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:12.917: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:12.917: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:12.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:13.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:13.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:13.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:14.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:14.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:14.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:15.918: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:15.918: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:15.918: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:16.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:16.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:16.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:17.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:17.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:17.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:18.916: INFO: Wrong image for pod: daemon-set-d4wpr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:18.916: INFO: Pod daemon-set-d4wpr is not available
Jan 15 22:18:18.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:19.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:19.916: INFO: Pod daemon-set-q9qxd is not available
Jan 15 22:18:20.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:20.917: INFO: Pod daemon-set-q9qxd is not available
Jan 15 22:18:21.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:22.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:22.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:23.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:23.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:24.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:24.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:25.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:25.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:26.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:26.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:27.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:27.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:28.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:28.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:29.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:29.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:30.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:30.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:31.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:31.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:32.916: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:32.916: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:33.917: INFO: Wrong image for pod: daemon-set-h4ggk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Jan 15 22:18:33.917: INFO: Pod daemon-set-h4ggk is not available
Jan 15 22:18:34.916: INFO: Pod daemon-set-9h7c8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 15 22:18:34.941: INFO: Number of nodes with available pods: 2
Jan 15 22:18:34.941: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:18:35.950: INFO: Number of nodes with available pods: 2
Jan 15 22:18:35.950: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:18:36.951: INFO: Number of nodes with available pods: 2
Jan 15 22:18:36.951: INFO: Node aks-nodepool1-25266157-vmss000000 is running more than one daemon pod
Jan 15 22:18:37.950: INFO: Number of nodes with available pods: 3
Jan 15 22:18:37.950: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5952, will wait for the garbage collector to delete the pods
Jan 15 22:18:38.028: INFO: Deleting DaemonSet.extensions daemon-set took: 6.942941ms
Jan 15 22:18:38.329: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.241171ms
Jan 15 22:18:49.132: INFO: Number of nodes with available pods: 0
Jan 15 22:18:49.132: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 22:18:49.135: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5952/daemonsets","resourceVersion":"17246"},"items":null}

Jan 15 22:18:49.138: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5952/pods","resourceVersion":"17246"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:18:49.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5952" for this suite.
Jan 15 22:18:55.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:18:55.328: INFO: namespace daemonsets-5952 deletion completed in 6.154821662s

• [SLOW TEST:65.555 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:18:55.328: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jan 15 22:18:58.429: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:18:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8772" for this suite.
Jan 15 22:19:04.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:19:04.601: INFO: namespace container-runtime-8772 deletion completed in 6.151273638s

• [SLOW TEST:9.273 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:19:04.602: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6002
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 22:19:04.656: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 22:19:30.758: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.178:8080/dial?request=hostName&protocol=udp&host=10.244.0.64&port=8081&tries=1'] Namespace:pod-network-test-6002 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:19:30.758: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:19:31.233: INFO: Waiting for endpoints: map[]
Jan 15 22:19:31.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.178:8080/dial?request=hostName&protocol=udp&host=10.244.2.177&port=8081&tries=1'] Namespace:pod-network-test-6002 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:19:31.237: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:19:31.651: INFO: Waiting for endpoints: map[]
Jan 15 22:19:31.655: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.178:8080/dial?request=hostName&protocol=udp&host=10.244.1.58&port=8081&tries=1'] Namespace:pod-network-test-6002 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 22:19:31.655: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
Jan 15 22:19:32.199: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:19:32.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6002" for this suite.
Jan 15 22:19:54.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:19:54.398: INFO: namespace pod-network-test-6002 deletion completed in 22.194155149s

• [SLOW TEST:49.796 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:19:54.399: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:19:54.458: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39" in namespace "downward-api-3516" to be "success or failure"
Jan 15 22:19:54.462: INFO: Pod "downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39": Phase="Pending", Reason="", readiness=false. Elapsed: 4.297925ms
Jan 15 22:19:56.468: INFO: Pod "downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009942893s
Jan 15 22:19:58.471: INFO: Pod "downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013573843s
STEP: Saw pod success
Jan 15 22:19:58.471: INFO: Pod "downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39" satisfied condition "success or failure"
Jan 15 22:19:58.474: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39 container client-container: <nil>
STEP: delete the pod
Jan 15 22:19:58.497: INFO: Waiting for pod downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39 to disappear
Jan 15 22:19:58.500: INFO: Pod downwardapi-volume-94bd3a74-8a37-4bd1-a89a-ed9d56099e39 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:19:58.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3516" for this suite.
Jan 15 22:20:04.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:20:04.645: INFO: namespace downward-api-3516 deletion completed in 6.13928475s

• [SLOW TEST:10.247 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:20:04.646: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Jan 15 22:20:04.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-4925'
Jan 15 22:20:05.048: INFO: stderr: ""
Jan 15 22:20:05.048: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Jan 15 22:20:06.054: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:20:06.054: INFO: Found 0 / 1
Jan 15 22:20:07.052: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:20:07.052: INFO: Found 0 / 1
Jan 15 22:20:08.053: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:20:08.053: INFO: Found 1 / 1
Jan 15 22:20:08.053: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 22:20:08.056: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:20:08.056: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 15 22:20:08.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925'
Jan 15 22:20:08.157: INFO: stderr: ""
Jan 15 22:20:08.157: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:20:06.746 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:20:06.746 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:20:06.746 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:20:06.746 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 15 22:20:08.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925 --tail=1'
Jan 15 22:20:08.294: INFO: stderr: ""
Jan 15 22:20:08.294: INFO: stdout: "1:M 15 Jan 22:20:06.746 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 15 22:20:08.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925 --limit-bytes=1'
Jan 15 22:20:08.410: INFO: stderr: ""
Jan 15 22:20:08.411: INFO: stdout: " "
STEP: exposing timestamps
Jan 15 22:20:08.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925 --tail=1 --timestamps'
Jan 15 22:20:08.508: INFO: stderr: ""
Jan 15 22:20:08.508: INFO: stdout: "2020-01-15T22:20:06.747106709Z 1:M 15 Jan 22:20:06.746 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 15 22:20:11.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925 --since=1s'
Jan 15 22:20:11.120: INFO: stderr: ""
Jan 15 22:20:11.120: INFO: stdout: ""
Jan 15 22:20:11.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs redis-master-jsj9v redis-master --namespace=kubectl-4925 --since=24h'
Jan 15 22:20:11.232: INFO: stderr: ""
Jan 15 22:20:11.232: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:20:06.746 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:20:06.746 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:20:06.746 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:20:06.746 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Jan 15 22:20:11.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-4925'
Jan 15 22:20:11.335: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 22:20:11.335: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 15 22:20:11.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4925'
Jan 15 22:20:11.429: INFO: stderr: "No resources found.\n"
Jan 15 22:20:11.429: INFO: stdout: ""
Jan 15 22:20:11.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=nginx --namespace=kubectl-4925 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:20:11.510: INFO: stderr: ""
Jan 15 22:20:11.511: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:20:11.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4925" for this suite.
Jan 15 22:20:23.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:20:23.696: INFO: namespace kubectl-4925 deletion completed in 12.175233903s

• [SLOW TEST:19.050 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:20:23.696: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Jan 15 22:20:23.752: INFO: Waiting up to 5m0s for pod "downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365" in namespace "downward-api-104" to be "success or failure"
Jan 15 22:20:23.755: INFO: Pod "downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365": Phase="Pending", Reason="", readiness=false. Elapsed: 3.328419ms
Jan 15 22:20:25.759: INFO: Pod "downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007164686s
Jan 15 22:20:27.764: INFO: Pod "downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011956352s
STEP: Saw pod success
Jan 15 22:20:27.764: INFO: Pod "downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365" satisfied condition "success or failure"
Jan 15 22:20:27.767: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:20:27.790: INFO: Waiting for pod downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365 to disappear
Jan 15 22:20:27.795: INFO: Pod downward-api-bf5e94fd-a148-42d2-962c-b96f3a2e2365 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:20:27.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-104" for this suite.
Jan 15 22:20:33.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:20:33.954: INFO: namespace downward-api-104 deletion completed in 6.149954335s

• [SLOW TEST:10.258 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:20:33.955: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:20:38.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4771" for this suite.
Jan 15 22:20:44.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:20:44.212: INFO: namespace emptydir-wrapper-4771 deletion completed in 6.139752684s

• [SLOW TEST:10.258 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:20:44.214: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-41546b20-b641-4996-acbb-08c371a78a01
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:20:44.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1943" for this suite.
Jan 15 22:20:50.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:20:50.518: INFO: namespace configmap-1943 deletion completed in 6.237189782s

• [SLOW TEST:6.304 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:20:50.518: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Jan 15 22:20:50.567: INFO: PodSpec: initContainers in spec.initContainers
Jan 15 22:21:40.965: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9cf0602f-5307-46e3-af1f-c6e552b05153", GenerateName:"", Namespace:"init-container-6971", SelfLink:"/api/v1/namespaces/init-container-6971/pods/pod-init-9cf0602f-5307-46e3-af1f-c6e552b05153", UID:"46cac6f1-7184-41d2-a0b7-651296fe4063", ResourceVersion:"17799", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63714723650, loc:(*time.Location)(0x7ed0a00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"567552645"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-cxp7s", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024f7700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cxp7s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cxp7s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cxp7s", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0009982a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-nodepool1-25266157-vmss000001", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00200e0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000998320)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000998340)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000998348), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00099834c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723650, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723650, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723650, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723650, loc:(*time.Location)(0x7ed0a00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.5", PodIP:"10.244.2.183", StartTime:(*v1.Time)(0xc0026258e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0007d4690)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0007d4700)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4a717b451fde6ef2dec7c7600de2ad39db378952105749747708785b6e9b79a4"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002625920), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002625900), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:21:40.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6971" for this suite.
Jan 15 22:22:02.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:03.150: INFO: namespace init-container-6971 deletion completed in 22.179489634s

• [SLOW TEST:72.632 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:22:03.151: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Jan 15 22:22:03.206: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Jan 15 22:22:03.972: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jan 15 22:22:06.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:08.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:10.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:12.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:14.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:16.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:18.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:20.030: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723724, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723723, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:23.189: INFO: Waited 1.15580723s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:22:24.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4167" for this suite.
Jan 15 22:22:30.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:30.363: INFO: namespace aggregator-4167 deletion completed in 6.230862331s

• [SLOW TEST:27.212 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:22:30.363: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Jan 15 22:22:30.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-7940'
Jan 15 22:22:30.762: INFO: stderr: ""
Jan 15 22:22:30.762: INFO: stdout: "pod/pause created\n"
Jan 15 22:22:30.762: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 15 22:22:30.762: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7940" to be "running and ready"
Jan 15 22:22:30.767: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.132628ms
Jan 15 22:22:32.772: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00985026s
Jan 15 22:22:34.776: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.014094384s
Jan 15 22:22:34.776: INFO: Pod "pause" satisfied condition "running and ready"
Jan 15 22:22:34.776: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 15 22:22:34.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 label pods pause testing-label=testing-label-value --namespace=kubectl-7940'
Jan 15 22:22:34.871: INFO: stderr: ""
Jan 15 22:22:34.871: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 15 22:22:34.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pod pause -L testing-label --namespace=kubectl-7940'
Jan 15 22:22:34.961: INFO: stderr: ""
Jan 15 22:22:34.961: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 15 22:22:34.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 label pods pause testing-label- --namespace=kubectl-7940'
Jan 15 22:22:35.051: INFO: stderr: ""
Jan 15 22:22:35.051: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 15 22:22:35.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pod pause -L testing-label --namespace=kubectl-7940'
Jan 15 22:22:35.135: INFO: stderr: ""
Jan 15 22:22:35.135: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Jan 15 22:22:35.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-7940'
Jan 15 22:22:35.228: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 22:22:35.228: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 15 22:22:35.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=pause --no-headers --namespace=kubectl-7940'
Jan 15 22:22:35.330: INFO: stderr: "No resources found.\n"
Jan 15 22:22:35.330: INFO: stdout: ""
Jan 15 22:22:35.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=pause --namespace=kubectl-7940 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:22:35.419: INFO: stderr: ""
Jan 15 22:22:35.419: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:22:35.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7940" for this suite.
Jan 15 22:22:41.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:41.584: INFO: namespace kubectl-7940 deletion completed in 6.159238751s

• [SLOW TEST:11.221 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:22:41.585: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:22:41.634: INFO: Creating deployment "test-recreate-deployment"
Jan 15 22:22:41.640: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 15 22:22:41.650: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan 15 22:22:43.660: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 15 22:22:43.664: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723761, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723761, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723761, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714723761, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:22:45.669: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 15 22:22:45.679: INFO: Updating deployment test-recreate-deployment
Jan 15 22:22:45.679: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Jan 15 22:22:45.755: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6555,SelfLink:/apis/apps/v1/namespaces/deployment-6555/deployments/test-recreate-deployment,UID:62295c01-266c-4058-a685-c1eed592239a,ResourceVersion:18069,Generation:2,CreationTimestamp:2020-01-15 22:22:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-01-15 22:22:45 +0000 UTC 2020-01-15 22:22:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-01-15 22:22:45 +0000 UTC 2020-01-15 22:22:41 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 22:22:45.759: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-6555,SelfLink:/apis/apps/v1/namespaces/deployment-6555/replicasets/test-recreate-deployment-5c8c9cc69d,UID:6a17d0cf-4192-4939-a7d7-af9dc1c89147,ResourceVersion:18067,Generation:1,CreationTimestamp:2020-01-15 22:22:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 62295c01-266c-4058-a685-c1eed592239a 0xc003fd0a47 0xc003fd0a48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:22:45.759: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 15 22:22:45.759: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-6555,SelfLink:/apis/apps/v1/namespaces/deployment-6555/replicasets/test-recreate-deployment-6df85df6b9,UID:7ff2aaf7-703b-4358-b5d0-b72f53a6a237,ResourceVersion:18057,Generation:2,CreationTimestamp:2020-01-15 22:22:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 62295c01-266c-4058-a685-c1eed592239a 0xc003fd0b17 0xc003fd0b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:22:45.762: INFO: Pod "test-recreate-deployment-5c8c9cc69d-6bnlf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-6bnlf,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-6555,SelfLink:/api/v1/namespaces/deployment-6555/pods/test-recreate-deployment-5c8c9cc69d-6bnlf,UID:7fa89429-ba58-4cca-a129-0b3208300d8e,ResourceVersion:18068,Generation:0,CreationTimestamp:2020-01-15 22:22:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 6a17d0cf-4192-4939-a7d7-af9dc1c89147 0xc003fd1417 0xc003fd1418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ncq6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ncq6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ncq6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fd1480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fd14a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:22:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:22:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:22:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:22:45 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2020-01-15 22:22:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:22:45.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6555" for this suite.
Jan 15 22:22:51.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:51.969: INFO: namespace deployment-6555 deletion completed in 6.202080515s

• [SLOW TEST:10.385 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:22:51.970: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-c39ccd4b-503d-4f31-a36b-d6ee4155950c in namespace container-probe-80
Jan 15 22:22:54.045: INFO: Started pod busybox-c39ccd4b-503d-4f31-a36b-d6ee4155950c in namespace container-probe-80
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:22:54.048: INFO: Initial restart count of pod busybox-c39ccd4b-503d-4f31-a36b-d6ee4155950c is 0
Jan 15 22:23:42.154: INFO: Restart count of pod container-probe-80/busybox-c39ccd4b-503d-4f31-a36b-d6ee4155950c is now 1 (48.105190813s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:23:42.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-80" for this suite.
Jan 15 22:23:48.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:23:48.311: INFO: namespace container-probe-80 deletion completed in 6.140459501s

• [SLOW TEST:56.341 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:23:48.312: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 22:23:48.368: INFO: Waiting up to 5m0s for pod "pod-cd6d312a-60b7-429b-afc1-b9455784b741" in namespace "emptydir-7469" to be "success or failure"
Jan 15 22:23:48.370: INFO: Pod "pod-cd6d312a-60b7-429b-afc1-b9455784b741": Phase="Pending", Reason="", readiness=false. Elapsed: 2.798815ms
Jan 15 22:23:50.391: INFO: Pod "pod-cd6d312a-60b7-429b-afc1-b9455784b741": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023338864s
Jan 15 22:23:52.395: INFO: Pod "pod-cd6d312a-60b7-429b-afc1-b9455784b741": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027423218s
STEP: Saw pod success
Jan 15 22:23:52.395: INFO: Pod "pod-cd6d312a-60b7-429b-afc1-b9455784b741" satisfied condition "success or failure"
Jan 15 22:23:52.399: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-cd6d312a-60b7-429b-afc1-b9455784b741 container test-container: <nil>
STEP: delete the pod
Jan 15 22:23:52.422: INFO: Waiting for pod pod-cd6d312a-60b7-429b-afc1-b9455784b741 to disappear
Jan 15 22:23:52.426: INFO: Pod pod-cd6d312a-60b7-429b-afc1-b9455784b741 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:23:52.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7469" for this suite.
Jan 15 22:23:58.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:23:58.621: INFO: namespace emptydir-7469 deletion completed in 6.189015102s

• [SLOW TEST:10.309 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:23:58.621: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:23:58.692: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad" in namespace "projected-8975" to be "success or failure"
Jan 15 22:23:58.697: INFO: Pod "downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.367124ms
Jan 15 22:24:00.700: INFO: Pod "downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007804058s
Jan 15 22:24:02.704: INFO: Pod "downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01175599s
STEP: Saw pod success
Jan 15 22:24:02.704: INFO: Pod "downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad" satisfied condition "success or failure"
Jan 15 22:24:02.707: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad container client-container: <nil>
STEP: delete the pod
Jan 15 22:24:02.738: INFO: Waiting for pod downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad to disappear
Jan 15 22:24:02.742: INFO: Pod downwardapi-volume-4fd309ad-9903-4a98-b408-b603646c57ad no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:24:02.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8975" for this suite.
Jan 15 22:24:08.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:08.900: INFO: namespace projected-8975 deletion completed in 6.150782331s

• [SLOW TEST:10.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:24:08.901: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:24:08.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-881'
Jan 15 22:24:09.054: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 22:24:09.054: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 15 22:24:09.071: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-pzj4b]
Jan 15 22:24:09.072: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-pzj4b" in namespace "kubectl-881" to be "running and ready"
Jan 15 22:24:09.082: INFO: Pod "e2e-test-nginx-rc-pzj4b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.845359ms
Jan 15 22:24:11.087: INFO: Pod "e2e-test-nginx-rc-pzj4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015636879s
Jan 15 22:24:13.091: INFO: Pod "e2e-test-nginx-rc-pzj4b": Phase="Running", Reason="", readiness=true. Elapsed: 4.019450391s
Jan 15 22:24:13.091: INFO: Pod "e2e-test-nginx-rc-pzj4b" satisfied condition "running and ready"
Jan 15 22:24:13.091: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-pzj4b]
Jan 15 22:24:13.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 logs rc/e2e-test-nginx-rc --namespace=kubectl-881'
Jan 15 22:24:13.259: INFO: stderr: ""
Jan 15 22:24:13.259: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Jan 15 22:24:13.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete rc e2e-test-nginx-rc --namespace=kubectl-881'
Jan 15 22:24:13.359: INFO: stderr: ""
Jan 15 22:24:13.359: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:24:13.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-881" for this suite.
Jan 15 22:24:35.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:35.542: INFO: namespace kubectl-881 deletion completed in 22.177594005s

• [SLOW TEST:26.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:24:35.542: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-e3a84fda-7e81-4e72-86f5-05f48b735bef
STEP: Creating a pod to test consume secrets
Jan 15 22:24:35.610: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f" in namespace "projected-6304" to be "success or failure"
Jan 15 22:24:35.614: INFO: Pod "pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.099416ms
Jan 15 22:24:37.617: INFO: Pod "pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006475179s
Jan 15 22:24:39.621: INFO: Pod "pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011086345s
STEP: Saw pod success
Jan 15 22:24:39.622: INFO: Pod "pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f" satisfied condition "success or failure"
Jan 15 22:24:39.624: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:24:39.645: INFO: Waiting for pod pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f to disappear
Jan 15 22:24:39.649: INFO: Pod pod-projected-secrets-78af4bb1-a51e-40b8-802b-e51f3460578f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:24:39.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6304" for this suite.
Jan 15 22:24:45.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:45.843: INFO: namespace projected-6304 deletion completed in 6.185594205s

• [SLOW TEST:10.302 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:24:45.844: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:24:45.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4386" for this suite.
Jan 15 22:25:07.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:25:08.061: INFO: namespace pods-4386 deletion completed in 22.138422834s

• [SLOW TEST:22.217 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:25:08.061: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:25:08.129: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Jan 15 22:25:10.172: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:25:11.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6948" for this suite.
Jan 15 22:25:17.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:25:17.335: INFO: namespace replication-controller-6948 deletion completed in 6.143554106s

• [SLOW TEST:9.274 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:25:17.336: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-fmjc
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:25:17.403: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-fmjc" in namespace "subpath-9731" to be "success or failure"
Jan 15 22:25:17.406: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.909515ms
Jan 15 22:25:19.409: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006595906s
Jan 15 22:25:21.417: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 4.014116013s
Jan 15 22:25:23.422: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 6.019092704s
Jan 15 22:25:25.428: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 8.0257195s
Jan 15 22:25:27.432: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 10.029734078s
Jan 15 22:25:29.436: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 12.033295851s
Jan 15 22:25:31.440: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 14.037691825s
Jan 15 22:25:33.445: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 16.041914895s
Jan 15 22:25:35.449: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 18.046252462s
Jan 15 22:25:37.453: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 20.050140923s
Jan 15 22:25:39.457: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Running", Reason="", readiness=true. Elapsed: 22.054132782s
Jan 15 22:25:41.461: INFO: Pod "pod-subpath-test-secret-fmjc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058058136s
STEP: Saw pod success
Jan 15 22:25:41.461: INFO: Pod "pod-subpath-test-secret-fmjc" satisfied condition "success or failure"
Jan 15 22:25:41.464: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-subpath-test-secret-fmjc container test-container-subpath-secret-fmjc: <nil>
STEP: delete the pod
Jan 15 22:25:41.490: INFO: Waiting for pod pod-subpath-test-secret-fmjc to disappear
Jan 15 22:25:41.494: INFO: Pod pod-subpath-test-secret-fmjc no longer exists
STEP: Deleting pod pod-subpath-test-secret-fmjc
Jan 15 22:25:41.494: INFO: Deleting pod "pod-subpath-test-secret-fmjc" in namespace "subpath-9731"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:25:41.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9731" for this suite.
Jan 15 22:25:47.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:25:47.650: INFO: namespace subpath-9731 deletion completed in 6.145363861s

• [SLOW TEST:30.314 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:25:47.650: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:25:47.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d" in namespace "projected-3670" to be "success or failure"
Jan 15 22:25:47.739: INFO: Pod "downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.931232ms
Jan 15 22:25:49.743: INFO: Pod "downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009917574s
Jan 15 22:25:51.749: INFO: Pod "downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016265525s
STEP: Saw pod success
Jan 15 22:25:51.749: INFO: Pod "downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d" satisfied condition "success or failure"
Jan 15 22:25:51.754: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d container client-container: <nil>
STEP: delete the pod
Jan 15 22:25:51.789: INFO: Waiting for pod downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d to disappear
Jan 15 22:25:51.793: INFO: Pod downwardapi-volume-da27608c-1e6b-40ec-bc1c-7a25798c500d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:25:51.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3670" for this suite.
Jan 15 22:25:57.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:25:58.011: INFO: namespace projected-3670 deletion completed in 6.209070351s

• [SLOW TEST:10.360 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:25:58.011: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8578, will wait for the garbage collector to delete the pods
Jan 15 22:26:02.138: INFO: Deleting Job.batch foo took: 11.515961ms
Jan 15 22:26:02.438: INFO: Terminating Job.batch foo pods took: 300.377407ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:26:36.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8578" for this suite.
Jan 15 22:26:42.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:26:42.931: INFO: namespace job-8578 deletion completed in 6.182424698s

• [SLOW TEST:44.920 seconds]
[sig-apps] Job
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:26:42.931: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-2edf0015-b017-49a8-bc5d-a90493e5ce30
STEP: Creating a pod to test consume configMaps
Jan 15 22:26:42.997: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249" in namespace "projected-626" to be "success or failure"
Jan 15 22:26:43.001: INFO: Pod "pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249": Phase="Pending", Reason="", readiness=false. Elapsed: 3.211017ms
Jan 15 22:26:45.005: INFO: Pod "pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007298675s
Jan 15 22:26:47.008: INFO: Pod "pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010895328s
STEP: Saw pod success
Jan 15 22:26:47.008: INFO: Pod "pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249" satisfied condition "success or failure"
Jan 15 22:26:47.011: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:26:47.031: INFO: Waiting for pod pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249 to disappear
Jan 15 22:26:47.034: INFO: Pod pod-projected-configmaps-bb492c57-5676-490f-ad7b-5c2b1eb32249 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:26:47.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-626" for this suite.
Jan 15 22:26:53.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:26:53.240: INFO: namespace projected-626 deletion completed in 6.199941646s

• [SLOW TEST:10.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:26:53.240: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Jan 15 22:26:57.317: INFO: Pod pod-hostip-deac25ff-a77f-4437-bdda-4e190818e565 has hostIP: 10.240.0.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:26:57.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3925" for this suite.
Jan 15 22:27:19.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:27:19.513: INFO: namespace pods-3925 deletion completed in 22.190968839s

• [SLOW TEST:26.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:27:19.514: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-kbgk
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:27:19.599: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-kbgk" in namespace "subpath-7266" to be "success or failure"
Jan 15 22:27:19.603: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.121122ms
Jan 15 22:27:21.608: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009944538s
Jan 15 22:27:23.613: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 4.014231544s
Jan 15 22:27:25.616: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 6.017958744s
Jan 15 22:27:27.621: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 8.022060344s
Jan 15 22:27:29.624: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 10.025896439s
Jan 15 22:27:31.628: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 12.029825533s
Jan 15 22:27:33.632: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 14.033535122s
Jan 15 22:27:35.636: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 16.037697611s
Jan 15 22:27:37.640: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 18.041772398s
Jan 15 22:27:39.644: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 20.045812281s
Jan 15 22:27:41.649: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Running", Reason="", readiness=true. Elapsed: 22.050119563s
Jan 15 22:27:43.652: INFO: Pod "pod-subpath-test-downwardapi-kbgk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05389474s
STEP: Saw pod success
Jan 15 22:27:43.653: INFO: Pod "pod-subpath-test-downwardapi-kbgk" satisfied condition "success or failure"
Jan 15 22:27:43.656: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-subpath-test-downwardapi-kbgk container test-container-subpath-downwardapi-kbgk: <nil>
STEP: delete the pod
Jan 15 22:27:43.678: INFO: Waiting for pod pod-subpath-test-downwardapi-kbgk to disappear
Jan 15 22:27:43.681: INFO: Pod pod-subpath-test-downwardapi-kbgk no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-kbgk
Jan 15 22:27:43.681: INFO: Deleting pod "pod-subpath-test-downwardapi-kbgk" in namespace "subpath-7266"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:27:43.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7266" for this suite.
Jan 15 22:27:49.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:27:49.920: INFO: namespace subpath-7266 deletion completed in 6.227189253s

• [SLOW TEST:30.406 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:27:49.921: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-f8575caf-4a3f-4d11-a3d9-ec12421a531d
STEP: Creating a pod to test consume secrets
Jan 15 22:27:50.074: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8" in namespace "projected-3686" to be "success or failure"
Jan 15 22:27:50.077: INFO: Pod "pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.154517ms
Jan 15 22:27:52.082: INFO: Pod "pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007837888s
Jan 15 22:27:54.088: INFO: Pod "pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014334366s
STEP: Saw pod success
Jan 15 22:27:54.088: INFO: Pod "pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8" satisfied condition "success or failure"
Jan 15 22:27:54.092: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:27:54.115: INFO: Waiting for pod pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8 to disappear
Jan 15 22:27:54.118: INFO: Pod pod-projected-secrets-558df024-34a2-4c35-9a55-0d761a20ead8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:27:54.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3686" for this suite.
Jan 15 22:28:00.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:00.310: INFO: namespace projected-3686 deletion completed in 6.186717899s

• [SLOW TEST:10.389 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:28:00.311: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Jan 15 22:28:00.400: INFO: Waiting up to 5m0s for pod "client-containers-dad1ac09-4762-4364-ab86-153c51272971" in namespace "containers-3096" to be "success or failure"
Jan 15 22:28:00.403: INFO: Pod "client-containers-dad1ac09-4762-4364-ab86-153c51272971": Phase="Pending", Reason="", readiness=false. Elapsed: 3.601819ms
Jan 15 22:28:02.410: INFO: Pod "client-containers-dad1ac09-4762-4364-ab86-153c51272971": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009797285s
Jan 15 22:28:04.414: INFO: Pod "client-containers-dad1ac09-4762-4364-ab86-153c51272971": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013973938s
STEP: Saw pod success
Jan 15 22:28:04.414: INFO: Pod "client-containers-dad1ac09-4762-4364-ab86-153c51272971" satisfied condition "success or failure"
Jan 15 22:28:04.417: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod client-containers-dad1ac09-4762-4364-ab86-153c51272971 container test-container: <nil>
STEP: delete the pod
Jan 15 22:28:04.439: INFO: Waiting for pod client-containers-dad1ac09-4762-4364-ab86-153c51272971 to disappear
Jan 15 22:28:04.442: INFO: Pod client-containers-dad1ac09-4762-4364-ab86-153c51272971 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:28:04.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3096" for this suite.
Jan 15 22:28:10.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:10.594: INFO: namespace containers-3096 deletion completed in 6.146234947s

• [SLOW TEST:10.283 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:28:10.594: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 22:28:15.174: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a115be1d-14cc-438f-9c7a-2d2b9c8d2e93"
Jan 15 22:28:15.174: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a115be1d-14cc-438f-9c7a-2d2b9c8d2e93" in namespace "pods-3009" to be "terminated due to deadline exceeded"
Jan 15 22:28:15.177: INFO: Pod "pod-update-activedeadlineseconds-a115be1d-14cc-438f-9c7a-2d2b9c8d2e93": Phase="Running", Reason="", readiness=true. Elapsed: 3.083816ms
Jan 15 22:28:17.181: INFO: Pod "pod-update-activedeadlineseconds-a115be1d-14cc-438f-9c7a-2d2b9c8d2e93": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.007069453s
Jan 15 22:28:17.181: INFO: Pod "pod-update-activedeadlineseconds-a115be1d-14cc-438f-9c7a-2d2b9c8d2e93" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:28:17.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3009" for this suite.
Jan 15 22:28:23.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:23.335: INFO: namespace pods-3009 deletion completed in 6.148737613s

• [SLOW TEST:12.741 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:28:23.335: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-51c8e393-665e-46ce-9134-de25bc54c347
STEP: Creating a pod to test consume configMaps
Jan 15 22:28:23.409: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046" in namespace "projected-7025" to be "success or failure"
Jan 15 22:28:23.412: INFO: Pod "pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046": Phase="Pending", Reason="", readiness=false. Elapsed: 3.240917ms
Jan 15 22:28:25.417: INFO: Pod "pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00834215s
Jan 15 22:28:27.421: INFO: Pod "pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012383274s
STEP: Saw pod success
Jan 15 22:28:27.421: INFO: Pod "pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046" satisfied condition "success or failure"
Jan 15 22:28:27.424: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:28:27.446: INFO: Waiting for pod pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046 to disappear
Jan 15 22:28:27.449: INFO: Pod pod-projected-configmaps-fc5ef4bf-8179-4950-a016-52fd3b487046 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:28:27.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7025" for this suite.
Jan 15 22:28:33.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:33.668: INFO: namespace projected-7025 deletion completed in 6.21250771s

• [SLOW TEST:10.333 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:28:33.669: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Jan 15 22:28:33.736: INFO: Waiting up to 5m0s for pod "downward-api-4de43932-ea23-45e8-a339-910c0e0584dd" in namespace "downward-api-1300" to be "success or failure"
Jan 15 22:28:33.740: INFO: Pod "downward-api-4de43932-ea23-45e8-a339-910c0e0584dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042921ms
Jan 15 22:28:35.744: INFO: Pod "downward-api-4de43932-ea23-45e8-a339-910c0e0584dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007639133s
Jan 15 22:28:37.749: INFO: Pod "downward-api-4de43932-ea23-45e8-a339-910c0e0584dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012220949s
STEP: Saw pod success
Jan 15 22:28:37.749: INFO: Pod "downward-api-4de43932-ea23-45e8-a339-910c0e0584dd" satisfied condition "success or failure"
Jan 15 22:28:37.751: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downward-api-4de43932-ea23-45e8-a339-910c0e0584dd container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:28:37.781: INFO: Waiting for pod downward-api-4de43932-ea23-45e8-a339-910c0e0584dd to disappear
Jan 15 22:28:37.784: INFO: Pod downward-api-4de43932-ea23-45e8-a339-910c0e0584dd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:28:37.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1300" for this suite.
Jan 15 22:28:43.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:43.936: INFO: namespace downward-api-1300 deletion completed in 6.147383932s

• [SLOW TEST:10.268 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:28:43.937: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-1706
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1706 to expose endpoints map[]
Jan 15 22:28:43.998: INFO: Get endpoints failed (4.231722ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 15 22:28:45.003: INFO: successfully validated that service endpoint-test2 in namespace services-1706 exposes endpoints map[] (1.009214989s elapsed)
STEP: Creating pod pod1 in namespace services-1706
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1706 to expose endpoints map[pod1:[80]]
Jan 15 22:28:48.050: INFO: successfully validated that service endpoint-test2 in namespace services-1706 exposes endpoints map[pod1:[80]] (3.038907624s elapsed)
STEP: Creating pod pod2 in namespace services-1706
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1706 to expose endpoints map[pod1:[80] pod2:[80]]
Jan 15 22:28:51.107: INFO: successfully validated that service endpoint-test2 in namespace services-1706 exposes endpoints map[pod1:[80] pod2:[80]] (3.051329783s elapsed)
STEP: Deleting pod pod1 in namespace services-1706
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1706 to expose endpoints map[pod2:[80]]
Jan 15 22:28:51.126: INFO: successfully validated that service endpoint-test2 in namespace services-1706 exposes endpoints map[pod2:[80]] (8.696545ms elapsed)
STEP: Deleting pod pod2 in namespace services-1706
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1706 to expose endpoints map[]
Jan 15 22:28:51.140: INFO: successfully validated that service endpoint-test2 in namespace services-1706 exposes endpoints map[] (6.066532ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:28:51.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1706" for this suite.
Jan 15 22:29:13.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:13.361: INFO: namespace services-1706 deletion completed in 22.165717554s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.424 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:29:13.362: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:29:17.623: INFO: DNS probes using dns-test-c2baaf84-9a1b-41d3-9d88-6af3f2836e64 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:29:21.843: INFO: DNS probes using dns-test-36d54a6c-fc9e-4ca5-8f49-fdaf0e01479c succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9919.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9919.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:29:28.075: INFO: DNS probes using dns-test-e559da8f-06e9-46bf-a6d1-62f19cc409ad succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:29:28.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9919" for this suite.
Jan 15 22:29:34.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:34.250: INFO: namespace dns-9919 deletion completed in 6.141317232s

• [SLOW TEST:20.888 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:29:34.250: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-5988
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5988 to expose endpoints map[]
Jan 15 22:29:34.313: INFO: successfully validated that service multi-endpoint-test in namespace services-5988 exposes endpoints map[] (4.260822ms elapsed)
STEP: Creating pod pod1 in namespace services-5988
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5988 to expose endpoints map[pod1:[100]]
Jan 15 22:29:37.354: INFO: successfully validated that service multi-endpoint-test in namespace services-5988 exposes endpoints map[pod1:[100]] (3.0306479s elapsed)
STEP: Creating pod pod2 in namespace services-5988
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5988 to expose endpoints map[pod1:[100] pod2:[101]]
Jan 15 22:29:40.420: INFO: successfully validated that service multi-endpoint-test in namespace services-5988 exposes endpoints map[pod1:[100] pod2:[101]] (3.059855147s elapsed)
STEP: Deleting pod pod1 in namespace services-5988
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5988 to expose endpoints map[pod2:[101]]
Jan 15 22:29:41.446: INFO: successfully validated that service multi-endpoint-test in namespace services-5988 exposes endpoints map[pod2:[101]] (1.018301206s elapsed)
STEP: Deleting pod pod2 in namespace services-5988
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5988 to expose endpoints map[]
Jan 15 22:29:42.461: INFO: successfully validated that service multi-endpoint-test in namespace services-5988 exposes endpoints map[] (1.009784061s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:29:42.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5988" for this suite.
Jan 15 22:30:04.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:04.679: INFO: namespace services-5988 deletion completed in 22.192950102s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:30.429 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:30:04.680: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4051.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4051.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:30:09.463: INFO: DNS probes using dns-4051/dns-test-d6696589-e4ba-4451-b3e4-e660481877b1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:30:09.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4051" for this suite.
Jan 15 22:30:15.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:15.634: INFO: namespace dns-4051 deletion completed in 6.146889834s

• [SLOW TEST:10.954 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:30:15.634: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:30:40.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2288" for this suite.
Jan 15 22:30:46.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:47.088: INFO: namespace container-runtime-2288 deletion completed in 6.143373026s

• [SLOW TEST:31.454 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:30:47.089: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:30:47.151: INFO: (0) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.415243ms)
Jan 15 22:30:47.239: INFO: (1) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.276057ms)
Jan 15 22:30:47.327: INFO: (2) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.074351ms)
Jan 15 22:30:47.415: INFO: (3) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.081056ms)
Jan 15 22:30:47.503: INFO: (4) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.246357ms)
Jan 15 22:30:47.591: INFO: (5) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.511353ms)
Jan 15 22:30:47.679: INFO: (6) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.934555ms)
Jan 15 22:30:47.767: INFO: (7) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.921756ms)
Jan 15 22:30:47.855: INFO: (8) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.054156ms)
Jan 15 22:30:47.943: INFO: (9) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.955856ms)
Jan 15 22:30:48.030: INFO: (10) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.719954ms)
Jan 15 22:30:48.119: INFO: (11) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.372958ms)
Jan 15 22:30:48.207: INFO: (12) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.973856ms)
Jan 15 22:30:48.295: INFO: (13) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.636154ms)
Jan 15 22:30:48.383: INFO: (14) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.487059ms)
Jan 15 22:30:48.471: INFO: (15) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.507553ms)
Jan 15 22:30:48.558: INFO: (16) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.744755ms)
Jan 15 22:30:48.647: INFO: (17) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.675159ms)
Jan 15 22:30:48.734: INFO: (18) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 87.188852ms)
Jan 15 22:30:48.823: INFO: (19) /api/v1/nodes/aks-nodepool1-25266157-vmss000000:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 88.116756ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:30:48.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7601" for this suite.
Jan 15 22:30:54.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:54.980: INFO: namespace proxy-7601 deletion completed in 6.152349352s

• [SLOW TEST:7.891 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:30:54.981: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0115 22:30:56.098784      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 22:30:56.098: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:30:56.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7057" for this suite.
Jan 15 22:31:02.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:02.283: INFO: namespace gc-7057 deletion completed in 6.179806873s

• [SLOW TEST:7.302 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:31:02.283: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-d91a872b-4b5d-4546-8b1a-f2e17d2c23fe
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:31:06.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4977" for this suite.
Jan 15 22:31:28.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:28.604: INFO: namespace configmap-4977 deletion completed in 22.13317224s

• [SLOW TEST:26.321 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:31:28.605: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Jan 15 22:31:28.666: INFO: Waiting up to 5m0s for pod "client-containers-a2d467f9-ee60-4f89-865b-de42e268a994" in namespace "containers-7672" to be "success or failure"
Jan 15 22:31:28.669: INFO: Pod "client-containers-a2d467f9-ee60-4f89-865b-de42e268a994": Phase="Pending", Reason="", readiness=false. Elapsed: 3.052916ms
Jan 15 22:31:30.674: INFO: Pod "client-containers-a2d467f9-ee60-4f89-865b-de42e268a994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007702962s
Jan 15 22:31:32.681: INFO: Pod "client-containers-a2d467f9-ee60-4f89-865b-de42e268a994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014130315s
STEP: Saw pod success
Jan 15 22:31:32.681: INFO: Pod "client-containers-a2d467f9-ee60-4f89-865b-de42e268a994" satisfied condition "success or failure"
Jan 15 22:31:32.684: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod client-containers-a2d467f9-ee60-4f89-865b-de42e268a994 container test-container: <nil>
STEP: delete the pod
Jan 15 22:31:32.707: INFO: Waiting for pod client-containers-a2d467f9-ee60-4f89-865b-de42e268a994 to disappear
Jan 15 22:31:32.711: INFO: Pod client-containers-a2d467f9-ee60-4f89-865b-de42e268a994 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:31:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7672" for this suite.
Jan 15 22:31:38.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:38.897: INFO: namespace containers-7672 deletion completed in 6.181758788s

• [SLOW TEST:10.293 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:31:38.898: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-2921cff7-1c41-4987-88c5-27c2c6331643
STEP: Creating a pod to test consume secrets
Jan 15 22:31:38.964: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29" in namespace "projected-1251" to be "success or failure"
Jan 15 22:31:38.968: INFO: Pod "pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29": Phase="Pending", Reason="", readiness=false. Elapsed: 3.73412ms
Jan 15 22:31:40.972: INFO: Pod "pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008011955s
Jan 15 22:31:42.976: INFO: Pod "pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011901287s
STEP: Saw pod success
Jan 15 22:31:42.976: INFO: Pod "pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29" satisfied condition "success or failure"
Jan 15 22:31:42.979: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:31:43.003: INFO: Waiting for pod pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29 to disappear
Jan 15 22:31:43.008: INFO: Pod pod-projected-secrets-59338890-5e0a-47b0-ae57-5e69c161fe29 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:31:43.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1251" for this suite.
Jan 15 22:31:49.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:49.172: INFO: namespace projected-1251 deletion completed in 6.157467238s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:31:49.173: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 22:31:53.782: INFO: Successfully updated pod "pod-update-a983a8ad-fa67-4ba0-9a3c-ee2f9a255ce0"
STEP: verifying the updated pod is in kubernetes
Jan 15 22:31:53.788: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:31:53.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3431" for this suite.
Jan 15 22:32:15.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:15.957: INFO: namespace pods-3431 deletion completed in 22.16246507s

• [SLOW TEST:26.784 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:32:15.957: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Jan 15 22:32:16.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-1740'
Jan 15 22:32:17.137: INFO: stderr: ""
Jan 15 22:32:17.137: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 22:32:17.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1740'
Jan 15 22:32:17.231: INFO: stderr: ""
Jan 15 22:32:17.231: INFO: stdout: "update-demo-nautilus-qdskj update-demo-nautilus-s7np5 "
Jan 15 22:32:17.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qdskj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1740'
Jan 15 22:32:17.322: INFO: stderr: ""
Jan 15 22:32:17.322: INFO: stdout: ""
Jan 15 22:32:17.322: INFO: update-demo-nautilus-qdskj is created but not running
Jan 15 22:32:22.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1740'
Jan 15 22:32:22.406: INFO: stderr: ""
Jan 15 22:32:22.406: INFO: stdout: "update-demo-nautilus-qdskj update-demo-nautilus-s7np5 "
Jan 15 22:32:22.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qdskj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1740'
Jan 15 22:32:22.493: INFO: stderr: ""
Jan 15 22:32:22.493: INFO: stdout: "true"
Jan 15 22:32:22.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-qdskj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1740'
Jan 15 22:32:22.600: INFO: stderr: ""
Jan 15 22:32:22.600: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 22:32:22.600: INFO: validating pod update-demo-nautilus-qdskj
Jan 15 22:32:22.694: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 22:32:22.694: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 22:32:22.694: INFO: update-demo-nautilus-qdskj is verified up and running
Jan 15 22:32:22.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-s7np5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1740'
Jan 15 22:32:22.779: INFO: stderr: ""
Jan 15 22:32:22.779: INFO: stdout: "true"
Jan 15 22:32:22.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-s7np5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1740'
Jan 15 22:32:22.877: INFO: stderr: ""
Jan 15 22:32:22.877: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 22:32:22.877: INFO: validating pod update-demo-nautilus-s7np5
Jan 15 22:32:22.970: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 22:32:22.970: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 22:32:22.970: INFO: update-demo-nautilus-s7np5 is verified up and running
STEP: using delete to clean up resources
Jan 15 22:32:22.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete --grace-period=0 --force -f - --namespace=kubectl-1740'
Jan 15 22:32:23.060: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 22:32:23.060: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 22:32:23.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1740'
Jan 15 22:32:23.153: INFO: stderr: "No resources found.\n"
Jan 15 22:32:23.153: INFO: stdout: ""
Jan 15 22:32:23.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=update-demo --namespace=kubectl-1740 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:32:23.242: INFO: stderr: ""
Jan 15 22:32:23.242: INFO: stdout: "update-demo-nautilus-qdskj\nupdate-demo-nautilus-s7np5\n"
Jan 15 22:32:23.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1740'
Jan 15 22:32:23.859: INFO: stderr: "No resources found.\n"
Jan 15 22:32:23.859: INFO: stdout: ""
Jan 15 22:32:23.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -l name=update-demo --namespace=kubectl-1740 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:32:23.949: INFO: stderr: ""
Jan 15 22:32:23.949: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:32:23.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1740" for this suite.
Jan 15 22:32:45.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:46.186: INFO: namespace kubectl-1740 deletion completed in 22.228860262s

• [SLOW TEST:30.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:32:46.187: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-xnvk
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:32:46.256: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xnvk" in namespace "subpath-8889" to be "success or failure"
Jan 15 22:32:46.260: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057121ms
Jan 15 22:32:48.264: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008101405s
Jan 15 22:32:50.268: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 4.012470088s
Jan 15 22:32:52.273: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 6.016981871s
Jan 15 22:32:54.277: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 8.021120051s
Jan 15 22:32:56.281: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 10.025031028s
Jan 15 22:32:58.284: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 12.028824503s
Jan 15 22:33:00.290: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 14.034644388s
Jan 15 22:33:02.294: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 16.038677361s
Jan 15 22:33:04.299: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 18.042903134s
Jan 15 22:33:06.302: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 20.046717904s
Jan 15 22:33:08.306: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Running", Reason="", readiness=true. Elapsed: 22.050778374s
Jan 15 22:33:10.312: INFO: Pod "pod-subpath-test-configmap-xnvk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056123749s
STEP: Saw pod success
Jan 15 22:33:10.312: INFO: Pod "pod-subpath-test-configmap-xnvk" satisfied condition "success or failure"
Jan 15 22:33:10.325: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-subpath-test-configmap-xnvk container test-container-subpath-configmap-xnvk: <nil>
STEP: delete the pod
Jan 15 22:33:10.353: INFO: Waiting for pod pod-subpath-test-configmap-xnvk to disappear
Jan 15 22:33:10.356: INFO: Pod pod-subpath-test-configmap-xnvk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xnvk
Jan 15 22:33:10.356: INFO: Deleting pod "pod-subpath-test-configmap-xnvk" in namespace "subpath-8889"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:33:10.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8889" for this suite.
Jan 15 22:33:16.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:16.519: INFO: namespace subpath-8889 deletion completed in 6.152000213s

• [SLOW TEST:30.332 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:33:16.519: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:33:16.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-1998'
Jan 15 22:33:16.660: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 22:33:16.660: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Jan 15 22:33:18.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1998'
Jan 15 22:33:18.774: INFO: stderr: ""
Jan 15 22:33:18.774: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:33:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1998" for this suite.
Jan 15 22:33:40.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:40.967: INFO: namespace kubectl-1998 deletion completed in 22.187512732s

• [SLOW TEST:24.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:33:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Jan 15 22:33:45.586: INFO: Successfully updated pod "labelsupdate2e9ca107-11cc-4df4-bbff-a5fddf4f24cd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:33:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-928" for this suite.
Jan 15 22:34:09.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:34:09.802: INFO: namespace projected-928 deletion completed in 22.147576026s

• [SLOW TEST:28.834 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:34:09.803: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3048
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Jan 15 22:34:09.868: INFO: Found 0 stateful pods, waiting for 3
Jan 15 22:34:19.874: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:19.874: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:19.874: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 22:34:19.910: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 15 22:34:29.949: INFO: Updating stateful set ss2
Jan 15 22:34:29.959: INFO: Waiting for Pod statefulset-3048/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Jan 15 22:34:40.013: INFO: Found 2 stateful pods, waiting for 3
Jan 15 22:34:50.018: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:50.018: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:50.018: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 15 22:34:50.047: INFO: Updating stateful set ss2
Jan 15 22:34:50.058: INFO: Waiting for Pod statefulset-3048/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 22:35:00.094: INFO: Updating stateful set ss2
Jan 15 22:35:00.102: INFO: Waiting for StatefulSet statefulset-3048/ss2 to complete update
Jan 15 22:35:00.102: INFO: Waiting for Pod statefulset-3048/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Jan 15 22:35:10.111: INFO: Waiting for StatefulSet statefulset-3048/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Jan 15 22:35:20.111: INFO: Deleting all statefulset in ns statefulset-3048
Jan 15 22:35:20.116: INFO: Scaling statefulset ss2 to 0
Jan 15 22:35:50.134: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:35:50.139: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:35:50.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3048" for this suite.
Jan 15 22:35:56.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:35:56.369: INFO: namespace statefulset-3048 deletion completed in 6.201649781s

• [SLOW TEST:106.566 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:35:56.370: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8466.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8466.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 243.97.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.97.243_udp@PTR;check="$$(dig +tcp +noall +answer +search 243.97.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.97.243_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8466.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8466.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8466.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 243.97.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.97.243_udp@PTR;check="$$(dig +tcp +noall +answer +search 243.97.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.97.243_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 22:36:00.505: INFO: Unable to read wheezy_udp@dns-test-service.dns-8466.svc.cluster.local from pod dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3: the server could not find the requested resource (get pods dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3)
Jan 15 22:36:00.634: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local from pod dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3: the server could not find the requested resource (get pods dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3)
Jan 15 22:36:00.639: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local from pod dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3: the server could not find the requested resource (get pods dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3)
Jan 15 22:36:01.341: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local from pod dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3: the server could not find the requested resource (get pods dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3)
Jan 15 22:36:01.346: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local from pod dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3: the server could not find the requested resource (get pods dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3)
Jan 15 22:36:01.713: INFO: Lookups using dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3 failed for: [wheezy_udp@dns-test-service.dns-8466.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8466.svc.cluster.local]

Jan 15 22:36:08.287: INFO: DNS probes using dns-8466/dns-test-0967b2c0-476e-423c-a357-4ec1ff3cede3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:36:08.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8466" for this suite.
Jan 15 22:36:14.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:14.564: INFO: namespace dns-8466 deletion completed in 6.184608967s

• [SLOW TEST:18.195 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:36:14.565: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Jan 15 22:36:18.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 exec pod-sharedvolume-ead7b18e-b1e1-4f91-b7b9-53df572e28d1 -c busybox-main-container --namespace=emptydir-2466 -- cat /usr/share/volumeshare/shareddata.txt'
Jan 15 22:36:19.186: INFO: stderr: ""
Jan 15 22:36:19.186: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:36:19.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2466" for this suite.
Jan 15 22:36:25.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:25.361: INFO: namespace emptydir-2466 deletion completed in 6.169527576s

• [SLOW TEST:10.796 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:36:25.363: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:36:25.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5854'
Jan 15 22:36:25.512: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 22:36:25.512: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Jan 15 22:36:27.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5854'
Jan 15 22:36:27.612: INFO: stderr: ""
Jan 15 22:36:27.612: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:36:27.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5854" for this suite.
Jan 15 22:37:51.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:51.802: INFO: namespace kubectl-5854 deletion completed in 1m24.182763678s

• [SLOW TEST:86.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:37:51.802: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 15 22:37:51.878: INFO: Waiting up to 5m0s for pod "pod-0dd15645-3972-4036-868c-126b9e7d5332" in namespace "emptydir-30" to be "success or failure"
Jan 15 22:37:51.893: INFO: Pod "pod-0dd15645-3972-4036-868c-126b9e7d5332": Phase="Pending", Reason="", readiness=false. Elapsed: 14.704374ms
Jan 15 22:37:53.897: INFO: Pod "pod-0dd15645-3972-4036-868c-126b9e7d5332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018863795s
Jan 15 22:37:55.903: INFO: Pod "pod-0dd15645-3972-4036-868c-126b9e7d5332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025403128s
STEP: Saw pod success
Jan 15 22:37:55.903: INFO: Pod "pod-0dd15645-3972-4036-868c-126b9e7d5332" satisfied condition "success or failure"
Jan 15 22:37:55.907: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-0dd15645-3972-4036-868c-126b9e7d5332 container test-container: <nil>
STEP: delete the pod
Jan 15 22:37:55.940: INFO: Waiting for pod pod-0dd15645-3972-4036-868c-126b9e7d5332 to disappear
Jan 15 22:37:55.947: INFO: Pod pod-0dd15645-3972-4036-868c-126b9e7d5332 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:37:55.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-30" for this suite.
Jan 15 22:38:01.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:02.101: INFO: namespace emptydir-30 deletion completed in 6.146884635s

• [SLOW TEST:10.299 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:38:02.101: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 15 22:38:02.184: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21038,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 22:38:02.184: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21039,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 22:38:02.184: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21040,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 15 22:38:12.223: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21058,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 22:38:12.224: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21059,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 15 22:38:12.224: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9931,SelfLink:/api/v1/namespaces/watch-9931/configmaps/e2e-watch-test-label-changed,UID:b2a8ba33-2ee7-41ab-96be-a05ff53f54c2,ResourceVersion:21060,Generation:0,CreationTimestamp:2020-01-15 22:38:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:38:12.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9931" for this suite.
Jan 15 22:38:18.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:18.390: INFO: namespace watch-9931 deletion completed in 6.160667385s

• [SLOW TEST:16.289 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:38:18.390: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-ng2q
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:38:18.476: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ng2q" in namespace "subpath-6393" to be "success or failure"
Jan 15 22:38:18.482: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Pending", Reason="", readiness=false. Elapsed: 5.431827ms
Jan 15 22:38:20.487: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010063541s
Jan 15 22:38:22.491: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 4.014656853s
Jan 15 22:38:24.495: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 6.018650062s
Jan 15 22:38:26.505: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 8.0286345s
Jan 15 22:38:28.509: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 10.032240206s
Jan 15 22:38:30.513: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 12.036388013s
Jan 15 22:38:32.518: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 14.041577025s
Jan 15 22:38:34.523: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 16.046058732s
Jan 15 22:38:36.527: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 18.049957436s
Jan 15 22:38:38.531: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 20.05397484s
Jan 15 22:38:40.535: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Running", Reason="", readiness=true. Elapsed: 22.058543246s
Jan 15 22:38:42.539: INFO: Pod "pod-subpath-test-projected-ng2q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.062796549s
STEP: Saw pod success
Jan 15 22:38:42.539: INFO: Pod "pod-subpath-test-projected-ng2q" satisfied condition "success or failure"
Jan 15 22:38:42.543: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-subpath-test-projected-ng2q container test-container-subpath-projected-ng2q: <nil>
STEP: delete the pod
Jan 15 22:38:42.566: INFO: Waiting for pod pod-subpath-test-projected-ng2q to disappear
Jan 15 22:38:42.570: INFO: Pod pod-subpath-test-projected-ng2q no longer exists
STEP: Deleting pod pod-subpath-test-projected-ng2q
Jan 15 22:38:42.570: INFO: Deleting pod "pod-subpath-test-projected-ng2q" in namespace "subpath-6393"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:38:42.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6393" for this suite.
Jan 15 22:38:48.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:48.735: INFO: namespace subpath-6393 deletion completed in 6.154677722s

• [SLOW TEST:30.345 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:38:48.736: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-658e1ec5-1955-4559-b2d6-fb72c7d7bb9b
STEP: Creating a pod to test consume secrets
Jan 15 22:38:48.794: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560" in namespace "projected-6796" to be "success or failure"
Jan 15 22:38:48.797: INFO: Pod "pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560": Phase="Pending", Reason="", readiness=false. Elapsed: 2.678913ms
Jan 15 22:38:50.801: INFO: Pod "pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006891214s
Jan 15 22:38:52.806: INFO: Pod "pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011242714s
STEP: Saw pod success
Jan 15 22:38:52.806: INFO: Pod "pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560" satisfied condition "success or failure"
Jan 15 22:38:52.808: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:38:52.830: INFO: Waiting for pod pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560 to disappear
Jan 15 22:38:52.833: INFO: Pod pod-projected-secrets-6f1dc0c0-25bf-4d77-82cc-143298848560 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:38:52.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6796" for this suite.
Jan 15 22:38:58.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:59.000: INFO: namespace projected-6796 deletion completed in 6.155978623s

• [SLOW TEST:10.264 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:38:59.000: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:38:59.071: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 15 22:39:04.075: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 22:39:04.075: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 15 22:39:06.080: INFO: Creating deployment "test-rollover-deployment"
Jan 15 22:39:06.090: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 15 22:39:08.099: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 15 22:39:08.109: INFO: Ensure that both replica sets have 1 created replica
Jan 15 22:39:08.117: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 15 22:39:08.126: INFO: Updating deployment test-rollover-deployment
Jan 15 22:39:08.126: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 15 22:39:10.139: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 15 22:39:10.148: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 15 22:39:10.158: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:10.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724748, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:12.167: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:12.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724750, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:14.169: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:14.169: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724750, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:16.167: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:16.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724750, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:18.168: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:18.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724750, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:20.168: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:39:20.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724750, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63714724746, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:39:22.167: INFO: 
Jan 15 22:39:22.167: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Jan 15 22:39:22.185: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6884,SelfLink:/apis/apps/v1/namespaces/deployment-6884/deployments/test-rollover-deployment,UID:803e6dad-34d5-436f-a77a-27328740c2b5,ResourceVersion:21297,Generation:2,CreationTimestamp:2020-01-15 22:39:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-01-15 22:39:06 +0000 UTC 2020-01-15 22:39:06 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-01-15 22:39:20 +0000 UTC 2020-01-15 22:39:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 22:39:22.189: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-6884,SelfLink:/apis/apps/v1/namespaces/deployment-6884/replicasets/test-rollover-deployment-854595fc44,UID:c9ca2788-d408-4288-82ac-973c1aaae269,ResourceVersion:21286,Generation:2,CreationTimestamp:2020-01-15 22:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 803e6dad-34d5-436f-a77a-27328740c2b5 0xc000a4cbe7 0xc000a4cbe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 22:39:22.189: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 15 22:39:22.189: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6884,SelfLink:/apis/apps/v1/namespaces/deployment-6884/replicasets/test-rollover-controller,UID:467d5360-bd99-4ee0-8e38-3c9cf8d28fb7,ResourceVersion:21296,Generation:2,CreationTimestamp:2020-01-15 22:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 803e6dad-34d5-436f-a77a-27328740c2b5 0xc000a4cb17 0xc000a4cb18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:39:22.189: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-6884,SelfLink:/apis/apps/v1/namespaces/deployment-6884/replicasets/test-rollover-deployment-9b8b997cf,UID:36dd1dfb-4f1e-4eae-8c64-4e60deb26744,ResourceVersion:21253,Generation:2,CreationTimestamp:2020-01-15 22:39:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 803e6dad-34d5-436f-a77a-27328740c2b5 0xc000a4ccb0 0xc000a4ccb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:39:22.193: INFO: Pod "test-rollover-deployment-854595fc44-c854f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-c854f,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-6884,SelfLink:/api/v1/namespaces/deployment-6884/pods/test-rollover-deployment-854595fc44-c854f,UID:0bb2bd29-cb3c-4f4b-a690-909ab25e5a08,ResourceVersion:21268,Generation:0,CreationTimestamp:2020-01-15 22:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 c9ca2788-d408-4288-82ac-973c1aaae269 0xc003dc5dd7 0xc003dc5dd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kxhp4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kxhp4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kxhp4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003dc5e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003dc5e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:39:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:39:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:39:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-01-15 22:39:08 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.235,StartTime:2020-01-15 22:39:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-01-15 22:39:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://be4a4be0f47037a1c4b7e8dffe95cb1e9093b9a7f5502170bc310d4b475e7902}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:39:22.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6884" for this suite.
Jan 15 22:39:28.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:39:28.368: INFO: namespace deployment-6884 deletion completed in 6.169797424s

• [SLOW TEST:29.368 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:39:28.369: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 22:39:28.433: INFO: Waiting up to 5m0s for pod "pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0" in namespace "emptydir-6947" to be "success or failure"
Jan 15 22:39:28.437: INFO: Pod "pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.972023ms
Jan 15 22:39:30.442: INFO: Pod "pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008616457s
Jan 15 22:39:32.446: INFO: Pod "pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012564581s
STEP: Saw pod success
Jan 15 22:39:32.446: INFO: Pod "pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0" satisfied condition "success or failure"
Jan 15 22:39:32.448: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0 container test-container: <nil>
STEP: delete the pod
Jan 15 22:39:32.469: INFO: Waiting for pod pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0 to disappear
Jan 15 22:39:32.472: INFO: Pod pod-0889955b-7bf6-4f1b-8021-eca4afd54bb0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:39:32.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6947" for this suite.
Jan 15 22:39:38.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:39:38.697: INFO: namespace emptydir-6947 deletion completed in 6.219872027s

• [SLOW TEST:10.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:39:38.698: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Jan 15 22:39:38.765: INFO: Waiting up to 5m0s for pod "var-expansion-97ffb66a-25ae-498b-a352-568e1d428807" in namespace "var-expansion-8185" to be "success or failure"
Jan 15 22:39:38.774: INFO: Pod "var-expansion-97ffb66a-25ae-498b-a352-568e1d428807": Phase="Pending", Reason="", readiness=false. Elapsed: 8.497748ms
Jan 15 22:39:40.778: INFO: Pod "var-expansion-97ffb66a-25ae-498b-a352-568e1d428807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012608552s
Jan 15 22:39:42.782: INFO: Pod "var-expansion-97ffb66a-25ae-498b-a352-568e1d428807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016702451s
STEP: Saw pod success
Jan 15 22:39:42.782: INFO: Pod "var-expansion-97ffb66a-25ae-498b-a352-568e1d428807" satisfied condition "success or failure"
Jan 15 22:39:42.785: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod var-expansion-97ffb66a-25ae-498b-a352-568e1d428807 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:39:42.807: INFO: Waiting for pod var-expansion-97ffb66a-25ae-498b-a352-568e1d428807 to disappear
Jan 15 22:39:42.810: INFO: Pod var-expansion-97ffb66a-25ae-498b-a352-568e1d428807 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:39:42.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8185" for this suite.
Jan 15 22:39:48.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:39:49.008: INFO: namespace var-expansion-8185 deletion completed in 6.191947587s

• [SLOW TEST:10.310 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:39:49.008: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:39:49.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b" in namespace "projected-8694" to be "success or failure"
Jan 15 22:39:49.078: INFO: Pod "downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.253318ms
Jan 15 22:39:51.083: INFO: Pod "downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007892599s
Jan 15 22:39:53.087: INFO: Pod "downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012362274s
STEP: Saw pod success
Jan 15 22:39:53.088: INFO: Pod "downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b" satisfied condition "success or failure"
Jan 15 22:39:53.091: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b container client-container: <nil>
STEP: delete the pod
Jan 15 22:39:53.112: INFO: Waiting for pod downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b to disappear
Jan 15 22:39:53.115: INFO: Pod downwardapi-volume-0e14a271-148a-47c0-87cf-25a875eb996b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:39:53.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8694" for this suite.
Jan 15 22:39:59.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:39:59.316: INFO: namespace projected-8694 deletion completed in 6.193662216s

• [SLOW TEST:10.309 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:39:59.317: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:40:05.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7861" for this suite.
Jan 15 22:40:11.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:11.663: INFO: namespace namespaces-7861 deletion completed in 6.16475216s
STEP: Destroying namespace "nsdeletetest-6160" for this suite.
Jan 15 22:40:11.667: INFO: Namespace nsdeletetest-6160 was already deleted
STEP: Destroying namespace "nsdeletetest-4169" for this suite.
Jan 15 22:40:17.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:17.825: INFO: namespace nsdeletetest-4169 deletion completed in 6.15864558s

• [SLOW TEST:18.508 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:40:17.826: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Jan 15 22:40:17.891: INFO: Waiting up to 5m0s for pod "var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324" in namespace "var-expansion-938" to be "success or failure"
Jan 15 22:40:17.895: INFO: Pod "var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083818ms
Jan 15 22:40:19.898: INFO: Pod "var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006978924s
Jan 15 22:40:21.906: INFO: Pod "var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01505905s
STEP: Saw pod success
Jan 15 22:40:21.907: INFO: Pod "var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324" satisfied condition "success or failure"
Jan 15 22:40:21.910: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:40:21.932: INFO: Waiting for pod var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324 to disappear
Jan 15 22:40:21.935: INFO: Pod var-expansion-6a4fc46b-3f6a-4a4f-b136-ddd29b58d324 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:40:21.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-938" for this suite.
Jan 15 22:40:27.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:28.088: INFO: namespace var-expansion-938 deletion completed in 6.148121346s

• [SLOW TEST:10.263 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:40:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:40:46.166: INFO: Container started at 2020-01-15 22:40:29 +0000 UTC, pod became ready at 2020-01-15 22:40:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:40:46.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1729" for this suite.
Jan 15 22:41:08.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:08.324: INFO: namespace container-probe-1729 deletion completed in 22.15104612s

• [SLOW TEST:40.235 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:41:08.324: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-3261/secret-test-84fd1e8b-7529-484d-ae10-dc5fd6522156
STEP: Creating a pod to test consume secrets
Jan 15 22:41:08.454: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d" in namespace "secrets-3261" to be "success or failure"
Jan 15 22:41:08.458: INFO: Pod "pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.60292ms
Jan 15 22:41:10.462: INFO: Pod "pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007887015s
Jan 15 22:41:12.469: INFO: Pod "pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014772821s
STEP: Saw pod success
Jan 15 22:41:12.469: INFO: Pod "pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d" satisfied condition "success or failure"
Jan 15 22:41:12.472: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d container env-test: <nil>
STEP: delete the pod
Jan 15 22:41:12.494: INFO: Waiting for pod pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d to disappear
Jan 15 22:41:12.497: INFO: Pod pod-configmaps-ce03ec4c-9826-4b68-a160-0386530ecd3d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:41:12.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3261" for this suite.
Jan 15 22:41:18.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:18.657: INFO: namespace secrets-3261 deletion completed in 6.154814039s

• [SLOW TEST:10.333 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:41:18.658: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Jan 15 22:41:18.712: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:41:19.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6335" for this suite.
Jan 15 22:41:25.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:25.963: INFO: namespace custom-resource-definition-6335 deletion completed in 6.150774869s

• [SLOW TEST:7.305 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:41:25.963: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-330fa879-86ae-4454-9af3-760d0d17bc52
STEP: Creating a pod to test consume secrets
Jan 15 22:41:26.096: INFO: Waiting up to 5m0s for pod "pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141" in namespace "secrets-1610" to be "success or failure"
Jan 15 22:41:26.103: INFO: Pod "pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141": Phase="Pending", Reason="", readiness=false. Elapsed: 6.457036ms
Jan 15 22:41:28.108: INFO: Pod "pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012116501s
STEP: Saw pod success
Jan 15 22:41:28.108: INFO: Pod "pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141" satisfied condition "success or failure"
Jan 15 22:41:28.113: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:41:28.136: INFO: Waiting for pod pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141 to disappear
Jan 15 22:41:28.139: INFO: Pod pod-secrets-71863eb9-6f61-419c-b21b-f84b4c85f141 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:41:28.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1610" for this suite.
Jan 15 22:41:34.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:34.293: INFO: namespace secrets-1610 deletion completed in 6.148122401s
STEP: Destroying namespace "secret-namespace-850" for this suite.
Jan 15 22:41:40.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:40.504: INFO: namespace secret-namespace-850 deletion completed in 6.211130313s

• [SLOW TEST:14.541 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:41:40.506: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Jan 15 22:41:40.564: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:41:43.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2159" for this suite.
Jan 15 22:41:49.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:50.130: INFO: namespace init-container-2159 deletion completed in 6.162821985s

• [SLOW TEST:9.623 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:41:50.130: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Jan 15 22:41:50.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 create -f - --namespace=kubectl-8614'
Jan 15 22:41:50.619: INFO: stderr: ""
Jan 15 22:41:50.619: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 22:41:50.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8614'
Jan 15 22:41:50.723: INFO: stderr: ""
Jan 15 22:41:50.723: INFO: stdout: "update-demo-nautilus-9d2w7 update-demo-nautilus-c787c "
Jan 15 22:41:50.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-9d2w7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:41:50.807: INFO: stderr: ""
Jan 15 22:41:50.807: INFO: stdout: ""
Jan 15 22:41:50.807: INFO: update-demo-nautilus-9d2w7 is created but not running
Jan 15 22:41:55.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8614'
Jan 15 22:41:55.890: INFO: stderr: ""
Jan 15 22:41:55.890: INFO: stdout: "update-demo-nautilus-9d2w7 update-demo-nautilus-c787c "
Jan 15 22:41:55.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-9d2w7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:41:55.986: INFO: stderr: ""
Jan 15 22:41:55.986: INFO: stdout: "true"
Jan 15 22:41:55.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-9d2w7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:41:56.077: INFO: stderr: ""
Jan 15 22:41:56.078: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 22:41:56.078: INFO: validating pod update-demo-nautilus-9d2w7
Jan 15 22:41:56.173: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 22:41:56.173: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 22:41:56.173: INFO: update-demo-nautilus-9d2w7 is verified up and running
Jan 15 22:41:56.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c787c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:41:56.267: INFO: stderr: ""
Jan 15 22:41:56.267: INFO: stdout: "true"
Jan 15 22:41:56.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-nautilus-c787c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:41:56.347: INFO: stderr: ""
Jan 15 22:41:56.347: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 22:41:56.347: INFO: validating pod update-demo-nautilus-c787c
Jan 15 22:41:56.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 22:41:56.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 22:41:56.482: INFO: update-demo-nautilus-c787c is verified up and running
STEP: rolling-update to new replication controller
Jan 15 22:41:56.484: INFO: scanned /root for discovery docs: <nil>
Jan 15 22:41:56.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-8614'
Jan 15 22:42:18.981: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 22:42:18.981: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 22:42:18.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8614'
Jan 15 22:42:19.939: INFO: stderr: ""
Jan 15 22:42:19.939: INFO: stdout: "update-demo-kitten-h9m5n update-demo-kitten-zj6dd "
Jan 15 22:42:19.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-kitten-h9m5n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:42:20.026: INFO: stderr: ""
Jan 15 22:42:20.026: INFO: stdout: "true"
Jan 15 22:42:20.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-kitten-h9m5n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:42:20.113: INFO: stderr: ""
Jan 15 22:42:20.113: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 22:42:20.114: INFO: validating pod update-demo-kitten-h9m5n
Jan 15 22:42:20.250: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 22:42:20.250: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 22:42:20.250: INFO: update-demo-kitten-h9m5n is verified up and running
Jan 15 22:42:20.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-kitten-zj6dd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:42:20.353: INFO: stderr: ""
Jan 15 22:42:20.353: INFO: stdout: "true"
Jan 15 22:42:20.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-089408705 get pods update-demo-kitten-zj6dd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8614'
Jan 15 22:42:20.460: INFO: stderr: ""
Jan 15 22:42:20.460: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 22:42:20.460: INFO: validating pod update-demo-kitten-zj6dd
Jan 15 22:42:20.554: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 22:42:20.554: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 22:42:20.554: INFO: update-demo-kitten-zj6dd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:42:20.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8614" for this suite.
Jan 15 22:42:42.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:42:42.729: INFO: namespace kubectl-8614 deletion completed in 22.16749292s

• [SLOW TEST:52.598 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Jan 15 22:42:42.735: INFO: >>> kubeConfig: /tmp/kubeconfig-089408705
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 22:42:42.801: INFO: Waiting up to 5m0s for pod "pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296" in namespace "emptydir-7054" to be "success or failure"
Jan 15 22:42:42.805: INFO: Pod "pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296": Phase="Pending", Reason="", readiness=false. Elapsed: 3.498619ms
Jan 15 22:42:44.810: INFO: Pod "pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008921936s
Jan 15 22:42:46.818: INFO: Pod "pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01623056s
STEP: Saw pod success
Jan 15 22:42:46.818: INFO: Pod "pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296" satisfied condition "success or failure"
Jan 15 22:42:46.820: INFO: Trying to get logs from node aks-nodepool1-25266157-vmss000001 pod pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296 container test-container: <nil>
STEP: delete the pod
Jan 15 22:42:46.882: INFO: Waiting for pod pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296 to disappear
Jan 15 22:42:46.889: INFO: Pod pod-99c6818f-93ee-4af3-89a0-f1f41fb9b296 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Jan 15 22:42:46.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7054" for this suite.
Jan 15 22:42:52.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:42:53.090: INFO: namespace emptydir-7054 deletion completed in 6.194346895s

• [SLOW TEST:10.356 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSJan 15 22:42:53.090: INFO: Running AfterSuite actions on all nodes
Jan 15 22:42:53.090: INFO: Running AfterSuite actions on node 1
Jan 15 22:42:53.091: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 6049.723 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h40m51.16025113s
Test Suite Passed
