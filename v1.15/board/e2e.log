I1210 09:27:38.886431      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-132482711
I1210 09:27:38.886514      15 e2e.go:241] Starting e2e run "3944fac4-c0e0-4fbc-8eca-f2c5247d4f7b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575970058 - Will randomize all specs
Will run 215 of 4413 specs

Dec 10 09:27:38.958: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:27:38.960: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 10 09:27:39.132: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 10 09:27:39.222: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 10 09:27:39.222: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec 10 09:27:39.222: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 10 09:27:39.262: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-mips64le' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 10 09:27:39.262: INFO: e2e test version: v1.15.3
Dec 10 09:27:39.274: INFO: kube-apiserver version: v1.15.3-1+0c6be0f131f191-dirty
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:27:39.274: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
Dec 10 09:27:39.493: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec 10 09:27:39.544: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 09:27:39.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a" in namespace "projected-2574" to be "success or failure"
Dec 10 09:27:39.745: INFO: Pod "downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.846259ms
Dec 10 09:27:41.763: INFO: Pod "downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03593419s
Dec 10 09:27:43.782: INFO: Pod "downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055416872s
STEP: Saw pod success
Dec 10 09:27:43.783: INFO: Pod "downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a" satisfied condition "success or failure"
Dec 10 09:27:43.801: INFO: Trying to get logs from node node1 pod downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a container client-container: <nil>
STEP: delete the pod
Dec 10 09:27:43.892: INFO: Waiting for pod downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a to disappear
Dec 10 09:27:43.907: INFO: Pod downwardapi-volume-3d53acea-d0d8-47b1-9f74-4d2b3fee219a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:27:43.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2574" for this suite.
Dec 10 09:27:49.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:27:50.567: INFO: namespace projected-2574 deletion completed in 6.628796075s

• [SLOW TEST:11.293 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:27:50.567: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:27:50.907: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:27:53.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9184" for this suite.
Dec 10 09:28:33.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:28:33.811: INFO: namespace pods-9184 deletion completed in 40.62553419s

• [SLOW TEST:43.243 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:28:33.811: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3999
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 10 09:28:42.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:42.391: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:44.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:44.410: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:46.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:46.409: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:48.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:48.411: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:50.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:50.413: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:52.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:52.410: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:54.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:54.411: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:56.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:56.412: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:28:58.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:28:58.411: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 09:29:00.392: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 09:29:00.411: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:29:00.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3999" for this suite.
Dec 10 09:29:24.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:29:25.115: INFO: namespace container-lifecycle-hook-3999 deletion completed in 24.631548512s

• [SLOW TEST:51.304 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:29:25.115: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9737
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 09:29:25.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104" in namespace "downward-api-9737" to be "success or failure"
Dec 10 09:29:25.510: INFO: Pod "downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104": Phase="Pending", Reason="", readiness=false. Elapsed: 21.129206ms
Dec 10 09:29:27.536: INFO: Pod "downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047576705s
Dec 10 09:29:29.554: INFO: Pod "downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065490159s
STEP: Saw pod success
Dec 10 09:29:29.554: INFO: Pod "downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104" satisfied condition "success or failure"
Dec 10 09:29:29.571: INFO: Trying to get logs from node node1 pod downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104 container client-container: <nil>
STEP: delete the pod
Dec 10 09:29:29.648: INFO: Waiting for pod downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104 to disappear
Dec 10 09:29:29.663: INFO: Pod downwardapi-volume-5fb46a12-556b-4762-b767-b81c26886104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:29:29.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9737" for this suite.
Dec 10 09:29:35.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:29:36.334: INFO: namespace downward-api-9737 deletion completed in 6.639154039s

• [SLOW TEST:11.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:29:36.334: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-81b573f7-dce9-48aa-972b-390560e6e2af
STEP: Creating a pod to test consume secrets
Dec 10 09:29:36.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778" in namespace "projected-138" to be "success or failure"
Dec 10 09:29:36.755: INFO: Pod "pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778": Phase="Pending", Reason="", readiness=false. Elapsed: 19.056177ms
Dec 10 09:29:38.774: INFO: Pod "pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038627461s
Dec 10 09:29:40.800: INFO: Pod "pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064004273s
STEP: Saw pod success
Dec 10 09:29:40.800: INFO: Pod "pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778" satisfied condition "success or failure"
Dec 10 09:29:40.820: INFO: Trying to get logs from node node1 pod pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 09:29:40.923: INFO: Waiting for pod pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778 to disappear
Dec 10 09:29:40.940: INFO: Pod pod-projected-secrets-070e00c5-5413-49f8-a6d2-975aec0a0778 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:29:40.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-138" for this suite.
Dec 10 09:29:47.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:29:47.596: INFO: namespace projected-138 deletion completed in 6.625736292s

• [SLOW TEST:11.262 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:29:47.596: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Dec 10 09:29:47.981: INFO: Waiting up to 5m0s for pod "var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd" in namespace "var-expansion-2067" to be "success or failure"
Dec 10 09:29:47.999: INFO: Pod "var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.355278ms
Dec 10 09:29:50.024: INFO: Pod "var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042305885s
Dec 10 09:29:52.042: INFO: Pod "var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060548964s
STEP: Saw pod success
Dec 10 09:29:52.042: INFO: Pod "var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd" satisfied condition "success or failure"
Dec 10 09:29:52.059: INFO: Trying to get logs from node node1 pod var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd container dapi-container: <nil>
STEP: delete the pod
Dec 10 09:29:52.138: INFO: Waiting for pod var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd to disappear
Dec 10 09:29:52.153: INFO: Pod var-expansion-0de2b55e-25e1-45b3-99fb-1b25343597bd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:29:52.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2067" for this suite.
Dec 10 09:29:58.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:29:58.846: INFO: namespace var-expansion-2067 deletion completed in 6.661891541s

• [SLOW TEST:11.250 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:29:58.846: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:30:59.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8626" for this suite.
Dec 10 09:31:23.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:31:23.952: INFO: namespace container-probe-8626 deletion completed in 24.658214598s

• [SLOW TEST:85.106 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:31:23.953: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3428
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:31:52.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3428" for this suite.
Dec 10 09:31:58.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:31:59.013: INFO: namespace container-runtime-3428 deletion completed in 6.656096136s

• [SLOW TEST:35.060 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:31:59.014: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 10 09:31:59.479: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3536,SelfLink:/api/v1/namespaces/watch-3536/configmaps/e2e-watch-test-watch-closed,UID:a16528d7-3379-45a0-95ba-4293059aabc4,ResourceVersion:159578,Generation:0,CreationTimestamp:2019-12-10 09:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 09:31:59.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3536,SelfLink:/api/v1/namespaces/watch-3536/configmaps/e2e-watch-test-watch-closed,UID:a16528d7-3379-45a0-95ba-4293059aabc4,ResourceVersion:159579,Generation:0,CreationTimestamp:2019-12-10 09:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 10 09:31:59.558: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3536,SelfLink:/api/v1/namespaces/watch-3536/configmaps/e2e-watch-test-watch-closed,UID:a16528d7-3379-45a0-95ba-4293059aabc4,ResourceVersion:159580,Generation:0,CreationTimestamp:2019-12-10 09:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 09:31:59.558: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3536,SelfLink:/api/v1/namespaces/watch-3536/configmaps/e2e-watch-test-watch-closed,UID:a16528d7-3379-45a0-95ba-4293059aabc4,ResourceVersion:159581,Generation:0,CreationTimestamp:2019-12-10 09:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:31:59.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3536" for this suite.
Dec 10 09:32:05.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:32:06.239: INFO: namespace watch-3536 deletion completed in 6.659491067s

• [SLOW TEST:7.225 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:32:06.239: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9909
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-3b7c7c9b-8a80-4550-a3cc-15e5aa7d9d93
STEP: Creating secret with name s-test-opt-upd-967ae8fb-f96f-4e04-9d79-5f7a1de83067
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3b7c7c9b-8a80-4550-a3cc-15e5aa7d9d93
STEP: Updating secret s-test-opt-upd-967ae8fb-f96f-4e04-9d79-5f7a1de83067
STEP: Creating secret with name s-test-opt-create-36fa1ee8-3f5b-4fc5-b377-ede121b8b584
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:32:13.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9909" for this suite.
Dec 10 09:32:37.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:32:37.682: INFO: namespace secrets-9909 deletion completed in 24.611422533s

• [SLOW TEST:31.443 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:32:37.683: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 10 09:32:38.061: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 09:32:38.107: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 09:32:38.123: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Dec 10 09:32:38.155: INFO: kube-flannel-ds-amd64-v9n9h from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 09:32:38.156: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 10 09:32:38.156: INFO: sonobuoy from sonobuoy started at 2019-12-10 09:27:35 +0000 UTC (1 container statuses recorded)
Dec 10 09:32:38.156: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 09:32:38.156: INFO: kube-proxy-722tg from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 09:32:38.156: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 09:32:38.156: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Dec 10 09:32:38.211: INFO: kube-proxy-hbqzb from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 09:32:38.211: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 09:32:38.211: INFO: kube-flannel-ds-amd64-mszct from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 09:32:38.211: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 10 09:32:38.211: INFO: sonobuoy-e2e-job-95f5741cd1964606 from sonobuoy started at 2019-12-10 09:27:36 +0000 UTC (2 container statuses recorded)
Dec 10 09:32:38.211: INFO: 	Container e2e ready: true, restart count 0
Dec 10 09:32:38.211: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15def8a3cb898f5c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) were unschedulable, 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:32:39.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4832" for this suite.
Dec 10 09:32:45.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:32:46.099: INFO: namespace sched-pred-4832 deletion completed in 6.695372079s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:8.417 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:32:46.100: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-5af4ec18-4f45-4a70-8616-61b59e1ea0b5
STEP: Creating a pod to test consume configMaps
Dec 10 09:32:46.527: INFO: Waiting up to 5m0s for pod "pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e" in namespace "configmap-4884" to be "success or failure"
Dec 10 09:32:46.548: INFO: Pod "pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e": Phase="Pending", Reason="", readiness=false. Elapsed: 21.012111ms
Dec 10 09:32:48.565: INFO: Pod "pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038048603s
Dec 10 09:32:50.585: INFO: Pod "pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057782795s
STEP: Saw pod success
Dec 10 09:32:50.585: INFO: Pod "pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e" satisfied condition "success or failure"
Dec 10 09:32:50.601: INFO: Trying to get logs from node node1 pod pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 09:32:50.675: INFO: Waiting for pod pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e to disappear
Dec 10 09:32:50.690: INFO: Pod pod-configmaps-00d90191-7e4c-483d-9faa-b2eb96db0d0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:32:50.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4884" for this suite.
Dec 10 09:32:56.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:32:57.385: INFO: namespace configmap-4884 deletion completed in 6.665441328s

• [SLOW TEST:11.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:32:57.386: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:33:01.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1182" for this suite.
Dec 10 09:33:47.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:33:48.562: INFO: namespace kubelet-test-1182 deletion completed in 46.679509121s

• [SLOW TEST:51.176 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:33:48.562: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 10 09:33:59.235: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1210 09:33:59.235629      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:33:59.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6674" for this suite.
Dec 10 09:34:07.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:34:08.043: INFO: namespace gc-6674 deletion completed in 8.784267963s

• [SLOW TEST:19.481 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:34:08.044: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9289
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 10 09:34:08.453: INFO: Found 0 stateful pods, waiting for 3
Dec 10 09:34:18.475: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:34:18.475: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:34:18.475: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:34:18.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-9289 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:34:20.439: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:34:20.439: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:34:20.439: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 10 09:34:30.564: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 10 09:34:40.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-9289 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 09:34:41.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 09:34:41.311: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 09:34:41.311: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 09:35:01.427: INFO: Waiting for StatefulSet statefulset-9289/ss2 to complete update
Dec 10 09:35:01.427: INFO: Waiting for Pod statefulset-9289/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Dec 10 09:35:11.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-9289 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:35:12.262: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:35:12.262: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:35:12.262: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 09:35:22.391: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 10 09:35:32.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-9289 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 09:35:33.185: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 09:35:33.185: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 09:35:33.185: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 09:35:43.293: INFO: Waiting for StatefulSet statefulset-9289/ss2 to complete update
Dec 10 09:35:43.293: INFO: Waiting for Pod statefulset-9289/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 10 09:35:43.293: INFO: Waiting for Pod statefulset-9289/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 10 09:35:43.293: INFO: Waiting for Pod statefulset-9289/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 10 09:35:53.337: INFO: Waiting for StatefulSet statefulset-9289/ss2 to complete update
Dec 10 09:35:53.337: INFO: Waiting for Pod statefulset-9289/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 10 09:35:53.337: INFO: Waiting for Pod statefulset-9289/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 10 09:36:03.336: INFO: Waiting for StatefulSet statefulset-9289/ss2 to complete update
Dec 10 09:36:03.337: INFO: Waiting for Pod statefulset-9289/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 10 09:36:13.330: INFO: Deleting all statefulset in ns statefulset-9289
Dec 10 09:36:13.348: INFO: Scaling statefulset ss2 to 0
Dec 10 09:36:33.449: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 09:36:33.465: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:36:33.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9289" for this suite.
Dec 10 09:36:41.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:36:42.276: INFO: namespace statefulset-9289 deletion completed in 8.707337369s

• [SLOW TEST:154.232 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:36:42.278: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8246
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8246
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8246
Dec 10 09:36:42.682: INFO: Found 0 stateful pods, waiting for 1
Dec 10 09:36:52.702: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 10 09:36:52.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:36:53.503: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:36:53.503: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:36:53.503: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 09:36:53.521: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 09:37:03.542: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 09:37:03.542: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 09:37:03.622: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:03.622: INFO: ss-0  node1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:35:46 +0000 UTC  }]
Dec 10 09:37:03.623: INFO: ss-1         Pending         []
Dec 10 09:37:03.623: INFO: 
Dec 10 09:37:03.623: INFO: StatefulSet ss has not reached scale 3, at 2
Dec 10 09:37:04.646: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.970831406s
Dec 10 09:37:05.667: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.947078228s
Dec 10 09:37:06.688: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.925845279s
Dec 10 09:37:07.714: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.904978481s
Dec 10 09:37:08.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.879009671s
Dec 10 09:37:09.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.859168193s
Dec 10 09:37:10.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.838867442s
Dec 10 09:37:11.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.816817239s
Dec 10 09:37:12.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 795.965717ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8246
Dec 10 09:37:13.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 09:37:14.534: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 09:37:14.534: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 09:37:14.534: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 09:37:14.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 09:37:15.208: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 10 09:37:15.208: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 09:37:15.208: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 09:37:15.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 09:37:15.905: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 10 09:37:15.905: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 09:37:15.905: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 09:37:15.924: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:37:15.924: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:37:15.924: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 10 09:37:15.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:37:16.600: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:37:16.600: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:37:16.600: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 09:37:16.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:37:17.349: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:37:17.349: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:37:17.349: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 09:37:17.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8246 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 09:37:18.087: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 09:37:18.087: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 09:37:18.087: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 09:37:18.087: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 09:37:18.103: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 10 09:37:28.143: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 09:37:28.143: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 09:37:28.143: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 09:37:28.207: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:28.207: INFO: ss-0  node1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:35:46 +0000 UTC  }]
Dec 10 09:37:28.207: INFO: ss-1  node2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:28.207: INFO: ss-2  node2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:28.207: INFO: 
Dec 10 09:37:28.207: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 09:37:29.227: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:29.227: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:35:46 +0000 UTC  }]
Dec 10 09:37:29.227: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:29.227: INFO: ss-2  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:29.227: INFO: 
Dec 10 09:37:29.227: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 09:37:30.248: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:30.248: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:35:46 +0000 UTC  }]
Dec 10 09:37:30.248: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:30.248: INFO: ss-2  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:30.248: INFO: 
Dec 10 09:37:30.248: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 09:37:31.269: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:31.269: INFO: ss-0  node1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:35:46 +0000 UTC  }]
Dec 10 09:37:31.269: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:31.269: INFO: ss-2  node2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:31.269: INFO: 
Dec 10 09:37:31.269: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 09:37:32.291: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:32.291: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:32.291: INFO: ss-2  node2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:32.291: INFO: 
Dec 10 09:37:32.291: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 10 09:37:33.311: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:33.311: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:33.311: INFO: ss-2  node2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:33.311: INFO: 
Dec 10 09:37:33.311: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 10 09:37:34.332: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec 10 09:37:34.332: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:34.332: INFO: ss-2  node2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:36:07 +0000 UTC  }]
Dec 10 09:37:34.332: INFO: 
Dec 10 09:37:34.332: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 10 09:37:35.350: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.851363008s
Dec 10 09:37:36.367: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.83287472s
Dec 10 09:37:37.386: INFO: Verifying statefulset ss doesn't scale past 0 for another 815.867738ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8246
Dec 10 09:37:38.409: INFO: Scaling statefulset ss to 0
Dec 10 09:37:38.480: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 10 09:37:38.504: INFO: Deleting all statefulset in ns statefulset-8246
Dec 10 09:37:38.521: INFO: Scaling statefulset ss to 0
Dec 10 09:37:38.571: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 09:37:38.586: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:37:38.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8246" for this suite.
Dec 10 09:37:46.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:37:47.450: INFO: namespace statefulset-8246 deletion completed in 8.759599519s

• [SLOW TEST:65.172 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:37:47.450: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Dec 10 09:37:47.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-9115'
Dec 10 09:37:48.697: INFO: stderr: ""
Dec 10 09:37:48.697: INFO: stdout: "pod/pause created\n"
Dec 10 09:37:48.697: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 10 09:37:48.697: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9115" to be "running and ready"
Dec 10 09:37:48.712: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.978557ms
Dec 10 09:37:50.729: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03175719s
Dec 10 09:37:52.749: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.051642573s
Dec 10 09:37:52.749: INFO: Pod "pause" satisfied condition "running and ready"
Dec 10 09:37:52.749: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 10 09:37:52.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 label pods pause testing-label=testing-label-value --namespace=kubectl-9115'
Dec 10 09:37:53.014: INFO: stderr: ""
Dec 10 09:37:53.014: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 10 09:37:53.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pod pause -L testing-label --namespace=kubectl-9115'
Dec 10 09:37:53.231: INFO: stderr: ""
Dec 10 09:37:53.231: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 10 09:37:53.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 label pods pause testing-label- --namespace=kubectl-9115'
Dec 10 09:37:53.457: INFO: stderr: ""
Dec 10 09:37:53.457: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 10 09:37:53.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pod pause -L testing-label --namespace=kubectl-9115'
Dec 10 09:37:53.692: INFO: stderr: ""
Dec 10 09:37:53.693: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Dec 10 09:37:53.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-9115'
Dec 10 09:37:53.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 09:37:53.970: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 10 09:37:53.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get rc,svc -l name=pause --no-headers --namespace=kubectl-9115'
Dec 10 09:37:54.238: INFO: stderr: "No resources found.\n"
Dec 10 09:37:54.238: INFO: stdout: ""
Dec 10 09:37:54.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -l name=pause --namespace=kubectl-9115 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 09:37:54.438: INFO: stderr: ""
Dec 10 09:37:54.438: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:37:54.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9115" for this suite.
Dec 10 09:38:00.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:38:01.136: INFO: namespace kubectl-9115 deletion completed in 6.667604691s

• [SLOW TEST:13.686 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:38:01.136: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7379
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 10 09:38:05.628: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-4f9172d7-a78d-45d4-a890-cd2fba57061c,GenerateName:,Namespace:events-7379,SelfLink:/api/v1/namespaces/events-7379/pods/send-events-4f9172d7-a78d-45d4-a890-cd2fba57061c,UID:c1862581-1605-4707-b811-71c62cbc3f26,ResourceVersion:160985,Generation:0,CreationTimestamp:2019-12-10 09:37:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 486328179,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pkdrj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pkdrj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-pkdrj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c175c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c175e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:38:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:38:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:38:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:37:05 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:10.253.1.77,StartTime:2019-12-10 09:38:02 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-12-10 09:38:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker://sha256:c6b8a28d5611cf83d297661ddd7f40672d286eafd7eb3852267e634e8eee0948 docker://f7a38e08e0d3268605f3e3fbfb49b6b2e30d2af17b8419a215fe0b2983e8907b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 10 09:38:07.650: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 10 09:38:09.672: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:38:09.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7379" for this suite.
Dec 10 09:38:49.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:38:50.375: INFO: namespace events-7379 deletion completed in 40.645270971s

• [SLOW TEST:49.239 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:38:50.375: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 09:38:55.374: INFO: Successfully updated pod "pod-update-d465aa3a-a8aa-41c3-8989-0f5db2a44a09"
STEP: verifying the updated pod is in kubernetes
Dec 10 09:38:55.414: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:38:55.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9675" for this suite.
Dec 10 09:39:19.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:39:20.152: INFO: namespace pods-9675 deletion completed in 24.706452603s

• [SLOW TEST:29.777 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:39:20.153: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 10 09:39:20.541: INFO: Waiting up to 5m0s for pod "downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891" in namespace "downward-api-4909" to be "success or failure"
Dec 10 09:39:20.571: INFO: Pod "downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891": Phase="Pending", Reason="", readiness=false. Elapsed: 30.040849ms
Dec 10 09:39:22.589: INFO: Pod "downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047317612s
Dec 10 09:39:24.607: INFO: Pod "downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065908523s
STEP: Saw pod success
Dec 10 09:39:24.607: INFO: Pod "downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891" satisfied condition "success or failure"
Dec 10 09:39:24.624: INFO: Trying to get logs from node node1 pod downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891 container dapi-container: <nil>
STEP: delete the pod
Dec 10 09:39:24.733: INFO: Waiting for pod downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891 to disappear
Dec 10 09:39:24.754: INFO: Pod downward-api-8a2b5b56-182e-4256-a4ad-b28c68482891 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:39:24.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4909" for this suite.
Dec 10 09:39:30.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:39:31.410: INFO: namespace downward-api-4909 deletion completed in 6.622461117s

• [SLOW TEST:11.257 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:39:31.411: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 10 09:39:31.757: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 09:39:31.806: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 09:39:31.832: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Dec 10 09:39:31.868: INFO: sonobuoy from sonobuoy started at 2019-12-10 09:27:35 +0000 UTC (1 container statuses recorded)
Dec 10 09:39:31.868: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 09:39:31.868: INFO: kube-proxy-722tg from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 09:39:31.868: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 09:39:31.868: INFO: kube-flannel-ds-amd64-v9n9h from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 09:39:31.868: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 10 09:39:31.868: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Dec 10 09:39:31.925: INFO: sonobuoy-e2e-job-95f5741cd1964606 from sonobuoy started at 2019-12-10 09:27:36 +0000 UTC (2 container statuses recorded)
Dec 10 09:39:31.925: INFO: 	Container e2e ready: true, restart count 0
Dec 10 09:39:31.925: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 09:39:31.925: INFO: kube-proxy-hbqzb from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 09:39:31.925: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 09:39:31.925: INFO: kube-flannel-ds-amd64-mszct from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 09:39:31.925: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node node1
STEP: verifying the node has the label node node2
Dec 10 09:39:32.080: INFO: Pod kube-flannel-ds-amd64-mszct requesting resource cpu=100m on Node node2
Dec 10 09:39:32.080: INFO: Pod kube-flannel-ds-amd64-v9n9h requesting resource cpu=100m on Node node1
Dec 10 09:39:32.080: INFO: Pod kube-proxy-722tg requesting resource cpu=0m on Node node1
Dec 10 09:39:32.080: INFO: Pod kube-proxy-hbqzb requesting resource cpu=0m on Node node2
Dec 10 09:39:32.080: INFO: Pod sonobuoy requesting resource cpu=0m on Node node1
Dec 10 09:39:32.080: INFO: Pod sonobuoy-e2e-job-95f5741cd1964606 requesting resource cpu=0m on Node node2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0.15def904245169fe], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1480/filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0 to node2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0.15def911a369dc4f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0.15def911b3df5579], Reason = [Created], Message = [Created container filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0.15def911cf650286], Reason = [Started], Message = [Started container filler-pod-195718ba-792a-415a-863b-3fd02d18c6e0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a.15def90422f133ff], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1480/filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a to node1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a.15def911c64fa4ff], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a.15def911d7827621], Reason = [Created], Message = [Created container filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a.15def911f25b27fb], Reason = [Started], Message = [Started container filler-pod-6a2c796d-52f7-4f0b-82e1-54188c55cb1a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15def905190afedf], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) were unschedulable, 2 Insufficient cpu.]
STEP: removing the label node off the node node1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:39:37.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1480" for this suite.
Dec 10 09:39:43.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:39:44.114: INFO: namespace sched-pred-1480 deletion completed in 6.660946887s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.703 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:39:44.114: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:39:44.459: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 10 09:39:44.509: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 09:39:48.570: INFO: Creating deployment "test-rolling-update-deployment"
Dec 10 09:39:48.592: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 10 09:39:48.628: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 10 09:39:50.665: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 10 09:39:50.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567532, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567532, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567532, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567532, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 09:39:52.704: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 10 09:39:52.761: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1530,SelfLink:/apis/apps/v1/namespaces/deployment-1530/deployments/test-rolling-update-deployment,UID:be245d56-7403-49e9-bcb4-23a8dbf6b8d6,ResourceVersion:161311,Generation:1,CreationTimestamp:2019-12-10 09:38:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-10 09:38:52 +0000 UTC 2019-12-10 09:38:52 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-10 09:38:54 +0000 UTC 2019-12-10 09:38:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 09:39:52.780: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-1530,SelfLink:/apis/apps/v1/namespaces/deployment-1530/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:4ab9f4dd-f8e2-4d25-888a-4be289c109e8,ResourceVersion:161300,Generation:1,CreationTimestamp:2019-12-10 09:38:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment be245d56-7403-49e9-bcb4-23a8dbf6b8d6 0xc002a63917 0xc002a63918}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 10 09:39:52.780: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 10 09:39:52.780: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1530,SelfLink:/apis/apps/v1/namespaces/deployment-1530/replicasets/test-rolling-update-controller,UID:db1a6d60-bd3f-4c26-9eb2-15f6f703c486,ResourceVersion:161310,Generation:2,CreationTimestamp:2019-12-10 09:38:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment be245d56-7403-49e9-bcb4-23a8dbf6b8d6 0xc002a63847 0xc002a63848}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 09:39:52.800: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-4smvh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-4smvh,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-1530,SelfLink:/api/v1/namespaces/deployment-1530/pods/test-rolling-update-deployment-79f6b9d75c-4smvh,UID:40fb20c8-721e-4c13-973b-23006912fd8e,ResourceVersion:161299,Generation:0,CreationTimestamp:2019-12-10 09:38:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 4ab9f4dd-f8e2-4d25-888a-4be289c109e8 0xc0022c81d7 0xc0022c81d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p72dm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p72dm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p72dm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c8250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c8270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:39:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:39:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:39:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:38:52 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.78,StartTime:2019-12-10 09:39:48 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-10 09:39:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://60b1d603fb71840cfd9b73194814d9ea8e8e8fed68dc711acf57bd1ffa4dad88}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:39:52.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1530" for this suite.
Dec 10 09:40:00.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:40:01.491: INFO: namespace deployment-1530 deletion completed in 8.656760073s

• [SLOW TEST:17.377 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:40:01.492: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:40:19.940: INFO: Container started at 2019-12-10 09:40:03 +0000 UTC, pod became ready at 2019-12-10 09:40:19 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:40:19.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8066" for this suite.
Dec 10 09:40:44.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:40:44.649: INFO: namespace container-probe-8066 deletion completed in 24.678896529s

• [SLOW TEST:43.157 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:40:44.649: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 10 09:40:45.016: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:40:49.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4540" for this suite.
Dec 10 09:41:13.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:41:14.168: INFO: namespace init-container-4540 deletion completed in 24.672905725s

• [SLOW TEST:29.519 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:41:14.168: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-18a05afc-527a-4e2c-9201-eb6181c1f6f2
STEP: Creating a pod to test consume secrets
Dec 10 09:41:14.568: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35" in namespace "projected-3321" to be "success or failure"
Dec 10 09:41:14.584: INFO: Pod "pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35": Phase="Pending", Reason="", readiness=false. Elapsed: 16.426433ms
Dec 10 09:41:16.605: INFO: Pod "pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037193427s
Dec 10 09:41:18.623: INFO: Pod "pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055298156s
STEP: Saw pod success
Dec 10 09:41:18.623: INFO: Pod "pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35" satisfied condition "success or failure"
Dec 10 09:41:18.640: INFO: Trying to get logs from node node1 pod pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 09:41:18.716: INFO: Waiting for pod pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35 to disappear
Dec 10 09:41:18.737: INFO: Pod pod-projected-secrets-b3ab5f02-0ae2-44d3-8ce0-f3c0b2aa3c35 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:41:18.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3321" for this suite.
Dec 10 09:41:24.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:41:25.401: INFO: namespace projected-3321 deletion completed in 6.631342845s

• [SLOW TEST:11.233 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:41:25.402: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:41:25.795: INFO: Creating deployment "test-recreate-deployment"
Dec 10 09:41:25.839: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 10 09:41:25.891: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 10 09:41:27.927: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 10 09:41:27.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567629, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567629, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567629, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711567629, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 09:41:29.966: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 10 09:41:30.004: INFO: Updating deployment test-recreate-deployment
Dec 10 09:41:30.004: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 10 09:41:30.212: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4643,SelfLink:/apis/apps/v1/namespaces/deployment-4643/deployments/test-recreate-deployment,UID:09b373c0-e86e-4c4d-ab98-5e516f08884a,ResourceVersion:161622,Generation:2,CreationTimestamp:2019-12-10 09:40:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-12-10 09:40:33 +0000 UTC 2019-12-10 09:40:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-10 09:40:33 +0000 UTC 2019-12-10 09:40:29 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 10 09:41:30.233: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-4643,SelfLink:/apis/apps/v1/namespaces/deployment-4643/replicasets/test-recreate-deployment-5c8c9cc69d,UID:a7c804c2-5cdf-4706-89a0-48032e0062c9,ResourceVersion:161620,Generation:1,CreationTimestamp:2019-12-10 09:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 09b373c0-e86e-4c4d-ab98-5e516f08884a 0xc001c92027 0xc001c92028}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 09:41:30.233: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 10 09:41:30.233: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-4643,SelfLink:/apis/apps/v1/namespaces/deployment-4643/replicasets/test-recreate-deployment-6df85df6b9,UID:9d1812a7-e2a5-45b4-b388-ef62317c94b8,ResourceVersion:161611,Generation:2,CreationTimestamp:2019-12-10 09:40:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 09b373c0-e86e-4c4d-ab98-5e516f08884a 0xc001c920f7 0xc001c920f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 09:41:30.259: INFO: Pod "test-recreate-deployment-5c8c9cc69d-jgqlw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-jgqlw,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-4643,SelfLink:/api/v1/namespaces/deployment-4643/pods/test-recreate-deployment-5c8c9cc69d-jgqlw,UID:98c21047-a962-4626-ae56-fce60b2ef85a,ResourceVersion:161617,Generation:0,CreationTimestamp:2019-12-10 09:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d a7c804c2-5cdf-4706-89a0-48032e0062c9 0xc0047a6297 0xc0047a6298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bgkgw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bgkgw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bgkgw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0047a6310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0047a6330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:40:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:41:30.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4643" for this suite.
Dec 10 09:41:36.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:41:36.961: INFO: namespace deployment-4643 deletion completed in 6.669624384s

• [SLOW TEST:11.559 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:41:36.961: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1423
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 09:41:37.359: INFO: Waiting up to 5m0s for pod "pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df" in namespace "emptydir-1423" to be "success or failure"
Dec 10 09:41:37.378: INFO: Pod "pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df": Phase="Pending", Reason="", readiness=false. Elapsed: 19.287104ms
Dec 10 09:41:39.397: INFO: Pod "pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037921185s
Dec 10 09:41:41.416: INFO: Pod "pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057084666s
STEP: Saw pod success
Dec 10 09:41:41.416: INFO: Pod "pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df" satisfied condition "success or failure"
Dec 10 09:41:41.435: INFO: Trying to get logs from node node1 pod pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df container test-container: <nil>
STEP: delete the pod
Dec 10 09:41:41.534: INFO: Waiting for pod pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df to disappear
Dec 10 09:41:41.550: INFO: Pod pod-ad7e6366-6ecf-4bbc-8e5c-b1e56bb411df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:41:41.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1423" for this suite.
Dec 10 09:41:47.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:41:48.240: INFO: namespace emptydir-1423 deletion completed in 6.649341111s

• [SLOW TEST:11.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:41:48.240: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7574
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-d056cf80-b176-4d0a-8c4d-50573d3efaba
STEP: Creating configMap with name cm-test-opt-upd-699c4777-ce32-4ff0-bc6e-5d8b610acbf2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d056cf80-b176-4d0a-8c4d-50573d3efaba
STEP: Updating configmap cm-test-opt-upd-699c4777-ce32-4ff0-bc6e-5d8b610acbf2
STEP: Creating configMap with name cm-test-opt-create-92240ebb-70fc-4c40-8f43-4a234a36b022
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:43:15.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7574" for this suite.
Dec 10 09:43:39.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:43:39.697: INFO: namespace projected-7574 deletion completed in 24.652741115s

• [SLOW TEST:111.457 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:43:39.697: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-8a818fdd-b144-46dc-b082-32624d7a62e0
STEP: Creating a pod to test consume configMaps
Dec 10 09:43:40.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98" in namespace "projected-1264" to be "success or failure"
Dec 10 09:43:40.146: INFO: Pod "pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98": Phase="Pending", Reason="", readiness=false. Elapsed: 20.319143ms
Dec 10 09:43:42.165: INFO: Pod "pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039145701s
Dec 10 09:43:44.184: INFO: Pod "pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057980697s
STEP: Saw pod success
Dec 10 09:43:44.184: INFO: Pod "pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98" satisfied condition "success or failure"
Dec 10 09:43:44.211: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 09:43:44.322: INFO: Waiting for pod pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98 to disappear
Dec 10 09:43:44.375: INFO: Pod pod-projected-configmaps-650fd814-996f-4660-b665-90d7c74b1d98 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:43:44.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1264" for this suite.
Dec 10 09:43:50.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:43:51.072: INFO: namespace projected-1264 deletion completed in 6.663251648s

• [SLOW TEST:11.375 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:43:51.072: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3851
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3851.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3851.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 09:43:55.808: INFO: DNS probes using dns-3851/dns-test-ca2f0d5b-55ce-4402-8061-156e53153e32 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:43:55.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3851" for this suite.
Dec 10 09:44:01.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:44:02.519: INFO: namespace dns-3851 deletion completed in 6.630306523s

• [SLOW TEST:11.447 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:44:02.520: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Dec 10 09:44:02.891: INFO: Waiting up to 5m0s for pod "var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b" in namespace "var-expansion-3335" to be "success or failure"
Dec 10 09:44:02.912: INFO: Pod "var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.205692ms
Dec 10 09:44:04.933: INFO: Pod "var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041616702s
Dec 10 09:44:06.955: INFO: Pod "var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063427976s
STEP: Saw pod success
Dec 10 09:44:06.955: INFO: Pod "var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b" satisfied condition "success or failure"
Dec 10 09:44:06.971: INFO: Trying to get logs from node node1 pod var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b container dapi-container: <nil>
STEP: delete the pod
Dec 10 09:44:07.057: INFO: Waiting for pod var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b to disappear
Dec 10 09:44:07.072: INFO: Pod var-expansion-0dc81091-0193-47e5-8d31-68c9b93c7c8b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:44:07.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3335" for this suite.
Dec 10 09:44:13.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:44:13.722: INFO: namespace var-expansion-3335 deletion completed in 6.619448778s

• [SLOW TEST:11.202 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:44:13.723: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9110
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 09:44:14.071: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 09:44:34.441: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.253.2.80:8080/dial?request=hostName&protocol=udp&host=10.253.1.92&port=8081&tries=1'] Namespace:pod-network-test-9110 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:44:34.441: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:44:34.934: INFO: Waiting for endpoints: map[]
Dec 10 09:44:34.951: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.253.2.80:8080/dial?request=hostName&protocol=udp&host=10.253.2.79&port=8081&tries=1'] Namespace:pod-network-test-9110 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:44:34.951: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:44:35.395: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:44:35.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9110" for this suite.
Dec 10 09:44:59.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:45:00.088: INFO: namespace pod-network-test-9110 deletion completed in 24.660317972s

• [SLOW TEST:46.365 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:45:00.088: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Dec 10 09:45:00.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 cluster-info'
Dec 10 09:45:02.108: INFO: stderr: ""
Dec 10 09:45:02.108: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:45:02.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6726" for this suite.
Dec 10 09:45:08.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:45:08.857: INFO: namespace kubectl-6726 deletion completed in 6.711467456s

• [SLOW TEST:8.769 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:45:08.858: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2999
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2999
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 10 09:45:09.322: INFO: Found 0 stateful pods, waiting for 3
Dec 10 09:45:19.348: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:45:19.348: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:45:19.348: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 10 09:45:19.450: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 10 09:45:29.581: INFO: Updating stateful set ss2
Dec 10 09:45:29.621: INFO: Waiting for Pod statefulset-2999/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Dec 10 09:45:39.810: INFO: Found 2 stateful pods, waiting for 3
Dec 10 09:45:49.833: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:45:49.833: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 09:45:49.833: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 10 09:45:49.918: INFO: Updating stateful set ss2
Dec 10 09:45:49.955: INFO: Waiting for Pod statefulset-2999/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 10 09:46:00.046: INFO: Updating stateful set ss2
Dec 10 09:46:00.082: INFO: Waiting for StatefulSet statefulset-2999/ss2 to complete update
Dec 10 09:46:00.082: INFO: Waiting for Pod statefulset-2999/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 10 09:46:10.116: INFO: Deleting all statefulset in ns statefulset-2999
Dec 10 09:46:10.132: INFO: Scaling statefulset ss2 to 0
Dec 10 09:46:30.271: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 09:46:30.293: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:46:30.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2999" for this suite.
Dec 10 09:46:38.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:46:39.046: INFO: namespace statefulset-2999 deletion completed in 8.656239906s

• [SLOW TEST:90.189 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:46:39.046: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 09:46:39.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7" in namespace "downward-api-5702" to be "success or failure"
Dec 10 09:46:39.454: INFO: Pod "downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.467717ms
Dec 10 09:46:41.472: INFO: Pod "downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042698464s
Dec 10 09:46:43.492: INFO: Pod "downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06276805s
STEP: Saw pod success
Dec 10 09:46:43.492: INFO: Pod "downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7" satisfied condition "success or failure"
Dec 10 09:46:43.509: INFO: Trying to get logs from node node1 pod downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7 container client-container: <nil>
STEP: delete the pod
Dec 10 09:46:43.610: INFO: Waiting for pod downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7 to disappear
Dec 10 09:46:43.627: INFO: Pod downwardapi-volume-e7be81ef-01e7-4402-ae1c-494361b1cbe7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:46:43.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5702" for this suite.
Dec 10 09:46:49.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:46:50.346: INFO: namespace downward-api-5702 deletion completed in 6.687255774s

• [SLOW TEST:11.299 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:46:50.346: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 10 09:46:55.340: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1868 pod-service-account-aa668d10-02a1-4c94-99f0-bb1f5f7b45b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 10 09:46:56.062: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1868 pod-service-account-aa668d10-02a1-4c94-99f0-bb1f5f7b45b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 10 09:46:56.790: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1868 pod-service-account-aa668d10-02a1-4c94-99f0-bb1f5f7b45b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:46:57.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1868" for this suite.
Dec 10 09:47:03.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:47:04.205: INFO: namespace svcaccounts-1868 deletion completed in 6.682929381s

• [SLOW TEST:13.859 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:47:04.205: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 09:47:04.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24" in namespace "downward-api-5694" to be "success or failure"
Dec 10 09:47:04.616: INFO: Pod "downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24": Phase="Pending", Reason="", readiness=false. Elapsed: 24.144827ms
Dec 10 09:47:06.635: INFO: Pod "downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043329601s
Dec 10 09:47:08.659: INFO: Pod "downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067389989s
STEP: Saw pod success
Dec 10 09:47:08.659: INFO: Pod "downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24" satisfied condition "success or failure"
Dec 10 09:47:08.680: INFO: Trying to get logs from node node1 pod downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24 container client-container: <nil>
STEP: delete the pod
Dec 10 09:47:08.756: INFO: Waiting for pod downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24 to disappear
Dec 10 09:47:08.772: INFO: Pod downwardapi-volume-f4c44d80-a233-4bd5-b1a7-b85a9a088a24 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:47:08.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5694" for this suite.
Dec 10 09:47:14.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:47:15.440: INFO: namespace downward-api-5694 deletion completed in 6.63551259s

• [SLOW TEST:11.235 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:47:15.440: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9647
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:47:15.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9647" for this suite.
Dec 10 09:47:21.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:47:22.606: INFO: namespace services-9647 deletion completed in 6.754355479s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:7.166 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:47:22.607: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 09:47:22.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5913'
Dec 10 09:47:23.189: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 10 09:47:23.189: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Dec 10 09:47:25.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5913'
Dec 10 09:47:25.485: INFO: stderr: ""
Dec 10 09:47:25.485: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:47:25.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5913" for this suite.
Dec 10 09:47:31.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:47:32.174: INFO: namespace kubectl-5913 deletion completed in 6.637860538s

• [SLOW TEST:9.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:47:32.175: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 10 09:48:02.669: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:48:02.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1210 09:48:02.669295      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-667" for this suite.
Dec 10 09:48:08.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:48:09.429: INFO: namespace gc-667 deletion completed in 6.737536883s

• [SLOW TEST:37.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:48:09.430: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a511b270-2ee5-4ff1-831e-6cc9b94bcc46
STEP: Creating a pod to test consume configMaps
Dec 10 09:48:10.031: INFO: Waiting up to 5m0s for pod "pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40" in namespace "configmap-9564" to be "success or failure"
Dec 10 09:48:10.046: INFO: Pod "pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40": Phase="Pending", Reason="", readiness=false. Elapsed: 14.831498ms
Dec 10 09:48:12.064: INFO: Pod "pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032393943s
Dec 10 09:48:14.081: INFO: Pod "pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049397482s
STEP: Saw pod success
Dec 10 09:48:14.081: INFO: Pod "pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40" satisfied condition "success or failure"
Dec 10 09:48:14.097: INFO: Trying to get logs from node node1 pod pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 09:48:14.168: INFO: Waiting for pod pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40 to disappear
Dec 10 09:48:14.182: INFO: Pod pod-configmaps-9008d019-57ef-4282-8f33-92f4021fba40 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:48:14.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9564" for this suite.
Dec 10 09:48:20.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:48:20.880: INFO: namespace configmap-9564 deletion completed in 6.667407704s

• [SLOW TEST:11.450 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:48:20.880: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-986244d8-3c8b-4ee5-8e48-0dcc62b47458
STEP: Creating a pod to test consume configMaps
Dec 10 09:48:21.270: INFO: Waiting up to 5m0s for pod "pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5" in namespace "configmap-5605" to be "success or failure"
Dec 10 09:48:21.291: INFO: Pod "pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 21.390634ms
Dec 10 09:48:23.310: INFO: Pod "pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040411642s
Dec 10 09:48:25.336: INFO: Pod "pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065712475s
STEP: Saw pod success
Dec 10 09:48:25.336: INFO: Pod "pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5" satisfied condition "success or failure"
Dec 10 09:48:25.354: INFO: Trying to get logs from node node1 pod pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 09:48:25.427: INFO: Waiting for pod pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5 to disappear
Dec 10 09:48:25.446: INFO: Pod pod-configmaps-48f68e7f-4dbd-4cd3-b558-cd2b148d4eb5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:48:25.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5605" for this suite.
Dec 10 09:48:31.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:48:32.159: INFO: namespace configmap-5605 deletion completed in 6.682156509s

• [SLOW TEST:11.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:48:32.159: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-60
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658
Dec 10 09:48:32.614: INFO: Pod name my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658: Found 0 pods out of 1
Dec 10 09:48:37.633: INFO: Pod name my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658: Found 1 pods out of 1
Dec 10 09:48:37.633: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658" are running
Dec 10 09:48:37.650: INFO: Pod "my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658-zh7cs" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 09:48:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 09:48:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 09:48:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 09:47:36 +0000 UTC Reason: Message:}])
Dec 10 09:48:37.650: INFO: Trying to dial the pod
Dec 10 09:48:42.724: INFO: Controller my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658: Got expected result from replica 1 [my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658-zh7cs]: "my-hostname-basic-1a782441-65bc-4b01-820e-3f5ccb4d3658-zh7cs", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:48:42.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-60" for this suite.
Dec 10 09:48:48.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:48:49.393: INFO: namespace replication-controller-60 deletion completed in 6.635067541s

• [SLOW TEST:17.234 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:48:49.393: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-tj4z
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 09:48:49.837: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tj4z" in namespace "subpath-4810" to be "success or failure"
Dec 10 09:48:49.856: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Pending", Reason="", readiness=false. Elapsed: 19.492845ms
Dec 10 09:48:51.873: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036368392s
Dec 10 09:48:53.892: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 4.055230745s
Dec 10 09:48:55.912: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 6.075250776s
Dec 10 09:48:57.933: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 8.096786879s
Dec 10 09:48:59.954: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 10.117823398s
Dec 10 09:49:01.973: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 12.136172013s
Dec 10 09:49:03.990: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 14.153344919s
Dec 10 09:49:06.007: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 16.170183985s
Dec 10 09:49:08.025: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 18.188223729s
Dec 10 09:49:10.048: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 20.211221687s
Dec 10 09:49:12.066: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Running", Reason="", readiness=true. Elapsed: 22.229680092s
Dec 10 09:49:14.104: INFO: Pod "pod-subpath-test-secret-tj4z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.267526694s
STEP: Saw pod success
Dec 10 09:49:14.104: INFO: Pod "pod-subpath-test-secret-tj4z" satisfied condition "success or failure"
Dec 10 09:49:14.121: INFO: Trying to get logs from node node1 pod pod-subpath-test-secret-tj4z container test-container-subpath-secret-tj4z: <nil>
STEP: delete the pod
Dec 10 09:49:14.202: INFO: Waiting for pod pod-subpath-test-secret-tj4z to disappear
Dec 10 09:49:14.217: INFO: Pod pod-subpath-test-secret-tj4z no longer exists
STEP: Deleting pod pod-subpath-test-secret-tj4z
Dec 10 09:49:14.217: INFO: Deleting pod "pod-subpath-test-secret-tj4z" in namespace "subpath-4810"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:49:14.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4810" for this suite.
Dec 10 09:49:20.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:49:20.917: INFO: namespace subpath-4810 deletion completed in 6.61825266s

• [SLOW TEST:31.523 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:49:20.917: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3333/configmap-test-01dd7bbf-918f-428f-a850-fdca67acfa4f
STEP: Creating a pod to test consume configMaps
Dec 10 09:49:21.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b" in namespace "configmap-3333" to be "success or failure"
Dec 10 09:49:21.370: INFO: Pod "pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.731447ms
Dec 10 09:49:23.390: INFO: Pod "pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037489935s
Dec 10 09:49:25.411: INFO: Pod "pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057947109s
STEP: Saw pod success
Dec 10 09:49:25.411: INFO: Pod "pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b" satisfied condition "success or failure"
Dec 10 09:49:25.430: INFO: Trying to get logs from node node1 pod pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b container env-test: <nil>
STEP: delete the pod
Dec 10 09:49:25.527: INFO: Waiting for pod pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b to disappear
Dec 10 09:49:25.542: INFO: Pod pod-configmaps-5b692bfe-42c7-4573-8994-16720de6cd0b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:49:25.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3333" for this suite.
Dec 10 09:49:31.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:49:32.217: INFO: namespace configmap-3333 deletion completed in 6.643843032s

• [SLOW TEST:11.300 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:49:32.217: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 09:49:32.594: INFO: Waiting up to 5m0s for pod "downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9" in namespace "projected-5848" to be "success or failure"
Dec 10 09:49:32.619: INFO: Pod "downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.598639ms
Dec 10 09:49:34.638: INFO: Pod "downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043376784s
Dec 10 09:49:36.658: INFO: Pod "downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063767535s
STEP: Saw pod success
Dec 10 09:49:36.658: INFO: Pod "downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9" satisfied condition "success or failure"
Dec 10 09:49:36.675: INFO: Trying to get logs from node node1 pod downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9 container client-container: <nil>
STEP: delete the pod
Dec 10 09:49:36.761: INFO: Waiting for pod downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9 to disappear
Dec 10 09:49:36.777: INFO: Pod downwardapi-volume-773382c7-f8f4-411b-a62f-91fc2594f8d9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:49:36.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5848" for this suite.
Dec 10 09:49:42.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:49:43.445: INFO: namespace projected-5848 deletion completed in 6.637176917s

• [SLOW TEST:11.228 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:49:43.445: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 10 09:49:43.834: INFO: Waiting up to 5m0s for pod "downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181" in namespace "downward-api-8929" to be "success or failure"
Dec 10 09:49:43.855: INFO: Pod "downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181": Phase="Pending", Reason="", readiness=false. Elapsed: 21.702242ms
Dec 10 09:49:45.876: INFO: Pod "downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04216291s
Dec 10 09:49:47.898: INFO: Pod "downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063977204s
STEP: Saw pod success
Dec 10 09:49:47.898: INFO: Pod "downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181" satisfied condition "success or failure"
Dec 10 09:49:47.915: INFO: Trying to get logs from node node1 pod downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181 container dapi-container: <nil>
STEP: delete the pod
Dec 10 09:49:48.035: INFO: Waiting for pod downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181 to disappear
Dec 10 09:49:48.051: INFO: Pod downward-api-88f0cea3-ddac-4d8a-9249-f9dda4275181 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:49:48.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8929" for this suite.
Dec 10 09:49:54.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:49:54.899: INFO: namespace downward-api-8929 deletion completed in 6.815634609s

• [SLOW TEST:11.453 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:49:54.899: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1053
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:49:55.444: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f934bdb6-aab5-4eb4-b55f-dfb743707a12", Controller:(*bool)(0xc00274281a), BlockOwnerDeletion:(*bool)(0xc00274281b)}}
Dec 10 09:49:55.469: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"709aa0ec-7ab1-464d-9a85-a967fc20bb92", Controller:(*bool)(0xc002742a1a), BlockOwnerDeletion:(*bool)(0xc002742a1b)}}
Dec 10 09:49:55.520: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"5573091d-279b-4e35-aac1-78e58d8127ff", Controller:(*bool)(0xc0027fe922), BlockOwnerDeletion:(*bool)(0xc0027fe923)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:50:00.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1053" for this suite.
Dec 10 09:50:06.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:50:07.258: INFO: namespace gc-1053 deletion completed in 6.662940856s

• [SLOW TEST:12.359 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:50:07.259: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Dec 10 09:50:07.640: INFO: Waiting up to 5m0s for pod "client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61" in namespace "containers-3019" to be "success or failure"
Dec 10 09:50:07.658: INFO: Pod "client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61": Phase="Pending", Reason="", readiness=false. Elapsed: 17.215523ms
Dec 10 09:50:09.696: INFO: Pod "client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055283571s
Dec 10 09:50:11.716: INFO: Pod "client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075724063s
STEP: Saw pod success
Dec 10 09:50:11.716: INFO: Pod "client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61" satisfied condition "success or failure"
Dec 10 09:50:11.734: INFO: Trying to get logs from node node1 pod client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61 container test-container: <nil>
STEP: delete the pod
Dec 10 09:50:11.836: INFO: Waiting for pod client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61 to disappear
Dec 10 09:50:11.857: INFO: Pod client-containers-9ca75d1c-c5c2-4458-af45-72dec24e1d61 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:50:11.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3019" for this suite.
Dec 10 09:50:17.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:50:18.537: INFO: namespace containers-3019 deletion completed in 6.646341385s

• [SLOW TEST:11.278 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:50:18.538: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 10 09:50:18.922: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:50:36.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5884" for this suite.
Dec 10 09:50:42.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:50:43.397: INFO: namespace pods-5884 deletion completed in 6.657454038s

• [SLOW TEST:24.859 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:50:43.397: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 09:50:43.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8359'
Dec 10 09:50:43.986: INFO: stderr: ""
Dec 10 09:50:43.987: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Dec 10 09:50:44.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete pods e2e-test-nginx-pod --namespace=kubectl-8359'
Dec 10 09:50:47.208: INFO: stderr: ""
Dec 10 09:50:47.208: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:50:47.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8359" for this suite.
Dec 10 09:50:53.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:50:53.874: INFO: namespace kubectl-8359 deletion completed in 6.635040253s

• [SLOW TEST:10.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:50:53.875: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 09:50:54.257: INFO: Waiting up to 5m0s for pod "pod-771c8d2c-22bd-48b5-927b-2680aadb82f6" in namespace "emptydir-1959" to be "success or failure"
Dec 10 09:50:54.281: INFO: Pod "pod-771c8d2c-22bd-48b5-927b-2680aadb82f6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.110415ms
Dec 10 09:50:56.307: INFO: Pod "pod-771c8d2c-22bd-48b5-927b-2680aadb82f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049566798s
Dec 10 09:50:58.350: INFO: Pod "pod-771c8d2c-22bd-48b5-927b-2680aadb82f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.093106785s
STEP: Saw pod success
Dec 10 09:50:58.350: INFO: Pod "pod-771c8d2c-22bd-48b5-927b-2680aadb82f6" satisfied condition "success or failure"
Dec 10 09:50:58.368: INFO: Trying to get logs from node node1 pod pod-771c8d2c-22bd-48b5-927b-2680aadb82f6 container test-container: <nil>
STEP: delete the pod
Dec 10 09:50:58.452: INFO: Waiting for pod pod-771c8d2c-22bd-48b5-927b-2680aadb82f6 to disappear
Dec 10 09:50:58.471: INFO: Pod pod-771c8d2c-22bd-48b5-927b-2680aadb82f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:50:58.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1959" for this suite.
Dec 10 09:51:04.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:51:05.179: INFO: namespace emptydir-1959 deletion completed in 6.629112153s

• [SLOW TEST:11.305 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:51:05.180: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-95a8d70c-3891-451b-932c-a2ffe754df18
STEP: Creating a pod to test consume configMaps
Dec 10 09:51:05.586: INFO: Waiting up to 5m0s for pod "pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0" in namespace "configmap-1385" to be "success or failure"
Dec 10 09:51:05.606: INFO: Pod "pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.351076ms
Dec 10 09:51:07.624: INFO: Pod "pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038555001s
Dec 10 09:51:09.645: INFO: Pod "pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058816727s
STEP: Saw pod success
Dec 10 09:51:09.645: INFO: Pod "pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0" satisfied condition "success or failure"
Dec 10 09:51:09.669: INFO: Trying to get logs from node node1 pod pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 09:51:09.751: INFO: Waiting for pod pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0 to disappear
Dec 10 09:51:09.767: INFO: Pod pod-configmaps-2991b2d8-56a0-4e33-b222-fb858e6c40d0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:51:09.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1385" for this suite.
Dec 10 09:51:15.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:51:16.438: INFO: namespace configmap-1385 deletion completed in 6.639908124s

• [SLOW TEST:11.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:51:16.438: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 09:51:16.791: INFO: Creating deployment "nginx-deployment"
Dec 10 09:51:16.816: INFO: Waiting for observed generation 1
Dec 10 09:51:18.855: INFO: Waiting for all required pods to come up
Dec 10 09:51:18.885: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 10 09:51:24.942: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 10 09:51:24.977: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 10 09:51:25.016: INFO: Updating deployment nginx-deployment
Dec 10 09:51:25.016: INFO: Waiting for observed generation 2
Dec 10 09:51:27.050: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 10 09:51:27.065: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 10 09:51:27.081: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 10 09:51:27.126: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 10 09:51:27.126: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 10 09:51:27.149: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 10 09:51:27.187: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 10 09:51:27.187: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 10 09:51:27.224: INFO: Updating deployment nginx-deployment
Dec 10 09:51:27.224: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 10 09:51:27.276: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 10 09:51:29.323: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 10 09:51:29.355: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-342,SelfLink:/apis/apps/v1/namespaces/deployment-342/deployments/nginx-deployment,UID:008531ce-45d3-45ec-a1b0-e82d990c3bcd,ResourceVersion:163842,Generation:3,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-12-10 09:50:30 +0000 UTC 2019-12-10 09:50:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-10 09:50:31 +0000 UTC 2019-12-10 09:50:20 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 10 09:51:29.374: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-342,SelfLink:/apis/apps/v1/namespaces/deployment-342/replicasets/nginx-deployment-55fb7cb77f,UID:94540e36-f73c-4e01-abd2-aef5896312c6,ResourceVersion:163839,Generation:3,CreationTimestamp:2019-12-10 09:50:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 008531ce-45d3-45ec-a1b0-e82d990c3bcd 0xc0026259f7 0xc0026259f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 09:51:29.374: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 10 09:51:29.374: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-342,SelfLink:/apis/apps/v1/namespaces/deployment-342/replicasets/nginx-deployment-7b8c6f4498,UID:43b3a1e9-1820-4992-b44c-de5ca1edbbe3,ResourceVersion:163838,Generation:3,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 008531ce-45d3-45ec-a1b0-e82d990c3bcd 0xc002625ac7 0xc002625ac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 10 09:51:29.424: INFO: Pod "nginx-deployment-55fb7cb77f-6cppn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6cppn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-6cppn,UID:c9c39ce9-f13c-49c2-86c9-3c044ebf69d5,ResourceVersion:163860,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e84e97 0xc002e84e98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e84f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e84f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.424: INFO: Pod "nginx-deployment-55fb7cb77f-9wxrg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9wxrg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-9wxrg,UID:7baf8f1d-2322-48a8-84a4-758c6220a68f,ResourceVersion:163881,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85000 0xc002e85001}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e850a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.424: INFO: Pod "nginx-deployment-55fb7cb77f-bcqsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bcqsc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-bcqsc,UID:c0f57589-07cc-4ec4-8122-06230ab3ed3a,ResourceVersion:163825,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85170 0xc002e85171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e851f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.425: INFO: Pod "nginx-deployment-55fb7cb77f-d2x56" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d2x56,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-d2x56,UID:7d0c3bb0-3ed1-4cbe-8ccd-6b7059269a44,ResourceVersion:163847,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85290 0xc002e85291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:30 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.425: INFO: Pod "nginx-deployment-55fb7cb77f-g8t49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-g8t49,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-g8t49,UID:667dd1df-b23a-41ea-991e-ba73624df248,ResourceVersion:163770,Generation:0,CreationTimestamp:2019-12-10 09:50:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85400 0xc002e85401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e854a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:29 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.425: INFO: Pod "nginx-deployment-55fb7cb77f-jtg2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jtg2f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-jtg2f,UID:3484584e-08ba-4961-a3e9-b10c0d8a9b19,ResourceVersion:163769,Generation:0,CreationTimestamp:2019-12-10 09:50:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85570 0xc002e85571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e855f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:29 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.426: INFO: Pod "nginx-deployment-55fb7cb77f-pwbgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pwbgk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-pwbgk,UID:2f972359-ce83-4139-a6f4-954f598544af,ResourceVersion:163745,Generation:0,CreationTimestamp:2019-12-10 09:50:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e856e0 0xc002e856e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:28 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.426: INFO: Pod "nginx-deployment-55fb7cb77f-q4vlh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q4vlh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-q4vlh,UID:6f41cb5f-dabf-4512-bed0-a936c65183f4,ResourceVersion:163851,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85850 0xc002e85851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e858d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e858f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.426: INFO: Pod "nginx-deployment-55fb7cb77f-q65rj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q65rj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-q65rj,UID:614d1b49-8345-4521-b989-c8763705c82d,ResourceVersion:163879,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e859c0 0xc002e859c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.427: INFO: Pod "nginx-deployment-55fb7cb77f-qpzlq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qpzlq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-qpzlq,UID:164dcb85-be63-4293-aaa0-6ede5735b0d9,ResourceVersion:163876,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85b30 0xc002e85b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.427: INFO: Pod "nginx-deployment-55fb7cb77f-tmtbn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tmtbn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-tmtbn,UID:947897d5-c043-48bb-bc1f-b20ee9f6c97e,ResourceVersion:163878,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85ca0 0xc002e85ca1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.427: INFO: Pod "nginx-deployment-55fb7cb77f-vfgwm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vfgwm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-vfgwm,UID:9f7e5926-fedb-4da2-ad26-3502c64c0b58,ResourceVersion:163760,Generation:0,CreationTimestamp:2019-12-10 09:50:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85e10 0xc002e85e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e85e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e85eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:28 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.428: INFO: Pod "nginx-deployment-55fb7cb77f-xzbx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-xzbx5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-55fb7cb77f-xzbx5,UID:a74ce9b7-06fd-4349-9519-d8d328bbc338,ResourceVersion:163744,Generation:0,CreationTimestamp:2019-12-10 09:50:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 94540e36-f73c-4e01-abd2-aef5896312c6 0xc002e85f80 0xc002e85f81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:28 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.428: INFO: Pod "nginx-deployment-7b8c6f4498-2qnw6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2qnw6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-2qnw6,UID:723993d7-bde6-473a-b5d3-e9a5d7da9ec2,ResourceVersion:163874,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c0f0 0xc002b8c0f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.428: INFO: Pod "nginx-deployment-7b8c6f4498-7w7c2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7w7c2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-7w7c2,UID:01ce79e5-4d49-4fa7-bff8-6b3052d8e6bf,ResourceVersion:163884,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c247 0xc002b8c248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.429: INFO: Pod "nginx-deployment-7b8c6f4498-7zkr8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7zkr8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-7zkr8,UID:b5cd4948-3b94-4a4c-8dcc-161fc5e6e507,ResourceVersion:163872,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c3a7 0xc002b8c3a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.429: INFO: Pod "nginx-deployment-7b8c6f4498-8262p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8262p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-8262p,UID:34bc564e-9bc7-4531-8bcb-0129e9d39d0c,ResourceVersion:163875,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c507 0xc002b8c508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.429: INFO: Pod "nginx-deployment-7b8c6f4498-8b564" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8b564,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-8b564,UID:d0d0b6a7-0f7d-43a1-b065-41b8927bba79,ResourceVersion:163675,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c667 0xc002b8c668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:10.253.1.115,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://db66d4696c9c01dd6c0687161da263190c8ef2b4adabbbb17515a353db8049b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.430: INFO: Pod "nginx-deployment-7b8c6f4498-96n9t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-96n9t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-96n9t,UID:58a7d6b5-76bb-44df-842a-f5fdf81fd321,ResourceVersion:163701,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c7d7 0xc002b8c7d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.87,StartTime:2019-12-10 09:51:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://2887c3db8b857e74b194941222965a1b424e86b8451aae8715c946ece4022a84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.430: INFO: Pod "nginx-deployment-7b8c6f4498-96sp6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-96sp6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-96sp6,UID:4c99b988-92e5-427b-8e78-311f2d7c66ce,ResourceVersion:163704,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8c940 0xc002b8c941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8c9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8c9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.89,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://92329599e9363ccd93beb58c7dd5185f9d3c3cdfd8c47e33791ad5031f87d4f2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.430: INFO: Pod "nginx-deployment-7b8c6f4498-9gfv2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9gfv2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-9gfv2,UID:0c13d299-3710-4feb-887e-0bdec43b6009,ResourceVersion:163846,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8caa0 0xc002b8caa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8cb10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8cb30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:30 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.431: INFO: Pod "nginx-deployment-7b8c6f4498-bcjxf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bcjxf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-bcjxf,UID:a590d836-68c5-4493-8483-357cf3e2f159,ResourceVersion:163880,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8cbf7 0xc002b8cbf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8cc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8cc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.431: INFO: Pod "nginx-deployment-7b8c6f4498-btp4q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-btp4q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-btp4q,UID:27fc5d3a-321a-4cf2-b658-df8945b4972f,ResourceVersion:163695,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8cd57 0xc002b8cd58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8cdd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8cdf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.88,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://46d90a181550d20e6766feb62d20a9c8d02acbfdfbea8a269f86c79e71c07da7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.431: INFO: Pod "nginx-deployment-7b8c6f4498-ctrhn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ctrhn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-ctrhn,UID:dcc89dd0-ba87-4d49-b06e-527c4a4abed4,ResourceVersion:163692,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8cec0 0xc002b8cec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8cf30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8cf50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:10.253.1.118,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://dd01bf1a9c0d7c56e05407d267192dcd7407e6ce0a97cd78883f74e9b51fa2fd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.432: INFO: Pod "nginx-deployment-7b8c6f4498-hpmgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hpmgx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-hpmgx,UID:41ae0514-d11c-499b-972c-45eb81355193,ResourceVersion:163826,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d027 0xc002b8d028}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.432: INFO: Pod "nginx-deployment-7b8c6f4498-jpgsq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jpgsq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-jpgsq,UID:1ef5055a-d2f0-4add-b90d-99ae0a644c48,ResourceVersion:163678,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d140 0xc002b8d141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:10.253.1.116,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://037fd38372f92f1ed70345ffb52c490d94da506f66a6b3a3bee7c97cee44f2c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.432: INFO: Pod "nginx-deployment-7b8c6f4498-lwll9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lwll9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-lwll9,UID:07ef5604-3a7b-4a6a-8b9a-f4491a5a0b84,ResourceVersion:163877,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d2a7 0xc002b8d2a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.432: INFO: Pod "nginx-deployment-7b8c6f4498-mpvt2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mpvt2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-mpvt2,UID:2dc95dee-8f43-40d7-b449-80bddd8f893c,ResourceVersion:163689,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d407 0xc002b8d408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:10.253.1.117,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://d912c7ee596371513f3a49fdc27079bfe5a398281056963e44624dc2dbdd47a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.433: INFO: Pod "nginx-deployment-7b8c6f4498-qcvxp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qcvxp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-qcvxp,UID:2eaa468e-b19a-42fc-be8a-68a6cf6b7d94,ResourceVersion:163885,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d577 0xc002b8d578}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.433: INFO: Pod "nginx-deployment-7b8c6f4498-qh4xr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qh4xr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-qh4xr,UID:2b0b2efc-c201-48fa-95fb-f9bab2256d19,ResourceVersion:163835,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d6d7 0xc002b8d6d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:30 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.434: INFO: Pod "nginx-deployment-7b8c6f4498-t442s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-t442s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-t442s,UID:750b06f4-dadd-40d6-b158-17c6c8e9cade,ResourceVersion:163841,Generation:0,CreationTimestamp:2019-12-10 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d837 0xc002b8d838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8d8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8d8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:30 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.29,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.434: INFO: Pod "nginx-deployment-7b8c6f4498-wvppk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wvppk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-wvppk,UID:17de60bf-cea5-4db9-bf8c-bd39137a08fa,ResourceVersion:163707,Generation:0,CreationTimestamp:2019-12-10 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8d997 0xc002b8d998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8da10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8da30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:20 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.90,StartTime:2019-12-10 09:51:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-10 09:51:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://dec30b834cd004b21146275c98f1fb41c0cacce84f0b1015e429ac25e062d1ee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 09:51:29.434: INFO: Pod "nginx-deployment-7b8c6f4498-zjxhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zjxhc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-342,SelfLink:/api/v1/namespaces/deployment-342/pods/nginx-deployment-7b8c6f4498-zjxhc,UID:c8d422f1-f129-43c1-8c0b-cf0461e7898c,ResourceVersion:163882,Generation:0,CreationTimestamp:2019-12-10 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 43b3a1e9-1820-4992-b44c-de5ca1edbbe3 0xc002b8db00 0xc002b8db01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pdcnh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pdcnh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pdcnh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b8db70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b8db90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:51:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:,StartTime:2019-12-10 09:51:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:51:29.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-342" for this suite.
Dec 10 09:51:39.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:51:40.176: INFO: namespace deployment-342 deletion completed in 10.719519606s

• [SLOW TEST:23.738 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:51:40.176: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 09:51:50.803: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 09:51:50.820: INFO: Pod pod-with-poststart-http-hook still exists
Dec 10 09:51:52.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 09:51:52.840: INFO: Pod pod-with-poststart-http-hook still exists
Dec 10 09:51:54.820: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 09:51:54.840: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:51:54.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1929" for this suite.
Dec 10 09:52:18.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:52:19.510: INFO: namespace container-lifecycle-hook-1929 deletion completed in 24.638642913s

• [SLOW TEST:39.333 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:52:19.510: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 10 09:53:00.066: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:53:00.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1210 09:53:00.065912      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2691" for this suite.
Dec 10 09:53:08.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:53:08.724: INFO: namespace gc-2691 deletion completed in 8.637230107s

• [SLOW TEST:49.214 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:53:08.725: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5604
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 10 09:53:09.109: INFO: Waiting up to 5m0s for pod "pod-33414bee-ab71-4333-8f01-075e2d7de1c6" in namespace "emptydir-5604" to be "success or failure"
Dec 10 09:53:09.127: INFO: Pod "pod-33414bee-ab71-4333-8f01-075e2d7de1c6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.193552ms
Dec 10 09:53:11.149: INFO: Pod "pod-33414bee-ab71-4333-8f01-075e2d7de1c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039461913s
Dec 10 09:53:13.166: INFO: Pod "pod-33414bee-ab71-4333-8f01-075e2d7de1c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0567772s
STEP: Saw pod success
Dec 10 09:53:13.166: INFO: Pod "pod-33414bee-ab71-4333-8f01-075e2d7de1c6" satisfied condition "success or failure"
Dec 10 09:53:13.182: INFO: Trying to get logs from node node1 pod pod-33414bee-ab71-4333-8f01-075e2d7de1c6 container test-container: <nil>
STEP: delete the pod
Dec 10 09:53:13.291: INFO: Waiting for pod pod-33414bee-ab71-4333-8f01-075e2d7de1c6 to disappear
Dec 10 09:53:13.308: INFO: Pod pod-33414bee-ab71-4333-8f01-075e2d7de1c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:53:13.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5604" for this suite.
Dec 10 09:53:19.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:53:20.024: INFO: namespace emptydir-5604 deletion completed in 6.654982086s

• [SLOW TEST:11.299 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:53:20.025: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-lznn
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 09:53:20.432: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lznn" in namespace "subpath-3116" to be "success or failure"
Dec 10 09:53:20.448: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Pending", Reason="", readiness=false. Elapsed: 15.669744ms
Dec 10 09:53:22.468: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03612532s
Dec 10 09:53:24.488: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 4.055758505s
Dec 10 09:53:26.513: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 6.080682257s
Dec 10 09:53:28.535: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 8.102405539s
Dec 10 09:53:30.557: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 10.124754137s
Dec 10 09:53:32.576: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 12.143658025s
Dec 10 09:53:34.594: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 14.161547684s
Dec 10 09:53:36.613: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 16.180541768s
Dec 10 09:53:38.633: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 18.200695871s
Dec 10 09:53:40.651: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 20.219118655s
Dec 10 09:53:42.670: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Running", Reason="", readiness=true. Elapsed: 22.237924265s
Dec 10 09:53:44.692: INFO: Pod "pod-subpath-test-configmap-lznn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.259645427s
STEP: Saw pod success
Dec 10 09:53:44.692: INFO: Pod "pod-subpath-test-configmap-lznn" satisfied condition "success or failure"
Dec 10 09:53:44.709: INFO: Trying to get logs from node node1 pod pod-subpath-test-configmap-lznn container test-container-subpath-configmap-lznn: <nil>
STEP: delete the pod
Dec 10 09:53:44.802: INFO: Waiting for pod pod-subpath-test-configmap-lznn to disappear
Dec 10 09:53:44.824: INFO: Pod pod-subpath-test-configmap-lznn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lznn
Dec 10 09:53:44.825: INFO: Deleting pod "pod-subpath-test-configmap-lznn" in namespace "subpath-3116"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:53:44.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3116" for this suite.
Dec 10 09:53:50.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:53:51.517: INFO: namespace subpath-3116 deletion completed in 6.634178955s

• [SLOW TEST:31.493 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:53:51.518: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-4906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4906
I1210 09:53:51.916361      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4906, replica count: 1
I1210 09:53:52.967130      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 09:53:53.967792      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 09:53:54.968195      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 09:53:55.167: INFO: Created: latency-svc-2tkz5
Dec 10 09:53:55.184: INFO: Got endpoints: latency-svc-2tkz5 [115.649653ms]
Dec 10 09:53:55.294: INFO: Created: latency-svc-qk85p
Dec 10 09:53:55.311: INFO: Got endpoints: latency-svc-qk85p [127.059705ms]
Dec 10 09:53:55.414: INFO: Created: latency-svc-7js2b
Dec 10 09:53:55.457: INFO: Got endpoints: latency-svc-7js2b [273.406872ms]
Dec 10 09:53:55.507: INFO: Created: latency-svc-tcb85
Dec 10 09:53:55.520: INFO: Got endpoints: latency-svc-tcb85 [335.988324ms]
Dec 10 09:53:55.600: INFO: Created: latency-svc-lnhxc
Dec 10 09:53:55.618: INFO: Got endpoints: latency-svc-lnhxc [434.117589ms]
Dec 10 09:53:55.718: INFO: Created: latency-svc-gpx8t
Dec 10 09:53:55.735: INFO: Got endpoints: latency-svc-gpx8t [550.804267ms]
Dec 10 09:53:55.841: INFO: Created: latency-svc-tpfsv
Dec 10 09:53:55.873: INFO: Got endpoints: latency-svc-tpfsv [688.379254ms]
Dec 10 09:53:55.937: INFO: Created: latency-svc-lpcwl
Dec 10 09:53:55.959: INFO: Got endpoints: latency-svc-lpcwl [773.915723ms]
Dec 10 09:53:56.008: INFO: Created: latency-svc-n4b64
Dec 10 09:53:56.042: INFO: Got endpoints: latency-svc-n4b64 [857.641554ms]
Dec 10 09:53:56.106: INFO: Created: latency-svc-5gdgv
Dec 10 09:53:56.174: INFO: Created: latency-svc-95xn2
Dec 10 09:53:56.179: INFO: Got endpoints: latency-svc-5gdgv [993.584503ms]
Dec 10 09:53:56.195: INFO: Got endpoints: latency-svc-95xn2 [1.010197202s]
Dec 10 09:53:56.339: INFO: Created: latency-svc-28f7b
Dec 10 09:53:56.364: INFO: Got endpoints: latency-svc-28f7b [1.179114053s]
Dec 10 09:53:56.423: INFO: Created: latency-svc-7gq2n
Dec 10 09:53:56.434: INFO: Got endpoints: latency-svc-7gq2n [1.249216267s]
Dec 10 09:53:56.526: INFO: Created: latency-svc-mrd4q
Dec 10 09:53:56.551: INFO: Got endpoints: latency-svc-mrd4q [1.365949521s]
Dec 10 09:53:56.614: INFO: Created: latency-svc-gpg8j
Dec 10 09:53:56.633: INFO: Got endpoints: latency-svc-gpg8j [1.448055526s]
Dec 10 09:53:56.703: INFO: Created: latency-svc-plt52
Dec 10 09:53:56.717: INFO: Got endpoints: latency-svc-plt52 [1.532532389s]
Dec 10 09:53:56.772: INFO: Created: latency-svc-527k2
Dec 10 09:53:56.787: INFO: Got endpoints: latency-svc-527k2 [1.475756938s]
Dec 10 09:53:56.893: INFO: Created: latency-svc-m7bbk
Dec 10 09:53:56.900: INFO: Got endpoints: latency-svc-m7bbk [1.442829744s]
Dec 10 09:53:57.000: INFO: Created: latency-svc-zdjrb
Dec 10 09:53:57.012: INFO: Got endpoints: latency-svc-zdjrb [1.492690032s]
Dec 10 09:53:57.114: INFO: Created: latency-svc-rkxf4
Dec 10 09:53:57.148: INFO: Got endpoints: latency-svc-rkxf4 [1.529206622s]
Dec 10 09:53:57.237: INFO: Created: latency-svc-c4xs8
Dec 10 09:53:57.335: INFO: Got endpoints: latency-svc-c4xs8 [1.59968169s]
Dec 10 09:53:57.346: INFO: Created: latency-svc-5w8fk
Dec 10 09:53:57.380: INFO: Got endpoints: latency-svc-5w8fk [1.507358445s]
Dec 10 09:53:57.444: INFO: Created: latency-svc-8psph
Dec 10 09:53:57.462: INFO: Got endpoints: latency-svc-8psph [1.503626185s]
Dec 10 09:53:57.561: INFO: Created: latency-svc-vhxkz
Dec 10 09:53:57.589: INFO: Got endpoints: latency-svc-vhxkz [1.547090887s]
Dec 10 09:53:57.675: INFO: Created: latency-svc-jf8zk
Dec 10 09:53:57.693: INFO: Got endpoints: latency-svc-jf8zk [1.514294671s]
Dec 10 09:53:57.750: INFO: Created: latency-svc-9svsf
Dec 10 09:53:57.788: INFO: Got endpoints: latency-svc-9svsf [1.593145975s]
Dec 10 09:53:57.866: INFO: Created: latency-svc-p76w6
Dec 10 09:53:57.886: INFO: Got endpoints: latency-svc-p76w6 [1.521853953s]
Dec 10 09:53:57.970: INFO: Created: latency-svc-g6w2t
Dec 10 09:53:57.993: INFO: Got endpoints: latency-svc-g6w2t [1.558773129s]
Dec 10 09:53:58.052: INFO: Created: latency-svc-xrw4q
Dec 10 09:53:58.068: INFO: Got endpoints: latency-svc-xrw4q [1.516904722s]
Dec 10 09:53:58.158: INFO: Created: latency-svc-7xrvv
Dec 10 09:53:58.176: INFO: Got endpoints: latency-svc-7xrvv [1.542312356s]
Dec 10 09:53:58.274: INFO: Created: latency-svc-7hmc9
Dec 10 09:53:58.336: INFO: Got endpoints: latency-svc-7hmc9 [1.618410431s]
Dec 10 09:53:58.352: INFO: Created: latency-svc-gzstb
Dec 10 09:53:58.392: INFO: Got endpoints: latency-svc-gzstb [1.604775483s]
Dec 10 09:53:58.440: INFO: Created: latency-svc-btr8g
Dec 10 09:53:58.453: INFO: Got endpoints: latency-svc-btr8g [1.553045369s]
Dec 10 09:53:58.525: INFO: Created: latency-svc-47l55
Dec 10 09:53:58.537: INFO: Got endpoints: latency-svc-47l55 [1.524132075s]
Dec 10 09:53:58.631: INFO: Created: latency-svc-dclt8
Dec 10 09:53:58.652: INFO: Got endpoints: latency-svc-dclt8 [1.504638032s]
Dec 10 09:53:58.697: INFO: Created: latency-svc-xcj8v
Dec 10 09:53:58.723: INFO: Got endpoints: latency-svc-xcj8v [1.388267662s]
Dec 10 09:53:58.766: INFO: Created: latency-svc-7wwdj
Dec 10 09:53:58.793: INFO: Got endpoints: latency-svc-7wwdj [1.412309296s]
Dec 10 09:53:58.873: INFO: Created: latency-svc-v9fh7
Dec 10 09:53:58.900: INFO: Got endpoints: latency-svc-v9fh7 [1.437430306s]
Dec 10 09:53:58.977: INFO: Created: latency-svc-gjslb
Dec 10 09:53:58.991: INFO: Got endpoints: latency-svc-gjslb [1.40145058s]
Dec 10 09:53:59.061: INFO: Created: latency-svc-ggh7b
Dec 10 09:53:59.070: INFO: Got endpoints: latency-svc-ggh7b [1.377229132s]
Dec 10 09:53:59.123: INFO: Created: latency-svc-6qzck
Dec 10 09:53:59.148: INFO: Got endpoints: latency-svc-6qzck [1.359491223s]
Dec 10 09:53:59.218: INFO: Created: latency-svc-6cjds
Dec 10 09:53:59.236: INFO: Got endpoints: latency-svc-6cjds [1.349491503s]
Dec 10 09:53:59.282: INFO: Created: latency-svc-742nf
Dec 10 09:53:59.294: INFO: Got endpoints: latency-svc-742nf [1.301573885s]
Dec 10 09:53:59.393: INFO: Created: latency-svc-264gs
Dec 10 09:53:59.408: INFO: Got endpoints: latency-svc-264gs [1.339701043s]
Dec 10 09:53:59.494: INFO: Created: latency-svc-jfng6
Dec 10 09:53:59.531: INFO: Got endpoints: latency-svc-jfng6 [1.355079332s]
Dec 10 09:53:59.583: INFO: Created: latency-svc-ghd2r
Dec 10 09:53:59.600: INFO: Got endpoints: latency-svc-ghd2r [1.263991911s]
Dec 10 09:53:59.676: INFO: Created: latency-svc-t5wzm
Dec 10 09:53:59.691: INFO: Got endpoints: latency-svc-t5wzm [1.298969269s]
Dec 10 09:53:59.761: INFO: Created: latency-svc-k9x2w
Dec 10 09:53:59.770: INFO: Got endpoints: latency-svc-k9x2w [1.316713233s]
Dec 10 09:53:59.906: INFO: Created: latency-svc-m8bzr
Dec 10 09:53:59.929: INFO: Got endpoints: latency-svc-m8bzr [1.392657214s]
Dec 10 09:54:00.024: INFO: Created: latency-svc-w966k
Dec 10 09:54:00.033: INFO: Got endpoints: latency-svc-w966k [1.380397436s]
Dec 10 09:54:00.077: INFO: Created: latency-svc-4lhkb
Dec 10 09:54:00.094: INFO: Got endpoints: latency-svc-4lhkb [1.3709848s]
Dec 10 09:54:00.181: INFO: Created: latency-svc-pkngr
Dec 10 09:54:00.196: INFO: Got endpoints: latency-svc-pkngr [1.40316241s]
Dec 10 09:54:00.259: INFO: Created: latency-svc-kjfff
Dec 10 09:54:00.271: INFO: Got endpoints: latency-svc-kjfff [1.370994489s]
Dec 10 09:54:00.381: INFO: Created: latency-svc-bqgsx
Dec 10 09:54:00.408: INFO: Got endpoints: latency-svc-bqgsx [1.416979523s]
Dec 10 09:54:00.449: INFO: Created: latency-svc-5vq84
Dec 10 09:54:00.468: INFO: Got endpoints: latency-svc-5vq84 [1.397467167s]
Dec 10 09:54:00.538: INFO: Created: latency-svc-fspnp
Dec 10 09:54:00.558: INFO: Got endpoints: latency-svc-fspnp [1.410189978s]
Dec 10 09:54:00.604: INFO: Created: latency-svc-fbdk4
Dec 10 09:54:00.621: INFO: Got endpoints: latency-svc-fbdk4 [1.385147194s]
Dec 10 09:54:00.697: INFO: Created: latency-svc-p4x28
Dec 10 09:54:00.777: INFO: Got endpoints: latency-svc-p4x28 [1.482578422s]
Dec 10 09:54:00.809: INFO: Created: latency-svc-wt2j9
Dec 10 09:54:00.833: INFO: Got endpoints: latency-svc-wt2j9 [1.425567831s]
Dec 10 09:54:01.026: INFO: Created: latency-svc-bhh6f
Dec 10 09:54:01.036: INFO: Got endpoints: latency-svc-bhh6f [1.505423715s]
Dec 10 09:54:01.103: INFO: Created: latency-svc-xhw2w
Dec 10 09:54:01.122: INFO: Got endpoints: latency-svc-xhw2w [1.52224881s]
Dec 10 09:54:01.190: INFO: Created: latency-svc-g2qkb
Dec 10 09:54:01.280: INFO: Got endpoints: latency-svc-g2qkb [1.589396313s]
Dec 10 09:54:01.333: INFO: Created: latency-svc-kc2x8
Dec 10 09:54:01.353: INFO: Got endpoints: latency-svc-kc2x8 [1.582432536s]
Dec 10 09:54:01.411: INFO: Created: latency-svc-njz9g
Dec 10 09:54:01.430: INFO: Got endpoints: latency-svc-njz9g [1.500476308s]
Dec 10 09:54:01.490: INFO: Created: latency-svc-rcbsg
Dec 10 09:54:01.506: INFO: Got endpoints: latency-svc-rcbsg [1.472811821s]
Dec 10 09:54:01.886: INFO: Created: latency-svc-qjkbj
Dec 10 09:54:01.906: INFO: Got endpoints: latency-svc-qjkbj [1.811167056s]
Dec 10 09:54:02.030: INFO: Created: latency-svc-jrjft
Dec 10 09:54:02.047: INFO: Got endpoints: latency-svc-jrjft [1.85093146s]
Dec 10 09:54:02.146: INFO: Created: latency-svc-cbnqq
Dec 10 09:54:02.153: INFO: Got endpoints: latency-svc-cbnqq [1.8816406s]
Dec 10 09:54:02.203: INFO: Created: latency-svc-xtk5k
Dec 10 09:54:02.217: INFO: Got endpoints: latency-svc-xtk5k [1.808855703s]
Dec 10 09:54:02.276: INFO: Created: latency-svc-dmsg6
Dec 10 09:54:02.292: INFO: Got endpoints: latency-svc-dmsg6 [1.824499208s]
Dec 10 09:54:02.374: INFO: Created: latency-svc-75rb5
Dec 10 09:54:02.397: INFO: Got endpoints: latency-svc-75rb5 [1.838631925s]
Dec 10 09:54:02.439: INFO: Created: latency-svc-lxczr
Dec 10 09:54:02.461: INFO: Got endpoints: latency-svc-lxczr [1.839965703s]
Dec 10 09:54:02.536: INFO: Created: latency-svc-rvvd2
Dec 10 09:54:02.553: INFO: Got endpoints: latency-svc-rvvd2 [1.775696156s]
Dec 10 09:54:02.614: INFO: Created: latency-svc-2x9lt
Dec 10 09:54:02.621: INFO: Got endpoints: latency-svc-2x9lt [1.787219603s]
Dec 10 09:54:02.758: INFO: Created: latency-svc-xn4bl
Dec 10 09:54:02.765: INFO: Got endpoints: latency-svc-xn4bl [1.728927326s]
Dec 10 09:54:02.875: INFO: Created: latency-svc-nmkdx
Dec 10 09:54:02.896: INFO: Got endpoints: latency-svc-nmkdx [1.773216818s]
Dec 10 09:54:02.953: INFO: Created: latency-svc-9mjtb
Dec 10 09:54:02.975: INFO: Got endpoints: latency-svc-9mjtb [1.694359076s]
Dec 10 09:54:03.031: INFO: Created: latency-svc-s8qhz
Dec 10 09:54:03.056: INFO: Got endpoints: latency-svc-s8qhz [1.703759939s]
Dec 10 09:54:03.142: INFO: Created: latency-svc-qtk57
Dec 10 09:54:03.162: INFO: Got endpoints: latency-svc-qtk57 [1.731782368s]
Dec 10 09:54:03.235: INFO: Created: latency-svc-pn4wk
Dec 10 09:54:03.251: INFO: Got endpoints: latency-svc-pn4wk [1.745742569s]
Dec 10 09:54:03.297: INFO: Created: latency-svc-kxr75
Dec 10 09:54:03.311: INFO: Got endpoints: latency-svc-kxr75 [1.404895725s]
Dec 10 09:54:03.369: INFO: Created: latency-svc-xpswp
Dec 10 09:54:03.385: INFO: Got endpoints: latency-svc-xpswp [1.337599619s]
Dec 10 09:54:03.458: INFO: Created: latency-svc-qfsll
Dec 10 09:54:03.474: INFO: Got endpoints: latency-svc-qfsll [1.321874272s]
Dec 10 09:54:03.537: INFO: Created: latency-svc-cdpb4
Dec 10 09:54:03.553: INFO: Got endpoints: latency-svc-cdpb4 [1.336379094s]
Dec 10 09:54:03.623: INFO: Created: latency-svc-m7w2q
Dec 10 09:54:03.640: INFO: Got endpoints: latency-svc-m7w2q [1.348132571s]
Dec 10 09:54:03.688: INFO: Created: latency-svc-m4wsl
Dec 10 09:54:03.715: INFO: Got endpoints: latency-svc-m4wsl [1.31812311s]
Dec 10 09:54:03.780: INFO: Created: latency-svc-r4bpb
Dec 10 09:54:03.789: INFO: Got endpoints: latency-svc-r4bpb [1.327885352s]
Dec 10 09:54:03.843: INFO: Created: latency-svc-fxf66
Dec 10 09:54:03.862: INFO: Got endpoints: latency-svc-fxf66 [1.309409414s]
Dec 10 09:54:03.948: INFO: Created: latency-svc-8f66j
Dec 10 09:54:03.948: INFO: Got endpoints: latency-svc-8f66j [1.327090571s]
Dec 10 09:54:04.034: INFO: Created: latency-svc-rcdck
Dec 10 09:54:04.066: INFO: Got endpoints: latency-svc-rcdck [1.30104019s]
Dec 10 09:54:04.187: INFO: Created: latency-svc-vxlfn
Dec 10 09:54:04.187: INFO: Got endpoints: latency-svc-vxlfn [1.291387037s]
Dec 10 09:54:04.219: INFO: Created: latency-svc-998dr
Dec 10 09:54:04.231: INFO: Got endpoints: latency-svc-998dr [1.255898105s]
Dec 10 09:54:04.356: INFO: Created: latency-svc-s9nrt
Dec 10 09:54:04.359: INFO: Got endpoints: latency-svc-s9nrt [1.30224628s]
Dec 10 09:54:04.430: INFO: Created: latency-svc-rn2bl
Dec 10 09:54:04.439: INFO: Got endpoints: latency-svc-rn2bl [1.277302323s]
Dec 10 09:54:04.508: INFO: Created: latency-svc-hlhkz
Dec 10 09:54:04.526: INFO: Got endpoints: latency-svc-hlhkz [1.274909699s]
Dec 10 09:54:04.575: INFO: Created: latency-svc-dqr97
Dec 10 09:54:04.590: INFO: Got endpoints: latency-svc-dqr97 [1.279021674s]
Dec 10 09:54:04.683: INFO: Created: latency-svc-45gg5
Dec 10 09:54:04.695: INFO: Got endpoints: latency-svc-45gg5 [1.310344903s]
Dec 10 09:54:04.768: INFO: Created: latency-svc-rnqhh
Dec 10 09:54:04.785: INFO: Got endpoints: latency-svc-rnqhh [1.310402903s]
Dec 10 09:54:04.852: INFO: Created: latency-svc-smslh
Dec 10 09:54:04.884: INFO: Got endpoints: latency-svc-smslh [1.330749163s]
Dec 10 09:54:04.947: INFO: Created: latency-svc-gj7v8
Dec 10 09:54:04.974: INFO: Got endpoints: latency-svc-gj7v8 [1.333522352s]
Dec 10 09:54:05.033: INFO: Created: latency-svc-kqq79
Dec 10 09:54:05.052: INFO: Got endpoints: latency-svc-kqq79 [1.337115071s]
Dec 10 09:54:05.120: INFO: Created: latency-svc-ddv96
Dec 10 09:54:05.147: INFO: Got endpoints: latency-svc-ddv96 [1.358412981s]
Dec 10 09:54:05.245: INFO: Created: latency-svc-z4wv8
Dec 10 09:54:05.261: INFO: Got endpoints: latency-svc-z4wv8 [1.399228545s]
Dec 10 09:54:05.337: INFO: Created: latency-svc-sfthz
Dec 10 09:54:05.356: INFO: Got endpoints: latency-svc-sfthz [1.408341233s]
Dec 10 09:54:05.421: INFO: Created: latency-svc-xgqw2
Dec 10 09:54:05.446: INFO: Got endpoints: latency-svc-xgqw2 [1.380214237s]
Dec 10 09:54:05.543: INFO: Created: latency-svc-w99tl
Dec 10 09:54:05.584: INFO: Got endpoints: latency-svc-w99tl [1.396730146s]
Dec 10 09:54:05.683: INFO: Created: latency-svc-bpgc7
Dec 10 09:54:05.710: INFO: Got endpoints: latency-svc-bpgc7 [1.47949454s]
Dec 10 09:54:05.765: INFO: Created: latency-svc-2jmfd
Dec 10 09:54:05.781: INFO: Got endpoints: latency-svc-2jmfd [1.422251785s]
Dec 10 09:54:05.865: INFO: Created: latency-svc-h5s97
Dec 10 09:54:05.888: INFO: Got endpoints: latency-svc-h5s97 [1.448561766s]
Dec 10 09:54:05.943: INFO: Created: latency-svc-86vfp
Dec 10 09:54:06.002: INFO: Got endpoints: latency-svc-86vfp [1.476057837s]
Dec 10 09:54:06.106: INFO: Created: latency-svc-l4nsw
Dec 10 09:54:06.122: INFO: Got endpoints: latency-svc-l4nsw [1.532192567s]
Dec 10 09:54:06.183: INFO: Created: latency-svc-mjt5t
Dec 10 09:54:06.205: INFO: Got endpoints: latency-svc-mjt5t [1.509577595s]
Dec 10 09:54:06.256: INFO: Created: latency-svc-w67f4
Dec 10 09:54:06.263: INFO: Got endpoints: latency-svc-w67f4 [1.47771938s]
Dec 10 09:54:06.335: INFO: Created: latency-svc-tf56q
Dec 10 09:54:06.349: INFO: Got endpoints: latency-svc-tf56q [1.464953473s]
Dec 10 09:54:06.449: INFO: Created: latency-svc-qkhvg
Dec 10 09:54:06.461: INFO: Got endpoints: latency-svc-qkhvg [1.487146274s]
Dec 10 09:54:06.562: INFO: Created: latency-svc-s2pqr
Dec 10 09:54:06.587: INFO: Got endpoints: latency-svc-s2pqr [1.53467737s]
Dec 10 09:54:06.726: INFO: Created: latency-svc-xxfmh
Dec 10 09:54:06.741: INFO: Got endpoints: latency-svc-xxfmh [1.593865353s]
Dec 10 09:54:06.782: INFO: Created: latency-svc-tlklk
Dec 10 09:54:06.798: INFO: Got endpoints: latency-svc-tlklk [1.536279957s]
Dec 10 09:54:06.851: INFO: Created: latency-svc-d6fwk
Dec 10 09:54:06.899: INFO: Got endpoints: latency-svc-d6fwk [1.542952369s]
Dec 10 09:54:06.927: INFO: Created: latency-svc-h64jl
Dec 10 09:54:06.941: INFO: Got endpoints: latency-svc-h64jl [1.494311364s]
Dec 10 09:54:07.027: INFO: Created: latency-svc-bv494
Dec 10 09:54:07.056: INFO: Got endpoints: latency-svc-bv494 [1.472242688s]
Dec 10 09:54:07.149: INFO: Created: latency-svc-br7lq
Dec 10 09:54:07.186: INFO: Got endpoints: latency-svc-br7lq [1.475455196s]
Dec 10 09:54:07.307: INFO: Created: latency-svc-kw4t2
Dec 10 09:54:07.345: INFO: Got endpoints: latency-svc-kw4t2 [1.563714511s]
Dec 10 09:54:07.413: INFO: Created: latency-svc-scrp9
Dec 10 09:54:07.421: INFO: Got endpoints: latency-svc-scrp9 [1.533176377s]
Dec 10 09:54:07.494: INFO: Created: latency-svc-qz7qj
Dec 10 09:54:07.511: INFO: Got endpoints: latency-svc-qz7qj [1.508373191s]
Dec 10 09:54:07.568: INFO: Created: latency-svc-fq4q6
Dec 10 09:54:07.598: INFO: Got endpoints: latency-svc-fq4q6 [1.476223514s]
Dec 10 09:54:07.663: INFO: Created: latency-svc-mfxnk
Dec 10 09:54:07.674: INFO: Got endpoints: latency-svc-mfxnk [1.469054226s]
Dec 10 09:54:07.788: INFO: Created: latency-svc-k2f6b
Dec 10 09:54:07.829: INFO: Got endpoints: latency-svc-k2f6b [1.56595196s]
Dec 10 09:54:07.870: INFO: Created: latency-svc-mz7vw
Dec 10 09:54:07.886: INFO: Got endpoints: latency-svc-mz7vw [1.537005972s]
Dec 10 09:54:07.957: INFO: Created: latency-svc-gqf7k
Dec 10 09:54:07.967: INFO: Got endpoints: latency-svc-gqf7k [1.506163501s]
Dec 10 09:54:08.024: INFO: Created: latency-svc-stgsd
Dec 10 09:54:08.043: INFO: Got endpoints: latency-svc-stgsd [1.456103691s]
Dec 10 09:54:08.121: INFO: Created: latency-svc-jntgg
Dec 10 09:54:08.139: INFO: Got endpoints: latency-svc-jntgg [1.397728562s]
Dec 10 09:54:08.190: INFO: Created: latency-svc-5rkkr
Dec 10 09:54:08.243: INFO: Got endpoints: latency-svc-5rkkr [1.445509026s]
Dec 10 09:54:08.383: INFO: Created: latency-svc-nmcdb
Dec 10 09:54:08.406: INFO: Got endpoints: latency-svc-nmcdb [1.506662956s]
Dec 10 09:54:08.670: INFO: Created: latency-svc-k45sm
Dec 10 09:54:08.677: INFO: Got endpoints: latency-svc-k45sm [1.736266814s]
Dec 10 09:54:08.784: INFO: Created: latency-svc-tl7bv
Dec 10 09:54:08.786: INFO: Got endpoints: latency-svc-tl7bv [1.730488866s]
Dec 10 09:54:08.832: INFO: Created: latency-svc-d2bmt
Dec 10 09:54:08.842: INFO: Got endpoints: latency-svc-d2bmt [1.656553694s]
Dec 10 09:54:08.948: INFO: Created: latency-svc-tp2nc
Dec 10 09:54:08.968: INFO: Got endpoints: latency-svc-tp2nc [1.623745914s]
Dec 10 09:54:09.028: INFO: Created: latency-svc-pvclv
Dec 10 09:54:09.067: INFO: Got endpoints: latency-svc-pvclv [1.645602312s]
Dec 10 09:54:09.134: INFO: Created: latency-svc-9p2wp
Dec 10 09:54:09.149: INFO: Got endpoints: latency-svc-9p2wp [1.637983811s]
Dec 10 09:54:09.239: INFO: Created: latency-svc-ndthg
Dec 10 09:54:09.255: INFO: Got endpoints: latency-svc-ndthg [1.6565916s]
Dec 10 09:54:09.307: INFO: Created: latency-svc-vjnhc
Dec 10 09:54:09.321: INFO: Got endpoints: latency-svc-vjnhc [1.647154475s]
Dec 10 09:54:09.412: INFO: Created: latency-svc-49gvh
Dec 10 09:54:09.435: INFO: Got endpoints: latency-svc-49gvh [1.60605684s]
Dec 10 09:54:09.492: INFO: Created: latency-svc-rv7lg
Dec 10 09:54:09.509: INFO: Got endpoints: latency-svc-rv7lg [1.622757039s]
Dec 10 09:54:09.610: INFO: Created: latency-svc-h7snn
Dec 10 09:54:09.610: INFO: Got endpoints: latency-svc-h7snn [1.642403789s]
Dec 10 09:54:09.666: INFO: Created: latency-svc-d2b5k
Dec 10 09:54:09.698: INFO: Got endpoints: latency-svc-d2b5k [1.655170857s]
Dec 10 09:54:09.779: INFO: Created: latency-svc-959j5
Dec 10 09:54:09.782: INFO: Got endpoints: latency-svc-959j5 [1.643505512s]
Dec 10 09:54:09.848: INFO: Created: latency-svc-2srnl
Dec 10 09:54:09.866: INFO: Got endpoints: latency-svc-2srnl [1.622648904s]
Dec 10 09:54:09.972: INFO: Created: latency-svc-7zlmw
Dec 10 09:54:10.003: INFO: Got endpoints: latency-svc-7zlmw [1.59738138s]
Dec 10 09:54:10.058: INFO: Created: latency-svc-rddtx
Dec 10 09:54:10.070: INFO: Got endpoints: latency-svc-rddtx [1.392867451s]
Dec 10 09:54:10.137: INFO: Created: latency-svc-szc8v
Dec 10 09:54:10.159: INFO: Got endpoints: latency-svc-szc8v [1.372211675s]
Dec 10 09:54:10.217: INFO: Created: latency-svc-wjbkv
Dec 10 09:54:10.235: INFO: Got endpoints: latency-svc-wjbkv [1.392811679s]
Dec 10 09:54:10.313: INFO: Created: latency-svc-gxff6
Dec 10 09:54:10.325: INFO: Got endpoints: latency-svc-gxff6 [1.356841822s]
Dec 10 09:54:10.429: INFO: Created: latency-svc-mm25r
Dec 10 09:54:10.446: INFO: Got endpoints: latency-svc-mm25r [1.379592225s]
Dec 10 09:54:10.533: INFO: Created: latency-svc-9492n
Dec 10 09:54:10.539: INFO: Got endpoints: latency-svc-9492n [1.389766012s]
Dec 10 09:54:10.655: INFO: Created: latency-svc-485gs
Dec 10 09:54:10.904: INFO: Got endpoints: latency-svc-485gs [1.649311741s]
Dec 10 09:54:10.910: INFO: Created: latency-svc-r26p5
Dec 10 09:54:10.927: INFO: Got endpoints: latency-svc-r26p5 [1.605858565s]
Dec 10 09:54:11.079: INFO: Created: latency-svc-2hndk
Dec 10 09:54:11.115: INFO: Got endpoints: latency-svc-2hndk [1.680703579s]
Dec 10 09:54:11.187: INFO: Created: latency-svc-2qlw2
Dec 10 09:54:11.202: INFO: Got endpoints: latency-svc-2qlw2 [1.693072521s]
Dec 10 09:54:11.325: INFO: Created: latency-svc-kkkcv
Dec 10 09:54:11.347: INFO: Got endpoints: latency-svc-kkkcv [1.737034749s]
Dec 10 09:54:11.382: INFO: Created: latency-svc-brm5d
Dec 10 09:54:11.400: INFO: Got endpoints: latency-svc-brm5d [1.701810526s]
Dec 10 09:54:11.462: INFO: Created: latency-svc-jqvml
Dec 10 09:54:11.485: INFO: Got endpoints: latency-svc-jqvml [1.702606405s]
Dec 10 09:54:11.556: INFO: Created: latency-svc-ppnd9
Dec 10 09:54:11.575: INFO: Got endpoints: latency-svc-ppnd9 [1.70871431s]
Dec 10 09:54:11.635: INFO: Created: latency-svc-5qtj5
Dec 10 09:54:11.663: INFO: Got endpoints: latency-svc-5qtj5 [1.659510954s]
Dec 10 09:54:11.746: INFO: Created: latency-svc-ml2t4
Dec 10 09:54:11.762: INFO: Got endpoints: latency-svc-ml2t4 [1.691567836s]
Dec 10 09:54:11.844: INFO: Created: latency-svc-9t97x
Dec 10 09:54:11.861: INFO: Got endpoints: latency-svc-9t97x [1.70241866s]
Dec 10 09:54:11.974: INFO: Created: latency-svc-kkz2j
Dec 10 09:54:11.982: INFO: Got endpoints: latency-svc-kkz2j [1.746557355s]
Dec 10 09:54:12.054: INFO: Created: latency-svc-s6qmz
Dec 10 09:54:12.066: INFO: Got endpoints: latency-svc-s6qmz [1.740304019s]
Dec 10 09:54:12.124: INFO: Created: latency-svc-wc5b2
Dec 10 09:54:12.184: INFO: Got endpoints: latency-svc-wc5b2 [1.737630545s]
Dec 10 09:54:12.202: INFO: Created: latency-svc-ncz2m
Dec 10 09:54:12.230: INFO: Got endpoints: latency-svc-ncz2m [1.690992969s]
Dec 10 09:54:12.285: INFO: Created: latency-svc-wjj75
Dec 10 09:54:12.303: INFO: Got endpoints: latency-svc-wjj75 [1.398393477s]
Dec 10 09:54:12.378: INFO: Created: latency-svc-wlftx
Dec 10 09:54:12.408: INFO: Got endpoints: latency-svc-wlftx [1.480878164s]
Dec 10 09:54:12.620: INFO: Created: latency-svc-kffjs
Dec 10 09:54:12.620: INFO: Got endpoints: latency-svc-kffjs [1.50466811s]
Dec 10 09:54:12.679: INFO: Created: latency-svc-8twmj
Dec 10 09:54:12.690: INFO: Got endpoints: latency-svc-8twmj [1.48830441s]
Dec 10 09:54:12.758: INFO: Created: latency-svc-76zwr
Dec 10 09:54:12.783: INFO: Got endpoints: latency-svc-76zwr [1.435966397s]
Dec 10 09:54:12.860: INFO: Created: latency-svc-q2jhw
Dec 10 09:54:12.865: INFO: Got endpoints: latency-svc-q2jhw [1.465252536s]
Dec 10 09:54:12.953: INFO: Created: latency-svc-wvgk6
Dec 10 09:54:12.980: INFO: Got endpoints: latency-svc-wvgk6 [1.494828409s]
Dec 10 09:54:13.084: INFO: Created: latency-svc-9798g
Dec 10 09:54:13.136: INFO: Got endpoints: latency-svc-9798g [1.560995114s]
Dec 10 09:54:13.200: INFO: Created: latency-svc-jh554
Dec 10 09:54:13.218: INFO: Got endpoints: latency-svc-jh554 [1.555105678s]
Dec 10 09:54:13.277: INFO: Created: latency-svc-rxszp
Dec 10 09:54:13.288: INFO: Got endpoints: latency-svc-rxszp [1.526110981s]
Dec 10 09:54:13.379: INFO: Created: latency-svc-t7shq
Dec 10 09:54:13.406: INFO: Got endpoints: latency-svc-t7shq [1.544480777s]
Dec 10 09:54:13.459: INFO: Created: latency-svc-rqrq5
Dec 10 09:54:13.489: INFO: Got endpoints: latency-svc-rqrq5 [1.50703191s]
Dec 10 09:54:13.555: INFO: Created: latency-svc-mcftc
Dec 10 09:54:13.577: INFO: Got endpoints: latency-svc-mcftc [1.511532386s]
Dec 10 09:54:13.659: INFO: Created: latency-svc-wtfsm
Dec 10 09:54:13.677: INFO: Got endpoints: latency-svc-wtfsm [1.492916068s]
Dec 10 09:54:13.741: INFO: Created: latency-svc-ffrqk
Dec 10 09:54:13.760: INFO: Got endpoints: latency-svc-ffrqk [1.530035204s]
Dec 10 09:54:13.853: INFO: Created: latency-svc-8dmlf
Dec 10 09:54:13.872: INFO: Got endpoints: latency-svc-8dmlf [1.569287927s]
Dec 10 09:54:13.952: INFO: Created: latency-svc-fdvst
Dec 10 09:54:13.986: INFO: Got endpoints: latency-svc-fdvst [1.578315318s]
Dec 10 09:54:14.023: INFO: Created: latency-svc-6sqnr
Dec 10 09:54:14.036: INFO: Got endpoints: latency-svc-6sqnr [1.415937717s]
Dec 10 09:54:14.098: INFO: Created: latency-svc-m86nc
Dec 10 09:54:14.124: INFO: Got endpoints: latency-svc-m86nc [1.434335237s]
Dec 10 09:54:14.165: INFO: Created: latency-svc-ptxnw
Dec 10 09:54:14.194: INFO: Got endpoints: latency-svc-ptxnw [1.411022243s]
Dec 10 09:54:14.331: INFO: Created: latency-svc-s4tmd
Dec 10 09:54:14.344: INFO: Got endpoints: latency-svc-s4tmd [1.478407832s]
Dec 10 09:54:14.385: INFO: Created: latency-svc-mb857
Dec 10 09:54:14.396: INFO: Got endpoints: latency-svc-mb857 [1.416242953s]
Dec 10 09:54:14.459: INFO: Created: latency-svc-q7lcq
Dec 10 09:54:14.475: INFO: Got endpoints: latency-svc-q7lcq [1.339042627s]
Dec 10 09:54:14.597: INFO: Created: latency-svc-2nlct
Dec 10 09:54:14.629: INFO: Got endpoints: latency-svc-2nlct [1.410785426s]
Dec 10 09:54:14.675: INFO: Created: latency-svc-77v4w
Dec 10 09:54:14.687: INFO: Got endpoints: latency-svc-77v4w [1.39884142s]
Dec 10 09:54:14.740: INFO: Created: latency-svc-d862m
Dec 10 09:54:14.759: INFO: Got endpoints: latency-svc-d862m [1.352919424s]
Dec 10 09:54:14.822: INFO: Created: latency-svc-7p486
Dec 10 09:54:14.840: INFO: Got endpoints: latency-svc-7p486 [1.350922822s]
Dec 10 09:54:14.911: INFO: Created: latency-svc-6r7ng
Dec 10 09:54:14.940: INFO: Got endpoints: latency-svc-6r7ng [1.363005173s]
Dec 10 09:54:14.986: INFO: Created: latency-svc-gdfxz
Dec 10 09:54:15.002: INFO: Got endpoints: latency-svc-gdfxz [1.325496279s]
Dec 10 09:54:15.075: INFO: Created: latency-svc-4kkhk
Dec 10 09:54:15.083: INFO: Got endpoints: latency-svc-4kkhk [1.323220098s]
Dec 10 09:54:15.140: INFO: Created: latency-svc-7z9hz
Dec 10 09:54:15.156: INFO: Got endpoints: latency-svc-7z9hz [1.28375108s]
Dec 10 09:54:15.156: INFO: Latencies: [127.059705ms 273.406872ms 335.988324ms 434.117589ms 550.804267ms 688.379254ms 773.915723ms 857.641554ms 993.584503ms 1.010197202s 1.179114053s 1.249216267s 1.255898105s 1.263991911s 1.274909699s 1.277302323s 1.279021674s 1.28375108s 1.291387037s 1.298969269s 1.30104019s 1.301573885s 1.30224628s 1.309409414s 1.310344903s 1.310402903s 1.316713233s 1.31812311s 1.321874272s 1.323220098s 1.325496279s 1.327090571s 1.327885352s 1.330749163s 1.333522352s 1.336379094s 1.337115071s 1.337599619s 1.339042627s 1.339701043s 1.348132571s 1.349491503s 1.350922822s 1.352919424s 1.355079332s 1.356841822s 1.358412981s 1.359491223s 1.363005173s 1.365949521s 1.3709848s 1.370994489s 1.372211675s 1.377229132s 1.379592225s 1.380214237s 1.380397436s 1.385147194s 1.388267662s 1.389766012s 1.392657214s 1.392811679s 1.392867451s 1.396730146s 1.397467167s 1.397728562s 1.398393477s 1.39884142s 1.399228545s 1.40145058s 1.40316241s 1.404895725s 1.408341233s 1.410189978s 1.410785426s 1.411022243s 1.412309296s 1.415937717s 1.416242953s 1.416979523s 1.422251785s 1.425567831s 1.434335237s 1.435966397s 1.437430306s 1.442829744s 1.445509026s 1.448055526s 1.448561766s 1.456103691s 1.464953473s 1.465252536s 1.469054226s 1.472242688s 1.472811821s 1.475455196s 1.475756938s 1.476057837s 1.476223514s 1.47771938s 1.478407832s 1.47949454s 1.480878164s 1.482578422s 1.487146274s 1.48830441s 1.492690032s 1.492916068s 1.494311364s 1.494828409s 1.500476308s 1.503626185s 1.504638032s 1.50466811s 1.505423715s 1.506163501s 1.506662956s 1.50703191s 1.507358445s 1.508373191s 1.509577595s 1.511532386s 1.514294671s 1.516904722s 1.521853953s 1.52224881s 1.524132075s 1.526110981s 1.529206622s 1.530035204s 1.532192567s 1.532532389s 1.533176377s 1.53467737s 1.536279957s 1.537005972s 1.542312356s 1.542952369s 1.544480777s 1.547090887s 1.553045369s 1.555105678s 1.558773129s 1.560995114s 1.563714511s 1.56595196s 1.569287927s 1.578315318s 1.582432536s 1.589396313s 1.593145975s 1.593865353s 1.59738138s 1.59968169s 1.604775483s 1.605858565s 1.60605684s 1.618410431s 1.622648904s 1.622757039s 1.623745914s 1.637983811s 1.642403789s 1.643505512s 1.645602312s 1.647154475s 1.649311741s 1.655170857s 1.656553694s 1.6565916s 1.659510954s 1.680703579s 1.690992969s 1.691567836s 1.693072521s 1.694359076s 1.701810526s 1.70241866s 1.702606405s 1.703759939s 1.70871431s 1.728927326s 1.730488866s 1.731782368s 1.736266814s 1.737034749s 1.737630545s 1.740304019s 1.745742569s 1.746557355s 1.773216818s 1.775696156s 1.787219603s 1.808855703s 1.811167056s 1.824499208s 1.838631925s 1.839965703s 1.85093146s 1.8816406s]
Dec 10 09:54:15.156: INFO: 50 %ile: 1.478407832s
Dec 10 09:54:15.156: INFO: 90 %ile: 1.70871431s
Dec 10 09:54:15.156: INFO: 99 %ile: 1.85093146s
Dec 10 09:54:15.156: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:54:15.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4906" for this suite.
Dec 10 09:54:59.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:54:59.871: INFO: namespace svc-latency-4906 deletion completed in 44.684652618s

• [SLOW TEST:68.353 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:54:59.871: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 10 09:55:00.236: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:55:04.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6145" for this suite.
Dec 10 09:55:10.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:55:11.577: INFO: namespace init-container-6145 deletion completed in 6.6604609s

• [SLOW TEST:11.706 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:55:11.577: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Dec 10 09:55:16.056: INFO: Pod pod-hostip-6c6fc664-59d2-42b8-b109-36235ec17042 has hostIP: 10.164.17.29
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:55:16.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9713" for this suite.
Dec 10 09:55:40.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:55:40.734: INFO: namespace pods-9713 deletion completed in 24.643635316s

• [SLOW TEST:29.157 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:55:40.734: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5892.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5892.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5892.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5892.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5892.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5892.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 09:55:45.455: INFO: DNS probes using dns-5892/dns-test-ad7a9980-0320-4d30-bbdb-0738b1ee158b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:55:45.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5892" for this suite.
Dec 10 09:55:51.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:55:52.205: INFO: namespace dns-5892 deletion completed in 6.674683977s

• [SLOW TEST:11.471 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:55:52.205: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Dec 10 09:55:52.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 --namespace=kubectl-1730 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 10 09:55:56.829: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 10 09:55:56.829: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:55:58.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1730" for this suite.
Dec 10 09:56:06.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:56:07.585: INFO: namespace kubectl-1730 deletion completed in 8.688922256s

• [SLOW TEST:15.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:56:07.586: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7886
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7932
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:56:14.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6448" for this suite.
Dec 10 09:56:20.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:56:21.497: INFO: namespace namespaces-6448 deletion completed in 6.675197794s
STEP: Destroying namespace "nsdeletetest-7886" for this suite.
Dec 10 09:56:21.513: INFO: Namespace nsdeletetest-7886 was already deleted
STEP: Destroying namespace "nsdeletetest-7932" for this suite.
Dec 10 09:56:27.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:56:28.169: INFO: namespace nsdeletetest-7932 deletion completed in 6.655847201s

• [SLOW TEST:20.583 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:56:28.169: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 09:56:28.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8576'
Dec 10 09:56:28.793: INFO: stderr: ""
Dec 10 09:56:28.794: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 10 09:56:33.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pod e2e-test-nginx-pod --namespace=kubectl-8576 -o json'
Dec 10 09:56:34.066: INFO: stderr: ""
Dec 10 09:56:34.066: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-10T09:55:32Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8576\",\n        \"resourceVersion\": \"166230\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8576/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d9c4421f-724d-4450-8cad-11ce6c507921\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-6xc8r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-6xc8r\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-6xc8r\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-10T09:56:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-10T09:56:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-10T09:56:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-10T09:55:32Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://9cef3d9a0f5aa82f64d81a9b5a725c0b86c21cd47fac2dffa3b828126e702667\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-10T09:56:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.164.17.29\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.253.1.142\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-10T09:56:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 10 09:56:34.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 replace -f - --namespace=kubectl-8576'
Dec 10 09:56:34.564: INFO: stderr: ""
Dec 10 09:56:34.564: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Dec 10 09:56:34.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete pods e2e-test-nginx-pod --namespace=kubectl-8576'
Dec 10 09:56:37.104: INFO: stderr: ""
Dec 10 09:56:37.104: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:56:37.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8576" for this suite.
Dec 10 09:56:45.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:56:45.790: INFO: namespace kubectl-8576 deletion completed in 8.654115972s

• [SLOW TEST:17.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:56:45.791: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 10 09:56:51.329: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:56:51.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6625" for this suite.
Dec 10 09:57:15.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:57:16.153: INFO: namespace replicaset-6625 deletion completed in 24.694411285s

• [SLOW TEST:30.362 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:57:16.153: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 10 09:57:24.704: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:24.704: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:25.148: INFO: Exec stderr: ""
Dec 10 09:57:25.148: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:25.148: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:25.618: INFO: Exec stderr: ""
Dec 10 09:57:25.618: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:25.618: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:26.077: INFO: Exec stderr: ""
Dec 10 09:57:26.077: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:26.077: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:26.539: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 10 09:57:26.539: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:26.539: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:27.007: INFO: Exec stderr: ""
Dec 10 09:57:27.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:27.007: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:27.477: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 10 09:57:27.477: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:27.477: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:27.966: INFO: Exec stderr: ""
Dec 10 09:57:27.966: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:27.966: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:28.434: INFO: Exec stderr: ""
Dec 10 09:57:28.434: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:28.434: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:28.899: INFO: Exec stderr: ""
Dec 10 09:57:28.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5871 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 09:57:28.899: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 09:57:29.378: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:57:29.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5871" for this suite.
Dec 10 09:58:21.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:58:22.069: INFO: namespace e2e-kubelet-etc-hosts-5871 deletion completed in 52.658458427s

• [SLOW TEST:65.916 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:58:22.069: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 10 09:58:22.443: INFO: Waiting up to 5m0s for pod "downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc" in namespace "downward-api-4895" to be "success or failure"
Dec 10 09:58:22.461: INFO: Pod "downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc": Phase="Pending", Reason="", readiness=false. Elapsed: 17.850073ms
Dec 10 09:58:24.480: INFO: Pod "downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036827649s
Dec 10 09:58:26.507: INFO: Pod "downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064317832s
STEP: Saw pod success
Dec 10 09:58:26.507: INFO: Pod "downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc" satisfied condition "success or failure"
Dec 10 09:58:26.532: INFO: Trying to get logs from node node2 pod downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc container dapi-container: <nil>
STEP: delete the pod
Dec 10 09:58:26.665: INFO: Waiting for pod downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc to disappear
Dec 10 09:58:26.680: INFO: Pod downward-api-c96b10bd-1b15-4d99-bad2-3f43f98031fc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:58:26.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4895" for this suite.
Dec 10 09:58:32.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:58:33.386: INFO: namespace downward-api-4895 deletion completed in 6.67469122s

• [SLOW TEST:11.317 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:58:33.387: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-639.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-639.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-639.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-639.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-639.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 122.251.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.251.122_udp@PTR;check="$$(dig +tcp +noall +answer +search 122.251.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.251.122_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-639.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-639.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-639.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-639.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-639.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-639.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-639.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 122.251.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.251.122_udp@PTR;check="$$(dig +tcp +noall +answer +search 122.251.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.251.122_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 09:58:37.978: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.006: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.035: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.063: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.256: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.285: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.313: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.342: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:38.513: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:58:43.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.573: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.603: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.636: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.843: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.872: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.900: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:43.929: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:44.097: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:58:48.547: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.608: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.638: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.854: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.883: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.912: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:48.941: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:49.124: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:58:53.550: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.582: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.613: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.643: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.849: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.877: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.906: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:53.936: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:54.114: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:58:58.544: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.608: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.639: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.892: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.918: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.949: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:58.979: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:58:59.170: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:59:03.542: INFO: Unable to read wheezy_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.569: INFO: Unable to read wheezy_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.599: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.627: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.822: INFO: Unable to read jessie_udp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.848: INFO: Unable to read jessie_tcp@dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.875: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:03.904: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local from pod dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22: the server could not find the requested resource (get pods dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22)
Dec 10 09:59:04.069: INFO: Lookups using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 failed for: [wheezy_udp@dns-test-service.dns-639.svc.cluster.local wheezy_tcp@dns-test-service.dns-639.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_udp@dns-test-service.dns-639.svc.cluster.local jessie_tcp@dns-test-service.dns-639.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-639.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-639.svc.cluster.local]

Dec 10 09:59:09.093: INFO: DNS probes using dns-639/dns-test-36bc4465-2991-4b88-adee-0cbf64eb9f22 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:59:09.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-639" for this suite.
Dec 10 09:59:15.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:59:16.135: INFO: namespace dns-639 deletion completed in 6.68957026s

• [SLOW TEST:42.748 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:59:16.135: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Dec 10 09:59:16.532: INFO: Waiting up to 5m0s for pod "client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd" in namespace "containers-7046" to be "success or failure"
Dec 10 09:59:16.548: INFO: Pod "client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.81698ms
Dec 10 09:59:18.570: INFO: Pod "client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037919024s
Dec 10 09:59:20.591: INFO: Pod "client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058813824s
STEP: Saw pod success
Dec 10 09:59:20.591: INFO: Pod "client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd" satisfied condition "success or failure"
Dec 10 09:59:20.609: INFO: Trying to get logs from node node1 pod client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd container test-container: <nil>
STEP: delete the pod
Dec 10 09:59:20.700: INFO: Waiting for pod client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd to disappear
Dec 10 09:59:20.716: INFO: Pod client-containers-5eaa54be-c26e-43e5-9ef7-e4dcd2e767fd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:59:20.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7046" for this suite.
Dec 10 09:59:26.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:59:27.447: INFO: namespace containers-7046 deletion completed in 6.699191386s

• [SLOW TEST:11.312 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:59:27.448: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:59:33.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9310" for this suite.
Dec 10 09:59:39.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:59:39.962: INFO: namespace watch-9310 deletion completed in 6.770003825s

• [SLOW TEST:12.514 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:59:39.963: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-47
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 09:59:40.340: INFO: Waiting up to 5m0s for pod "pod-af68cdc2-2886-45e1-aa70-77e45318ad6e" in namespace "emptydir-47" to be "success or failure"
Dec 10 09:59:40.358: INFO: Pod "pod-af68cdc2-2886-45e1-aa70-77e45318ad6e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.629783ms
Dec 10 09:59:42.378: INFO: Pod "pod-af68cdc2-2886-45e1-aa70-77e45318ad6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038478938s
Dec 10 09:59:44.398: INFO: Pod "pod-af68cdc2-2886-45e1-aa70-77e45318ad6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058363643s
STEP: Saw pod success
Dec 10 09:59:44.398: INFO: Pod "pod-af68cdc2-2886-45e1-aa70-77e45318ad6e" satisfied condition "success or failure"
Dec 10 09:59:44.415: INFO: Trying to get logs from node node1 pod pod-af68cdc2-2886-45e1-aa70-77e45318ad6e container test-container: <nil>
STEP: delete the pod
Dec 10 09:59:44.495: INFO: Waiting for pod pod-af68cdc2-2886-45e1-aa70-77e45318ad6e to disappear
Dec 10 09:59:44.510: INFO: Pod pod-af68cdc2-2886-45e1-aa70-77e45318ad6e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:59:44.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-47" for this suite.
Dec 10 09:59:50.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 09:59:51.219: INFO: namespace emptydir-47 deletion completed in 6.677125446s

• [SLOW TEST:11.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 09:59:51.219: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 09:59:51.635: INFO: Waiting up to 5m0s for pod "pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7" in namespace "emptydir-731" to be "success or failure"
Dec 10 09:59:51.663: INFO: Pod "pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.166445ms
Dec 10 09:59:53.681: INFO: Pod "pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046467327s
Dec 10 09:59:55.703: INFO: Pod "pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068238547s
STEP: Saw pod success
Dec 10 09:59:55.703: INFO: Pod "pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7" satisfied condition "success or failure"
Dec 10 09:59:55.722: INFO: Trying to get logs from node node1 pod pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7 container test-container: <nil>
STEP: delete the pod
Dec 10 09:59:55.810: INFO: Waiting for pod pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7 to disappear
Dec 10 09:59:55.825: INFO: Pod pod-4a394cca-a365-4f35-9d34-f146a3fe1cf7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 09:59:55.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-731" for this suite.
Dec 10 10:00:01.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:00:02.592: INFO: namespace emptydir-731 deletion completed in 6.720585478s

• [SLOW TEST:11.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:00:02.592: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1176, will wait for the garbage collector to delete the pods
Dec 10 10:00:07.159: INFO: Deleting Job.batch foo took: 25.160764ms
Dec 10 10:00:07.460: INFO: Terminating Job.batch foo pods took: 300.503535ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:00:46.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1176" for this suite.
Dec 10 10:00:52.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:00:53.549: INFO: namespace job-1176 deletion completed in 6.63963828s

• [SLOW TEST:50.957 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:00:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1024
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f0f0ad0e-e02c-4957-a354-1b5274534791
STEP: Creating a pod to test consume configMaps
Dec 10 10:00:53.965: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670" in namespace "projected-1024" to be "success or failure"
Dec 10 10:00:53.987: INFO: Pod "pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670": Phase="Pending", Reason="", readiness=false. Elapsed: 22.430051ms
Dec 10 10:00:56.005: INFO: Pod "pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03985217s
Dec 10 10:00:58.023: INFO: Pod "pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058017031s
STEP: Saw pod success
Dec 10 10:00:58.023: INFO: Pod "pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670" satisfied condition "success or failure"
Dec 10 10:00:58.040: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:00:58.119: INFO: Waiting for pod pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670 to disappear
Dec 10 10:00:58.134: INFO: Pod pod-projected-configmaps-113ad93f-0ee2-4fac-aa1d-bfcd0b48b670 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:00:58.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1024" for this suite.
Dec 10 10:01:04.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:01:04.811: INFO: namespace projected-1024 deletion completed in 6.647817638s

• [SLOW TEST:11.262 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:01:04.812: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4126
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 10:01:05.324: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:05.356: INFO: Number of nodes with available pods: 0
Dec 10 10:01:05.356: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:06.388: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:06.406: INFO: Number of nodes with available pods: 0
Dec 10 10:01:06.406: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:07.389: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:07.417: INFO: Number of nodes with available pods: 0
Dec 10 10:01:07.417: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:08.388: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:08.406: INFO: Number of nodes with available pods: 2
Dec 10 10:01:08.406: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 10 10:01:08.488: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:08.507: INFO: Number of nodes with available pods: 1
Dec 10 10:01:08.507: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:09.538: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:09.555: INFO: Number of nodes with available pods: 1
Dec 10 10:01:09.555: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:10.540: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:10.560: INFO: Number of nodes with available pods: 1
Dec 10 10:01:10.560: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:11.546: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:11.565: INFO: Number of nodes with available pods: 1
Dec 10 10:01:11.565: INFO: Node node1 is running more than one daemon pod
Dec 10 10:01:12.545: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:01:12.564: INFO: Number of nodes with available pods: 2
Dec 10 10:01:12.564: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4126, will wait for the garbage collector to delete the pods
Dec 10 10:01:12.689: INFO: Deleting DaemonSet.extensions daemon-set took: 26.001921ms
Dec 10 10:01:12.989: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.301563ms
Dec 10 10:01:26.815: INFO: Number of nodes with available pods: 0
Dec 10 10:01:26.815: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 10:01:26.835: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4126/daemonsets","resourceVersion":"167216"},"items":null}

Dec 10 10:01:26.850: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4126/pods","resourceVersion":"167216"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:01:26.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4126" for this suite.
Dec 10 10:01:33.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:01:33.628: INFO: namespace daemonsets-4126 deletion completed in 6.686189894s

• [SLOW TEST:28.816 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:01:33.630: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 10 10:01:40.193: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:01:40.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1210 10:01:40.193299      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-770" for this suite.
Dec 10 10:01:48.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:01:48.867: INFO: namespace gc-770 deletion completed in 8.650332074s

• [SLOW TEST:15.237 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:01:48.867: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 10 10:01:57.409: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 10:01:57.427: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 10:01:59.427: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 10:01:59.445: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 10:02:01.427: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 10:02:01.444: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:02:01.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5664" for this suite.
Dec 10 10:02:25.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:02:26.181: INFO: namespace container-lifecycle-hook-5664 deletion completed in 24.670659959s

• [SLOW TEST:37.314 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:02:26.181: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Dec 10 10:02:26.563: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-132482711 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:02:26.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4213" for this suite.
Dec 10 10:02:32.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:02:33.422: INFO: namespace kubectl-4213 deletion completed in 6.619376121s

• [SLOW TEST:7.241 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:02:33.423: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-8a29142c-6a25-493c-841a-fe08f66b4828
STEP: Creating secret with name secret-projected-all-test-volume-78075742-9082-42c9-8021-76f7d64cdf10
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 10 10:02:33.841: INFO: Waiting up to 5m0s for pod "projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e" in namespace "projected-9440" to be "success or failure"
Dec 10 10:02:33.939: INFO: Pod "projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 98.019886ms
Dec 10 10:02:35.958: INFO: Pod "projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116952686s
Dec 10 10:02:37.980: INFO: Pod "projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138868383s
STEP: Saw pod success
Dec 10 10:02:37.980: INFO: Pod "projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e" satisfied condition "success or failure"
Dec 10 10:02:37.997: INFO: Trying to get logs from node node1 pod projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 10 10:02:38.086: INFO: Waiting for pod projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e to disappear
Dec 10 10:02:38.102: INFO: Pod projected-volume-ef3d0e30-dd80-44f8-8308-9f6dc5124f5e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:02:38.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9440" for this suite.
Dec 10 10:02:44.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:02:44.827: INFO: namespace projected-9440 deletion completed in 6.691003082s

• [SLOW TEST:11.404 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:02:44.828: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1816
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:02:50.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1816" for this suite.
Dec 10 10:03:14.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:03:15.027: INFO: namespace replication-controller-1816 deletion completed in 24.659170498s

• [SLOW TEST:30.199 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:03:15.028: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6490
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 10:03:15.372: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 10:03:41.719: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.253.1.164:8080/dial?request=hostName&protocol=http&host=10.253.1.163&port=8080&tries=1'] Namespace:pod-network-test-6490 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:03:41.719: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:03:42.199: INFO: Waiting for endpoints: map[]
Dec 10 10:03:42.225: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.253.1.164:8080/dial?request=hostName&protocol=http&host=10.253.2.120&port=8080&tries=1'] Namespace:pod-network-test-6490 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:03:42.225: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:03:42.709: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:03:42.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6490" for this suite.
Dec 10 10:04:06.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:07.347: INFO: namespace pod-network-test-6490 deletion completed in 24.608554935s

• [SLOW TEST:52.319 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:07.348: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 10 10:04:07.732: INFO: Waiting up to 5m0s for pod "downward-api-452390c1-73e3-49c8-8f31-5054d0eef597" in namespace "downward-api-7646" to be "success or failure"
Dec 10 10:04:07.754: INFO: Pod "downward-api-452390c1-73e3-49c8-8f31-5054d0eef597": Phase="Pending", Reason="", readiness=false. Elapsed: 22.850725ms
Dec 10 10:04:09.771: INFO: Pod "downward-api-452390c1-73e3-49c8-8f31-5054d0eef597": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038991661s
Dec 10 10:04:11.789: INFO: Pod "downward-api-452390c1-73e3-49c8-8f31-5054d0eef597": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057234661s
STEP: Saw pod success
Dec 10 10:04:11.789: INFO: Pod "downward-api-452390c1-73e3-49c8-8f31-5054d0eef597" satisfied condition "success or failure"
Dec 10 10:04:11.812: INFO: Trying to get logs from node node1 pod downward-api-452390c1-73e3-49c8-8f31-5054d0eef597 container dapi-container: <nil>
STEP: delete the pod
Dec 10 10:04:11.909: INFO: Waiting for pod downward-api-452390c1-73e3-49c8-8f31-5054d0eef597 to disappear
Dec 10 10:04:11.925: INFO: Pod downward-api-452390c1-73e3-49c8-8f31-5054d0eef597 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:04:11.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7646" for this suite.
Dec 10 10:04:18.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:18.664: INFO: namespace downward-api-7646 deletion completed in 6.706542702s

• [SLOW TEST:11.316 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:18.664: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:04:19.074: INFO: (0) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 48.315784ms)
Dec 10 10:04:19.105: INFO: (1) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.521041ms)
Dec 10 10:04:19.136: INFO: (2) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.989723ms)
Dec 10 10:04:19.166: INFO: (3) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.779553ms)
Dec 10 10:04:19.196: INFO: (4) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.583465ms)
Dec 10 10:04:19.225: INFO: (5) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.653758ms)
Dec 10 10:04:19.255: INFO: (6) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.885614ms)
Dec 10 10:04:19.286: INFO: (7) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.584502ms)
Dec 10 10:04:19.316: INFO: (8) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.99485ms)
Dec 10 10:04:19.348: INFO: (9) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 32.285029ms)
Dec 10 10:04:19.379: INFO: (10) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.876118ms)
Dec 10 10:04:19.411: INFO: (11) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 31.372452ms)
Dec 10 10:04:19.441: INFO: (12) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.618147ms)
Dec 10 10:04:19.472: INFO: (13) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.758115ms)
Dec 10 10:04:19.501: INFO: (14) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.850404ms)
Dec 10 10:04:19.531: INFO: (15) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.57263ms)
Dec 10 10:04:19.563: INFO: (16) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 32.390495ms)
Dec 10 10:04:19.593: INFO: (17) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.571581ms)
Dec 10 10:04:19.622: INFO: (18) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 29.238678ms)
Dec 10 10:04:19.651: INFO: (19) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.525412ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:04:19.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-693" for this suite.
Dec 10 10:04:27.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:28.335: INFO: namespace proxy-693 deletion completed in 8.66107739s

• [SLOW TEST:9.671 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:28.336: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-10286857-a3c1-4d3f-bc5b-c5c84aba2c69
STEP: Creating a pod to test consume configMaps
Dec 10 10:04:28.759: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509" in namespace "projected-4133" to be "success or failure"
Dec 10 10:04:28.814: INFO: Pod "pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509": Phase="Pending", Reason="", readiness=false. Elapsed: 54.45166ms
Dec 10 10:04:30.835: INFO: Pod "pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075225812s
Dec 10 10:04:32.855: INFO: Pod "pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095650689s
STEP: Saw pod success
Dec 10 10:04:32.855: INFO: Pod "pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509" satisfied condition "success or failure"
Dec 10 10:04:32.871: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:04:32.966: INFO: Waiting for pod pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509 to disappear
Dec 10 10:04:32.982: INFO: Pod pod-projected-configmaps-d5286cfe-2741-4f09-8446-52a0b9232509 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:04:32.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4133" for this suite.
Dec 10 10:04:39.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:39.689: INFO: namespace projected-4133 deletion completed in 6.674574439s

• [SLOW TEST:11.353 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:39.689: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7786
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 10:04:40.080: INFO: Waiting up to 5m0s for pod "pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2" in namespace "emptydir-7786" to be "success or failure"
Dec 10 10:04:40.109: INFO: Pod "pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.587052ms
Dec 10 10:04:42.129: INFO: Pod "pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048426925s
Dec 10 10:04:44.149: INFO: Pod "pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068529643s
STEP: Saw pod success
Dec 10 10:04:44.149: INFO: Pod "pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2" satisfied condition "success or failure"
Dec 10 10:04:44.213: INFO: Trying to get logs from node node1 pod pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2 container test-container: <nil>
STEP: delete the pod
Dec 10 10:04:44.385: INFO: Waiting for pod pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2 to disappear
Dec 10 10:04:44.403: INFO: Pod pod-21b58281-b704-41d1-a8ea-c5b2080d7dd2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:04:44.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7786" for this suite.
Dec 10 10:04:50.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:51.080: INFO: namespace emptydir-7786 deletion completed in 6.645489646s

• [SLOW TEST:11.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:51.080: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-dc1b5b00-1686-49ba-b40b-0043de98db64
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:04:51.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1047" for this suite.
Dec 10 10:04:57.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:04:58.146: INFO: namespace secrets-1047 deletion completed in 6.664567777s

• [SLOW TEST:7.067 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:04:58.147: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:04:58.548: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 10 10:05:03.568: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 10:05:03.569: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 10 10:05:05.588: INFO: Creating deployment "test-rollover-deployment"
Dec 10 10:05:05.631: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 10 10:05:07.691: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 10 10:05:07.733: INFO: Ensure that both replica sets have 1 created replica
Dec 10 10:05:07.765: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 10 10:05:07.802: INFO: Updating deployment test-rollover-deployment
Dec 10 10:05:07.802: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 10 10:05:09.835: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 10 10:05:09.871: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 10 10:05:09.910: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:09.910: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:11.945: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:11.945: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:13.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:13.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:15.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:15.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:17.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:17.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:19.946: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:19.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:21.950: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:21.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:23.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:23.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:25.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:25.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:27.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:27.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:29.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:29.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:31.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:31.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:33.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:33.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:35.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:35.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:37.957: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:37.957: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:39.946: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:39.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:41.950: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:41.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:43.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:43.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:45.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:45.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:47.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:47.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:49.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:49.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:51.946: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:51.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:53.951: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:53.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:55.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:55.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:57.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:57.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:05:59.950: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:05:59.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:01.951: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:01.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:03.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:03.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:05.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:05.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:07.947: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:07.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:09.945: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:09.945: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:11.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:11.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:13.949: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:13.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:15.948: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:15.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:17.952: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 10:06:17.952: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569053, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711569049, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:06:19.950: INFO: 
Dec 10 10:06:19.950: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 10 10:06:20.054: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9819,SelfLink:/apis/apps/v1/namespaces/deployment-9819/deployments/test-rollover-deployment,UID:c5870778-1139-46ad-a140-bfe14e8cb4ee,ResourceVersion:168191,Generation:2,CreationTimestamp:2019-12-10 10:04:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-10 10:04:09 +0000 UTC 2019-12-10 10:04:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-10 10:05:23 +0000 UTC 2019-12-10 10:04:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 10:06:20.073: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9819,SelfLink:/apis/apps/v1/namespaces/deployment-9819/replicasets/test-rollover-deployment-854595fc44,UID:65c68005-f52f-438e-9a25-c80ed2941372,ResourceVersion:168180,Generation:2,CreationTimestamp:2019-12-10 10:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c5870778-1139-46ad-a140-bfe14e8cb4ee 0xc003309667 0xc003309668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 10 10:06:20.073: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 10 10:06:20.073: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9819,SelfLink:/apis/apps/v1/namespaces/deployment-9819/replicasets/test-rollover-controller,UID:14159983-44e5-4722-8671-21f4fa8ff6c2,ResourceVersion:168190,Generation:2,CreationTimestamp:2019-12-10 10:04:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c5870778-1139-46ad-a140-bfe14e8cb4ee 0xc003309597 0xc003309598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 10:06:20.073: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9819,SelfLink:/apis/apps/v1/namespaces/deployment-9819/replicasets/test-rollover-deployment-9b8b997cf,UID:76ef4e35-918b-43e4-8d42-ebf7cb54b02d,ResourceVersion:168057,Generation:2,CreationTimestamp:2019-12-10 10:04:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c5870778-1139-46ad-a140-bfe14e8cb4ee 0xc003309730 0xc003309731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 10:06:20.091: INFO: Pod "test-rollover-deployment-854595fc44-6p787" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-6p787,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9819,SelfLink:/api/v1/namespaces/deployment-9819/pods/test-rollover-deployment-854595fc44-6p787,UID:65cca4c0-9df9-46e0-9650-6242685898f9,ResourceVersion:168072,Generation:0,CreationTimestamp:2019-12-10 10:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 65c68005-f52f-438e-9a25-c80ed2941372 0xc004522307 0xc004522308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-h58xd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h58xd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h58xd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc004522380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0045223a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:05:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:05:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:05:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.121,StartTime:2019-12-10 10:05:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-10 10:05:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://82494f1c50e70fa63f5a4fad2675af5659a2242c660ee3192952a1c17718b1ec}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:06:20.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9819" for this suite.
Dec 10 10:06:28.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:06:28.759: INFO: namespace deployment-9819 deletion completed in 8.639006785s

• [SLOW TEST:90.612 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:06:28.760: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:06:29.103: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:06:33.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-909" for this suite.
Dec 10 10:07:13.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:07:14.262: INFO: namespace pods-909 deletion completed in 40.645724576s

• [SLOW TEST:45.502 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:07:14.262: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9823
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-3e14b277-8c81-4324-be3d-fccba5475223
STEP: Creating a pod to test consume configMaps
Dec 10 10:07:14.652: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c" in namespace "projected-9823" to be "success or failure"
Dec 10 10:07:14.673: INFO: Pod "pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.030601ms
Dec 10 10:07:16.692: INFO: Pod "pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040033099s
Dec 10 10:07:18.710: INFO: Pod "pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057823464s
STEP: Saw pod success
Dec 10 10:07:18.710: INFO: Pod "pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c" satisfied condition "success or failure"
Dec 10 10:07:18.726: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:07:18.796: INFO: Waiting for pod pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c to disappear
Dec 10 10:07:18.812: INFO: Pod pod-projected-configmaps-bb489e8c-35b6-4ee3-90cc-6416d6d8e76c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:07:18.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9823" for this suite.
Dec 10 10:07:24.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:07:25.463: INFO: namespace projected-9823 deletion completed in 6.6196175s

• [SLOW TEST:11.201 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:07:25.463: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:07:29.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9379" for this suite.
Dec 10 10:08:22.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:08:22.603: INFO: namespace kubelet-test-9379 deletion completed in 52.637520952s

• [SLOW TEST:57.140 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:08:22.603: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-471
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Dec 10 10:08:22.986: INFO: Waiting up to 5m0s for pod "client-containers-d7574de8-7129-4241-941e-fe0119478593" in namespace "containers-471" to be "success or failure"
Dec 10 10:08:23.004: INFO: Pod "client-containers-d7574de8-7129-4241-941e-fe0119478593": Phase="Pending", Reason="", readiness=false. Elapsed: 18.434857ms
Dec 10 10:08:25.023: INFO: Pod "client-containers-d7574de8-7129-4241-941e-fe0119478593": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036634631s
Dec 10 10:08:27.041: INFO: Pod "client-containers-d7574de8-7129-4241-941e-fe0119478593": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055084143s
STEP: Saw pod success
Dec 10 10:08:27.041: INFO: Pod "client-containers-d7574de8-7129-4241-941e-fe0119478593" satisfied condition "success or failure"
Dec 10 10:08:27.064: INFO: Trying to get logs from node node1 pod client-containers-d7574de8-7129-4241-941e-fe0119478593 container test-container: <nil>
STEP: delete the pod
Dec 10 10:08:27.178: INFO: Waiting for pod client-containers-d7574de8-7129-4241-941e-fe0119478593 to disappear
Dec 10 10:08:27.193: INFO: Pod client-containers-d7574de8-7129-4241-941e-fe0119478593 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:08:27.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-471" for this suite.
Dec 10 10:08:33.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:08:33.933: INFO: namespace containers-471 deletion completed in 6.702768844s

• [SLOW TEST:11.329 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:08:33.933: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5045
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 10 10:08:34.311: INFO: Waiting up to 5m0s for pod "pod-86c768b4-a2a4-4e70-a157-40b575be0149" in namespace "emptydir-5045" to be "success or failure"
Dec 10 10:08:34.353: INFO: Pod "pod-86c768b4-a2a4-4e70-a157-40b575be0149": Phase="Pending", Reason="", readiness=false. Elapsed: 41.955306ms
Dec 10 10:08:36.371: INFO: Pod "pod-86c768b4-a2a4-4e70-a157-40b575be0149": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05966858s
Dec 10 10:08:38.389: INFO: Pod "pod-86c768b4-a2a4-4e70-a157-40b575be0149": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077944196s
STEP: Saw pod success
Dec 10 10:08:38.389: INFO: Pod "pod-86c768b4-a2a4-4e70-a157-40b575be0149" satisfied condition "success or failure"
Dec 10 10:08:38.409: INFO: Trying to get logs from node node1 pod pod-86c768b4-a2a4-4e70-a157-40b575be0149 container test-container: <nil>
STEP: delete the pod
Dec 10 10:08:38.494: INFO: Waiting for pod pod-86c768b4-a2a4-4e70-a157-40b575be0149 to disappear
Dec 10 10:08:38.511: INFO: Pod pod-86c768b4-a2a4-4e70-a157-40b575be0149 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:08:38.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5045" for this suite.
Dec 10 10:08:44.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:08:45.305: INFO: namespace emptydir-5045 deletion completed in 6.761224029s

• [SLOW TEST:11.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:08:45.306: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7716
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 10:08:45.663: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 10:09:06.042: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.253.1.175:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7716 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:09:06.042: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:09:06.529: INFO: Found all expected endpoints: [netserver-0]
Dec 10 10:09:06.550: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.253.2.122:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7716 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:09:06.550: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:09:07.028: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:09:07.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7716" for this suite.
Dec 10 10:09:31.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:09:31.702: INFO: namespace pod-network-test-7716 deletion completed in 24.642412717s

• [SLOW TEST:46.397 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:09:31.703: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9e0c666b-9284-4a3f-9658-ce5957afef15
STEP: Creating a pod to test consume configMaps
Dec 10 10:09:32.118: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147" in namespace "projected-1807" to be "success or failure"
Dec 10 10:09:32.135: INFO: Pod "pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147": Phase="Pending", Reason="", readiness=false. Elapsed: 16.869671ms
Dec 10 10:09:34.152: INFO: Pod "pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034077866s
Dec 10 10:09:36.170: INFO: Pod "pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051471002s
STEP: Saw pod success
Dec 10 10:09:36.170: INFO: Pod "pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147" satisfied condition "success or failure"
Dec 10 10:09:36.187: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:09:36.274: INFO: Waiting for pod pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147 to disappear
Dec 10 10:09:36.290: INFO: Pod pod-projected-configmaps-4e75f324-abc3-48af-963d-0488e4422147 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:09:36.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1807" for this suite.
Dec 10 10:09:42.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:09:42.963: INFO: namespace projected-1807 deletion completed in 6.641281406s

• [SLOW TEST:11.261 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:09:42.963: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7244
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8272
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:10:11.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9241" for this suite.
Dec 10 10:10:17.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:10:17.866: INFO: namespace namespaces-9241 deletion completed in 6.623510913s
STEP: Destroying namespace "nsdeletetest-7244" for this suite.
Dec 10 10:10:17.881: INFO: Namespace nsdeletetest-7244 was already deleted
STEP: Destroying namespace "nsdeletetest-8272" for this suite.
Dec 10 10:10:23.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:10:24.575: INFO: namespace nsdeletetest-8272 deletion completed in 6.693578219s

• [SLOW TEST:41.611 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:10:24.575: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9430
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-b3f57ace-38d8-4772-b046-5908122a089d
STEP: Creating a pod to test consume configMaps
Dec 10 10:10:24.998: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b" in namespace "projected-9430" to be "success or failure"
Dec 10 10:10:25.018: INFO: Pod "pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.488965ms
Dec 10 10:10:27.039: INFO: Pod "pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040934558s
Dec 10 10:10:29.058: INFO: Pod "pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059605391s
STEP: Saw pod success
Dec 10 10:10:29.058: INFO: Pod "pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b" satisfied condition "success or failure"
Dec 10 10:10:29.077: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:10:29.154: INFO: Waiting for pod pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b to disappear
Dec 10 10:10:29.170: INFO: Pod pod-projected-configmaps-f7c9264c-5642-44a2-a5bf-69038a17541b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:10:29.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9430" for this suite.
Dec 10 10:10:37.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:10:37.909: INFO: namespace projected-9430 deletion completed in 8.705907908s

• [SLOW TEST:13.334 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:10:37.909: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 10:10:38.274: INFO: Waiting up to 5m0s for pod "pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c" in namespace "emptydir-8297" to be "success or failure"
Dec 10 10:10:38.296: INFO: Pod "pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c": Phase="Pending", Reason="", readiness=false. Elapsed: 22.780247ms
Dec 10 10:10:40.315: INFO: Pod "pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041087455s
Dec 10 10:10:42.335: INFO: Pod "pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061117204s
STEP: Saw pod success
Dec 10 10:10:42.335: INFO: Pod "pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c" satisfied condition "success or failure"
Dec 10 10:10:42.351: INFO: Trying to get logs from node node1 pod pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c container test-container: <nil>
STEP: delete the pod
Dec 10 10:10:42.425: INFO: Waiting for pod pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c to disappear
Dec 10 10:10:42.441: INFO: Pod pod-46470964-fdbf-4a9c-a4f4-5bd1a428c61c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:10:42.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8297" for this suite.
Dec 10 10:10:48.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:10:49.108: INFO: namespace emptydir-8297 deletion completed in 6.636074338s

• [SLOW TEST:11.199 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:10:49.108: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 10 10:10:49.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-1190'
Dec 10 10:10:51.098: INFO: stderr: ""
Dec 10 10:10:51.098: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 10:10:52.116: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:10:52.116: INFO: Found 0 / 1
Dec 10 10:10:53.126: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:10:53.126: INFO: Found 0 / 1
Dec 10 10:10:54.117: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:10:54.117: INFO: Found 1 / 1
Dec 10 10:10:54.117: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 10 10:10:54.133: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:10:54.133: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 10:10:54.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 patch pod redis-master-bvchq --namespace=kubectl-1190 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 10 10:10:54.384: INFO: stderr: ""
Dec 10 10:10:54.384: INFO: stdout: "pod/redis-master-bvchq patched\n"
STEP: checking annotations
Dec 10 10:10:54.403: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:10:54.403: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:10:54.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1190" for this suite.
Dec 10 10:11:18.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:11:19.086: INFO: namespace kubectl-1190 deletion completed in 24.643823537s

• [SLOW TEST:29.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:11:19.086: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3834
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Dec 10 10:11:19.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-3834'
Dec 10 10:11:19.943: INFO: stderr: ""
Dec 10 10:11:19.943: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Dec 10 10:11:20.962: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:11:20.962: INFO: Found 0 / 1
Dec 10 10:11:21.968: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:11:21.968: INFO: Found 0 / 1
Dec 10 10:11:22.963: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:11:22.963: INFO: Found 1 / 1
Dec 10 10:11:22.963: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 10:11:22.981: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:11:22.981: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 10 10:11:22.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 logs redis-master-9bs6q redis-master --namespace=kubectl-3834'
Dec 10 10:11:23.259: INFO: stderr: ""
Dec 10 10:11:23.259: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 10:11:22.028 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 10:11:22.028 # Server started, Redis version 3.2.12\n1:M 10 Dec 10:11:22.028 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 10:11:22.028 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 10 10:11:23.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 log redis-master-9bs6q redis-master --namespace=kubectl-3834 --tail=1'
Dec 10 10:11:23.559: INFO: stderr: ""
Dec 10 10:11:23.559: INFO: stdout: "1:M 10 Dec 10:11:22.028 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 10 10:11:23.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 log redis-master-9bs6q redis-master --namespace=kubectl-3834 --limit-bytes=1'
Dec 10 10:11:23.841: INFO: stderr: ""
Dec 10 10:11:23.841: INFO: stdout: " "
STEP: exposing timestamps
Dec 10 10:11:23.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 log redis-master-9bs6q redis-master --namespace=kubectl-3834 --tail=1 --timestamps'
Dec 10 10:11:24.137: INFO: stderr: ""
Dec 10 10:11:24.137: INFO: stdout: "2019-12-10T10:11:22.028964883Z 1:M 10 Dec 10:11:22.028 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 10 10:11:26.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 log redis-master-9bs6q redis-master --namespace=kubectl-3834 --since=1s'
Dec 10 10:11:26.929: INFO: stderr: ""
Dec 10 10:11:26.929: INFO: stdout: ""
Dec 10 10:11:26.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 log redis-master-9bs6q redis-master --namespace=kubectl-3834 --since=24h'
Dec 10 10:11:27.215: INFO: stderr: ""
Dec 10 10:11:27.215: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 10:11:22.028 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 10:11:22.028 # Server started, Redis version 3.2.12\n1:M 10 Dec 10:11:22.028 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 10:11:22.028 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Dec 10 10:11:27.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-3834'
Dec 10 10:11:27.450: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:11:27.450: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 10 10:11:27.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3834'
Dec 10 10:11:27.747: INFO: stderr: "No resources found.\n"
Dec 10 10:11:27.747: INFO: stdout: ""
Dec 10 10:11:27.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -l name=nginx --namespace=kubectl-3834 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 10:11:27.977: INFO: stderr: ""
Dec 10 10:11:27.977: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:11:27.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3834" for this suite.
Dec 10 10:11:52.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:11:52.674: INFO: namespace kubectl-3834 deletion completed in 24.662689291s

• [SLOW TEST:33.588 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:11:52.675: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-05bbb922-7195-457b-9e94-a35e94ae2587
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:11:53.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5336" for this suite.
Dec 10 10:11:59.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:11:59.742: INFO: namespace configmap-5336 deletion completed in 6.682415808s

• [SLOW TEST:7.067 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:11:59.743: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3704
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-09c3967a-e3b1-49cc-b469-1516cb8fb296
STEP: Creating configMap with name cm-test-opt-upd-992cc3b0-f714-4c4d-bcf7-7dd9dea1a2fe
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-09c3967a-e3b1-49cc-b469-1516cb8fb296
STEP: Updating configmap cm-test-opt-upd-992cc3b0-f714-4c4d-bcf7-7dd9dea1a2fe
STEP: Creating configMap with name cm-test-opt-create-d6763b51-a3e5-409c-a0b6-dbd1a4d841f9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:12:06.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3704" for this suite.
Dec 10 10:12:30.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:12:31.339: INFO: namespace configmap-3704 deletion completed in 24.678888664s

• [SLOW TEST:31.597 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:12:31.340: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:12:31.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17" in namespace "downward-api-1499" to be "success or failure"
Dec 10 10:12:31.724: INFO: Pod "downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17": Phase="Pending", Reason="", readiness=false. Elapsed: 18.626971ms
Dec 10 10:12:33.742: INFO: Pod "downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037258177s
Dec 10 10:12:35.760: INFO: Pod "downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054646077s
STEP: Saw pod success
Dec 10 10:12:35.760: INFO: Pod "downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17" satisfied condition "success or failure"
Dec 10 10:12:35.775: INFO: Trying to get logs from node node1 pod downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17 container client-container: <nil>
STEP: delete the pod
Dec 10 10:12:35.866: INFO: Waiting for pod downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17 to disappear
Dec 10 10:12:35.884: INFO: Pod downwardapi-volume-7ef14d39-b7cf-431f-b18a-2359b22eff17 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:12:35.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1499" for this suite.
Dec 10 10:12:41.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:12:42.604: INFO: namespace downward-api-1499 deletion completed in 6.682797394s

• [SLOW TEST:11.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:12:42.604: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6450
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 10:12:46.115: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:12:46.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6450" for this suite.
Dec 10 10:12:52.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:12:52.830: INFO: namespace container-runtime-6450 deletion completed in 6.607683063s

• [SLOW TEST:10.226 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:12:52.830: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 10 10:12:53.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-493'
Dec 10 10:12:53.667: INFO: stderr: ""
Dec 10 10:12:53.667: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 10:12:53.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-493'
Dec 10 10:12:53.900: INFO: stderr: ""
Dec 10 10:12:53.900: INFO: stdout: "update-demo-nautilus-7x2r7 update-demo-nautilus-dwn44 "
Dec 10 10:12:53.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-7x2r7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-493'
Dec 10 10:12:54.121: INFO: stderr: ""
Dec 10 10:12:54.121: INFO: stdout: ""
Dec 10 10:12:54.121: INFO: update-demo-nautilus-7x2r7 is created but not running
Dec 10 10:12:59.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-493'
Dec 10 10:12:59.367: INFO: stderr: ""
Dec 10 10:12:59.367: INFO: stdout: "update-demo-nautilus-7x2r7 update-demo-nautilus-dwn44 "
Dec 10 10:12:59.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-7x2r7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-493'
Dec 10 10:12:59.609: INFO: stderr: ""
Dec 10 10:12:59.609: INFO: stdout: "true"
Dec 10 10:12:59.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-7x2r7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-493'
Dec 10 10:12:59.856: INFO: stderr: ""
Dec 10 10:12:59.856: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 10:12:59.856: INFO: validating pod update-demo-nautilus-7x2r7
Dec 10 10:12:59.898: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 10:12:59.898: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 10:12:59.898: INFO: update-demo-nautilus-7x2r7 is verified up and running
Dec 10 10:12:59.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-dwn44 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-493'
Dec 10 10:13:00.130: INFO: stderr: ""
Dec 10 10:13:00.130: INFO: stdout: "true"
Dec 10 10:13:00.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-dwn44 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-493'
Dec 10 10:13:00.334: INFO: stderr: ""
Dec 10 10:13:00.334: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 10:13:00.334: INFO: validating pod update-demo-nautilus-dwn44
Dec 10 10:13:00.371: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 10:13:00.371: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 10:13:00.371: INFO: update-demo-nautilus-dwn44 is verified up and running
STEP: using delete to clean up resources
Dec 10 10:13:00.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-493'
Dec 10 10:13:00.665: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:13:00.665: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 10:13:00.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-493'
Dec 10 10:13:00.948: INFO: stderr: "No resources found.\n"
Dec 10 10:13:00.948: INFO: stdout: ""
Dec 10 10:13:00.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -l name=update-demo --namespace=kubectl-493 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 10:13:01.216: INFO: stderr: ""
Dec 10 10:13:01.216: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:13:01.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-493" for this suite.
Dec 10 10:13:07.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:13:07.880: INFO: namespace kubectl-493 deletion completed in 6.63226843s

• [SLOW TEST:15.050 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:13:07.881: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6745
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:13:08.272: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 10 10:13:13.291: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 10:13:13.291: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 10 10:13:17.438: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6745,SelfLink:/apis/apps/v1/namespaces/deployment-6745/deployments/test-cleanup-deployment,UID:8eb8ee06-389c-4c98-85b6-1895e6229d7c,ResourceVersion:169449,Generation:1,CreationTimestamp:2019-12-10 10:12:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-10 10:12:17 +0000 UTC 2019-12-10 10:12:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-10 10:12:19 +0000 UTC 2019-12-10 10:12:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 10:13:17.458: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-6745,SelfLink:/apis/apps/v1/namespaces/deployment-6745/replicasets/test-cleanup-deployment-55bbcbc84c,UID:dfecbba0-0c04-4051-9bf9-026f850d7c63,ResourceVersion:169437,Generation:1,CreationTimestamp:2019-12-10 10:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8eb8ee06-389c-4c98-85b6-1895e6229d7c 0xc0026fc3e7 0xc0026fc3e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 10 10:13:17.478: INFO: Pod "test-cleanup-deployment-55bbcbc84c-6qshv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-6qshv,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-6745,SelfLink:/api/v1/namespaces/deployment-6745/pods/test-cleanup-deployment-55bbcbc84c-6qshv,UID:189742bd-3210-4801-a5d8-2df13838c2e3,ResourceVersion:169436,Generation:0,CreationTimestamp:2019-12-10 10:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c dfecbba0-0c04-4051-9bf9-026f850d7c63 0xc0027c2cc7 0xc0027c2cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zvj58 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvj58,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zvj58 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027c2d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027c2d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:13:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:13:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:13:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-10 10:12:17 +0000 UTC  }],Message:,Reason:,HostIP:10.164.17.35,PodIP:10.253.2.125,StartTime:2019-12-10 10:13:13 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-10 10:13:15 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://5bed9a00f9440fd3bb549683eff86ae8a9028d614f0e75c7a708fc16e2bbd417}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:13:17.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6745" for this suite.
Dec 10 10:13:23.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:13:24.180: INFO: namespace deployment-6745 deletion completed in 6.670317857s

• [SLOW TEST:16.299 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:13:24.180: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-67fba87c-d664-46de-a1bf-72659713869b
STEP: Creating a pod to test consume secrets
Dec 10 10:13:24.566: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db" in namespace "projected-4808" to be "success or failure"
Dec 10 10:13:24.593: INFO: Pod "pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db": Phase="Pending", Reason="", readiness=false. Elapsed: 26.522911ms
Dec 10 10:13:26.610: INFO: Pod "pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043859444s
Dec 10 10:13:28.629: INFO: Pod "pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062963523s
STEP: Saw pod success
Dec 10 10:13:28.629: INFO: Pod "pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db" satisfied condition "success or failure"
Dec 10 10:13:28.646: INFO: Trying to get logs from node node1 pod pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:13:28.721: INFO: Waiting for pod pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db to disappear
Dec 10 10:13:28.737: INFO: Pod pod-projected-secrets-183a6b3c-acbf-4b8b-b920-9c18cf0bf2db no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:13:28.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4808" for this suite.
Dec 10 10:13:34.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:13:35.401: INFO: namespace projected-4808 deletion completed in 6.633388472s

• [SLOW TEST:11.221 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:13:35.401: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4030
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-7n72
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 10:13:35.859: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7n72" in namespace "subpath-4030" to be "success or failure"
Dec 10 10:13:35.882: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Pending", Reason="", readiness=false. Elapsed: 22.914369ms
Dec 10 10:13:37.906: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046660013s
Dec 10 10:13:39.926: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 4.066321723s
Dec 10 10:13:41.946: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 6.086571236s
Dec 10 10:13:43.964: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 8.104653659s
Dec 10 10:13:45.985: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 10.125916681s
Dec 10 10:13:48.005: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 12.14561554s
Dec 10 10:13:50.024: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 14.164365321s
Dec 10 10:13:52.043: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 16.183824849s
Dec 10 10:13:54.062: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 18.202440975s
Dec 10 10:13:56.081: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 20.221611012s
Dec 10 10:13:58.099: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Running", Reason="", readiness=true. Elapsed: 22.239959067s
Dec 10 10:14:00.121: INFO: Pod "pod-subpath-test-projected-7n72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.261961824s
STEP: Saw pod success
Dec 10 10:14:00.121: INFO: Pod "pod-subpath-test-projected-7n72" satisfied condition "success or failure"
Dec 10 10:14:00.139: INFO: Trying to get logs from node node1 pod pod-subpath-test-projected-7n72 container test-container-subpath-projected-7n72: <nil>
STEP: delete the pod
Dec 10 10:14:00.293: INFO: Waiting for pod pod-subpath-test-projected-7n72 to disappear
Dec 10 10:14:00.312: INFO: Pod pod-subpath-test-projected-7n72 no longer exists
STEP: Deleting pod pod-subpath-test-projected-7n72
Dec 10 10:14:00.312: INFO: Deleting pod "pod-subpath-test-projected-7n72" in namespace "subpath-4030"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:14:00.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4030" for this suite.
Dec 10 10:14:06.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:14:07.049: INFO: namespace subpath-4030 deletion completed in 6.686088647s

• [SLOW TEST:31.647 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:14:07.049: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 10:14:15.657: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:15.676: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:17.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:17.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:19.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:19.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:21.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:21.695: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:23.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:23.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:25.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:25.695: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:27.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:27.697: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:29.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:29.699: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:31.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:31.696: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:33.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:33.700: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 10:14:35.677: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 10:14:35.698: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:14:35.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7543" for this suite.
Dec 10 10:14:59.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:15:00.406: INFO: namespace container-lifecycle-hook-7543 deletion completed in 24.666143313s

• [SLOW TEST:53.358 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:15:00.407: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 10:15:05.465: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cb19ca3a-ff75-4d43-9522-c1ff64245e36"
Dec 10 10:15:05.465: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cb19ca3a-ff75-4d43-9522-c1ff64245e36" in namespace "pods-979" to be "terminated due to deadline exceeded"
Dec 10 10:15:05.482: INFO: Pod "pod-update-activedeadlineseconds-cb19ca3a-ff75-4d43-9522-c1ff64245e36": Phase="Running", Reason="", readiness=true. Elapsed: 17.291772ms
Dec 10 10:15:07.500: INFO: Pod "pod-update-activedeadlineseconds-cb19ca3a-ff75-4d43-9522-c1ff64245e36": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.035308173s
Dec 10 10:15:07.500: INFO: Pod "pod-update-activedeadlineseconds-cb19ca3a-ff75-4d43-9522-c1ff64245e36" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:15:07.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-979" for this suite.
Dec 10 10:15:13.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:15:14.215: INFO: namespace pods-979 deletion completed in 6.68174608s

• [SLOW TEST:13.808 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:15:14.215: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-1a902bfa-732c-4b4a-b5ad-d6b8fb117787 in namespace container-probe-9060
Dec 10 10:15:18.657: INFO: Started pod test-webserver-1a902bfa-732c-4b4a-b5ad-d6b8fb117787 in namespace container-probe-9060
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 10:15:18.673: INFO: Initial restart count of pod test-webserver-1a902bfa-732c-4b4a-b5ad-d6b8fb117787 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:19:19.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9060" for this suite.
Dec 10 10:19:25.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:19:25.721: INFO: namespace container-probe-9060 deletion completed in 6.617789368s

• [SLOW TEST:251.506 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:19:25.722: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Dec 10 10:19:26.695: INFO: created pod pod-service-account-defaultsa
Dec 10 10:19:26.695: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 10 10:19:26.718: INFO: created pod pod-service-account-mountsa
Dec 10 10:19:26.718: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 10 10:19:26.744: INFO: created pod pod-service-account-nomountsa
Dec 10 10:19:26.744: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 10 10:19:26.768: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 10 10:19:26.768: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 10 10:19:26.806: INFO: created pod pod-service-account-mountsa-mountspec
Dec 10 10:19:26.806: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 10 10:19:26.834: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 10 10:19:26.834: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 10 10:19:26.903: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 10 10:19:26.904: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 10 10:19:26.935: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 10 10:19:26.935: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 10 10:19:26.959: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 10 10:19:26.959: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:19:26.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5659" for this suite.
Dec 10 10:19:51.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:19:51.662: INFO: namespace svcaccounts-5659 deletion completed in 24.664521274s

• [SLOW TEST:25.940 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:19:51.662: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-29d72a82-efad-4b2b-8f6a-8fdefcad9996
STEP: Creating a pod to test consume configMaps
Dec 10 10:19:52.069: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9" in namespace "configmap-7360" to be "success or failure"
Dec 10 10:19:52.088: INFO: Pod "pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.543522ms
Dec 10 10:19:54.107: INFO: Pod "pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037570237s
Dec 10 10:19:56.124: INFO: Pod "pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055126519s
STEP: Saw pod success
Dec 10 10:19:56.124: INFO: Pod "pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9" satisfied condition "success or failure"
Dec 10 10:19:56.139: INFO: Trying to get logs from node node1 pod pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:19:56.234: INFO: Waiting for pod pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9 to disappear
Dec 10 10:19:56.250: INFO: Pod pod-configmaps-1ebbf0a7-9ee3-4b43-bfcb-5bfa0f110ba9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:19:56.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7360" for this suite.
Dec 10 10:20:02.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:20:02.924: INFO: namespace configmap-7360 deletion completed in 6.637067501s

• [SLOW TEST:11.261 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:20:02.924: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:20:03.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71" in namespace "projected-3932" to be "success or failure"
Dec 10 10:20:03.321: INFO: Pod "downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71": Phase="Pending", Reason="", readiness=false. Elapsed: 18.41927ms
Dec 10 10:20:05.342: INFO: Pod "downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040028034s
Dec 10 10:20:07.360: INFO: Pod "downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058219105s
STEP: Saw pod success
Dec 10 10:20:07.360: INFO: Pod "downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71" satisfied condition "success or failure"
Dec 10 10:20:07.377: INFO: Trying to get logs from node node1 pod downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71 container client-container: <nil>
STEP: delete the pod
Dec 10 10:20:07.454: INFO: Waiting for pod downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71 to disappear
Dec 10 10:20:07.470: INFO: Pod downwardapi-volume-2a6602f7-dbfc-484e-afea-ccb5c2c7bf71 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:20:07.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3932" for this suite.
Dec 10 10:20:13.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:20:14.168: INFO: namespace projected-3932 deletion completed in 6.667347915s

• [SLOW TEST:11.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:20:14.168: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 10 10:20:17.192: INFO: Successfully updated pod "annotationupdatec7c6a3fa-72f8-4d2f-9c48-25b89fa6051c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:20:21.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7381" for this suite.
Dec 10 10:20:45.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:20:46.056: INFO: namespace downward-api-7381 deletion completed in 24.692199218s

• [SLOW TEST:31.887 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:20:46.056: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:20:50.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1589" for this suite.
Dec 10 10:21:30.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:21:31.371: INFO: namespace kubelet-test-1589 deletion completed in 40.654476579s

• [SLOW TEST:45.315 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:21:31.372: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:21:31.785: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b" in namespace "projected-4139" to be "success or failure"
Dec 10 10:21:31.805: INFO: Pod "downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.692706ms
Dec 10 10:21:33.832: INFO: Pod "downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046577463s
Dec 10 10:21:35.852: INFO: Pod "downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066240026s
STEP: Saw pod success
Dec 10 10:21:35.852: INFO: Pod "downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b" satisfied condition "success or failure"
Dec 10 10:21:35.870: INFO: Trying to get logs from node node2 pod downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b container client-container: <nil>
STEP: delete the pod
Dec 10 10:21:35.990: INFO: Waiting for pod downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b to disappear
Dec 10 10:21:36.007: INFO: Pod downwardapi-volume-21afafaf-4d44-4d12-b0df-482682d66f6b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:21:36.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4139" for this suite.
Dec 10 10:21:42.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:21:42.694: INFO: namespace projected-4139 deletion completed in 6.654645481s

• [SLOW TEST:11.323 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:21:42.695: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 10:21:43.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9458'
Dec 10 10:21:44.445: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 10 10:21:44.445: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Dec 10 10:21:44.484: INFO: scanned /root for discovery docs: <nil>
Dec 10 10:21:44.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9458'
Dec 10 10:22:00.667: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 10 10:22:00.667: INFO: stdout: "Created e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6\nScaling up e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 10 10:22:00.667: INFO: stdout: "Created e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6\nScaling up e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 10 10:22:00.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9458'
Dec 10 10:22:00.887: INFO: stderr: ""
Dec 10 10:22:00.887: INFO: stdout: "e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6-x5v9j "
Dec 10 10:22:00.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6-x5v9j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9458'
Dec 10 10:22:01.121: INFO: stderr: ""
Dec 10 10:22:01.121: INFO: stdout: "true"
Dec 10 10:22:01.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6-x5v9j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9458'
Dec 10 10:22:01.348: INFO: stderr: ""
Dec 10 10:22:01.348: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 10 10:22:01.348: INFO: e2e-test-nginx-rc-adf4a0521f30684fe86c6d8537432fa6-x5v9j is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Dec 10 10:22:01.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete rc e2e-test-nginx-rc --namespace=kubectl-9458'
Dec 10 10:22:01.629: INFO: stderr: ""
Dec 10 10:22:01.629: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:22:01.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9458" for this suite.
Dec 10 10:22:07.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:22:08.305: INFO: namespace kubectl-9458 deletion completed in 6.635387297s

• [SLOW TEST:25.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:22:08.306: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-7168/secret-test-15fc0d40-087e-4467-9ad8-84f125e87dd8
STEP: Creating a pod to test consume secrets
Dec 10 10:22:08.797: INFO: Waiting up to 5m0s for pod "pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c" in namespace "secrets-7168" to be "success or failure"
Dec 10 10:22:08.822: INFO: Pod "pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.311242ms
Dec 10 10:22:10.842: INFO: Pod "pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045004535s
Dec 10 10:22:12.861: INFO: Pod "pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063854907s
STEP: Saw pod success
Dec 10 10:22:12.861: INFO: Pod "pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c" satisfied condition "success or failure"
Dec 10 10:22:12.876: INFO: Trying to get logs from node node1 pod pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c container env-test: <nil>
STEP: delete the pod
Dec 10 10:22:12.956: INFO: Waiting for pod pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c to disappear
Dec 10 10:22:12.971: INFO: Pod pod-configmaps-2eae598f-6def-4f90-abfa-f71eee99186c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:22:12.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7168" for this suite.
Dec 10 10:22:19.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:22:19.741: INFO: namespace secrets-7168 deletion completed in 6.738856667s

• [SLOW TEST:11.435 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:22:19.742: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:22:20.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7" in namespace "downward-api-3922" to be "success or failure"
Dec 10 10:22:20.223: INFO: Pod "downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.233447ms
Dec 10 10:22:22.240: INFO: Pod "downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039219806s
Dec 10 10:22:24.260: INFO: Pod "downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059622832s
STEP: Saw pod success
Dec 10 10:22:24.260: INFO: Pod "downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7" satisfied condition "success or failure"
Dec 10 10:22:24.276: INFO: Trying to get logs from node node2 pod downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7 container client-container: <nil>
STEP: delete the pod
Dec 10 10:22:24.362: INFO: Waiting for pod downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7 to disappear
Dec 10 10:22:24.378: INFO: Pod downwardapi-volume-a247b5b8-bd31-4663-ba32-1b13c7c0f0d7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:22:24.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3922" for this suite.
Dec 10 10:22:30.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:22:31.058: INFO: namespace downward-api-3922 deletion completed in 6.646443342s

• [SLOW TEST:11.316 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:22:31.058: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-44e348fd-82e2-49c8-b9b8-9645d22c3f88
STEP: Creating a pod to test consume secrets
Dec 10 10:22:31.485: INFO: Waiting up to 5m0s for pod "pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c" in namespace "secrets-9151" to be "success or failure"
Dec 10 10:22:31.537: INFO: Pod "pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c": Phase="Pending", Reason="", readiness=false. Elapsed: 52.21552ms
Dec 10 10:22:33.556: INFO: Pod "pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071470969s
Dec 10 10:22:35.573: INFO: Pod "pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088028687s
STEP: Saw pod success
Dec 10 10:22:35.573: INFO: Pod "pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c" satisfied condition "success or failure"
Dec 10 10:22:35.589: INFO: Trying to get logs from node node1 pod pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:22:35.662: INFO: Waiting for pod pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c to disappear
Dec 10 10:22:35.677: INFO: Pod pod-secrets-29a77369-ff88-4688-a8fa-704ac3adfc4c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:22:35.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9151" for this suite.
Dec 10 10:22:41.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:22:42.406: INFO: namespace secrets-9151 deletion completed in 6.696303519s

• [SLOW TEST:11.348 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:22:42.407: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3604/configmap-test-989f7bd0-f6b0-41a9-8275-d7a3eff681fb
STEP: Creating a pod to test consume configMaps
Dec 10 10:22:42.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1" in namespace "configmap-3604" to be "success or failure"
Dec 10 10:22:42.858: INFO: Pod "pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.114439ms
Dec 10 10:22:44.879: INFO: Pod "pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038264029s
Dec 10 10:22:46.910: INFO: Pod "pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069104902s
STEP: Saw pod success
Dec 10 10:22:46.910: INFO: Pod "pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1" satisfied condition "success or failure"
Dec 10 10:22:46.931: INFO: Trying to get logs from node node1 pod pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1 container env-test: <nil>
STEP: delete the pod
Dec 10 10:22:47.073: INFO: Waiting for pod pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1 to disappear
Dec 10 10:22:47.092: INFO: Pod pod-configmaps-183c5bef-0930-48c3-8b3e-df2e211047c1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:22:47.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3604" for this suite.
Dec 10 10:22:53.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:22:53.748: INFO: namespace configmap-3604 deletion completed in 6.620880021s

• [SLOW TEST:11.341 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:22:53.749: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4029
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-961ad9f6-1992-4490-ae7f-c6a302305095
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-961ad9f6-1992-4490-ae7f-c6a302305095
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:24:30.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4029" for this suite.
Dec 10 10:24:54.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:24:55.087: INFO: namespace projected-4029 deletion completed in 24.672810928s

• [SLOW TEST:121.338 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:24:55.088: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-7909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-7909
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7909
STEP: Deleting pre-stop pod
Dec 10 10:25:08.653: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:25:08.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7909" for this suite.
Dec 10 10:25:48.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:25:49.387: INFO: namespace prestop-7909 deletion completed in 40.668691714s

• [SLOW TEST:54.299 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:25:49.387: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1489
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-df241d25-5ccd-4f16-b02a-d028026e9389
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:25:54.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1489" for this suite.
Dec 10 10:26:18.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:26:18.698: INFO: namespace configmap-1489 deletion completed in 24.665766025s

• [SLOW TEST:29.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:26:18.699: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6644
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6644
STEP: Creating statefulset with conflicting port in namespace statefulset-6644
STEP: Waiting until pod test-pod will start running in namespace statefulset-6644
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6644
Dec 10 10:26:23.233: INFO: Observed stateful pod in namespace: statefulset-6644, name: ss-0, uid: 98aeace8-47a2-4fcc-aa1d-0cb909eb3e1b, status phase: Pending. Waiting for statefulset controller to delete.
Dec 10 10:26:23.390: INFO: Observed stateful pod in namespace: statefulset-6644, name: ss-0, uid: 98aeace8-47a2-4fcc-aa1d-0cb909eb3e1b, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 10:26:23.409: INFO: Observed stateful pod in namespace: statefulset-6644, name: ss-0, uid: 98aeace8-47a2-4fcc-aa1d-0cb909eb3e1b, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 10:26:23.418: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6644
STEP: Removing pod with conflicting port in namespace statefulset-6644
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6644 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 10 10:26:27.505: INFO: Deleting all statefulset in ns statefulset-6644
Dec 10 10:26:27.523: INFO: Scaling statefulset ss to 0
Dec 10 10:26:37.605: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 10:26:37.623: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:26:37.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6644" for this suite.
Dec 10 10:26:45.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:26:46.380: INFO: namespace statefulset-6644 deletion completed in 8.652918466s

• [SLOW TEST:27.681 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:26:46.380: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 10:26:49.873: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:26:49.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1646" for this suite.
Dec 10 10:26:56.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:26:56.613: INFO: namespace container-runtime-1646 deletion completed in 6.658805578s

• [SLOW TEST:10.233 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:26:56.614: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-374
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:26:57.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9" in namespace "downward-api-374" to be "success or failure"
Dec 10 10:26:57.038: INFO: Pod "downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.176976ms
Dec 10 10:26:59.057: INFO: Pod "downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042879337s
Dec 10 10:27:01.075: INFO: Pod "downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061265724s
STEP: Saw pod success
Dec 10 10:27:01.075: INFO: Pod "downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9" satisfied condition "success or failure"
Dec 10 10:27:01.091: INFO: Trying to get logs from node node2 pod downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9 container client-container: <nil>
STEP: delete the pod
Dec 10 10:27:01.182: INFO: Waiting for pod downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9 to disappear
Dec 10 10:27:01.197: INFO: Pod downwardapi-volume-95ca8aa9-35f3-4020-a1e8-c42e8154c3f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:27:01.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-374" for this suite.
Dec 10 10:27:07.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:27:07.887: INFO: namespace downward-api-374 deletion completed in 6.659472511s

• [SLOW TEST:11.273 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:27:07.888: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-406
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 10:27:08.293: INFO: Waiting up to 5m0s for pod "pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5" in namespace "emptydir-406" to be "success or failure"
Dec 10 10:27:08.314: INFO: Pod "pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.53603ms
Dec 10 10:27:10.340: INFO: Pod "pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046962502s
Dec 10 10:27:12.358: INFO: Pod "pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064974654s
STEP: Saw pod success
Dec 10 10:27:12.358: INFO: Pod "pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5" satisfied condition "success or failure"
Dec 10 10:27:12.374: INFO: Trying to get logs from node node1 pod pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5 container test-container: <nil>
STEP: delete the pod
Dec 10 10:27:12.471: INFO: Waiting for pod pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5 to disappear
Dec 10 10:27:12.488: INFO: Pod pod-0ef0ef4c-ceb4-4f37-a9a9-57ca6dc24be5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:27:12.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-406" for this suite.
Dec 10 10:27:18.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:27:19.203: INFO: namespace emptydir-406 deletion completed in 6.686073797s

• [SLOW TEST:11.316 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:27:19.203: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1161
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Dec 10 10:27:19.582: INFO: Waiting up to 5m0s for pod "client-containers-13f14955-90cb-456a-8a8c-32b4903e392c" in namespace "containers-1161" to be "success or failure"
Dec 10 10:27:19.599: INFO: Pod "client-containers-13f14955-90cb-456a-8a8c-32b4903e392c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.558472ms
Dec 10 10:27:21.617: INFO: Pod "client-containers-13f14955-90cb-456a-8a8c-32b4903e392c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034885395s
Dec 10 10:27:23.636: INFO: Pod "client-containers-13f14955-90cb-456a-8a8c-32b4903e392c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053674804s
STEP: Saw pod success
Dec 10 10:27:23.636: INFO: Pod "client-containers-13f14955-90cb-456a-8a8c-32b4903e392c" satisfied condition "success or failure"
Dec 10 10:27:23.653: INFO: Trying to get logs from node node1 pod client-containers-13f14955-90cb-456a-8a8c-32b4903e392c container test-container: <nil>
STEP: delete the pod
Dec 10 10:27:23.730: INFO: Waiting for pod client-containers-13f14955-90cb-456a-8a8c-32b4903e392c to disappear
Dec 10 10:27:23.746: INFO: Pod client-containers-13f14955-90cb-456a-8a8c-32b4903e392c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:27:23.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1161" for this suite.
Dec 10 10:27:29.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:27:30.404: INFO: namespace containers-1161 deletion completed in 6.626822507s

• [SLOW TEST:11.201 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:27:30.404: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-89
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:27:30.828: INFO: (0) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 50.003234ms)
Dec 10 10:27:30.870: INFO: (1) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 41.767224ms)
Dec 10 10:27:30.901: INFO: (2) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 31.121985ms)
Dec 10 10:27:30.933: INFO: (3) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 31.751867ms)
Dec 10 10:27:30.968: INFO: (4) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 35.435401ms)
Dec 10 10:27:30.996: INFO: (5) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.84106ms)
Dec 10 10:27:31.024: INFO: (6) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.158422ms)
Dec 10 10:27:31.051: INFO: (7) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 26.333277ms)
Dec 10 10:27:31.079: INFO: (8) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.405079ms)
Dec 10 10:27:31.106: INFO: (9) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 26.514595ms)
Dec 10 10:27:31.133: INFO: (10) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.242086ms)
Dec 10 10:27:31.160: INFO: (11) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.145613ms)
Dec 10 10:27:31.187: INFO: (12) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 26.945696ms)
Dec 10 10:27:31.214: INFO: (13) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.223334ms)
Dec 10 10:27:31.242: INFO: (14) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.940299ms)
Dec 10 10:27:31.270: INFO: (15) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.700223ms)
Dec 10 10:27:31.298: INFO: (16) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.66059ms)
Dec 10 10:27:31.326: INFO: (17) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.867027ms)
Dec 10 10:27:31.354: INFO: (18) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.508741ms)
Dec 10 10:27:31.383: INFO: (19) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 28.512235ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:27:31.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-89" for this suite.
Dec 10 10:27:37.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:27:38.058: INFO: namespace proxy-89 deletion completed in 6.650619382s

• [SLOW TEST:7.654 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:27:38.059: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 10 10:27:41.070: INFO: Successfully updated pod "labelsupdatecb29b21a-51be-41f6-b363-63ee2466f5c9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:27:45.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3370" for this suite.
Dec 10 10:28:09.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:28:09.947: INFO: namespace projected-3370 deletion completed in 24.723538326s

• [SLOW TEST:31.889 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:28:09.948: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 10 10:28:10.295: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:28:13.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5216" for this suite.
Dec 10 10:28:21.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:28:22.351: INFO: namespace init-container-5216 deletion completed in 8.68611675s

• [SLOW TEST:12.403 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:28:22.352: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:28:22.793: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 10:28:22.846: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:22.865: INFO: Number of nodes with available pods: 0
Dec 10 10:28:22.866: INFO: Node node1 is running more than one daemon pod
Dec 10 10:28:23.899: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:23.917: INFO: Number of nodes with available pods: 0
Dec 10 10:28:23.917: INFO: Node node1 is running more than one daemon pod
Dec 10 10:28:24.897: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:24.915: INFO: Number of nodes with available pods: 0
Dec 10 10:28:24.915: INFO: Node node1 is running more than one daemon pod
Dec 10 10:28:25.900: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:25.917: INFO: Number of nodes with available pods: 2
Dec 10 10:28:25.917: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 10 10:28:26.061: INFO: Wrong image for pod: daemon-set-tmfvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:26.061: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:26.094: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:27.113: INFO: Wrong image for pod: daemon-set-tmfvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:27.113: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:27.145: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:28.113: INFO: Wrong image for pod: daemon-set-tmfvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:28.113: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:28.142: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:29.114: INFO: Wrong image for pod: daemon-set-tmfvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:29.114: INFO: Pod daemon-set-tmfvq is not available
Dec 10 10:28:29.114: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:29.144: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:30.114: INFO: Pod daemon-set-lr8w2 is not available
Dec 10 10:28:30.114: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:30.144: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:31.111: INFO: Pod daemon-set-lr8w2 is not available
Dec 10 10:28:31.111: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:31.140: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:32.114: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:32.142: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:33.115: INFO: Wrong image for pod: daemon-set-v8bgk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 10 10:28:33.115: INFO: Pod daemon-set-v8bgk is not available
Dec 10 10:28:33.145: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:34.111: INFO: Pod daemon-set-jrlrl is not available
Dec 10 10:28:34.142: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 10 10:28:34.162: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:34.182: INFO: Number of nodes with available pods: 1
Dec 10 10:28:34.182: INFO: Node node2 is running more than one daemon pod
Dec 10 10:28:35.213: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:35.231: INFO: Number of nodes with available pods: 1
Dec 10 10:28:35.231: INFO: Node node2 is running more than one daemon pod
Dec 10 10:28:36.219: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:28:36.238: INFO: Number of nodes with available pods: 2
Dec 10 10:28:36.238: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7709, will wait for the garbage collector to delete the pods
Dec 10 10:28:36.422: INFO: Deleting DaemonSet.extensions daemon-set took: 27.49959ms
Dec 10 10:28:36.723: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.575435ms
Dec 10 10:28:45.140: INFO: Number of nodes with available pods: 0
Dec 10 10:28:45.140: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 10:28:45.155: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7709/daemonsets","resourceVersion":"171932"},"items":null}

Dec 10 10:28:45.170: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7709/pods","resourceVersion":"171932"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:28:45.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7709" for this suite.
Dec 10 10:28:53.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:28:53.898: INFO: namespace daemonsets-7709 deletion completed in 8.65121336s

• [SLOW TEST:31.546 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:28:53.899: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3095
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:28:54.253: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:28:55.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3095" for this suite.
Dec 10 10:29:01.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:29:02.416: INFO: namespace custom-resource-definition-3095 deletion completed in 6.696904132s

• [SLOW TEST:8.517 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:29:02.416: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:29:02.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5329" for this suite.
Dec 10 10:29:08.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:29:09.505: INFO: namespace kubelet-test-5329 deletion completed in 6.641384122s

• [SLOW TEST:7.089 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:29:09.506: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:29:09.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569" in namespace "projected-9045" to be "success or failure"
Dec 10 10:29:09.980: INFO: Pod "downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569": Phase="Pending", Reason="", readiness=false. Elapsed: 21.760731ms
Dec 10 10:29:11.998: INFO: Pod "downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040007959s
Dec 10 10:29:14.018: INFO: Pod "downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059349842s
STEP: Saw pod success
Dec 10 10:29:14.018: INFO: Pod "downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569" satisfied condition "success or failure"
Dec 10 10:29:14.034: INFO: Trying to get logs from node node1 pod downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569 container client-container: <nil>
STEP: delete the pod
Dec 10 10:29:14.118: INFO: Waiting for pod downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569 to disappear
Dec 10 10:29:14.135: INFO: Pod downwardapi-volume-dd338b83-32f8-4032-ab49-28f022cda569 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:29:14.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9045" for this suite.
Dec 10 10:29:20.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:29:20.829: INFO: namespace projected-9045 deletion completed in 6.662559864s

• [SLOW TEST:11.323 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:29:20.830: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:29:21.199: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce" in namespace "projected-6085" to be "success or failure"
Dec 10 10:29:21.217: INFO: Pod "downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce": Phase="Pending", Reason="", readiness=false. Elapsed: 17.995801ms
Dec 10 10:29:23.236: INFO: Pod "downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037155658s
Dec 10 10:29:25.256: INFO: Pod "downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056549241s
STEP: Saw pod success
Dec 10 10:29:25.256: INFO: Pod "downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce" satisfied condition "success or failure"
Dec 10 10:29:25.273: INFO: Trying to get logs from node node2 pod downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce container client-container: <nil>
STEP: delete the pod
Dec 10 10:29:25.348: INFO: Waiting for pod downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce to disappear
Dec 10 10:29:25.365: INFO: Pod downwardapi-volume-24a1596b-216b-4f0f-a6ea-47bcbcf04fce no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:29:25.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6085" for this suite.
Dec 10 10:29:31.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:29:32.085: INFO: namespace projected-6085 deletion completed in 6.687800018s

• [SLOW TEST:11.256 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:29:32.086: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:29:32.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573" in namespace "projected-6859" to be "success or failure"
Dec 10 10:29:32.487: INFO: Pod "downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573": Phase="Pending", Reason="", readiness=false. Elapsed: 22.804009ms
Dec 10 10:29:34.510: INFO: Pod "downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045981025s
Dec 10 10:29:36.532: INFO: Pod "downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067204257s
STEP: Saw pod success
Dec 10 10:29:36.532: INFO: Pod "downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573" satisfied condition "success or failure"
Dec 10 10:29:36.548: INFO: Trying to get logs from node node1 pod downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573 container client-container: <nil>
STEP: delete the pod
Dec 10 10:29:36.624: INFO: Waiting for pod downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573 to disappear
Dec 10 10:29:36.641: INFO: Pod downwardapi-volume-83d458c1-5034-4eb4-840c-376e04a63573 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:29:36.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6859" for this suite.
Dec 10 10:29:42.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:29:43.333: INFO: namespace projected-6859 deletion completed in 6.657530084s

• [SLOW TEST:11.247 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:29:43.334: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 10 10:29:47.806: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-132482711 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 10 10:29:58.102: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:29:58.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1100" for this suite.
Dec 10 10:30:04.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:30:04.817: INFO: namespace pods-1100 deletion completed in 6.676220632s

• [SLOW TEST:21.484 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:30:04.818: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Dec 10 10:30:05.197: INFO: Waiting up to 5m0s for pod "var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7" in namespace "var-expansion-2636" to be "success or failure"
Dec 10 10:30:05.214: INFO: Pod "var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.40294ms
Dec 10 10:30:07.233: INFO: Pod "var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03639951s
Dec 10 10:30:09.254: INFO: Pod "var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057822902s
STEP: Saw pod success
Dec 10 10:30:09.255: INFO: Pod "var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7" satisfied condition "success or failure"
Dec 10 10:30:09.271: INFO: Trying to get logs from node node1 pod var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7 container dapi-container: <nil>
STEP: delete the pod
Dec 10 10:30:09.341: INFO: Waiting for pod var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7 to disappear
Dec 10 10:30:09.356: INFO: Pod var-expansion-d63be20a-2db4-4bc5-b9b2-f708b16090b7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:30:09.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2636" for this suite.
Dec 10 10:30:15.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:30:16.084: INFO: namespace var-expansion-2636 deletion completed in 6.692872927s

• [SLOW TEST:11.266 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:30:16.084: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 10:30:19.565: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:30:19.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6842" for this suite.
Dec 10 10:30:25.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:30:26.362: INFO: namespace container-runtime-6842 deletion completed in 6.702777576s

• [SLOW TEST:10.278 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:30:26.363: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7641
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-cd7ddc0d-c5f6-4578-bff4-7bba2b6c989a
STEP: Creating secret with name s-test-opt-upd-9f0c557f-1335-467d-a10c-ea89e21e293a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cd7ddc0d-c5f6-4578-bff4-7bba2b6c989a
STEP: Updating secret s-test-opt-upd-9f0c557f-1335-467d-a10c-ea89e21e293a
STEP: Creating secret with name s-test-opt-create-c78f299d-4ef4-4d36-bc03-47875e457c85
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:30:33.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7641" for this suite.
Dec 10 10:30:57.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:30:58.020: INFO: namespace projected-7641 deletion completed in 24.800349645s

• [SLOW TEST:31.657 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:30:58.021: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 10:31:01.516: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:31:01.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3664" for this suite.
Dec 10 10:31:07.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:31:08.286: INFO: namespace container-runtime-3664 deletion completed in 6.669554807s

• [SLOW TEST:10.266 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:31:08.287: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:31:08.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859" in namespace "projected-3431" to be "success or failure"
Dec 10 10:31:08.763: INFO: Pod "downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859": Phase="Pending", Reason="", readiness=false. Elapsed: 22.143556ms
Dec 10 10:31:10.788: INFO: Pod "downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047605223s
Dec 10 10:31:12.810: INFO: Pod "downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069236625s
STEP: Saw pod success
Dec 10 10:31:12.810: INFO: Pod "downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859" satisfied condition "success or failure"
Dec 10 10:31:12.828: INFO: Trying to get logs from node node2 pod downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859 container client-container: <nil>
STEP: delete the pod
Dec 10 10:31:12.901: INFO: Waiting for pod downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859 to disappear
Dec 10 10:31:12.917: INFO: Pod downwardapi-volume-12d6a84a-5e78-4940-9fcd-189976d71859 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:31:12.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3431" for this suite.
Dec 10 10:31:19.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:31:19.586: INFO: namespace projected-3431 deletion completed in 6.634248283s

• [SLOW TEST:11.299 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:31:19.586: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1240
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 10:31:19.931: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 10:31:44.265: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.253.2.139 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1240 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:31:44.265: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:31:45.778: INFO: Found all expected endpoints: [netserver-0]
Dec 10 10:31:45.799: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.253.1.225 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1240 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 10:31:45.799: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
Dec 10 10:31:47.296: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:31:47.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1240" for this suite.
Dec 10 10:32:11.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:32:12.004: INFO: namespace pod-network-test-1240 deletion completed in 24.676650915s

• [SLOW TEST:52.418 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:32:12.005: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 10 10:32:17.053: INFO: Successfully updated pod "labelsupdate75300995-4431-4c49-9ae7-2bcc44b968e9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:32:19.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5143" for this suite.
Dec 10 10:32:43.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:32:43.803: INFO: namespace downward-api-5143 deletion completed in 24.635724661s

• [SLOW TEST:31.799 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:32:43.804: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-4cnj
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 10:32:44.221: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4cnj" in namespace "subpath-4436" to be "success or failure"
Dec 10 10:32:44.237: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Pending", Reason="", readiness=false. Elapsed: 16.398452ms
Dec 10 10:32:46.256: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035166483s
Dec 10 10:32:48.275: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 4.054002849s
Dec 10 10:32:50.296: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 6.075410898s
Dec 10 10:32:52.315: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 8.094717077s
Dec 10 10:32:54.336: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 10.115267192s
Dec 10 10:32:56.355: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 12.134027367s
Dec 10 10:32:58.374: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 14.153175606s
Dec 10 10:33:00.391: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 16.170715163s
Dec 10 10:33:02.409: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 18.188507618s
Dec 10 10:33:04.441: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Running", Reason="", readiness=true. Elapsed: 20.220788253s
Dec 10 10:33:06.463: INFO: Pod "pod-subpath-test-configmap-4cnj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.242643872s
STEP: Saw pod success
Dec 10 10:33:06.463: INFO: Pod "pod-subpath-test-configmap-4cnj" satisfied condition "success or failure"
Dec 10 10:33:06.480: INFO: Trying to get logs from node node1 pod pod-subpath-test-configmap-4cnj container test-container-subpath-configmap-4cnj: <nil>
STEP: delete the pod
Dec 10 10:33:06.557: INFO: Waiting for pod pod-subpath-test-configmap-4cnj to disappear
Dec 10 10:33:06.573: INFO: Pod pod-subpath-test-configmap-4cnj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4cnj
Dec 10 10:33:06.573: INFO: Deleting pod "pod-subpath-test-configmap-4cnj" in namespace "subpath-4436"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:33:06.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4436" for this suite.
Dec 10 10:33:12.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:33:13.311: INFO: namespace subpath-4436 deletion completed in 6.687981582s

• [SLOW TEST:29.507 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:33:13.312: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Dec 10 10:33:13.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-5820'
Dec 10 10:33:15.757: INFO: stderr: ""
Dec 10 10:33:15.757: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 10:33:15.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5820'
Dec 10 10:33:16.030: INFO: stderr: ""
Dec 10 10:33:16.030: INFO: stdout: "update-demo-nautilus-jmx8b update-demo-nautilus-l9gjd "
Dec 10 10:33:16.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-jmx8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:16.282: INFO: stderr: ""
Dec 10 10:33:16.282: INFO: stdout: ""
Dec 10 10:33:16.282: INFO: update-demo-nautilus-jmx8b is created but not running
Dec 10 10:33:21.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5820'
Dec 10 10:33:21.539: INFO: stderr: ""
Dec 10 10:33:21.539: INFO: stdout: "update-demo-nautilus-jmx8b update-demo-nautilus-l9gjd "
Dec 10 10:33:21.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-jmx8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:21.767: INFO: stderr: ""
Dec 10 10:33:21.767: INFO: stdout: "true"
Dec 10 10:33:21.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-jmx8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:21.997: INFO: stderr: ""
Dec 10 10:33:21.997: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 10:33:21.997: INFO: validating pod update-demo-nautilus-jmx8b
Dec 10 10:33:22.039: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 10:33:22.039: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 10:33:22.039: INFO: update-demo-nautilus-jmx8b is verified up and running
Dec 10 10:33:22.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-l9gjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:22.270: INFO: stderr: ""
Dec 10 10:33:22.270: INFO: stdout: "true"
Dec 10 10:33:22.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-l9gjd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:22.517: INFO: stderr: ""
Dec 10 10:33:22.517: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 10:33:22.517: INFO: validating pod update-demo-nautilus-l9gjd
Dec 10 10:33:22.557: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 10:33:22.557: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 10:33:22.557: INFO: update-demo-nautilus-l9gjd is verified up and running
STEP: rolling-update to new replication controller
Dec 10 10:33:22.559: INFO: scanned /root for discovery docs: <nil>
Dec 10 10:33:22.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5820'
Dec 10 10:33:45.893: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 10 10:33:45.893: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 10:33:45.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5820'
Dec 10 10:33:46.125: INFO: stderr: ""
Dec 10 10:33:46.125: INFO: stdout: "update-demo-kitten-bgtrs update-demo-kitten-p57k8 "
Dec 10 10:33:46.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-kitten-bgtrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:46.357: INFO: stderr: ""
Dec 10 10:33:46.357: INFO: stdout: "true"
Dec 10 10:33:46.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-kitten-bgtrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:46.645: INFO: stderr: ""
Dec 10 10:33:46.645: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 10 10:33:46.645: INFO: validating pod update-demo-kitten-bgtrs
Dec 10 10:33:46.685: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 10 10:33:46.685: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 10 10:33:46.685: INFO: update-demo-kitten-bgtrs is verified up and running
Dec 10 10:33:46.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-kitten-p57k8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:46.924: INFO: stderr: ""
Dec 10 10:33:46.924: INFO: stdout: "true"
Dec 10 10:33:46.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-kitten-p57k8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5820'
Dec 10 10:33:47.171: INFO: stderr: ""
Dec 10 10:33:47.171: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 10 10:33:47.171: INFO: validating pod update-demo-kitten-p57k8
Dec 10 10:33:47.211: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 10 10:33:47.211: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 10 10:33:47.211: INFO: update-demo-kitten-p57k8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:33:47.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5820" for this suite.
Dec 10 10:34:11.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:34:11.945: INFO: namespace kubectl-5820 deletion completed in 24.702785752s

• [SLOW TEST:58.634 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:34:11.946: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-ae8b0cdf-fb24-46e1-a119-e5f77cfacee0
STEP: Creating a pod to test consume secrets
Dec 10 10:34:12.345: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0" in namespace "projected-5548" to be "success or failure"
Dec 10 10:34:12.363: INFO: Pod "pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.077683ms
Dec 10 10:34:14.384: INFO: Pod "pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038449584s
Dec 10 10:34:16.405: INFO: Pod "pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05998704s
STEP: Saw pod success
Dec 10 10:34:16.405: INFO: Pod "pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0" satisfied condition "success or failure"
Dec 10 10:34:16.422: INFO: Trying to get logs from node node1 pod pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:34:16.506: INFO: Waiting for pod pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0 to disappear
Dec 10 10:34:16.526: INFO: Pod pod-projected-secrets-0e6cc91a-e041-43ea-a3f3-b323971488f0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:34:16.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5548" for this suite.
Dec 10 10:34:22.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:34:23.248: INFO: namespace projected-5548 deletion completed in 6.688289015s

• [SLOW TEST:11.302 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:34:23.248: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2598
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:34:23.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0" in namespace "projected-2598" to be "success or failure"
Dec 10 10:34:23.666: INFO: Pod "downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0": Phase="Pending", Reason="", readiness=false. Elapsed: 35.686123ms
Dec 10 10:34:25.686: INFO: Pod "downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055410851s
Dec 10 10:34:27.705: INFO: Pod "downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074549715s
STEP: Saw pod success
Dec 10 10:34:27.705: INFO: Pod "downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0" satisfied condition "success or failure"
Dec 10 10:34:27.723: INFO: Trying to get logs from node node1 pod downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0 container client-container: <nil>
STEP: delete the pod
Dec 10 10:34:27.800: INFO: Waiting for pod downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0 to disappear
Dec 10 10:34:27.817: INFO: Pod downwardapi-volume-91dac768-2752-45b1-a263-3d34c507c5c0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:34:27.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2598" for this suite.
Dec 10 10:34:33.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:34:34.496: INFO: namespace projected-2598 deletion completed in 6.64444333s

• [SLOW TEST:11.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:34:34.497: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-4a37762f-997d-4614-8fa3-7b669be589b1 in namespace container-probe-1188
Dec 10 10:34:38.931: INFO: Started pod busybox-4a37762f-997d-4614-8fa3-7b669be589b1 in namespace container-probe-1188
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 10:34:38.946: INFO: Initial restart count of pod busybox-4a37762f-997d-4614-8fa3-7b669be589b1 is 0
Dec 10 10:35:25.405: INFO: Restart count of pod container-probe-1188/busybox-4a37762f-997d-4614-8fa3-7b669be589b1 is now 1 (46.45912169s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:35:25.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1188" for this suite.
Dec 10 10:35:31.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:35:32.161: INFO: namespace container-probe-1188 deletion completed in 6.686041541s

• [SLOW TEST:57.664 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:35:32.161: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 10:35:32.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5" in namespace "downward-api-9531" to be "success or failure"
Dec 10 10:35:32.555: INFO: Pod "downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.01419ms
Dec 10 10:35:34.581: INFO: Pod "downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050083327s
Dec 10 10:35:36.599: INFO: Pod "downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068389201s
STEP: Saw pod success
Dec 10 10:35:36.599: INFO: Pod "downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5" satisfied condition "success or failure"
Dec 10 10:35:36.614: INFO: Trying to get logs from node node1 pod downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5 container client-container: <nil>
STEP: delete the pod
Dec 10 10:35:36.679: INFO: Waiting for pod downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5 to disappear
Dec 10 10:35:36.696: INFO: Pod downwardapi-volume-95e840c1-d7a6-43f5-9c18-c2ad155f70a5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:35:36.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9531" for this suite.
Dec 10 10:35:42.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:35:43.365: INFO: namespace downward-api-9531 deletion completed in 6.637289585s

• [SLOW TEST:11.204 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:35:43.365: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 10:35:43.750: INFO: Waiting up to 5m0s for pod "pod-417494d4-65e8-4fb7-9e43-aba3835942cc" in namespace "emptydir-4630" to be "success or failure"
Dec 10 10:35:43.768: INFO: Pod "pod-417494d4-65e8-4fb7-9e43-aba3835942cc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.485482ms
Dec 10 10:35:45.792: INFO: Pod "pod-417494d4-65e8-4fb7-9e43-aba3835942cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04196573s
Dec 10 10:35:47.811: INFO: Pod "pod-417494d4-65e8-4fb7-9e43-aba3835942cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061274624s
STEP: Saw pod success
Dec 10 10:35:47.811: INFO: Pod "pod-417494d4-65e8-4fb7-9e43-aba3835942cc" satisfied condition "success or failure"
Dec 10 10:35:47.829: INFO: Trying to get logs from node node1 pod pod-417494d4-65e8-4fb7-9e43-aba3835942cc container test-container: <nil>
STEP: delete the pod
Dec 10 10:35:47.916: INFO: Waiting for pod pod-417494d4-65e8-4fb7-9e43-aba3835942cc to disappear
Dec 10 10:35:47.932: INFO: Pod pod-417494d4-65e8-4fb7-9e43-aba3835942cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:35:47.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4630" for this suite.
Dec 10 10:35:54.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:35:54.649: INFO: namespace emptydir-4630 deletion completed in 6.685620149s

• [SLOW TEST:11.283 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:35:54.649: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-69c09042-a438-45ab-a836-5f3465182f96 in namespace container-probe-8846
Dec 10 10:35:59.113: INFO: Started pod liveness-69c09042-a438-45ab-a836-5f3465182f96 in namespace container-probe-8846
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 10:35:59.128: INFO: Initial restart count of pod liveness-69c09042-a438-45ab-a836-5f3465182f96 is 0
Dec 10 10:36:11.258: INFO: Restart count of pod container-probe-8846/liveness-69c09042-a438-45ab-a836-5f3465182f96 is now 1 (12.130142282s elapsed)
Dec 10 10:36:31.449: INFO: Restart count of pod container-probe-8846/liveness-69c09042-a438-45ab-a836-5f3465182f96 is now 2 (32.321161348s elapsed)
Dec 10 10:36:51.668: INFO: Restart count of pod container-probe-8846/liveness-69c09042-a438-45ab-a836-5f3465182f96 is now 3 (52.540510049s elapsed)
Dec 10 10:37:11.868: INFO: Restart count of pod container-probe-8846/liveness-69c09042-a438-45ab-a836-5f3465182f96 is now 4 (1m12.740175675s elapsed)
Dec 10 10:38:20.580: INFO: Restart count of pod container-probe-8846/liveness-69c09042-a438-45ab-a836-5f3465182f96 is now 5 (2m21.45227703s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:38:20.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8846" for this suite.
Dec 10 10:38:26.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:38:27.316: INFO: namespace container-probe-8846 deletion completed in 6.661558619s

• [SLOW TEST:152.668 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:38:27.317: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-9408a775-9149-4280-acb3-3d96bee8fece
STEP: Creating a pod to test consume configMaps
Dec 10 10:38:27.765: INFO: Waiting up to 5m0s for pod "pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224" in namespace "configmap-1509" to be "success or failure"
Dec 10 10:38:27.788: INFO: Pod "pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224": Phase="Pending", Reason="", readiness=false. Elapsed: 22.350449ms
Dec 10 10:38:29.807: INFO: Pod "pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041365421s
Dec 10 10:38:31.828: INFO: Pod "pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062898824s
STEP: Saw pod success
Dec 10 10:38:31.828: INFO: Pod "pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224" satisfied condition "success or failure"
Dec 10 10:38:31.847: INFO: Trying to get logs from node node1 pod pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:38:31.943: INFO: Waiting for pod pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224 to disappear
Dec 10 10:38:31.959: INFO: Pod pod-configmaps-bd0fb5e5-15cd-42f9-a118-aad1b241f224 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:38:31.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1509" for this suite.
Dec 10 10:38:38.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:38:38.661: INFO: namespace configmap-1509 deletion completed in 6.667747255s

• [SLOW TEST:11.344 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:38:38.661: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-e50e1df8-40e1-4dd5-9e1d-af75970cfd14
STEP: Creating a pod to test consume secrets
Dec 10 10:38:39.055: INFO: Waiting up to 5m0s for pod "pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c" in namespace "secrets-6026" to be "success or failure"
Dec 10 10:38:39.075: INFO: Pod "pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.296406ms
Dec 10 10:38:41.092: INFO: Pod "pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037487446s
Dec 10 10:38:43.111: INFO: Pod "pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056192151s
STEP: Saw pod success
Dec 10 10:38:43.111: INFO: Pod "pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c" satisfied condition "success or failure"
Dec 10 10:38:43.128: INFO: Trying to get logs from node node1 pod pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:38:43.211: INFO: Waiting for pod pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c to disappear
Dec 10 10:38:43.226: INFO: Pod pod-secrets-7d874911-d4b6-4fae-a102-d6fd4575f54c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:38:43.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6026" for this suite.
Dec 10 10:38:49.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:38:49.926: INFO: namespace secrets-6026 deletion completed in 6.669976231s

• [SLOW TEST:11.265 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:38:49.926: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-9180
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9180 to expose endpoints map[]
Dec 10 10:38:50.401: INFO: Get endpoints failed (19.604323ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 10 10:38:51.419: INFO: successfully validated that service endpoint-test2 in namespace services-9180 exposes endpoints map[] (1.037408111s elapsed)
STEP: Creating pod pod1 in namespace services-9180
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9180 to expose endpoints map[pod1:[80]]
Dec 10 10:38:54.600: INFO: successfully validated that service endpoint-test2 in namespace services-9180 exposes endpoints map[pod1:[80]] (3.155715187s elapsed)
STEP: Creating pod pod2 in namespace services-9180
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9180 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 10 10:38:57.839: INFO: successfully validated that service endpoint-test2 in namespace services-9180 exposes endpoints map[pod1:[80] pod2:[80]] (3.213902182s elapsed)
STEP: Deleting pod pod1 in namespace services-9180
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9180 to expose endpoints map[pod2:[80]]
Dec 10 10:38:57.934: INFO: successfully validated that service endpoint-test2 in namespace services-9180 exposes endpoints map[pod2:[80]] (66.577451ms elapsed)
STEP: Deleting pod pod2 in namespace services-9180
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9180 to expose endpoints map[]
Dec 10 10:38:58.995: INFO: successfully validated that service endpoint-test2 in namespace services-9180 exposes endpoints map[] (1.036479553s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:38:59.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9180" for this suite.
Dec 10 10:39:23.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:39:23.810: INFO: namespace services-9180 deletion completed in 24.673053674s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:33.884 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:39:23.810: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-5d034161-9923-481b-b830-6afd47457767
STEP: Creating a pod to test consume secrets
Dec 10 10:39:24.219: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5" in namespace "projected-5521" to be "success or failure"
Dec 10 10:39:24.238: INFO: Pod "pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5": Phase="Pending", Reason="", readiness=false. Elapsed: 19.572963ms
Dec 10 10:39:26.262: INFO: Pod "pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043582241s
Dec 10 10:39:28.283: INFO: Pod "pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06444674s
STEP: Saw pod success
Dec 10 10:39:28.283: INFO: Pod "pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5" satisfied condition "success or failure"
Dec 10 10:39:28.303: INFO: Trying to get logs from node node1 pod pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:39:28.391: INFO: Waiting for pod pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5 to disappear
Dec 10 10:39:28.407: INFO: Pod pod-projected-secrets-ed591920-7ccb-4e6d-b52a-b8b4a7c897e5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:39:28.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5521" for this suite.
Dec 10 10:39:34.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:39:35.083: INFO: namespace projected-5521 deletion completed in 6.641103793s

• [SLOW TEST:11.273 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:39:35.084: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5065
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Dec 10 10:39:35.421: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-132482711 proxy --unix-socket=/tmp/kubectl-proxy-unix206120202/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:39:35.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5065" for this suite.
Dec 10 10:39:41.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:39:42.173: INFO: namespace kubectl-5065 deletion completed in 6.640247821s

• [SLOW TEST:7.090 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:39:42.174: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:39:42.645: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 10 10:39:42.684: INFO: Number of nodes with available pods: 0
Dec 10 10:39:42.684: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 10 10:39:42.798: INFO: Number of nodes with available pods: 0
Dec 10 10:39:42.798: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:43.817: INFO: Number of nodes with available pods: 0
Dec 10 10:39:43.817: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:44.816: INFO: Number of nodes with available pods: 0
Dec 10 10:39:44.816: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:45.818: INFO: Number of nodes with available pods: 1
Dec 10 10:39:45.818: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 10 10:39:45.905: INFO: Number of nodes with available pods: 1
Dec 10 10:39:45.905: INFO: Number of running nodes: 0, number of available pods: 1
Dec 10 10:39:46.925: INFO: Number of nodes with available pods: 0
Dec 10 10:39:46.925: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 10 10:39:46.995: INFO: Number of nodes with available pods: 0
Dec 10 10:39:46.995: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:48.013: INFO: Number of nodes with available pods: 0
Dec 10 10:39:48.013: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:49.015: INFO: Number of nodes with available pods: 0
Dec 10 10:39:49.015: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:50.010: INFO: Number of nodes with available pods: 0
Dec 10 10:39:50.011: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:51.014: INFO: Number of nodes with available pods: 0
Dec 10 10:39:51.014: INFO: Node node1 is running more than one daemon pod
Dec 10 10:39:52.014: INFO: Number of nodes with available pods: 1
Dec 10 10:39:52.014: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1348, will wait for the garbage collector to delete the pods
Dec 10 10:39:52.185: INFO: Deleting DaemonSet.extensions daemon-set took: 63.486675ms
Dec 10 10:39:52.485: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.435644ms
Dec 10 10:39:55.304: INFO: Number of nodes with available pods: 0
Dec 10 10:39:55.304: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 10:39:55.320: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1348/daemonsets","resourceVersion":"173888"},"items":null}

Dec 10 10:39:55.337: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1348/pods","resourceVersion":"173888"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:39:55.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1348" for this suite.
Dec 10 10:40:01.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:40:02.117: INFO: namespace daemonsets-1348 deletion completed in 6.655143335s

• [SLOW TEST:19.944 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:40:02.118: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9704
STEP: Creating secret with name secret-test-a3f3517c-dceb-4f2c-b468-20f3f57bedc4
STEP: Creating a pod to test consume secrets
Dec 10 10:40:02.918: INFO: Waiting up to 5m0s for pod "pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3" in namespace "secrets-9976" to be "success or failure"
Dec 10 10:40:02.939: INFO: Pod "pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.768323ms
Dec 10 10:40:04.959: INFO: Pod "pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041066699s
Dec 10 10:40:06.978: INFO: Pod "pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059716812s
STEP: Saw pod success
Dec 10 10:40:06.978: INFO: Pod "pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3" satisfied condition "success or failure"
Dec 10 10:40:06.995: INFO: Trying to get logs from node node1 pod pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:40:07.085: INFO: Waiting for pod pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3 to disappear
Dec 10 10:40:07.101: INFO: Pod pod-secrets-b71abdf2-2c75-487e-8786-c1281fc08ce3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:40:07.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9976" for this suite.
Dec 10 10:40:13.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:40:13.755: INFO: namespace secrets-9976 deletion completed in 6.623472787s
STEP: Destroying namespace "secret-namespace-9704" for this suite.
Dec 10 10:40:19.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:40:20.370: INFO: namespace secret-namespace-9704 deletion completed in 6.615648708s

• [SLOW TEST:18.253 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:40:20.371: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Dec 10 10:40:20.719: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 10 10:40:20.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:21.179: INFO: stderr: ""
Dec 10 10:40:21.179: INFO: stdout: "service/redis-slave created\n"
Dec 10 10:40:21.179: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 10 10:40:21.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:21.683: INFO: stderr: ""
Dec 10 10:40:21.683: INFO: stdout: "service/redis-master created\n"
Dec 10 10:40:21.683: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 10 10:40:21.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:22.158: INFO: stderr: ""
Dec 10 10:40:22.158: INFO: stdout: "service/frontend created\n"
Dec 10 10:40:22.159: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 10 10:40:22.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:22.639: INFO: stderr: ""
Dec 10 10:40:22.639: INFO: stdout: "deployment.apps/frontend created\n"
Dec 10 10:40:22.639: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 10 10:40:22.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:23.086: INFO: stderr: ""
Dec 10 10:40:23.086: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 10 10:40:23.086: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 10 10:40:23.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-7153'
Dec 10 10:40:23.747: INFO: stderr: ""
Dec 10 10:40:23.747: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 10 10:40:23.747: INFO: Waiting for all frontend pods to be Running.
Dec 10 10:40:33.798: INFO: Waiting for frontend to serve content.
Dec 10 10:40:33.980: INFO: Trying to add a new entry to the guestbook.
Dec 10 10:40:34.055: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 10 10:40:34.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:34.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:34.454: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 10:40:34.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:34.760: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:34.760: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 10:40:34.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:35.114: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:35.114: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 10:40:35.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:35.356: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:35.356: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 10:40:35.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:35.631: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:35.631: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 10:40:35.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-7153'
Dec 10 10:40:35.899: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 10:40:35.899: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:40:35.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7153" for this suite.
Dec 10 10:41:18.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:41:18.630: INFO: namespace kubectl-7153 deletion completed in 42.7003585s

• [SLOW TEST:58.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:41:18.631: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ea688561-0324-4132-be31-8d39bcad6aa8
STEP: Creating a pod to test consume secrets
Dec 10 10:41:19.062: INFO: Waiting up to 5m0s for pod "pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78" in namespace "secrets-8357" to be "success or failure"
Dec 10 10:41:19.079: INFO: Pod "pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78": Phase="Pending", Reason="", readiness=false. Elapsed: 16.562681ms
Dec 10 10:41:21.098: INFO: Pod "pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035709431s
Dec 10 10:41:23.120: INFO: Pod "pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057792297s
STEP: Saw pod success
Dec 10 10:41:23.120: INFO: Pod "pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78" satisfied condition "success or failure"
Dec 10 10:41:23.137: INFO: Trying to get logs from node node1 pod pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:41:23.212: INFO: Waiting for pod pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78 to disappear
Dec 10 10:41:23.229: INFO: Pod pod-secrets-fe5e38b9-9e35-4412-9b41-0847cfda0b78 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:41:23.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8357" for this suite.
Dec 10 10:41:29.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:41:29.910: INFO: namespace secrets-8357 deletion completed in 6.650270163s

• [SLOW TEST:11.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:41:29.910: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 10:41:30.297: INFO: Waiting up to 5m0s for pod "pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7" in namespace "emptydir-3637" to be "success or failure"
Dec 10 10:41:30.317: INFO: Pod "pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.6349ms
Dec 10 10:41:32.336: INFO: Pod "pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038667505s
Dec 10 10:41:34.357: INFO: Pod "pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059462722s
STEP: Saw pod success
Dec 10 10:41:34.357: INFO: Pod "pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7" satisfied condition "success or failure"
Dec 10 10:41:34.375: INFO: Trying to get logs from node node1 pod pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7 container test-container: <nil>
STEP: delete the pod
Dec 10 10:41:34.458: INFO: Waiting for pod pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7 to disappear
Dec 10 10:41:34.474: INFO: Pod pod-82f1937d-86b5-4322-8c2e-e8bc93a89ab7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:41:34.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3637" for this suite.
Dec 10 10:41:40.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:41:41.206: INFO: namespace emptydir-3637 deletion completed in 6.69974465s

• [SLOW TEST:11.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:41:41.206: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 10 10:41:46.267: INFO: Successfully updated pod "annotationupdate9fdb8d0a-fb89-4b8e-9642-3e93883c8302"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:41:48.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4055" for this suite.
Dec 10 10:42:12.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:42:13.131: INFO: namespace projected-4055 deletion completed in 24.752420556s

• [SLOW TEST:31.924 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:42:13.131: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5281
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-ffxz
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 10:42:13.530: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ffxz" in namespace "subpath-5281" to be "success or failure"
Dec 10 10:42:13.556: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Pending", Reason="", readiness=false. Elapsed: 25.873345ms
Dec 10 10:42:15.575: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04553882s
Dec 10 10:42:17.594: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 4.064721802s
Dec 10 10:42:19.614: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 6.083905396s
Dec 10 10:42:21.632: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 8.102052543s
Dec 10 10:42:23.651: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 10.121619606s
Dec 10 10:42:25.671: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 12.141693528s
Dec 10 10:42:27.690: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 14.160083371s
Dec 10 10:42:29.707: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 16.177722766s
Dec 10 10:42:31.728: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 18.19864819s
Dec 10 10:42:33.747: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Running", Reason="", readiness=true. Elapsed: 20.217588713s
Dec 10 10:42:35.766: INFO: Pod "pod-subpath-test-downwardapi-ffxz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.236560185s
STEP: Saw pod success
Dec 10 10:42:35.766: INFO: Pod "pod-subpath-test-downwardapi-ffxz" satisfied condition "success or failure"
Dec 10 10:42:35.783: INFO: Trying to get logs from node node1 pod pod-subpath-test-downwardapi-ffxz container test-container-subpath-downwardapi-ffxz: <nil>
STEP: delete the pod
Dec 10 10:42:35.882: INFO: Waiting for pod pod-subpath-test-downwardapi-ffxz to disappear
Dec 10 10:42:35.900: INFO: Pod pod-subpath-test-downwardapi-ffxz no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ffxz
Dec 10 10:42:35.900: INFO: Deleting pod "pod-subpath-test-downwardapi-ffxz" in namespace "subpath-5281"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:42:35.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5281" for this suite.
Dec 10 10:42:42.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:42:42.602: INFO: namespace subpath-5281 deletion completed in 6.651183138s

• [SLOW TEST:29.472 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:42:42.603: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[]
Dec 10 10:42:43.053: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[] (30.753901ms elapsed)
STEP: Creating pod pod1 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod1:[100]]
Dec 10 10:42:46.227: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod1:[100]] (3.143417809s elapsed)
STEP: Creating pod pod2 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 10 10:42:49.461: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod1:[100] pod2:[101]] (3.215182921s elapsed)
STEP: Deleting pod pod1 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod2:[101]]
Dec 10 10:42:49.532: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod2:[101]] (47.220698ms elapsed)
STEP: Deleting pod pod2 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[]
Dec 10 10:42:49.586: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[] (26.938532ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:42:49.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6480" for this suite.
Dec 10 10:43:13.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:43:14.416: INFO: namespace services-6480 deletion completed in 24.652172703s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.813 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:43:14.416: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 10 10:43:14.762: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 10:43:14.808: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 10:43:14.826: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Dec 10 10:43:14.868: INFO: kube-proxy-722tg from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 10:43:14.868: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 10:43:14.868: INFO: kube-flannel-ds-amd64-v9n9h from kube-system started at 2019-12-09 07:47:51 +0000 UTC (1 container statuses recorded)
Dec 10 10:43:14.868: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 10 10:43:14.868: INFO: sonobuoy from sonobuoy started at 2019-12-10 09:27:35 +0000 UTC (1 container statuses recorded)
Dec 10 10:43:14.868: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 10:43:14.868: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Dec 10 10:43:14.925: INFO: sonobuoy-e2e-job-95f5741cd1964606 from sonobuoy started at 2019-12-10 09:27:36 +0000 UTC (2 container statuses recorded)
Dec 10 10:43:14.925: INFO: 	Container e2e ready: true, restart count 0
Dec 10 10:43:14.925: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 10:43:14.925: INFO: kube-proxy-hbqzb from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 10:43:14.925: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 10:43:14.925: INFO: kube-flannel-ds-amd64-mszct from kube-system started at 2019-12-10 07:21:55 +0000 UTC (1 container statuses recorded)
Dec 10 10:43:14.925: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8e4f666f-93dc-4e6e-8cf5-6bb74e161dda 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8e4f666f-93dc-4e6e-8cf5-6bb74e161dda off the node node1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8e4f666f-93dc-4e6e-8cf5-6bb74e161dda
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:43:23.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3438" for this suite.
Dec 10 10:43:37.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:43:37.948: INFO: namespace sched-pred-3438 deletion completed in 14.657165606s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:23.532 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:43:37.948: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8949
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8949
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8949
Dec 10 10:43:38.370: INFO: Found 0 stateful pods, waiting for 1
Dec 10 10:43:48.390: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 10 10:43:48.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 10:43:50.447: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 10:43:50.447: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 10:43:50.447: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 10:43:50.467: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 10:44:00.495: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 10:44:00.495: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 10:44:00.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999933s
Dec 10 10:44:01.619: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.967625801s
Dec 10 10:44:02.639: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.947808934s
Dec 10 10:44:03.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9283622s
Dec 10 10:44:04.676: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.910224511s
Dec 10 10:44:05.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.891010681s
Dec 10 10:44:06.716: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.872028474s
Dec 10 10:44:07.737: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.850378032s
Dec 10 10:44:08.762: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.829104873s
Dec 10 10:44:09.782: INFO: Verifying statefulset ss doesn't scale past 1 for another 805.198425ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8949
Dec 10 10:44:10.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:44:11.483: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 10:44:11.483: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 10:44:11.483: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 10:44:11.502: INFO: Found 1 stateful pods, waiting for 3
Dec 10 10:44:21.535: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 10:44:21.535: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 10:44:21.535: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 10 10:44:21.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 10:44:22.288: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 10:44:22.288: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 10:44:22.288: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 10:44:22.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 10:44:23.027: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 10:44:23.027: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 10:44:23.027: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 10:44:23.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 10:44:23.769: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 10 10:44:23.769: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 10:44:23.769: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 10:44:23.769: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 10:44:23.792: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 10 10:44:33.831: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 10:44:33.831: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 10:44:33.831: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 10:44:33.902: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999574s
Dec 10 10:44:34.929: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.976206129s
Dec 10 10:44:35.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.948318497s
Dec 10 10:44:36.970: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.927978149s
Dec 10 10:44:37.994: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.90738843s
Dec 10 10:44:39.016: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.884159383s
Dec 10 10:44:40.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.862170158s
Dec 10 10:44:41.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.840415538s
Dec 10 10:44:42.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.818859191s
Dec 10 10:44:43.097: INFO: Verifying statefulset ss doesn't scale past 3 for another 799.139545ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8949
Dec 10 10:44:44.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:44:44.850: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 10:44:44.850: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 10:44:44.850: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 10:44:44.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:44:45.614: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 10 10:44:45.614: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 10:44:45.614: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 10:44:45.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:44:46.214: INFO: rc: 1
Dec 10 10:44:46.214: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc002fc55f0 exit status 1 <nil> <nil> true [0xc0014bf830 0xc0014bf918 0xc0014bf968] [0xc0014bf830 0xc0014bf918 0xc0014bf968] [0xc0014bf8a0 0xc0014bf960] [0x9d21f0 0x9d21f0] 0xc000f84300 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1
Dec 10 10:44:56.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:44:56.480: INFO: rc: 1
Dec 10 10:44:56.481: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001385e30 exit status 1 <nil> <nil> true [0xc0016041e8 0xc001604200 0xc001604218] [0xc0016041e8 0xc001604200 0xc001604218] [0xc0016041f8 0xc001604210] [0x9d21f0 0x9d21f0] 0xc00288f500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:06.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:06.768: INFO: rc: 1
Dec 10 10:45:06.769: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fc5920 exit status 1 <nil> <nil> true [0xc0014bf988 0xc0014bfa08 0xc0014bfa78] [0xc0014bf988 0xc0014bfa08 0xc0014bfa78] [0xc0014bf9f0 0xc0014bfa30] [0x9d21f0 0x9d21f0] 0xc000f84660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:16.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:17.034: INFO: rc: 1
Dec 10 10:45:17.034: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00274a1e0 exit status 1 <nil> <nil> true [0xc001604220 0xc001604238 0xc001604250] [0xc001604220 0xc001604238 0xc001604250] [0xc001604230 0xc001604248] [0x9d21f0 0x9d21f0] 0xc00288f860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:27.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:27.279: INFO: rc: 1
Dec 10 10:45:27.279: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00274a600 exit status 1 <nil> <nil> true [0xc001604258 0xc001604270 0xc001604288] [0xc001604258 0xc001604270 0xc001604288] [0xc001604268 0xc001604280] [0x9d21f0 0x9d21f0] 0xc00288fc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:37.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:37.552: INFO: rc: 1
Dec 10 10:45:37.552: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00274aa80 exit status 1 <nil> <nil> true [0xc001604290 0xc0016042a8 0xc0016042c0] [0xc001604290 0xc0016042a8 0xc0016042c0] [0xc0016042a0 0xc0016042b8] [0x9d21f0 0x9d21f0] 0xc000e0c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:47.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:47.811: INFO: rc: 1
Dec 10 10:45:47.811: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00274ade0 exit status 1 <nil> <nil> true [0xc0016042c8 0xc0016042e0 0xc0016042f8] [0xc0016042c8 0xc0016042e0 0xc0016042f8] [0xc0016042d8 0xc0016042f0] [0x9d21f0 0x9d21f0] 0xc000e0c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:45:57.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:45:58.057: INFO: rc: 1
Dec 10 10:45:58.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fc5c80 exit status 1 <nil> <nil> true [0xc0014bfaa8 0xc0014bfae0 0xc0014bfb70] [0xc0014bfaa8 0xc0014bfae0 0xc0014bfb70] [0xc0014bfac8 0xc0014bfb60] [0x9d21f0 0x9d21f0] 0xc000f849c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:08.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:08.304: INFO: rc: 1
Dec 10 10:46:08.304: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00274b1d0 exit status 1 <nil> <nil> true [0xc001604300 0xc001604318 0xc001604330] [0xc001604300 0xc001604318 0xc001604330] [0xc001604310 0xc001604328] [0x9d21f0 0x9d21f0] 0xc000e0c8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:18.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:18.573: INFO: rc: 1
Dec 10 10:46:18.573: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013847b0 exit status 1 <nil> <nil> true [0xc001604008 0xc001604020 0xc001604038] [0xc001604008 0xc001604020 0xc001604038] [0xc001604018 0xc001604030] [0x9d21f0 0x9d21f0] 0xc00288e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:28.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:28.808: INFO: rc: 1
Dec 10 10:46:28.808: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fc330 exit status 1 <nil> <nil> true [0xc0014be008 0xc0014be118 0xc0014be358] [0xc0014be008 0xc0014be118 0xc0014be358] [0xc0014be070 0xc0014be348] [0x9d21f0 0x9d21f0] 0xc0043d8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:38.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:39.038: INFO: rc: 1
Dec 10 10:46:39.038: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001384b10 exit status 1 <nil> <nil> true [0xc001604040 0xc001604058 0xc001604070] [0xc001604040 0xc001604058 0xc001604070] [0xc001604050 0xc001604068] [0x9d21f0 0x9d21f0] 0xc00288ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:49.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:49.281: INFO: rc: 1
Dec 10 10:46:49.281: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001384e70 exit status 1 <nil> <nil> true [0xc001604078 0xc001604090 0xc0016040a8] [0xc001604078 0xc001604090 0xc0016040a8] [0xc001604088 0xc0016040a0] [0x9d21f0 0x9d21f0] 0xc00288f080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:46:59.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:46:59.541: INFO: rc: 1
Dec 10 10:46:59.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013851d0 exit status 1 <nil> <nil> true [0xc0016040b0 0xc0016040d0 0xc0016040e8] [0xc0016040b0 0xc0016040d0 0xc0016040e8] [0xc0016040c0 0xc0016040e0] [0x9d21f0 0x9d21f0] 0xc00288f440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:47:09.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:47:09.776: INFO: rc: 1
Dec 10 10:47:09.776: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fc690 exit status 1 <nil> <nil> true [0xc0014be438 0xc0014be550 0xc0014be590] [0xc0014be438 0xc0014be550 0xc0014be590] [0xc0014be4f0 0xc0014be570] [0x9d21f0 0x9d21f0] 0xc0043d86c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:47:19.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:47:20.015: INFO: rc: 1
Dec 10 10:47:20.015: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001385560 exit status 1 <nil> <nil> true [0xc0016040f0 0xc001604108 0xc001604120] [0xc0016040f0 0xc001604108 0xc001604120] [0xc001604100 0xc001604118] [0x9d21f0 0x9d21f0] 0xc00288f800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:47:30.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:47:30.233: INFO: rc: 1
Dec 10 10:47:30.233: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001385920 exit status 1 <nil> <nil> true [0xc001604128 0xc001604140 0xc001604158] [0xc001604128 0xc001604140 0xc001604158] [0xc001604138 0xc001604150] [0x9d21f0 0x9d21f0] 0xc00288fb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:47:40.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:47:40.485: INFO: rc: 1
Dec 10 10:47:40.485: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001385c80 exit status 1 <nil> <nil> true [0xc001604160 0xc001604178 0xc001604190] [0xc001604160 0xc001604178 0xc001604190] [0xc001604170 0xc001604188] [0x9d21f0 0x9d21f0] 0xc0044e80c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:47:50.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:47:50.777: INFO: rc: 1
Dec 10 10:47:50.777: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fc9c0 exit status 1 <nil> <nil> true [0xc0014be5a0 0xc0014be5d8 0xc0014be6b0] [0xc0014be5a0 0xc0014be5d8 0xc0014be6b0] [0xc0014be5b8 0xc0014be670] [0x9d21f0 0x9d21f0] 0xc0043d8ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:00.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:01.014: INFO: rc: 1
Dec 10 10:48:01.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fcd20 exit status 1 <nil> <nil> true [0xc0014be6b8 0xc0014be710 0xc0014be750] [0xc0014be6b8 0xc0014be710 0xc0014be750] [0xc0014be6e8 0xc0014be748] [0x9d21f0 0x9d21f0] 0xc0043d8ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:11.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:11.290: INFO: rc: 1
Dec 10 10:48:11.290: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fd080 exit status 1 <nil> <nil> true [0xc0014be758 0xc0014be7d8 0xc0014be870] [0xc0014be758 0xc0014be7d8 0xc0014be870] [0xc0014be790 0xc0014be828] [0x9d21f0 0x9d21f0] 0xc0043d9200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:21.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:21.547: INFO: rc: 1
Dec 10 10:48:21.547: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fc300 exit status 1 <nil> <nil> true [0xc0014be060 0xc0014be270 0xc0014be438] [0xc0014be060 0xc0014be270 0xc0014be438] [0xc0014be118 0xc0014be358] [0x9d21f0 0x9d21f0] 0xc00288e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:31.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:31.780: INFO: rc: 1
Dec 10 10:48:31.780: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001384810 exit status 1 <nil> <nil> true [0xc001604000 0xc001604018 0xc001604030] [0xc001604000 0xc001604018 0xc001604030] [0xc001604010 0xc001604028] [0x9d21f0 0x9d21f0] 0xc0043d8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:41.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:42.018: INFO: rc: 1
Dec 10 10:48:42.018: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001384ba0 exit status 1 <nil> <nil> true [0xc001604038 0xc001604050 0xc001604068] [0xc001604038 0xc001604050 0xc001604068] [0xc001604048 0xc001604060] [0x9d21f0 0x9d21f0] 0xc0043d86c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:48:52.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:48:52.267: INFO: rc: 1
Dec 10 10:48:52.267: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001384f30 exit status 1 <nil> <nil> true [0xc001604070 0xc001604088 0xc0016040a0] [0xc001604070 0xc001604088 0xc0016040a0] [0xc001604080 0xc001604098] [0x9d21f0 0x9d21f0] 0xc0043d8ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:02.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:02.537: INFO: rc: 1
Dec 10 10:49:02.537: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013852c0 exit status 1 <nil> <nil> true [0xc0016040a8 0xc0016040c0 0xc0016040e0] [0xc0016040a8 0xc0016040c0 0xc0016040e0] [0xc0016040b8 0xc0016040d8] [0x9d21f0 0x9d21f0] 0xc0043d8ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:12.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:12.783: INFO: rc: 1
Dec 10 10:49:12.783: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fc6f0 exit status 1 <nil> <nil> true [0xc0014be498 0xc0014be558 0xc0014be5a0] [0xc0014be498 0xc0014be558 0xc0014be5a0] [0xc0014be550 0xc0014be590] [0x9d21f0 0x9d21f0] 0xc00288ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:22.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:23.022: INFO: rc: 1
Dec 10 10:49:23.022: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001385650 exit status 1 <nil> <nil> true [0xc0016040e8 0xc001604100 0xc001604118] [0xc0016040e8 0xc001604100 0xc001604118] [0xc0016040f8 0xc001604110] [0x9d21f0 0x9d21f0] 0xc0043d9200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:33.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:33.275: INFO: rc: 1
Dec 10 10:49:33.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fca50 exit status 1 <nil> <nil> true [0xc0014be5a8 0xc0014be5e8 0xc0014be6b8] [0xc0014be5a8 0xc0014be5e8 0xc0014be6b8] [0xc0014be5d8 0xc0014be6b0] [0x9d21f0 0x9d21f0] 0xc00288f080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:43.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:43.531: INFO: rc: 1
Dec 10 10:49:43.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029fcde0 exit status 1 <nil> <nil> true [0xc0014be6c8 0xc0014be740 0xc0014be758] [0xc0014be6c8 0xc0014be740 0xc0014be758] [0xc0014be710 0xc0014be750] [0x9d21f0 0x9d21f0] 0xc00288f440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 10:49:53.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 10:49:53.805: INFO: rc: 1
Dec 10 10:49:53.805: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec 10 10:49:53.805: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 10 10:49:53.869: INFO: Deleting all statefulset in ns statefulset-8949
Dec 10 10:49:53.893: INFO: Scaling statefulset ss to 0
Dec 10 10:49:53.945: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 10:49:53.960: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:49:54.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8949" for this suite.
Dec 10 10:50:02.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:50:02.711: INFO: namespace statefulset-8949 deletion completed in 8.647071467s

• [SLOW TEST:384.763 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:50:02.712: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-c4cvq in namespace proxy-2456
I1210 10:50:03.182612      15 runners.go:180] Created replication controller with name: proxy-service-c4cvq, namespace: proxy-2456, replica count: 1
I1210 10:50:04.234216      15 runners.go:180] proxy-service-c4cvq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 10:50:05.234583      15 runners.go:180] proxy-service-c4cvq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 10:50:06.234776      15 runners.go:180] proxy-service-c4cvq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 10:50:06.252: INFO: setup took 3.179311342s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 10 10:50:06.294: INFO: (0) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 41.987035ms)
Dec 10 10:50:06.304: INFO: (0) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 51.102955ms)
Dec 10 10:50:06.319: INFO: (0) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 66.464232ms)
Dec 10 10:50:06.320: INFO: (0) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 67.787715ms)
Dec 10 10:50:06.321: INFO: (0) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 68.603663ms)
Dec 10 10:50:06.335: INFO: (0) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 82.965107ms)
Dec 10 10:50:06.336: INFO: (0) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 83.531841ms)
Dec 10 10:50:06.341: INFO: (0) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 88.668146ms)
Dec 10 10:50:06.346: INFO: (0) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 93.022245ms)
Dec 10 10:50:06.346: INFO: (0) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 94.386985ms)
Dec 10 10:50:06.348: INFO: (0) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 95.852397ms)
Dec 10 10:50:06.356: INFO: (0) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 103.45597ms)
Dec 10 10:50:06.358: INFO: (0) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 104.770087ms)
Dec 10 10:50:06.360: INFO: (0) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 107.704604ms)
Dec 10 10:50:06.364: INFO: (0) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 112.157155ms)
Dec 10 10:50:06.367: INFO: (0) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 114.053954ms)
Dec 10 10:50:06.404: INFO: (1) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 37.516826ms)
Dec 10 10:50:06.406: INFO: (1) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 39.157074ms)
Dec 10 10:50:06.407: INFO: (1) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 40.636013ms)
Dec 10 10:50:06.408: INFO: (1) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 40.924153ms)
Dec 10 10:50:06.431: INFO: (1) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 63.61822ms)
Dec 10 10:50:06.431: INFO: (1) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 63.79939ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 65.829932ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 65.820638ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 66.092995ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 66.035959ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 65.889981ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 66.050165ms)
Dec 10 10:50:06.433: INFO: (1) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 65.925185ms)
Dec 10 10:50:06.457: INFO: (1) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 89.804724ms)
Dec 10 10:50:06.458: INFO: (1) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 90.888135ms)
Dec 10 10:50:06.472: INFO: (1) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 105.263169ms)
Dec 10 10:50:06.510: INFO: (2) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 37.195492ms)
Dec 10 10:50:06.510: INFO: (2) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 37.866411ms)
Dec 10 10:50:06.511: INFO: (2) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 38.267424ms)
Dec 10 10:50:06.511: INFO: (2) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 38.272263ms)
Dec 10 10:50:06.518: INFO: (2) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 44.814227ms)
Dec 10 10:50:06.519: INFO: (2) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 45.30414ms)
Dec 10 10:50:06.531: INFO: (2) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 57.238807ms)
Dec 10 10:50:06.531: INFO: (2) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 57.948795ms)
Dec 10 10:50:06.533: INFO: (2) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 59.047661ms)
Dec 10 10:50:06.533: INFO: (2) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 59.03826ms)
Dec 10 10:50:06.533: INFO: (2) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 59.424648ms)
Dec 10 10:50:06.533: INFO: (2) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 59.28487ms)
Dec 10 10:50:06.533: INFO: (2) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 59.925041ms)
Dec 10 10:50:06.535: INFO: (2) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 61.155175ms)
Dec 10 10:50:06.541: INFO: (2) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 67.977026ms)
Dec 10 10:50:06.541: INFO: (2) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 68.014134ms)
Dec 10 10:50:06.572: INFO: (3) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 30.084386ms)
Dec 10 10:50:06.572: INFO: (3) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 30.625456ms)
Dec 10 10:50:06.573: INFO: (3) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 30.332833ms)
Dec 10 10:50:06.596: INFO: (3) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 53.576392ms)
Dec 10 10:50:06.596: INFO: (3) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 54.170086ms)
Dec 10 10:50:06.597: INFO: (3) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 55.095194ms)
Dec 10 10:50:06.598: INFO: (3) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 55.050048ms)
Dec 10 10:50:06.598: INFO: (3) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 55.431296ms)
Dec 10 10:50:06.619: INFO: (3) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 76.931371ms)
Dec 10 10:50:06.623: INFO: (3) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 80.170778ms)
Dec 10 10:50:06.623: INFO: (3) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 81.32467ms)
Dec 10 10:50:06.625: INFO: (3) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 82.61933ms)
Dec 10 10:50:06.626: INFO: (3) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 84.243768ms)
Dec 10 10:50:06.631: INFO: (3) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 88.338431ms)
Dec 10 10:50:06.634: INFO: (3) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 92.383979ms)
Dec 10 10:50:06.643: INFO: (3) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 101.258113ms)
Dec 10 10:50:06.697: INFO: (4) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 53.590639ms)
Dec 10 10:50:06.698: INFO: (4) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 54.716817ms)
Dec 10 10:50:06.698: INFO: (4) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 55.116031ms)
Dec 10 10:50:06.698: INFO: (4) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 54.699522ms)
Dec 10 10:50:06.698: INFO: (4) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 55.345468ms)
Dec 10 10:50:06.700: INFO: (4) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 56.161998ms)
Dec 10 10:50:06.700: INFO: (4) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 55.646049ms)
Dec 10 10:50:06.700: INFO: (4) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 56.065644ms)
Dec 10 10:50:06.710: INFO: (4) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 66.766412ms)
Dec 10 10:50:06.717: INFO: (4) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 73.36208ms)
Dec 10 10:50:06.718: INFO: (4) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 74.382898ms)
Dec 10 10:50:06.719: INFO: (4) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 74.930931ms)
Dec 10 10:50:06.720: INFO: (4) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 76.257922ms)
Dec 10 10:50:06.720: INFO: (4) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 76.167738ms)
Dec 10 10:50:06.723: INFO: (4) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 79.628365ms)
Dec 10 10:50:06.725: INFO: (4) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 80.584723ms)
Dec 10 10:50:06.831: INFO: (5) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 104.184872ms)
Dec 10 10:50:06.832: INFO: (5) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 105.524218ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 105.886408ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 107.035393ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 106.489281ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 106.388037ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 105.693295ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 106.338691ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 105.56059ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 107.147904ms)
Dec 10 10:50:06.833: INFO: (5) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 106.626878ms)
Dec 10 10:50:06.834: INFO: (5) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 108.681327ms)
Dec 10 10:50:06.841: INFO: (5) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 114.855616ms)
Dec 10 10:50:06.842: INFO: (5) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 117.467998ms)
Dec 10 10:50:06.842: INFO: (5) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 117.36744ms)
Dec 10 10:50:06.844: INFO: (5) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 116.970744ms)
Dec 10 10:50:06.880: INFO: (6) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 36.03524ms)
Dec 10 10:50:06.881: INFO: (6) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 36.822696ms)
Dec 10 10:50:06.882: INFO: (6) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 36.46311ms)
Dec 10 10:50:06.893: INFO: (6) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 47.692563ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 56.177054ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 55.929009ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 57.488853ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 55.5916ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 55.866892ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 57.020875ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 56.278471ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 57.272357ms)
Dec 10 10:50:06.902: INFO: (6) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 56.679898ms)
Dec 10 10:50:06.906: INFO: (6) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 59.659118ms)
Dec 10 10:50:06.910: INFO: (6) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 63.877345ms)
Dec 10 10:50:06.911: INFO: (6) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 65.628088ms)
Dec 10 10:50:06.957: INFO: (7) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 46.056217ms)
Dec 10 10:50:06.964: INFO: (7) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 51.459091ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 52.988431ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 53.803224ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 53.187368ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 54.830004ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 55.159933ms)
Dec 10 10:50:06.966: INFO: (7) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 54.019946ms)
Dec 10 10:50:06.968: INFO: (7) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 55.65475ms)
Dec 10 10:50:06.970: INFO: (7) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 58.312263ms)
Dec 10 10:50:06.970: INFO: (7) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 57.821014ms)
Dec 10 10:50:06.970: INFO: (7) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 58.30795ms)
Dec 10 10:50:06.975: INFO: (7) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 61.699867ms)
Dec 10 10:50:06.976: INFO: (7) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 62.956545ms)
Dec 10 10:50:06.977: INFO: (7) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 64.920279ms)
Dec 10 10:50:06.978: INFO: (7) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 65.642709ms)
Dec 10 10:50:07.006: INFO: (8) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 27.892316ms)
Dec 10 10:50:07.007: INFO: (8) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 29.261627ms)
Dec 10 10:50:07.021: INFO: (8) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 42.62485ms)
Dec 10 10:50:07.022: INFO: (8) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 43.92696ms)
Dec 10 10:50:07.024: INFO: (8) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 45.234004ms)
Dec 10 10:50:07.024: INFO: (8) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 45.368536ms)
Dec 10 10:50:07.024: INFO: (8) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 44.969835ms)
Dec 10 10:50:07.025: INFO: (8) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 46.07647ms)
Dec 10 10:50:07.025: INFO: (8) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 45.953891ms)
Dec 10 10:50:07.025: INFO: (8) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 46.097167ms)
Dec 10 10:50:07.031: INFO: (8) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 51.656984ms)
Dec 10 10:50:07.034: INFO: (8) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 55.472321ms)
Dec 10 10:50:07.036: INFO: (8) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 57.607573ms)
Dec 10 10:50:07.037: INFO: (8) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 58.562462ms)
Dec 10 10:50:07.038: INFO: (8) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 59.271304ms)
Dec 10 10:50:07.050: INFO: (8) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 71.967318ms)
Dec 10 10:50:07.085: INFO: (9) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 34.102477ms)
Dec 10 10:50:07.111: INFO: (9) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 59.834206ms)
Dec 10 10:50:07.112: INFO: (9) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 60.488269ms)
Dec 10 10:50:07.112: INFO: (9) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 60.611926ms)
Dec 10 10:50:07.114: INFO: (9) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 62.449164ms)
Dec 10 10:50:07.116: INFO: (9) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 64.020874ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 66.880673ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 66.415102ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 66.731254ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 67.298434ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 67.770228ms)
Dec 10 10:50:07.118: INFO: (9) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 67.379142ms)
Dec 10 10:50:07.121: INFO: (9) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 69.999885ms)
Dec 10 10:50:07.129: INFO: (9) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 77.322166ms)
Dec 10 10:50:07.129: INFO: (9) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 77.15127ms)
Dec 10 10:50:07.129: INFO: (9) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 77.521042ms)
Dec 10 10:50:07.159: INFO: (10) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 30.021531ms)
Dec 10 10:50:07.171: INFO: (10) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 41.587134ms)
Dec 10 10:50:07.177: INFO: (10) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 47.294242ms)
Dec 10 10:50:07.179: INFO: (10) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 49.286371ms)
Dec 10 10:50:07.179: INFO: (10) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 49.742892ms)
Dec 10 10:50:07.179: INFO: (10) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 49.385173ms)
Dec 10 10:50:07.179: INFO: (10) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 49.648063ms)
Dec 10 10:50:07.181: INFO: (10) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 50.874049ms)
Dec 10 10:50:07.181: INFO: (10) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 50.358404ms)
Dec 10 10:50:07.181: INFO: (10) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 50.756935ms)
Dec 10 10:50:07.181: INFO: (10) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 50.539926ms)
Dec 10 10:50:07.182: INFO: (10) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 51.972728ms)
Dec 10 10:50:07.222: INFO: (10) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 91.289864ms)
Dec 10 10:50:07.224: INFO: (10) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 93.450538ms)
Dec 10 10:50:07.224: INFO: (10) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 94.242067ms)
Dec 10 10:50:07.224: INFO: (10) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 94.110411ms)
Dec 10 10:50:07.264: INFO: (11) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 39.739651ms)
Dec 10 10:50:07.264: INFO: (11) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 39.508467ms)
Dec 10 10:50:07.264: INFO: (11) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 40.05015ms)
Dec 10 10:50:07.265: INFO: (11) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 40.231993ms)
Dec 10 10:50:07.280: INFO: (11) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 55.028998ms)
Dec 10 10:50:07.280: INFO: (11) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 55.522928ms)
Dec 10 10:50:07.280: INFO: (11) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 55.234096ms)
Dec 10 10:50:07.282: INFO: (11) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 57.349564ms)
Dec 10 10:50:07.284: INFO: (11) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 59.820552ms)
Dec 10 10:50:07.287: INFO: (11) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 62.22204ms)
Dec 10 10:50:07.287: INFO: (11) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 62.552749ms)
Dec 10 10:50:07.287: INFO: (11) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 62.274839ms)
Dec 10 10:50:07.289: INFO: (11) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 63.817586ms)
Dec 10 10:50:07.289: INFO: (11) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 64.340225ms)
Dec 10 10:50:07.291: INFO: (11) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 65.976611ms)
Dec 10 10:50:07.293: INFO: (11) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 68.128911ms)
Dec 10 10:50:07.344: INFO: (12) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 50.241193ms)
Dec 10 10:50:07.344: INFO: (12) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 49.972304ms)
Dec 10 10:50:07.344: INFO: (12) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 50.067951ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 52.409549ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 51.64018ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 51.908874ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 53.078863ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 52.391268ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 52.863168ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 52.089598ms)
Dec 10 10:50:07.346: INFO: (12) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 51.900585ms)
Dec 10 10:50:07.352: INFO: (12) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 58.190564ms)
Dec 10 10:50:07.354: INFO: (12) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 59.473579ms)
Dec 10 10:50:07.355: INFO: (12) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 61.609305ms)
Dec 10 10:50:07.360: INFO: (12) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 65.787696ms)
Dec 10 10:50:07.360: INFO: (12) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 65.599952ms)
Dec 10 10:50:07.400: INFO: (13) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 39.121645ms)
Dec 10 10:50:07.402: INFO: (13) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 40.874079ms)
Dec 10 10:50:07.405: INFO: (13) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 44.267416ms)
Dec 10 10:50:07.413: INFO: (13) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 51.838538ms)
Dec 10 10:50:07.414: INFO: (13) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 52.263267ms)
Dec 10 10:50:07.415: INFO: (13) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 53.473614ms)
Dec 10 10:50:07.415: INFO: (13) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 53.944222ms)
Dec 10 10:50:07.415: INFO: (13) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 53.883293ms)
Dec 10 10:50:07.419: INFO: (13) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 57.222592ms)
Dec 10 10:50:07.420: INFO: (13) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 58.507104ms)
Dec 10 10:50:07.420: INFO: (13) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 58.024906ms)
Dec 10 10:50:07.421: INFO: (13) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 59.775724ms)
Dec 10 10:50:07.423: INFO: (13) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 62.795962ms)
Dec 10 10:50:07.427: INFO: (13) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 67.166841ms)
Dec 10 10:50:07.427: INFO: (13) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 66.350743ms)
Dec 10 10:50:07.434: INFO: (13) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 73.313763ms)
Dec 10 10:50:07.475: INFO: (14) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 39.842629ms)
Dec 10 10:50:07.483: INFO: (14) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 48.042689ms)
Dec 10 10:50:07.483: INFO: (14) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 48.515447ms)
Dec 10 10:50:07.483: INFO: (14) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 47.858299ms)
Dec 10 10:50:07.497: INFO: (14) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 60.670034ms)
Dec 10 10:50:07.502: INFO: (14) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 65.887439ms)
Dec 10 10:50:07.503: INFO: (14) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 67.258318ms)
Dec 10 10:50:07.503: INFO: (14) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 67.00786ms)
Dec 10 10:50:07.503: INFO: (14) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 67.186621ms)
Dec 10 10:50:07.503: INFO: (14) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 67.384764ms)
Dec 10 10:50:07.503: INFO: (14) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 67.057198ms)
Dec 10 10:50:07.504: INFO: (14) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 68.114886ms)
Dec 10 10:50:07.504: INFO: (14) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 68.933696ms)
Dec 10 10:50:07.504: INFO: (14) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 68.381098ms)
Dec 10 10:50:07.507: INFO: (14) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 72.032513ms)
Dec 10 10:50:07.512: INFO: (14) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 76.363175ms)
Dec 10 10:50:07.553: INFO: (15) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 39.819642ms)
Dec 10 10:50:07.553: INFO: (15) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 40.05429ms)
Dec 10 10:50:07.556: INFO: (15) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 42.076777ms)
Dec 10 10:50:07.557: INFO: (15) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 43.233382ms)
Dec 10 10:50:07.558: INFO: (15) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 43.595337ms)
Dec 10 10:50:07.558: INFO: (15) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 44.17561ms)
Dec 10 10:50:07.559: INFO: (15) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 45.185111ms)
Dec 10 10:50:07.561: INFO: (15) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 46.510575ms)
Dec 10 10:50:07.561: INFO: (15) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 47.220409ms)
Dec 10 10:50:07.586: INFO: (15) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 72.094346ms)
Dec 10 10:50:07.586: INFO: (15) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 71.278542ms)
Dec 10 10:50:07.588: INFO: (15) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 73.962893ms)
Dec 10 10:50:07.591: INFO: (15) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 76.830387ms)
Dec 10 10:50:07.592: INFO: (15) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 78.940543ms)
Dec 10 10:50:07.592: INFO: (15) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 79.838352ms)
Dec 10 10:50:07.599: INFO: (15) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 85.296404ms)
Dec 10 10:50:07.639: INFO: (16) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 39.695446ms)
Dec 10 10:50:07.641: INFO: (16) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 41.475286ms)
Dec 10 10:50:07.643: INFO: (16) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 44.076827ms)
Dec 10 10:50:07.655: INFO: (16) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 54.986549ms)
Dec 10 10:50:07.656: INFO: (16) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 55.665698ms)
Dec 10 10:50:07.656: INFO: (16) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 55.998194ms)
Dec 10 10:50:07.656: INFO: (16) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 55.800508ms)
Dec 10 10:50:07.656: INFO: (16) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 56.207497ms)
Dec 10 10:50:07.659: INFO: (16) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 58.498395ms)
Dec 10 10:50:07.659: INFO: (16) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 59.350521ms)
Dec 10 10:50:07.659: INFO: (16) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 60.593767ms)
Dec 10 10:50:07.660: INFO: (16) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 60.066889ms)
Dec 10 10:50:07.660: INFO: (16) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 59.987268ms)
Dec 10 10:50:07.665: INFO: (16) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 65.648053ms)
Dec 10 10:50:07.666: INFO: (16) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 66.565984ms)
Dec 10 10:50:07.668: INFO: (16) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 68.277925ms)
Dec 10 10:50:07.704: INFO: (17) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 35.939765ms)
Dec 10 10:50:07.704: INFO: (17) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 36.543745ms)
Dec 10 10:50:07.724: INFO: (17) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 55.166127ms)
Dec 10 10:50:07.725: INFO: (17) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 55.763879ms)
Dec 10 10:50:07.725: INFO: (17) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 55.300983ms)
Dec 10 10:50:07.725: INFO: (17) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 56.222095ms)
Dec 10 10:50:07.726: INFO: (17) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 57.096334ms)
Dec 10 10:50:07.726: INFO: (17) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 56.383516ms)
Dec 10 10:50:07.726: INFO: (17) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 57.339425ms)
Dec 10 10:50:07.727: INFO: (17) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 57.181898ms)
Dec 10 10:50:07.731: INFO: (17) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 62.819819ms)
Dec 10 10:50:07.733: INFO: (17) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 63.843443ms)
Dec 10 10:50:07.734: INFO: (17) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 64.833125ms)
Dec 10 10:50:07.735: INFO: (17) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 67.207609ms)
Dec 10 10:50:07.737: INFO: (17) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 67.055192ms)
Dec 10 10:50:07.737: INFO: (17) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 67.302139ms)
Dec 10 10:50:07.796: INFO: (18) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 58.084164ms)
Dec 10 10:50:07.796: INFO: (18) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 58.014561ms)
Dec 10 10:50:07.799: INFO: (18) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 61.32951ms)
Dec 10 10:50:07.800: INFO: (18) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 62.509575ms)
Dec 10 10:50:07.800: INFO: (18) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 62.508896ms)
Dec 10 10:50:07.801: INFO: (18) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 62.477878ms)
Dec 10 10:50:07.802: INFO: (18) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 65.002287ms)
Dec 10 10:50:07.803: INFO: (18) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 65.069256ms)
Dec 10 10:50:07.808: INFO: (18) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 70.21536ms)
Dec 10 10:50:07.808: INFO: (18) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 70.621556ms)
Dec 10 10:50:07.808: INFO: (18) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 69.882569ms)
Dec 10 10:50:07.808: INFO: (18) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 70.21923ms)
Dec 10 10:50:07.811: INFO: (18) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 73.304541ms)
Dec 10 10:50:07.812: INFO: (18) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 73.768652ms)
Dec 10 10:50:07.813: INFO: (18) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 74.317494ms)
Dec 10 10:50:07.813: INFO: (18) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 75.273969ms)
Dec 10 10:50:07.847: INFO: (19) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">test<... (200; 33.009226ms)
Dec 10 10:50:07.858: INFO: (19) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname2/proxy/: bar (200; 43.784289ms)
Dec 10 10:50:07.858: INFO: (19) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 43.658911ms)
Dec 10 10:50:07.865: INFO: (19) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:1080/proxy/rewriteme">... (200; 50.476546ms)
Dec 10 10:50:07.871: INFO: (19) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:460/proxy/: tls baz (200; 56.277401ms)
Dec 10 10:50:07.872: INFO: (19) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:162/proxy/: bar (200; 57.668764ms)
Dec 10 10:50:07.872: INFO: (19) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc/proxy/rewriteme">test</a> (200; 58.217875ms)
Dec 10 10:50:07.872: INFO: (19) /api/v1/namespaces/proxy-2456/pods/proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 57.965054ms)
Dec 10 10:50:07.872: INFO: (19) /api/v1/namespaces/proxy-2456/pods/http:proxy-service-c4cvq-94hwc:160/proxy/: foo (200; 58.893781ms)
Dec 10 10:50:07.873: INFO: (19) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname2/proxy/: tls qux (200; 59.491079ms)
Dec 10 10:50:07.873: INFO: (19) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:462/proxy/: tls qux (200; 59.69343ms)
Dec 10 10:50:07.874: INFO: (19) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname2/proxy/: bar (200; 59.177859ms)
Dec 10 10:50:07.874: INFO: (19) /api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/: <a href="/api/v1/namespaces/proxy-2456/pods/https:proxy-service-c4cvq-94hwc:443/proxy/tlsrewritem... (200; 60.538212ms)
Dec 10 10:50:07.874: INFO: (19) /api/v1/namespaces/proxy-2456/services/https:proxy-service-c4cvq:tlsportname1/proxy/: tls baz (200; 59.960239ms)
Dec 10 10:50:07.882: INFO: (19) /api/v1/namespaces/proxy-2456/services/proxy-service-c4cvq:portname1/proxy/: foo (200; 67.275728ms)
Dec 10 10:50:07.882: INFO: (19) /api/v1/namespaces/proxy-2456/services/http:proxy-service-c4cvq:portname1/proxy/: foo (200; 67.759795ms)
STEP: deleting ReplicationController proxy-service-c4cvq in namespace proxy-2456, will wait for the garbage collector to delete the pods
Dec 10 10:50:07.992: INFO: Deleting ReplicationController proxy-service-c4cvq took: 42.866325ms
Dec 10 10:50:08.293: INFO: Terminating ReplicationController proxy-service-c4cvq pods took: 300.612178ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:50:16.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2456" for this suite.
Dec 10 10:50:22.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:50:23.556: INFO: namespace proxy-2456 deletion completed in 6.730415757s

• [SLOW TEST:20.844 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:50:23.556: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-27
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-1f5f1f3b-cd57-48a3-ba62-1abe2ef15e20
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1f5f1f3b-cd57-48a3-ba62-1abe2ef15e20
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:51:31.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-27" for this suite.
Dec 10 10:51:55.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:51:56.210: INFO: namespace configmap-27 deletion completed in 24.661121677s

• [SLOW TEST:92.655 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:51:56.211: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:51:56.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2748" for this suite.
Dec 10 10:52:20.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:52:21.283: INFO: namespace pods-2748 deletion completed in 24.635286022s

• [SLOW TEST:25.073 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:52:21.284: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-2c6efffc-7e1c-4ec7-9b27-1cc50d596cf8
STEP: Creating a pod to test consume configMaps
Dec 10 10:52:21.691: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c" in namespace "projected-6750" to be "success or failure"
Dec 10 10:52:21.710: INFO: Pod "pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.296337ms
Dec 10 10:52:23.729: INFO: Pod "pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037624213s
Dec 10 10:52:25.748: INFO: Pod "pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056684545s
STEP: Saw pod success
Dec 10 10:52:25.748: INFO: Pod "pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c" satisfied condition "success or failure"
Dec 10 10:52:25.767: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 10:52:25.841: INFO: Waiting for pod pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c to disappear
Dec 10 10:52:25.859: INFO: Pod pod-projected-configmaps-0d7383a5-823c-49f1-8515-7d8ae35a825c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:52:25.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6750" for this suite.
Dec 10 10:52:31.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:52:32.532: INFO: namespace projected-6750 deletion completed in 6.641487129s

• [SLOW TEST:11.249 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:52:32.533: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7147
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-2bc26db5-8cf9-4e6d-a6f5-2f9ac3120486
STEP: Creating a pod to test consume secrets
Dec 10 10:52:32.927: INFO: Waiting up to 5m0s for pod "pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96" in namespace "secrets-7147" to be "success or failure"
Dec 10 10:52:32.949: INFO: Pod "pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96": Phase="Pending", Reason="", readiness=false. Elapsed: 22.312223ms
Dec 10 10:52:34.968: INFO: Pod "pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040738359s
Dec 10 10:52:36.987: INFO: Pod "pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059985273s
STEP: Saw pod success
Dec 10 10:52:36.987: INFO: Pod "pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96" satisfied condition "success or failure"
Dec 10 10:52:37.005: INFO: Trying to get logs from node node1 pod pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 10:52:37.085: INFO: Waiting for pod pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96 to disappear
Dec 10 10:52:37.106: INFO: Pod pod-secrets-0dd50a5c-7c18-4649-b2c1-0da19cbeed96 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:52:37.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7147" for this suite.
Dec 10 10:52:43.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:52:43.773: INFO: namespace secrets-7147 deletion completed in 6.635718669s

• [SLOW TEST:11.240 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:52:43.773: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9310
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:52:44.222: INFO: Create a RollingUpdate DaemonSet
Dec 10 10:52:44.243: INFO: Check that daemon pods launch on every node of the cluster
Dec 10 10:52:44.265: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:44.283: INFO: Number of nodes with available pods: 0
Dec 10 10:52:44.283: INFO: Node node1 is running more than one daemon pod
Dec 10 10:52:45.315: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:45.334: INFO: Number of nodes with available pods: 0
Dec 10 10:52:45.334: INFO: Node node1 is running more than one daemon pod
Dec 10 10:52:46.315: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:46.338: INFO: Number of nodes with available pods: 0
Dec 10 10:52:46.338: INFO: Node node1 is running more than one daemon pod
Dec 10 10:52:47.315: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:47.334: INFO: Number of nodes with available pods: 2
Dec 10 10:52:47.334: INFO: Number of running nodes: 2, number of available pods: 2
Dec 10 10:52:47.334: INFO: Update the DaemonSet to trigger a rollout
Dec 10 10:52:47.370: INFO: Updating DaemonSet daemon-set
Dec 10 10:52:51.460: INFO: Roll back the DaemonSet before rollout is complete
Dec 10 10:52:51.496: INFO: Updating DaemonSet daemon-set
Dec 10 10:52:51.496: INFO: Make sure DaemonSet rollback is complete
Dec 10 10:52:51.519: INFO: Wrong image for pod: daemon-set-s299r. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 10 10:52:51.519: INFO: Pod daemon-set-s299r is not available
Dec 10 10:52:51.543: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:52.562: INFO: Wrong image for pod: daemon-set-s299r. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 10 10:52:52.562: INFO: Pod daemon-set-s299r is not available
Dec 10 10:52:52.594: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:52:53.573: INFO: Pod daemon-set-ttskw is not available
Dec 10 10:52:53.606: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9310, will wait for the garbage collector to delete the pods
Dec 10 10:52:53.745: INFO: Deleting DaemonSet.extensions daemon-set took: 32.885958ms
Dec 10 10:52:54.046: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.361774ms
Dec 10 10:53:06.770: INFO: Number of nodes with available pods: 0
Dec 10 10:53:06.770: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 10:53:06.786: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9310/daemonsets","resourceVersion":"175950"},"items":null}

Dec 10 10:53:06.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9310/pods","resourceVersion":"175950"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:53:06.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9310" for this suite.
Dec 10 10:53:15.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:53:15.643: INFO: namespace daemonsets-9310 deletion completed in 8.751935143s

• [SLOW TEST:31.870 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:53:15.643: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 10:53:16.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7939'
Dec 10 10:53:16.241: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 10 10:53:16.241: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Dec 10 10:53:16.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete jobs e2e-test-nginx-job --namespace=kubectl-7939'
Dec 10 10:53:16.544: INFO: stderr: ""
Dec 10 10:53:16.544: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:53:16.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7939" for this suite.
Dec 10 10:53:22.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:53:23.299: INFO: namespace kubectl-7939 deletion completed in 6.716764425s

• [SLOW TEST:7.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:53:23.299: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 10 10:53:23.703: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176033,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 10:53:23.703: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176033,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 10 10:53:33.743: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176048,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 10 10:53:33.743: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176048,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 10 10:53:43.790: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176065,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 10:53:43.790: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176065,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 10 10:53:53.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176081,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 10:53:53.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-a,UID:21ebc190-a095-477a-8fc1-13e6c4ace7dd,ResourceVersion:176081,Generation:0,CreationTimestamp:2019-12-10 10:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 10 10:54:03.851: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-b,UID:7c707975-01a5-4bf9-bb39-3536b0032d1a,ResourceVersion:176097,Generation:0,CreationTimestamp:2019-12-10 10:53:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 10:54:03.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-b,UID:7c707975-01a5-4bf9-bb39-3536b0032d1a,ResourceVersion:176097,Generation:0,CreationTimestamp:2019-12-10 10:53:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 10 10:54:13.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-b,UID:7c707975-01a5-4bf9-bb39-3536b0032d1a,ResourceVersion:176113,Generation:0,CreationTimestamp:2019-12-10 10:53:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 10:54:13.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8523,SelfLink:/api/v1/namespaces/watch-8523/configmaps/e2e-watch-test-configmap-b,UID:7c707975-01a5-4bf9-bb39-3536b0032d1a,ResourceVersion:176113,Generation:0,CreationTimestamp:2019-12-10 10:53:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:54:23.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8523" for this suite.
Dec 10 10:54:30.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:54:30.630: INFO: namespace watch-8523 deletion completed in 6.706319264s

• [SLOW TEST:67.330 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:54:30.630: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-0afc84ba-df4c-462f-9e2b-dc6ddc33b06c in namespace container-probe-9703
Dec 10 10:54:35.056: INFO: Started pod liveness-0afc84ba-df4c-462f-9e2b-dc6ddc33b06c in namespace container-probe-9703
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 10:54:35.071: INFO: Initial restart count of pod liveness-0afc84ba-df4c-462f-9e2b-dc6ddc33b06c is 0
Dec 10 10:54:55.276: INFO: Restart count of pod container-probe-9703/liveness-0afc84ba-df4c-462f-9e2b-dc6ddc33b06c is now 1 (20.204669149s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:54:55.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9703" for this suite.
Dec 10 10:55:01.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:55:01.992: INFO: namespace container-probe-9703 deletion completed in 6.640858995s

• [SLOW TEST:31.363 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:55:01.993: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 10:55:02.371: INFO: Waiting up to 5m0s for pod "pod-8395343d-46a8-475e-ba06-09897438be2e" in namespace "emptydir-1194" to be "success or failure"
Dec 10 10:55:02.397: INFO: Pod "pod-8395343d-46a8-475e-ba06-09897438be2e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.241784ms
Dec 10 10:55:04.415: INFO: Pod "pod-8395343d-46a8-475e-ba06-09897438be2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043424654s
Dec 10 10:55:06.436: INFO: Pod "pod-8395343d-46a8-475e-ba06-09897438be2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064659772s
STEP: Saw pod success
Dec 10 10:55:06.436: INFO: Pod "pod-8395343d-46a8-475e-ba06-09897438be2e" satisfied condition "success or failure"
Dec 10 10:55:06.454: INFO: Trying to get logs from node node1 pod pod-8395343d-46a8-475e-ba06-09897438be2e container test-container: <nil>
STEP: delete the pod
Dec 10 10:55:06.538: INFO: Waiting for pod pod-8395343d-46a8-475e-ba06-09897438be2e to disappear
Dec 10 10:55:06.558: INFO: Pod pod-8395343d-46a8-475e-ba06-09897438be2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:55:06.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1194" for this suite.
Dec 10 10:55:12.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:55:13.234: INFO: namespace emptydir-1194 deletion completed in 6.643917213s

• [SLOW TEST:11.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:55:13.235: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6605
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 10 10:55:17.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 exec pod-sharedvolume-41c44c97-af41-4f36-9349-8c38486d955f -c busybox-main-container --namespace=emptydir-6605 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 10 10:55:19.590: INFO: stderr: ""
Dec 10 10:55:19.590: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:55:19.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6605" for this suite.
Dec 10 10:55:25.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:55:26.308: INFO: namespace emptydir-6605 deletion completed in 6.673618049s

• [SLOW TEST:13.073 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:55:26.308: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec 10 10:55:26.672: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Dec 10 10:55:27.260: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 10 10:55:29.514: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711572070, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711572070, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711572071, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711572070, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 10:56:22.576: INFO: Waited 51.016383238s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:56:23.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3555" for this suite.
Dec 10 10:56:29.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:56:30.588: INFO: namespace aggregator-3555 deletion completed in 6.659345522s

• [SLOW TEST:64.280 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:56:30.588: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 10 10:56:31.090: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5025,SelfLink:/api/v1/namespaces/watch-5025/configmaps/e2e-watch-test-resource-version,UID:86a44068-3454-471f-9041-69b2d6c13f06,ResourceVersion:176501,Generation:0,CreationTimestamp:2019-12-10 10:55:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 10:56:31.090: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-5025,SelfLink:/api/v1/namespaces/watch-5025/configmaps/e2e-watch-test-resource-version,UID:86a44068-3454-471f-9041-69b2d6c13f06,ResourceVersion:176502,Generation:0,CreationTimestamp:2019-12-10 10:55:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:56:31.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5025" for this suite.
Dec 10 10:56:37.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:56:37.808: INFO: namespace watch-5025 deletion completed in 6.696066906s

• [SLOW TEST:7.220 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:56:37.809: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1086
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 10:56:38.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-1086'
Dec 10 10:56:38.428: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 10 10:56:38.428: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Dec 10 10:56:42.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1086'
Dec 10 10:56:42.788: INFO: stderr: ""
Dec 10 10:56:42.788: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:56:42.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1086" for this suite.
Dec 10 10:57:06.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:57:07.470: INFO: namespace kubectl-1086 deletion completed in 24.642040501s

• [SLOW TEST:29.661 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:57:07.470: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:57:07.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 version'
Dec 10 10:57:08.107: INFO: stderr: ""
Dec 10 10:57:08.107: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15+\", GitVersion:\"v1.15.3-1+0c6be0f131f191-dirty\", GitCommit:\"0c6be0f131f1916aaddb778c90bdb1093db0a4ad\", GitTreeState:\"dirty\", BuildDate:\"2019-10-12T03:42:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/mips64le\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:57:08.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7688" for this suite.
Dec 10 10:57:14.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:57:14.762: INFO: namespace kubectl-7688 deletion completed in 6.621518236s

• [SLOW TEST:7.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:57:14.763: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 10 10:57:15.104: INFO: namespace kubectl-6345
Dec 10 10:57:15.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-6345'
Dec 10 10:57:16.024: INFO: stderr: ""
Dec 10 10:57:16.024: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 10:57:17.045: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:57:17.046: INFO: Found 0 / 1
Dec 10 10:57:18.044: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:57:18.044: INFO: Found 0 / 1
Dec 10 10:57:19.046: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:57:19.046: INFO: Found 1 / 1
Dec 10 10:57:19.046: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 10:57:19.064: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 10:57:19.064: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 10:57:19.064: INFO: wait on redis-master startup in kubectl-6345 
Dec 10 10:57:19.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 logs redis-master-75ktd redis-master --namespace=kubectl-6345'
Dec 10 10:57:19.398: INFO: stderr: ""
Dec 10 10:57:19.398: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 10:57:18.265 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 10:57:18.265 # Server started, Redis version 3.2.12\n1:M 10 Dec 10:57:18.266 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 10:57:18.266 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 10 10:57:19.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6345'
Dec 10 10:57:19.743: INFO: stderr: ""
Dec 10 10:57:19.744: INFO: stdout: "service/rm2 exposed\n"
Dec 10 10:57:19.762: INFO: Service rm2 in namespace kubectl-6345 found.
STEP: exposing service
Dec 10 10:57:21.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6345'
Dec 10 10:57:22.120: INFO: stderr: ""
Dec 10 10:57:22.120: INFO: stdout: "service/rm3 exposed\n"
Dec 10 10:57:22.144: INFO: Service rm3 in namespace kubectl-6345 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:57:24.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6345" for this suite.
Dec 10 10:57:48.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:57:48.865: INFO: namespace kubectl-6345 deletion completed in 24.653954207s

• [SLOW TEST:34.103 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:57:48.866: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:57:49.246: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 10 10:57:50.421: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:57:50.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3985" for this suite.
Dec 10 10:57:56.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:57:57.242: INFO: namespace replication-controller-3985 deletion completed in 6.766956038s

• [SLOW TEST:8.376 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:57:57.242: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9843
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 10:57:57.589: INFO: Creating ReplicaSet my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca
Dec 10 10:57:57.624: INFO: Pod name my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca: Found 0 pods out of 1
Dec 10 10:58:02.644: INFO: Pod name my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca: Found 1 pods out of 1
Dec 10 10:58:02.644: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca" is running
Dec 10 10:58:02.662: INFO: Pod "my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca-56ddp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 10:57:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 10:58:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 10:58:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-10 10:57:01 +0000 UTC Reason: Message:}])
Dec 10 10:58:02.662: INFO: Trying to dial the pod
Dec 10 10:58:07.747: INFO: Controller my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca: Got expected result from replica 1 [my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca-56ddp]: "my-hostname-basic-b9956b83-d2c0-4377-929e-d1191a51a4ca-56ddp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:58:07.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9843" for this suite.
Dec 10 10:58:13.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:58:14.429: INFO: namespace replicaset-9843 deletion completed in 6.648892751s

• [SLOW TEST:17.187 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:58:14.430: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 10 10:58:14.820: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 10 10:58:19.868: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:58:19.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6649" for this suite.
Dec 10 10:58:26.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:58:26.636: INFO: namespace replication-controller-6649 deletion completed in 6.641789373s

• [SLOW TEST:12.207 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:58:26.637: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 10:58:27.132: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:27.159: INFO: Number of nodes with available pods: 0
Dec 10 10:58:27.159: INFO: Node node1 is running more than one daemon pod
Dec 10 10:58:28.195: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:28.213: INFO: Number of nodes with available pods: 0
Dec 10 10:58:28.213: INFO: Node node1 is running more than one daemon pod
Dec 10 10:58:29.190: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:29.209: INFO: Number of nodes with available pods: 0
Dec 10 10:58:29.209: INFO: Node node1 is running more than one daemon pod
Dec 10 10:58:30.193: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:30.211: INFO: Number of nodes with available pods: 2
Dec 10 10:58:30.211: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 10 10:58:30.290: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:30.308: INFO: Number of nodes with available pods: 1
Dec 10 10:58:30.308: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:31.343: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:31.364: INFO: Number of nodes with available pods: 1
Dec 10 10:58:31.364: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:32.339: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:32.356: INFO: Number of nodes with available pods: 1
Dec 10 10:58:32.356: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:33.343: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:33.361: INFO: Number of nodes with available pods: 1
Dec 10 10:58:33.361: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:34.343: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:34.362: INFO: Number of nodes with available pods: 1
Dec 10 10:58:34.362: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:35.341: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:35.361: INFO: Number of nodes with available pods: 1
Dec 10 10:58:35.361: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:36.345: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:36.364: INFO: Number of nodes with available pods: 1
Dec 10 10:58:36.364: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:37.342: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:37.363: INFO: Number of nodes with available pods: 1
Dec 10 10:58:37.363: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:38.341: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:38.360: INFO: Number of nodes with available pods: 1
Dec 10 10:58:38.360: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:39.348: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:39.367: INFO: Number of nodes with available pods: 1
Dec 10 10:58:39.367: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:40.347: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:40.365: INFO: Number of nodes with available pods: 1
Dec 10 10:58:40.366: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:41.345: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:41.365: INFO: Number of nodes with available pods: 1
Dec 10 10:58:41.365: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:42.349: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:42.369: INFO: Number of nodes with available pods: 1
Dec 10 10:58:42.369: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:43.341: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:43.360: INFO: Number of nodes with available pods: 1
Dec 10 10:58:43.360: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:44.339: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:44.358: INFO: Number of nodes with available pods: 1
Dec 10 10:58:44.358: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:45.346: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:45.364: INFO: Number of nodes with available pods: 1
Dec 10 10:58:45.364: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:46.348: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:46.365: INFO: Number of nodes with available pods: 1
Dec 10 10:58:46.366: INFO: Node node2 is running more than one daemon pod
Dec 10 10:58:47.341: INFO: DaemonSet pods can't tolerate node indata-10-9-11-201.indata.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>} {Key:node.kubernetes.io/unschedulable Value: Effect:NoSchedule TimeAdded:2019-12-09 09:38:53 +0000 UTC}], skip checking this node
Dec 10 10:58:47.360: INFO: Number of nodes with available pods: 2
Dec 10 10:58:47.360: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5835, will wait for the garbage collector to delete the pods
Dec 10 10:58:47.468: INFO: Deleting DaemonSet.extensions daemon-set took: 26.537583ms
Dec 10 10:58:47.768: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.393289ms
Dec 10 10:58:56.786: INFO: Number of nodes with available pods: 0
Dec 10 10:58:56.786: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 10:58:56.802: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5835/daemonsets","resourceVersion":"177024"},"items":null}

Dec 10 10:58:56.817: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5835/pods","resourceVersion":"177024"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 10:58:56.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5835" for this suite.
Dec 10 10:59:02.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 10:59:03.538: INFO: namespace daemonsets-5835 deletion completed in 6.643231143s

• [SLOW TEST:36.901 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 10:59:03.539: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 10 10:59:04.980: INFO: Pod name wrapped-volume-race-6ece1749-13ca-44e9-97a6-68b0a9d89d4c: Found 0 pods out of 5
Dec 10 10:59:10.023: INFO: Pod name wrapped-volume-race-6ece1749-13ca-44e9-97a6-68b0a9d89d4c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6ece1749-13ca-44e9-97a6-68b0a9d89d4c in namespace emptydir-wrapper-5216, will wait for the garbage collector to delete the pods
Dec 10 10:59:22.245: INFO: Deleting ReplicationController wrapped-volume-race-6ece1749-13ca-44e9-97a6-68b0a9d89d4c took: 34.838105ms
Dec 10 10:59:22.746: INFO: Terminating ReplicationController wrapped-volume-race-6ece1749-13ca-44e9-97a6-68b0a9d89d4c pods took: 500.329572ms
STEP: Creating RC which spawns configmap-volume pods
Dec 10 11:00:07.131: INFO: Pod name wrapped-volume-race-392a5288-76e4-49d7-af35-5a853d488c5b: Found 0 pods out of 5
Dec 10 11:00:12.171: INFO: Pod name wrapped-volume-race-392a5288-76e4-49d7-af35-5a853d488c5b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-392a5288-76e4-49d7-af35-5a853d488c5b in namespace emptydir-wrapper-5216, will wait for the garbage collector to delete the pods
Dec 10 11:00:24.421: INFO: Deleting ReplicationController wrapped-volume-race-392a5288-76e4-49d7-af35-5a853d488c5b took: 40.135263ms
Dec 10 11:00:24.822: INFO: Terminating ReplicationController wrapped-volume-race-392a5288-76e4-49d7-af35-5a853d488c5b pods took: 400.611105ms
STEP: Creating RC which spawns configmap-volume pods
Dec 10 11:01:01.612: INFO: Pod name wrapped-volume-race-5951ab59-e809-440d-bdac-660f25c3ceca: Found 0 pods out of 5
Dec 10 11:01:06.664: INFO: Pod name wrapped-volume-race-5951ab59-e809-440d-bdac-660f25c3ceca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5951ab59-e809-440d-bdac-660f25c3ceca in namespace emptydir-wrapper-5216, will wait for the garbage collector to delete the pods
Dec 10 11:01:18.884: INFO: Deleting ReplicationController wrapped-volume-race-5951ab59-e809-440d-bdac-660f25c3ceca took: 36.543972ms
Dec 10 11:01:19.285: INFO: Terminating ReplicationController wrapped-volume-race-5951ab59-e809-440d-bdac-660f25c3ceca pods took: 400.726428ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:01:58.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5216" for this suite.
Dec 10 11:02:08.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:02:08.951: INFO: namespace emptydir-wrapper-5216 deletion completed in 10.649931223s

• [SLOW TEST:185.412 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:02:08.951: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0254405a-ed4c-4644-b825-1d4ee8b83fed
STEP: Creating a pod to test consume secrets
Dec 10 11:02:09.338: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124" in namespace "projected-931" to be "success or failure"
Dec 10 11:02:09.368: INFO: Pod "pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124": Phase="Pending", Reason="", readiness=false. Elapsed: 29.162398ms
Dec 10 11:02:11.387: INFO: Pod "pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048170597s
Dec 10 11:02:13.412: INFO: Pod "pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073382962s
STEP: Saw pod success
Dec 10 11:02:13.412: INFO: Pod "pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124" satisfied condition "success or failure"
Dec 10 11:02:13.432: INFO: Trying to get logs from node node1 pod pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 11:02:13.509: INFO: Waiting for pod pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124 to disappear
Dec 10 11:02:13.525: INFO: Pod pod-projected-secrets-83100a02-8055-4748-89bd-7d8f1c930124 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:02:13.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-931" for this suite.
Dec 10 11:02:19.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:02:20.190: INFO: namespace projected-931 deletion completed in 6.628451805s

• [SLOW TEST:11.239 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:02:20.191: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4598
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 11:02:20.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803" in namespace "downward-api-4598" to be "success or failure"
Dec 10 11:02:20.589: INFO: Pod "downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803": Phase="Pending", Reason="", readiness=false. Elapsed: 25.808836ms
Dec 10 11:02:22.611: INFO: Pod "downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047753488s
Dec 10 11:02:24.631: INFO: Pod "downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067199377s
STEP: Saw pod success
Dec 10 11:02:24.631: INFO: Pod "downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803" satisfied condition "success or failure"
Dec 10 11:02:24.648: INFO: Trying to get logs from node node1 pod downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803 container client-container: <nil>
STEP: delete the pod
Dec 10 11:02:24.754: INFO: Waiting for pod downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803 to disappear
Dec 10 11:02:24.770: INFO: Pod downwardapi-volume-6c8fa6a9-d066-4d40-9a4a-fc4dbe0f0803 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:02:24.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4598" for this suite.
Dec 10 11:02:30.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:02:31.470: INFO: namespace downward-api-4598 deletion completed in 6.668706112s

• [SLOW TEST:11.279 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:02:31.470: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 10 11:02:31.870: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb" in namespace "downward-api-2554" to be "success or failure"
Dec 10 11:02:31.892: INFO: Pod "downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.111129ms
Dec 10 11:02:33.913: INFO: Pod "downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043382202s
Dec 10 11:02:35.931: INFO: Pod "downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06142207s
STEP: Saw pod success
Dec 10 11:02:35.931: INFO: Pod "downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb" satisfied condition "success or failure"
Dec 10 11:02:35.949: INFO: Trying to get logs from node node2 pod downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb container client-container: <nil>
STEP: delete the pod
Dec 10 11:02:36.055: INFO: Waiting for pod downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb to disappear
Dec 10 11:02:36.071: INFO: Pod downwardapi-volume-17faceb9-f473-4481-9f08-5ef251ecdebb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:02:36.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2554" for this suite.
Dec 10 11:02:42.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:02:42.786: INFO: namespace downward-api-2554 deletion completed in 6.679441179s

• [SLOW TEST:11.316 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:02:42.786: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2707
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 10 11:02:53.306: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:02:53.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1210 11:02:53.306465      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2707" for this suite.
Dec 10 11:02:59.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:00.022: INFO: namespace gc-2707 deletion completed in 6.693419743s

• [SLOW TEST:17.236 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:00.022: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-74458cfc-a99d-432f-9d24-da3a5d5e9ada
STEP: Creating a pod to test consume secrets
Dec 10 11:03:00.422: INFO: Waiting up to 5m0s for pod "pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116" in namespace "secrets-8572" to be "success or failure"
Dec 10 11:03:00.440: INFO: Pod "pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116": Phase="Pending", Reason="", readiness=false. Elapsed: 18.679921ms
Dec 10 11:03:02.464: INFO: Pod "pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042019364s
Dec 10 11:03:04.483: INFO: Pod "pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060949472s
STEP: Saw pod success
Dec 10 11:03:04.483: INFO: Pod "pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116" satisfied condition "success or failure"
Dec 10 11:03:04.500: INFO: Trying to get logs from node node1 pod pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 11:03:04.568: INFO: Waiting for pod pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116 to disappear
Dec 10 11:03:04.582: INFO: Pod pod-secrets-808d53d0-7c66-4ba5-a0f8-bdc37cae5116 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:03:04.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8572" for this suite.
Dec 10 11:03:12.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:13.255: INFO: namespace secrets-8572 deletion completed in 8.641053725s

• [SLOW TEST:13.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:13.256: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 11:03:13.620: INFO: Waiting up to 5m0s for pod "pod-755655e1-7132-4a22-a021-f677e46bd798" in namespace "emptydir-7834" to be "success or failure"
Dec 10 11:03:13.637: INFO: Pod "pod-755655e1-7132-4a22-a021-f677e46bd798": Phase="Pending", Reason="", readiness=false. Elapsed: 17.431088ms
Dec 10 11:03:15.656: INFO: Pod "pod-755655e1-7132-4a22-a021-f677e46bd798": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036332159s
Dec 10 11:03:17.673: INFO: Pod "pod-755655e1-7132-4a22-a021-f677e46bd798": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053159225s
STEP: Saw pod success
Dec 10 11:03:17.673: INFO: Pod "pod-755655e1-7132-4a22-a021-f677e46bd798" satisfied condition "success or failure"
Dec 10 11:03:17.688: INFO: Trying to get logs from node node1 pod pod-755655e1-7132-4a22-a021-f677e46bd798 container test-container: <nil>
STEP: delete the pod
Dec 10 11:03:17.756: INFO: Waiting for pod pod-755655e1-7132-4a22-a021-f677e46bd798 to disappear
Dec 10 11:03:17.771: INFO: Pod pod-755655e1-7132-4a22-a021-f677e46bd798 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:03:17.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7834" for this suite.
Dec 10 11:03:23.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:24.457: INFO: namespace emptydir-7834 deletion completed in 6.653913158s

• [SLOW TEST:11.202 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:24.458: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-4805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Dec 10 11:03:24.850: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4805" to be "success or failure"
Dec 10 11:03:24.869: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 18.46732ms
Dec 10 11:03:26.886: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035318028s
Dec 10 11:03:28.905: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054519198s
STEP: Saw pod success
Dec 10 11:03:28.905: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 10 11:03:28.924: INFO: Trying to get logs from node node1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 10 11:03:28.997: INFO: Waiting for pod pod-host-path-test to disappear
Dec 10 11:03:29.013: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:03:29.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4805" for this suite.
Dec 10 11:03:35.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:35.689: INFO: namespace hostpath-4805 deletion completed in 6.640425724s

• [SLOW TEST:11.231 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:35.690: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b9b8f532-5505-4ab3-92a6-aa5f5811aa61
STEP: Creating a pod to test consume secrets
Dec 10 11:03:36.093: INFO: Waiting up to 5m0s for pod "pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371" in namespace "secrets-7623" to be "success or failure"
Dec 10 11:03:36.135: INFO: Pod "pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371": Phase="Pending", Reason="", readiness=false. Elapsed: 42.010701ms
Dec 10 11:03:38.153: INFO: Pod "pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060290863s
Dec 10 11:03:40.171: INFO: Pod "pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078398632s
STEP: Saw pod success
Dec 10 11:03:40.171: INFO: Pod "pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371" satisfied condition "success or failure"
Dec 10 11:03:40.188: INFO: Trying to get logs from node node1 pod pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 11:03:40.277: INFO: Waiting for pod pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371 to disappear
Dec 10 11:03:40.292: INFO: Pod pod-secrets-e5b7d6cc-1793-406d-8fb2-0593d8640371 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:03:40.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7623" for this suite.
Dec 10 11:03:46.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:47.027: INFO: namespace secrets-7623 deletion completed in 6.704771085s

• [SLOW TEST:11.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:47.027: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 11:03:47.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2908'
Dec 10 11:03:47.676: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 10 11:03:47.676: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 10 11:03:47.719: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xjs5k]
Dec 10 11:03:47.719: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xjs5k" in namespace "kubectl-2908" to be "running and ready"
Dec 10 11:03:47.735: INFO: Pod "e2e-test-nginx-rc-xjs5k": Phase="Pending", Reason="", readiness=false. Elapsed: 16.745724ms
Dec 10 11:03:49.755: INFO: Pod "e2e-test-nginx-rc-xjs5k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036521893s
Dec 10 11:03:51.772: INFO: Pod "e2e-test-nginx-rc-xjs5k": Phase="Running", Reason="", readiness=true. Elapsed: 4.053455033s
Dec 10 11:03:51.772: INFO: Pod "e2e-test-nginx-rc-xjs5k" satisfied condition "running and ready"
Dec 10 11:03:51.772: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xjs5k]
Dec 10 11:03:51.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 logs rc/e2e-test-nginx-rc --namespace=kubectl-2908'
Dec 10 11:03:52.072: INFO: stderr: ""
Dec 10 11:03:52.072: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Dec 10 11:03:52.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete rc e2e-test-nginx-rc --namespace=kubectl-2908'
Dec 10 11:03:52.325: INFO: stderr: ""
Dec 10 11:03:52.325: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:03:52.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2908" for this suite.
Dec 10 11:03:58.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:03:59.036: INFO: namespace kubectl-2908 deletion completed in 6.675797693s

• [SLOW TEST:12.009 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:03:59.036: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:04:03.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5556" for this suite.
Dec 10 11:04:09.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:04:10.119: INFO: namespace kubelet-test-5556 deletion completed in 6.639046194s

• [SLOW TEST:11.082 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:04:10.119: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2998
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-71427bfd-e4fa-421f-8547-538b5a1ade45
STEP: Creating a pod to test consume secrets
Dec 10 11:04:10.511: INFO: Waiting up to 5m0s for pod "pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9" in namespace "secrets-2998" to be "success or failure"
Dec 10 11:04:10.528: INFO: Pod "pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.0886ms
Dec 10 11:04:12.549: INFO: Pod "pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037888255s
Dec 10 11:04:14.569: INFO: Pod "pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057704035s
STEP: Saw pod success
Dec 10 11:04:14.569: INFO: Pod "pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9" satisfied condition "success or failure"
Dec 10 11:04:14.587: INFO: Trying to get logs from node node1 pod pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9 container secret-env-test: <nil>
STEP: delete the pod
Dec 10 11:04:14.704: INFO: Waiting for pod pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9 to disappear
Dec 10 11:04:14.725: INFO: Pod pod-secrets-05e73690-c075-4c7c-beb3-e1c1564c3cd9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:04:14.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2998" for this suite.
Dec 10 11:04:20.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:04:21.393: INFO: namespace secrets-2998 deletion completed in 6.63348127s

• [SLOW TEST:11.274 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:04:21.393: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 11:04:21.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-5899'
Dec 10 11:04:22.164: INFO: stderr: ""
Dec 10 11:04:22.164: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 10 11:04:22.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-5899'
Dec 10 11:04:22.681: INFO: stderr: ""
Dec 10 11:04:22.681: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 11:04:23.699: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 11:04:23.699: INFO: Found 0 / 1
Dec 10 11:04:24.705: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 11:04:24.705: INFO: Found 1 / 1
Dec 10 11:04:24.705: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 11:04:24.725: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 11:04:24.725: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 11:04:24.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 describe pod redis-master-5v2cb --namespace=kubectl-5899'
Dec 10 11:04:25.048: INFO: stderr: ""
Dec 10 11:04:25.048: INFO: stdout: "Name:           redis-master-5v2cb\nNamespace:      kubectl-5899\nPriority:       0\nNode:           node1/10.164.17.29\nStart Time:     Tue, 10 Dec 2019 11:04:22 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.253.1.44\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f94cc25f6625f19ad3333137c338da1cb72f4c84a91c0fef043397efdec91d8b\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 10 Dec 2019 11:04:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gbcfb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gbcfb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gbcfb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  60s   default-scheduler  Successfully assigned kubectl-5899/redis-master-5v2cb to node1\n  Normal  Pulled     2s    kubelet, node1     Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, node1     Created container redis-master\n  Normal  Started    1s    kubelet, node1     Started container redis-master\n"
Dec 10 11:04:25.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 describe rc redis-master --namespace=kubectl-5899'
Dec 10 11:04:25.358: INFO: stderr: ""
Dec 10 11:04:25.358: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5899\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  60s   replication-controller  Created pod: redis-master-5v2cb\n"
Dec 10 11:04:25.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 describe service redis-master --namespace=kubectl-5899'
Dec 10 11:04:25.656: INFO: stderr: ""
Dec 10 11:04:25.656: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5899\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.108.84.11\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.253.1.44:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 10 11:04:25.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 describe node indata-10-9-11-201.indata.com'
Dec 10 11:04:26.042: INFO: stderr: ""
Dec 10 11:04:26.042: INFO: stdout: "Name:               indata-10-9-11-201.indata.com\nRoles:              master\nLabels:             beta.kubernetes.io/arch=mips64le\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=mips64le\n                    kubernetes.io/hostname=indata-10-9-11-201.indata.com\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"02:35:48:51:f4:49\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.110.1.218\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 09 Dec 2019 05:47:02 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\n                    node.kubernetes.io/unschedulable:NoSchedule\nUnschedulable:      true\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 10 Dec 2019 11:03:29 +0000   Mon, 09 Dec 2019 05:46:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 10 Dec 2019 11:03:29 +0000   Mon, 09 Dec 2019 05:46:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 10 Dec 2019 11:03:29 +0000   Mon, 09 Dec 2019 05:46:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 10 Dec 2019 11:03:29 +0000   Mon, 09 Dec 2019 05:48:02 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.9.11.201\n  Hostname:    indata-10-9-11-201.indata.com\nCapacity:\n cpu:                8\n ephemeral-storage:  976285652Ki\n hugepages-32Mi:     0\n memory:             66156096Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  899744855394\n hugepages-32Mi:     0\n memory:             66053696Ki\n pods:               110\nSystem Info:\n Machine ID:                 9f056e6e945e44c4bdbfb191d07a2d6a\n System UUID:                9f056e6e945e44c4bdbfb191d07a2d6a\n Boot ID:                    764b5d1a-01fe-4477-a2d8-621364fe8272\n Kernel Version:             3.10.0-862.9.1.ns7_4.37.mips64el\n OS Image:                   NeoKylin Linux Server 7.0 (loongson)\n Operating System:           linux\n Architecture:               mips64le\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.15.3-mips\n Kube-Proxy Version:         v1.15.3-mips\nPodCIDR:                     10.253.0.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                     ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-f9f4b8b6c-7cd9m                                  100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     29h\n  kube-system                coredns-f9f4b8b6c-tfqg5                                  100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     29h\n  kube-system                etcd-indata-10-9-11-201.indata.com                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         29h\n  kube-system                kube-apiserver-indata-10-9-11-201.indata.com             250m (3%)     0 (0%)      0 (0%)           0 (0%)         29h\n  kube-system                kube-controller-manager-indata-10-9-11-201.indata.com    200m (2%)     0 (0%)      0 (0%)           0 (0%)         29h\n  kube-system                kube-flannel-ds-mips64le-r65d7                           100m (1%)     100m (1%)   50Mi (0%)        50Mi (0%)      29h\n  kube-system                kube-proxy-pbkqp                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         29h\n  kube-system                kube-scheduler-indata-10-9-11-201.indata.com             100m (1%)     0 (0%)      0 (0%)           0 (0%)         29h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (10%)  100m (1%)\n  memory             190Mi (0%)  390Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Dec 10 11:04:26.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 describe namespace kubectl-5899'
Dec 10 11:04:26.314: INFO: stderr: ""
Dec 10 11:04:26.314: INFO: stdout: "Name:         kubectl-5899\nLabels:       e2e-framework=kubectl\n              e2e-run=3944fac4-c0e0-4fbc-8eca-f2c5247d4f7b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:04:26.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5899" for this suite.
Dec 10 11:04:50.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:04:50.987: INFO: namespace kubectl-5899 deletion completed in 24.642549882s

• [SLOW TEST:29.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:04:50.987: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1086
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 10 11:04:51.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 create -f - --namespace=kubectl-1086'
Dec 10 11:04:51.788: INFO: stderr: ""
Dec 10 11:04:51.788: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 11:04:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:04:52.020: INFO: stderr: ""
Dec 10 11:04:52.020: INFO: stdout: "update-demo-nautilus-9w6t4 update-demo-nautilus-ln8pc "
Dec 10 11:04:52.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-9w6t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:04:52.227: INFO: stderr: ""
Dec 10 11:04:52.227: INFO: stdout: ""
Dec 10 11:04:52.227: INFO: update-demo-nautilus-9w6t4 is created but not running
Dec 10 11:04:57.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:04:57.488: INFO: stderr: ""
Dec 10 11:04:57.488: INFO: stdout: "update-demo-nautilus-9w6t4 update-demo-nautilus-ln8pc "
Dec 10 11:04:57.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-9w6t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:04:57.718: INFO: stderr: ""
Dec 10 11:04:57.719: INFO: stdout: "true"
Dec 10 11:04:57.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-9w6t4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:04:57.950: INFO: stderr: ""
Dec 10 11:04:57.950: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 11:04:57.950: INFO: validating pod update-demo-nautilus-9w6t4
Dec 10 11:04:57.989: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 11:04:57.989: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 11:04:57.989: INFO: update-demo-nautilus-9w6t4 is verified up and running
Dec 10 11:04:57.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:04:58.189: INFO: stderr: ""
Dec 10 11:04:58.189: INFO: stdout: "true"
Dec 10 11:04:58.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:04:58.394: INFO: stderr: ""
Dec 10 11:04:58.395: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 11:04:58.395: INFO: validating pod update-demo-nautilus-ln8pc
Dec 10 11:04:58.435: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 11:04:58.435: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 11:04:58.436: INFO: update-demo-nautilus-ln8pc is verified up and running
STEP: scaling down the replication controller
Dec 10 11:04:58.438: INFO: scanned /root for discovery docs: <nil>
Dec 10 11:04:58.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1086'
Dec 10 11:04:59.771: INFO: stderr: ""
Dec 10 11:04:59.772: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 11:04:59.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:05:00.008: INFO: stderr: ""
Dec 10 11:05:00.008: INFO: stdout: "update-demo-nautilus-9w6t4 update-demo-nautilus-ln8pc "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 10 11:05:05.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:05:05.247: INFO: stderr: ""
Dec 10 11:05:05.247: INFO: stdout: "update-demo-nautilus-ln8pc "
Dec 10 11:05:05.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:05.462: INFO: stderr: ""
Dec 10 11:05:05.462: INFO: stdout: "true"
Dec 10 11:05:05.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:05.694: INFO: stderr: ""
Dec 10 11:05:05.694: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 11:05:05.694: INFO: validating pod update-demo-nautilus-ln8pc
Dec 10 11:05:05.724: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 11:05:05.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 11:05:05.724: INFO: update-demo-nautilus-ln8pc is verified up and running
STEP: scaling up the replication controller
Dec 10 11:05:05.727: INFO: scanned /root for discovery docs: <nil>
Dec 10 11:05:05.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1086'
Dec 10 11:05:07.089: INFO: stderr: ""
Dec 10 11:05:07.089: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 11:05:07.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:05:07.323: INFO: stderr: ""
Dec 10 11:05:07.323: INFO: stdout: "update-demo-nautilus-82l7k update-demo-nautilus-ln8pc "
Dec 10 11:05:07.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-82l7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:07.551: INFO: stderr: ""
Dec 10 11:05:07.551: INFO: stdout: ""
Dec 10 11:05:07.551: INFO: update-demo-nautilus-82l7k is created but not running
Dec 10 11:05:12.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1086'
Dec 10 11:05:12.794: INFO: stderr: ""
Dec 10 11:05:12.794: INFO: stdout: "update-demo-nautilus-82l7k update-demo-nautilus-ln8pc "
Dec 10 11:05:12.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-82l7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:13.011: INFO: stderr: ""
Dec 10 11:05:13.011: INFO: stdout: "true"
Dec 10 11:05:13.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-82l7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:13.247: INFO: stderr: ""
Dec 10 11:05:13.247: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 11:05:13.247: INFO: validating pod update-demo-nautilus-82l7k
Dec 10 11:05:13.284: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 11:05:13.284: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 11:05:13.284: INFO: update-demo-nautilus-82l7k is verified up and running
Dec 10 11:05:13.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:13.529: INFO: stderr: ""
Dec 10 11:05:13.529: INFO: stdout: "true"
Dec 10 11:05:13.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods update-demo-nautilus-ln8pc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1086'
Dec 10 11:05:13.770: INFO: stderr: ""
Dec 10 11:05:13.770: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 11:05:13.770: INFO: validating pod update-demo-nautilus-ln8pc
Dec 10 11:05:13.800: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 11:05:13.800: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 11:05:13.800: INFO: update-demo-nautilus-ln8pc is verified up and running
STEP: using delete to clean up resources
Dec 10 11:05:13.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 delete --grace-period=0 --force -f - --namespace=kubectl-1086'
Dec 10 11:05:14.057: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 11:05:14.057: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 11:05:14.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1086'
Dec 10 11:05:14.327: INFO: stderr: "No resources found.\n"
Dec 10 11:05:14.327: INFO: stdout: ""
Dec 10 11:05:14.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 get pods -l name=update-demo --namespace=kubectl-1086 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 11:05:14.569: INFO: stderr: ""
Dec 10 11:05:14.569: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:05:14.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1086" for this suite.
Dec 10 11:05:38.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:05:39.167: INFO: namespace kubectl-1086 deletion completed in 24.56735115s

• [SLOW TEST:48.179 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:05:39.167: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-30
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 10 11:05:40.227: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:05:40.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1210 11:05:40.227381      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-30" for this suite.
Dec 10 11:05:46.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:05:47.039: INFO: namespace gc-30 deletion completed in 6.790479633s

• [SLOW TEST:7.872 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:05:47.039: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 10 11:05:47.517: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:178999,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 11:05:47.517: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:179000,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 10 11:05:47.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:179001,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 10 11:05:57.652: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:179019,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 11:05:57.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:179020,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 10 11:05:57.653: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8943,SelfLink:/api/v1/namespaces/watch-8943/configmaps/e2e-watch-test-label-changed,UID:8db9d419-49c6-406d-860b-ad0aaaa12735,ResourceVersion:179021,Generation:0,CreationTimestamp:2019-12-10 11:04:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:05:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8943" for this suite.
Dec 10 11:06:03.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:06:04.299: INFO: namespace watch-8943 deletion completed in 6.615219482s

• [SLOW TEST:17.260 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:06:04.299: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-3c894b3c-25f7-4335-b9fa-2b430ed48f94 in namespace container-probe-2870
Dec 10 11:06:08.704: INFO: Started pod busybox-3c894b3c-25f7-4335-b9fa-2b430ed48f94 in namespace container-probe-2870
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 11:06:08.751: INFO: Initial restart count of pod busybox-3c894b3c-25f7-4335-b9fa-2b430ed48f94 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:10:09.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2870" for this suite.
Dec 10 11:10:15.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:10:15.817: INFO: namespace container-probe-2870 deletion completed in 6.637965014s

• [SLOW TEST:251.518 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:10:15.818: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:10:20.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3576" for this suite.
Dec 10 11:10:26.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:10:27.126: INFO: namespace emptydir-wrapper-3576 deletion completed in 6.67703008s

• [SLOW TEST:11.308 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:10:27.126: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 11:10:27.515: INFO: Waiting up to 5m0s for pod "pod-cf50da9e-a1fb-427b-a35f-804809c22863" in namespace "emptydir-4939" to be "success or failure"
Dec 10 11:10:27.538: INFO: Pod "pod-cf50da9e-a1fb-427b-a35f-804809c22863": Phase="Pending", Reason="", readiness=false. Elapsed: 23.205987ms
Dec 10 11:10:29.558: INFO: Pod "pod-cf50da9e-a1fb-427b-a35f-804809c22863": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042780824s
Dec 10 11:10:31.588: INFO: Pod "pod-cf50da9e-a1fb-427b-a35f-804809c22863": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073049398s
STEP: Saw pod success
Dec 10 11:10:31.588: INFO: Pod "pod-cf50da9e-a1fb-427b-a35f-804809c22863" satisfied condition "success or failure"
Dec 10 11:10:31.604: INFO: Trying to get logs from node node1 pod pod-cf50da9e-a1fb-427b-a35f-804809c22863 container test-container: <nil>
STEP: delete the pod
Dec 10 11:10:31.707: INFO: Waiting for pod pod-cf50da9e-a1fb-427b-a35f-804809c22863 to disappear
Dec 10 11:10:31.723: INFO: Pod pod-cf50da9e-a1fb-427b-a35f-804809c22863 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:10:31.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4939" for this suite.
Dec 10 11:10:37.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:10:38.560: INFO: namespace emptydir-4939 deletion completed in 6.80404167s

• [SLOW TEST:11.434 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:10:38.561: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Dec 10 11:10:38.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-132482711 api-versions'
Dec 10 11:10:39.199: INFO: stderr: ""
Dec 10 11:10:39.199: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:10:39.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5901" for this suite.
Dec 10 11:10:45.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:10:45.865: INFO: namespace kubectl-5901 deletion completed in 6.642780256s

• [SLOW TEST:7.304 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:10:45.866: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 10 11:10:46.234: INFO: PodSpec: initContainers in spec.initContainers
Dec 10 11:11:33.436: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-abf2edd4-2a33-4370-82ab-a714c3ffb407", GenerateName:"", Namespace:"init-container-9962", SelfLink:"/api/v1/namespaces/init-container-9962/pods/pod-init-abf2edd4-2a33-4370-82ab-a714c3ffb407", UID:"3ad8605e-a965-4c2d-9fae-ae175b91e0d2", ResourceVersion:"179651", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63711572989, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"234890668"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-r9x2j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0016af940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r9x2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r9x2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r9x2j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d56cc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0025c7da0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d56d50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d56d70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001d56d78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d56d7c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711573047, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711573047, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711573047, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711572989, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.164.17.29", PodIP:"10.253.1.52", StartTime:(*v1.Time)(0xc0023d6f60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b083f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b08460)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker://sha256:758ec7f3a1ee85f8f08399b55641bfb13e8c1109287ddc5e22b68c3d653152ee", ContainerID:"docker://a10c0ac5ccb8c1e7d64941461bff6ae023eaf1fd97e33e1ad58526102e2838fe"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0023d6fa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0023d6f80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:11:33.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9962" for this suite.
Dec 10 11:11:57.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:11:58.148: INFO: namespace init-container-9962 deletion completed in 24.677582495s

• [SLOW TEST:72.282 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:11:58.149: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 10 11:11:58.541: INFO: Waiting up to 5m0s for pod "downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186" in namespace "downward-api-8484" to be "success or failure"
Dec 10 11:11:58.572: INFO: Pod "downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186": Phase="Pending", Reason="", readiness=false. Elapsed: 30.47646ms
Dec 10 11:12:00.593: INFO: Pod "downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051763936s
Dec 10 11:12:02.612: INFO: Pod "downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070741006s
STEP: Saw pod success
Dec 10 11:12:02.612: INFO: Pod "downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186" satisfied condition "success or failure"
Dec 10 11:12:02.627: INFO: Trying to get logs from node node1 pod downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186 container dapi-container: <nil>
STEP: delete the pod
Dec 10 11:12:02.702: INFO: Waiting for pod downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186 to disappear
Dec 10 11:12:02.717: INFO: Pod downward-api-88c5f84b-ec1d-4b55-80a2-438d3b8c5186 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:12:02.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8484" for this suite.
Dec 10 11:12:08.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:12:09.373: INFO: namespace downward-api-8484 deletion completed in 6.625811268s

• [SLOW TEST:11.225 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:12:09.374: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 10 11:12:13.959: INFO: Waiting up to 5m0s for pod "client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f" in namespace "pods-2571" to be "success or failure"
Dec 10 11:12:13.982: INFO: Pod "client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.672532ms
Dec 10 11:12:16.003: INFO: Pod "client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044169595s
Dec 10 11:12:18.021: INFO: Pod "client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062245253s
STEP: Saw pod success
Dec 10 11:12:18.021: INFO: Pod "client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f" satisfied condition "success or failure"
Dec 10 11:12:18.040: INFO: Trying to get logs from node node1 pod client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f container env3cont: <nil>
STEP: delete the pod
Dec 10 11:12:18.120: INFO: Waiting for pod client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f to disappear
Dec 10 11:12:18.137: INFO: Pod client-envvars-bded9730-578a-4fcc-9665-6343d9ffb34f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:12:18.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2571" for this suite.
Dec 10 11:12:58.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:12:58.844: INFO: namespace pods-2571 deletion completed in 40.676280342s

• [SLOW TEST:49.470 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:12:58.844: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 11:13:03.494: INFO: DNS probes using dns-test-955cab1e-ded3-484f-8454-721b0f40d8df succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 11:13:07.724: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:07.753: INFO: File jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:07.753: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:12.789: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains '' instead of 'bar.example.com.'
Dec 10 11:13:12.817: INFO: File jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:12.817: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:17.782: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:17.810: INFO: File jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:17.810: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:22.799: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:22.830: INFO: File jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:22.830: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:27.786: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:27.813: INFO: File jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:27.813: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:32.784: INFO: File wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local from pod  dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 11:13:32.811: INFO: Lookups using dns-6527/dns-test-00b4901d-4982-4881-8933-0486ef948677 failed for: [wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local]

Dec 10 11:13:37.818: INFO: DNS probes using dns-test-00b4901d-4982-4881-8933-0486ef948677 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6527.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6527.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 11:13:42.263: INFO: DNS probes using dns-test-6c4c4973-1c58-4d64-a101-d58f45283850 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:13:42.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6527" for this suite.
Dec 10 11:13:50.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:13:51.166: INFO: namespace dns-6527 deletion completed in 8.71664493s

• [SLOW TEST:52.322 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 10 11:13:51.166: INFO: >>> kubeConfig: /tmp/kubeconfig-132482711
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8501
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c421cfb3-8294-4beb-b4b8-c764063d104a
STEP: Creating a pod to test consume configMaps
Dec 10 11:13:51.639: INFO: Waiting up to 5m0s for pod "pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b" in namespace "configmap-8501" to be "success or failure"
Dec 10 11:13:51.659: INFO: Pod "pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.846784ms
Dec 10 11:13:53.678: INFO: Pod "pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038659746s
Dec 10 11:13:55.698: INFO: Pod "pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058447539s
STEP: Saw pod success
Dec 10 11:13:55.698: INFO: Pod "pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b" satisfied condition "success or failure"
Dec 10 11:13:55.715: INFO: Trying to get logs from node node1 pod pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 11:13:55.785: INFO: Waiting for pod pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b to disappear
Dec 10 11:13:55.800: INFO: Pod pod-configmaps-7015eb61-d5d5-4679-8b92-4acafa583b7b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 10 11:13:55.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8501" for this suite.
Dec 10 11:14:01.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 11:14:02.466: INFO: namespace configmap-8501 deletion completed in 6.63616495s

• [SLOW TEST:11.300 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSDec 10 11:14:02.466: INFO: Running AfterSuite actions on all nodes
Dec 10 11:14:02.466: INFO: Running AfterSuite actions on node 1
Dec 10 11:14:02.466: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6383.521 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h46m24.510240608s
Test Suite Passed
