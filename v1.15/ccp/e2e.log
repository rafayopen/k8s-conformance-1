I0301 06:26:18.228281      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-395293570
I0301 06:26:18.228614      16 e2e.go:243] Starting e2e run "87a378be-b89a-4b29-873c-91899e1968e0" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1583043976 - Will randomize all specs
Will run 215 of 4413 specs

Mar  1 06:26:18.405: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:26:18.407: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  1 06:26:18.434: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  1 06:26:18.486: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  1 06:26:18.486: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar  1 06:26:18.486: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  1 06:26:18.495: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar  1 06:26:18.495: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  1 06:26:18.495: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Mar  1 06:26:18.495: INFO: e2e test version: v1.15.6
Mar  1 06:26:18.498: INFO: kube-apiserver version: v1.15.6
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:26:18.498: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
Mar  1 06:26:18.529: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:26:18.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-8903'
Mar  1 06:26:19.476: INFO: stderr: ""
Mar  1 06:26:19.476: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  1 06:26:19.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-8903'
Mar  1 06:26:19.770: INFO: stderr: ""
Mar  1 06:26:19.771: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 06:26:20.778: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:20.778: INFO: Found 0 / 1
Mar  1 06:26:21.787: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:21.787: INFO: Found 0 / 1
Mar  1 06:26:22.782: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:22.782: INFO: Found 0 / 1
Mar  1 06:26:23.776: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:23.776: INFO: Found 0 / 1
Mar  1 06:26:24.776: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:24.776: INFO: Found 1 / 1
Mar  1 06:26:24.776: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 06:26:24.781: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:26:24.781: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 06:26:24.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 describe pod redis-master-mbvsx --namespace=kubectl-8903'
Mar  1 06:26:24.912: INFO: stderr: ""
Mar  1 06:26:24.912: INFO: stdout: "Name:           redis-master-mbvsx\nNamespace:      kubectl-8903\nPriority:       0\nNode:           alex-slot1-v3-vsp2-node-group-6fb930ab0d/10.10.128.9\nStart Time:     Sun, 01 Mar 2020 06:26:19 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 192.168.3.5/32\nStatus:         Running\nIP:             192.168.3.5\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f6ed108c2feb33c0c4f715483e0f447c15492dbe153233a49df4966018c5e1fe\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 01 Mar 2020 06:26:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-djdsg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-djdsg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-djdsg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                               Message\n  ----    ------     ----  ----                                               -------\n  Normal  Scheduled  4s    default-scheduler                                  Successfully assigned kubectl-8903/redis-master-mbvsx to alex-slot1-v3-vsp2-node-group-6fb930ab0d\n  Normal  Pulling    3s    kubelet, alex-slot1-v3-vsp2-node-group-6fb930ab0d  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, alex-slot1-v3-vsp2-node-group-6fb930ab0d  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, alex-slot1-v3-vsp2-node-group-6fb930ab0d  Created container redis-master\n  Normal  Started    1s    kubelet, alex-slot1-v3-vsp2-node-group-6fb930ab0d  Started container redis-master\n"
Mar  1 06:26:24.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 describe rc redis-master --namespace=kubectl-8903'
Mar  1 06:26:25.080: INFO: stderr: ""
Mar  1 06:26:25.080: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8903\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-mbvsx\n"
Mar  1 06:26:25.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 describe service redis-master --namespace=kubectl-8903'
Mar  1 06:26:25.221: INFO: stderr: ""
Mar  1 06:26:25.221: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8903\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.190.58\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.3.5:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  1 06:26:25.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 describe node alex-slot1-v3-vsp2-master-gro-455a452f9d'
Mar  1 06:26:25.446: INFO: stderr: ""
Mar  1 06:26:25.446: INFO: stdout: "Name:               alex-slot1-v3-vsp2-master-gro-455a452f9d\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=alex-slot1-v3-vsp2-master-gro-455a452f9d\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.128.28/22\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.70.192\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 01 Mar 2020 06:14:29 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 01 Mar 2020 06:15:27 +0000   Sun, 01 Mar 2020 06:15:27 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sun, 01 Mar 2020 06:25:40 +0000   Sun, 01 Mar 2020 06:14:23 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 01 Mar 2020 06:25:40 +0000   Sun, 01 Mar 2020 06:14:23 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 01 Mar 2020 06:25:40 +0000   Sun, 01 Mar 2020 06:14:23 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 01 Mar 2020 06:25:40 +0000   Sun, 01 Mar 2020 06:15:40 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.10.128.28\n  InternalIP:  10.10.128.28\n  Hostname:    alex-slot1-v3-vsp2-master-gro-455a452f9d\nCapacity:\n cpu:                4\n ephemeral-storage:  40470732Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16426048Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  37297826550\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16323648Ki\n pods:               110\nSystem Info:\n Machine ID:                 3ecf48eb3ee74ceda12555a76b87be10\n System UUID:                42154F44-2E76-537D-EF07-28368AF11A64\n Boot ID:                    1bc4367e-6553-4d43-9b87-29ffae08a9b5\n Kernel Version:             4.15.0-64-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.15.6\n Kube-Proxy Version:         v1.15.6\nPodCIDR:                     192.168.0.0/24\nProviderID:                  vsphere://42154f44-2e76-537d-ef07-28368af11a64\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                ------------  ----------  ---------------  -------------  ---\n  ccp                        ccp-vip-manager-alex-slot1-v3-vsp2-master-gro-455a452f9d            0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                calico-kube-controllers-68d8f5d5d4-vs675                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                calico-node-5hk7d                                                   250m (6%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                coredns-b5c558c76-ggl78                                             100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     11m\n  kube-system                coredns-b5c558c76-hhp5x                                             100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     11m\n  kube-system                etcd-alex-slot1-v3-vsp2-master-gro-455a452f9d                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                kube-apiserver-alex-slot1-v3-vsp2-master-gro-455a452f9d             250m (6%)     0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                kube-controller-manager-alex-slot1-v3-vsp2-master-gro-455a452f9d    200m (5%)     0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                kube-proxy-hrgjj                                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-scheduler-alex-slot1-v3-vsp2-master-gro-455a452f9d             100m (2%)     0 (0%)      0 (0%)           0 (0%)         10m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-knxkr             0 (0%)        0 (0%)      0 (0%)           0 (0%)         37s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1 (25%)     0 (0%)\n  memory             140Mi (0%)  340Mi (2%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                                                  Message\n  ----    ------                   ----               ----                                                  -------\n  Normal  NodeHasSufficientMemory  12m (x8 over 12m)  kubelet, alex-slot1-v3-vsp2-master-gro-455a452f9d     Node alex-slot1-v3-vsp2-master-gro-455a452f9d status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    12m (x8 over 12m)  kubelet, alex-slot1-v3-vsp2-master-gro-455a452f9d     Node alex-slot1-v3-vsp2-master-gro-455a452f9d status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     12m (x7 over 12m)  kubelet, alex-slot1-v3-vsp2-master-gro-455a452f9d     Node alex-slot1-v3-vsp2-master-gro-455a452f9d status is now: NodeHasSufficientPID\n  Normal  Starting                 11m                kube-proxy, alex-slot1-v3-vsp2-master-gro-455a452f9d  Starting kube-proxy.\n"
Mar  1 06:26:25.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 describe namespace kubectl-8903'
Mar  1 06:26:25.567: INFO: stderr: ""
Mar  1 06:26:25.567: INFO: stdout: "Name:         kubectl-8903\nLabels:       e2e-framework=kubectl\n              e2e-run=87a378be-b89a-4b29-873c-91899e1968e0\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:26:25.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8903" for this suite.
Mar  1 06:26:47.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:26:47.708: INFO: namespace kubectl-8903 deletion completed in 22.134801082s

• [SLOW TEST:29.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:26:47.710: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar  1 06:26:54.273: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4462 pod-service-account-bbebd3fc-fe23-4f8d-acca-f207880b6ed9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar  1 06:26:54.538: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4462 pod-service-account-bbebd3fc-fe23-4f8d-acca-f207880b6ed9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar  1 06:26:54.809: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4462 pod-service-account-bbebd3fc-fe23-4f8d-acca-f207880b6ed9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:26:55.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4462" for this suite.
Mar  1 06:27:01.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:27:01.206: INFO: namespace svcaccounts-4462 deletion completed in 6.142951922s

• [SLOW TEST:13.497 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:27:01.207: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Mar  1 06:27:01.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 --namespace=kubectl-6527 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  1 06:27:06.102: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  1 06:27:06.102: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:27:08.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6527" for this suite.
Mar  1 06:27:14.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:27:14.219: INFO: namespace kubectl-6527 deletion completed in 6.098290383s

• [SLOW TEST:13.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:27:14.219: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-d3d9bb7c-8d0d-43fe-9ac4-b12d93cad893
STEP: Creating a pod to test consume configMaps
Mar  1 06:27:14.267: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a" in namespace "projected-5359" to be "success or failure"
Mar  1 06:27:14.276: INFO: Pod "pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.205269ms
Mar  1 06:27:16.281: INFO: Pod "pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013289016s
Mar  1 06:27:18.284: INFO: Pod "pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016367504s
STEP: Saw pod success
Mar  1 06:27:18.284: INFO: Pod "pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a" satisfied condition "success or failure"
Mar  1 06:27:18.286: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:27:18.317: INFO: Waiting for pod pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a to disappear
Mar  1 06:27:18.320: INFO: Pod pod-projected-configmaps-4362e1b8-e0a3-41b8-851c-8a25a5b0b77a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:27:18.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5359" for this suite.
Mar  1 06:27:24.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:27:24.433: INFO: namespace projected-5359 deletion completed in 6.109535217s

• [SLOW TEST:10.214 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:27:24.434: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:27:24.466: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:27:28.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3903" for this suite.
Mar  1 06:28:06.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:28:06.737: INFO: namespace pods-3903 deletion completed in 38.108222462s

• [SLOW TEST:42.304 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:28:06.738: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Mar  1 06:28:06.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-7449'
Mar  1 06:28:07.002: INFO: stderr: ""
Mar  1 06:28:07.002: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 06:28:07.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7449'
Mar  1 06:28:07.115: INFO: stderr: ""
Mar  1 06:28:07.115: INFO: stdout: "update-demo-nautilus-2s2cb update-demo-nautilus-vh9dq "
Mar  1 06:28:07.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-2s2cb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7449'
Mar  1 06:28:07.217: INFO: stderr: ""
Mar  1 06:28:07.217: INFO: stdout: ""
Mar  1 06:28:07.217: INFO: update-demo-nautilus-2s2cb is created but not running
Mar  1 06:28:12.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7449'
Mar  1 06:28:12.326: INFO: stderr: ""
Mar  1 06:28:12.326: INFO: stdout: "update-demo-nautilus-2s2cb update-demo-nautilus-vh9dq "
Mar  1 06:28:12.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-2s2cb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7449'
Mar  1 06:28:12.428: INFO: stderr: ""
Mar  1 06:28:12.428: INFO: stdout: "true"
Mar  1 06:28:12.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-2s2cb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7449'
Mar  1 06:28:12.536: INFO: stderr: ""
Mar  1 06:28:12.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 06:28:12.536: INFO: validating pod update-demo-nautilus-2s2cb
Mar  1 06:28:12.541: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 06:28:12.541: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 06:28:12.541: INFO: update-demo-nautilus-2s2cb is verified up and running
Mar  1 06:28:12.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-vh9dq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7449'
Mar  1 06:28:12.654: INFO: stderr: ""
Mar  1 06:28:12.654: INFO: stdout: "true"
Mar  1 06:28:12.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-vh9dq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7449'
Mar  1 06:28:12.764: INFO: stderr: ""
Mar  1 06:28:12.764: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 06:28:12.764: INFO: validating pod update-demo-nautilus-vh9dq
Mar  1 06:28:12.768: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 06:28:12.768: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 06:28:12.768: INFO: update-demo-nautilus-vh9dq is verified up and running
STEP: using delete to clean up resources
Mar  1 06:28:12.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-7449'
Mar  1 06:28:12.889: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 06:28:12.889: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 06:28:12.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7449'
Mar  1 06:28:12.998: INFO: stderr: "No resources found.\n"
Mar  1 06:28:12.998: INFO: stdout: ""
Mar  1 06:28:12.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=update-demo --namespace=kubectl-7449 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 06:28:13.104: INFO: stderr: ""
Mar  1 06:28:13.104: INFO: stdout: "update-demo-nautilus-2s2cb\nupdate-demo-nautilus-vh9dq\n"
Mar  1 06:28:13.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7449'
Mar  1 06:28:13.727: INFO: stderr: "No resources found.\n"
Mar  1 06:28:13.727: INFO: stdout: ""
Mar  1 06:28:13.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=update-demo --namespace=kubectl-7449 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 06:28:13.833: INFO: stderr: ""
Mar  1 06:28:13.833: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:28:13.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7449" for this suite.
Mar  1 06:28:35.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:28:35.939: INFO: namespace kubectl-7449 deletion completed in 22.09937252s

• [SLOW TEST:29.202 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:28:35.941: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 06:28:35.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4528'
Mar  1 06:28:36.108: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 06:28:36.108: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  1 06:28:36.127: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-j7kdt]
Mar  1 06:28:36.127: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-j7kdt" in namespace "kubectl-4528" to be "running and ready"
Mar  1 06:28:36.137: INFO: Pod "e2e-test-nginx-rc-j7kdt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.10098ms
Mar  1 06:28:38.141: INFO: Pod "e2e-test-nginx-rc-j7kdt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013608797s
Mar  1 06:28:40.147: INFO: Pod "e2e-test-nginx-rc-j7kdt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019992912s
Mar  1 06:28:42.150: INFO: Pod "e2e-test-nginx-rc-j7kdt": Phase="Running", Reason="", readiness=true. Elapsed: 6.022891603s
Mar  1 06:28:42.150: INFO: Pod "e2e-test-nginx-rc-j7kdt" satisfied condition "running and ready"
Mar  1 06:28:42.150: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-j7kdt]
Mar  1 06:28:42.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs rc/e2e-test-nginx-rc --namespace=kubectl-4528'
Mar  1 06:28:42.283: INFO: stderr: ""
Mar  1 06:28:42.283: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Mar  1 06:28:42.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete rc e2e-test-nginx-rc --namespace=kubectl-4528'
Mar  1 06:28:42.389: INFO: stderr: ""
Mar  1 06:28:42.389: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:28:42.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4528" for this suite.
Mar  1 06:28:48.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:28:48.519: INFO: namespace kubectl-4528 deletion completed in 6.122513725s

• [SLOW TEST:12.579 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:28:48.520: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar  1 06:28:55.606: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:28:56.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4165" for this suite.
Mar  1 06:29:18.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:29:18.751: INFO: namespace replicaset-4165 deletion completed in 22.103336072s

• [SLOW TEST:30.232 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:29:18.752: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Mar  1 06:29:18.798: INFO: Waiting up to 5m0s for pod "client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb" in namespace "containers-3198" to be "success or failure"
Mar  1 06:29:18.804: INFO: Pod "client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.273008ms
Mar  1 06:29:20.809: INFO: Pod "client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010642208s
Mar  1 06:29:22.812: INFO: Pod "client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013690913s
STEP: Saw pod success
Mar  1 06:29:22.812: INFO: Pod "client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb" satisfied condition "success or failure"
Mar  1 06:29:22.814: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb container test-container: <nil>
STEP: delete the pod
Mar  1 06:29:22.833: INFO: Waiting for pod client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb to disappear
Mar  1 06:29:22.835: INFO: Pod client-containers-7dfc176c-b750-4cec-a77e-72d09d8c9deb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:29:22.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3198" for this suite.
Mar  1 06:29:28.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:29:28.937: INFO: namespace containers-3198 deletion completed in 6.097119706s

• [SLOW TEST:10.185 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:29:28.937: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-2455bc97-a11c-4f15-825b-94f96e82263e in namespace container-probe-9181
Mar  1 06:29:32.977: INFO: Started pod liveness-2455bc97-a11c-4f15-825b-94f96e82263e in namespace container-probe-9181
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 06:29:32.980: INFO: Initial restart count of pod liveness-2455bc97-a11c-4f15-825b-94f96e82263e is 0
Mar  1 06:29:51.017: INFO: Restart count of pod container-probe-9181/liveness-2455bc97-a11c-4f15-825b-94f96e82263e is now 1 (18.037444661s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:29:51.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9181" for this suite.
Mar  1 06:29:57.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:29:57.142: INFO: namespace container-probe-9181 deletion completed in 6.100653252s

• [SLOW TEST:28.205 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:29:57.142: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-10b920a2-669c-4e6b-a1f0-4937622bdad7
STEP: Creating a pod to test consume configMaps
Mar  1 06:29:57.185: INFO: Waiting up to 5m0s for pod "pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8" in namespace "configmap-2883" to be "success or failure"
Mar  1 06:29:57.192: INFO: Pod "pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.184575ms
Mar  1 06:29:59.195: INFO: Pod "pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009319204s
Mar  1 06:30:01.198: INFO: Pod "pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012982231s
STEP: Saw pod success
Mar  1 06:30:01.198: INFO: Pod "pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8" satisfied condition "success or failure"
Mar  1 06:30:01.201: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:30:01.218: INFO: Waiting for pod pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8 to disappear
Mar  1 06:30:01.221: INFO: Pod pod-configmaps-018b56eb-e27f-4e0e-9af7-b4d52f7b61e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:30:01.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2883" for this suite.
Mar  1 06:30:07.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:30:07.335: INFO: namespace configmap-2883 deletion completed in 6.109243921s

• [SLOW TEST:10.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:30:07.336: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Mar  1 06:30:11.400: INFO: Pod pod-hostip-6432d3fa-0ed0-4e7e-8ba3-756003fb61a7 has hostIP: 10.10.128.7
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:30:11.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6434" for this suite.
Mar  1 06:30:33.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:30:33.531: INFO: namespace pods-6434 deletion completed in 22.127261045s

• [SLOW TEST:26.195 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:30:33.531: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-8g7b
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 06:30:33.579: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8g7b" in namespace "subpath-5215" to be "success or failure"
Mar  1 06:30:33.587: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.206801ms
Mar  1 06:30:35.590: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010754439s
Mar  1 06:30:37.593: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 4.013563866s
Mar  1 06:30:39.597: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 6.017702446s
Mar  1 06:30:41.602: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 8.022211908s
Mar  1 06:30:43.605: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 10.025081979s
Mar  1 06:30:45.608: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 12.028829725s
Mar  1 06:30:47.612: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 14.032805587s
Mar  1 06:30:49.618: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 16.038752836s
Mar  1 06:30:51.623: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 18.043731347s
Mar  1 06:30:53.628: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 20.048057025s
Mar  1 06:30:55.631: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Running", Reason="", readiness=true. Elapsed: 22.051391802s
Mar  1 06:30:57.636: INFO: Pod "pod-subpath-test-projected-8g7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056688839s
STEP: Saw pod success
Mar  1 06:30:57.636: INFO: Pod "pod-subpath-test-projected-8g7b" satisfied condition "success or failure"
Mar  1 06:30:57.639: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-subpath-test-projected-8g7b container test-container-subpath-projected-8g7b: <nil>
STEP: delete the pod
Mar  1 06:30:57.670: INFO: Waiting for pod pod-subpath-test-projected-8g7b to disappear
Mar  1 06:30:57.672: INFO: Pod pod-subpath-test-projected-8g7b no longer exists
STEP: Deleting pod pod-subpath-test-projected-8g7b
Mar  1 06:30:57.672: INFO: Deleting pod "pod-subpath-test-projected-8g7b" in namespace "subpath-5215"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:30:57.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5215" for this suite.
Mar  1 06:31:03.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:31:03.785: INFO: namespace subpath-5215 deletion completed in 6.106821977s

• [SLOW TEST:30.254 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:31:03.789: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar  1 06:31:07.845: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-395293570 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  1 06:31:17.943: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:31:17.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6170" for this suite.
Mar  1 06:31:23.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:31:24.042: INFO: namespace pods-6170 deletion completed in 6.091781421s

• [SLOW TEST:20.253 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:31:24.044: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0a1e9c4a-4f3e-4411-824a-654a1bb8b8b4
STEP: Creating a pod to test consume secrets
Mar  1 06:31:24.112: INFO: Waiting up to 5m0s for pod "pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99" in namespace "secrets-2483" to be "success or failure"
Mar  1 06:31:24.116: INFO: Pod "pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.477294ms
Mar  1 06:31:26.119: INFO: Pod "pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007049175s
Mar  1 06:31:28.127: INFO: Pod "pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014572085s
STEP: Saw pod success
Mar  1 06:31:28.127: INFO: Pod "pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99" satisfied condition "success or failure"
Mar  1 06:31:28.130: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 06:31:28.156: INFO: Waiting for pod pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99 to disappear
Mar  1 06:31:28.159: INFO: Pod pod-secrets-f0f49ef1-9a56-44df-a0ae-67b0732f9b99 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:31:28.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2483" for this suite.
Mar  1 06:31:34.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:31:34.269: INFO: namespace secrets-2483 deletion completed in 6.104987785s
STEP: Destroying namespace "secret-namespace-218" for this suite.
Mar  1 06:31:40.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:31:40.374: INFO: namespace secret-namespace-218 deletion completed in 6.105021636s

• [SLOW TEST:16.331 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:31:40.375: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Mar  1 06:31:40.412: INFO: Waiting up to 5m0s for pod "client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585" in namespace "containers-9616" to be "success or failure"
Mar  1 06:31:40.415: INFO: Pod "client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218768ms
Mar  1 06:31:42.420: INFO: Pod "client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007989318s
Mar  1 06:31:44.423: INFO: Pod "client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011283496s
STEP: Saw pod success
Mar  1 06:31:44.423: INFO: Pod "client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585" satisfied condition "success or failure"
Mar  1 06:31:44.426: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585 container test-container: <nil>
STEP: delete the pod
Mar  1 06:31:44.450: INFO: Waiting for pod client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585 to disappear
Mar  1 06:31:44.452: INFO: Pod client-containers-c9900b3a-1223-4ba5-8a67-761dfd878585 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:31:44.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9616" for this suite.
Mar  1 06:31:50.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:31:50.587: INFO: namespace containers-9616 deletion completed in 6.130899935s

• [SLOW TEST:10.212 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:31:50.587: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2e4d62b8-89c9-4e94-bc08-de5c140a7475
STEP: Creating a pod to test consume secrets
Mar  1 06:31:50.631: INFO: Waiting up to 5m0s for pod "pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534" in namespace "secrets-1486" to be "success or failure"
Mar  1 06:31:50.633: INFO: Pod "pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21144ms
Mar  1 06:31:52.637: INFO: Pod "pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006065235s
Mar  1 06:31:54.641: INFO: Pod "pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009297937s
STEP: Saw pod success
Mar  1 06:31:54.641: INFO: Pod "pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534" satisfied condition "success or failure"
Mar  1 06:31:54.643: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 06:31:54.661: INFO: Waiting for pod pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534 to disappear
Mar  1 06:31:54.662: INFO: Pod pod-secrets-a89adaaa-7dd5-48a9-88c3-d9433b4fc534 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:31:54.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1486" for this suite.
Mar  1 06:32:00.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:32:00.785: INFO: namespace secrets-1486 deletion completed in 6.118240026s

• [SLOW TEST:10.198 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:32:00.785: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:32:04.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4283" for this suite.
Mar  1 06:32:10.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:32:10.981: INFO: namespace emptydir-wrapper-4283 deletion completed in 6.108958245s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:32:10.982: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 06:32:11.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-1512'
Mar  1 06:32:11.138: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 06:32:11.138: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Mar  1 06:32:13.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1512'
Mar  1 06:32:13.270: INFO: stderr: ""
Mar  1 06:32:13.270: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:32:13.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1512" for this suite.
Mar  1 06:32:35.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:32:35.389: INFO: namespace kubectl-1512 deletion completed in 22.113503015s

• [SLOW TEST:24.407 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:32:35.390: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 06:32:35.428: INFO: Waiting up to 5m0s for pod "pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36" in namespace "emptydir-8141" to be "success or failure"
Mar  1 06:32:35.438: INFO: Pod "pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.794708ms
Mar  1 06:32:37.441: INFO: Pod "pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013453781s
Mar  1 06:32:39.445: INFO: Pod "pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016850715s
STEP: Saw pod success
Mar  1 06:32:39.445: INFO: Pod "pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36" satisfied condition "success or failure"
Mar  1 06:32:39.447: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36 container test-container: <nil>
STEP: delete the pod
Mar  1 06:32:39.467: INFO: Waiting for pod pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36 to disappear
Mar  1 06:32:39.471: INFO: Pod pod-e6b49195-cd6a-4cfa-bf58-0668418a3d36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:32:39.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8141" for this suite.
Mar  1 06:32:45.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:32:45.575: INFO: namespace emptydir-8141 deletion completed in 6.100005749s

• [SLOW TEST:10.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:32:45.575: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:32:45.606: INFO: Creating deployment "nginx-deployment"
Mar  1 06:32:45.610: INFO: Waiting for observed generation 1
Mar  1 06:32:47.623: INFO: Waiting for all required pods to come up
Mar  1 06:32:47.628: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  1 06:32:49.647: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  1 06:32:49.654: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  1 06:32:49.660: INFO: Updating deployment nginx-deployment
Mar  1 06:32:49.660: INFO: Waiting for observed generation 2
Mar  1 06:32:51.672: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  1 06:32:51.675: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  1 06:32:51.678: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 06:32:51.687: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  1 06:32:51.687: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  1 06:32:51.690: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 06:32:51.695: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  1 06:32:51.695: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  1 06:32:51.701: INFO: Updating deployment nginx-deployment
Mar  1 06:32:51.701: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  1 06:32:51.729: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  1 06:32:51.761: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar  1 06:32:51.799: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-484,SelfLink:/apis/apps/v1/namespaces/deployment-484/deployments/nginx-deployment,UID:f4307350-fc40-4ae6-b833-31526fb281f8,ResourceVersion:4242,Generation:3,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2020-03-01 06:32:50 +0000 UTC 2020-03-01 06:32:46 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2020-03-01 06:32:52 +0000 UTC 2020-03-01 06:32:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar  1 06:32:51.833: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-484,SelfLink:/apis/apps/v1/namespaces/deployment-484/replicasets/nginx-deployment-55fb7cb77f,UID:1b44e7cf-4972-4a7b-a07e-f4613d3736dd,ResourceVersion:4205,Generation:3,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4307350-fc40-4ae6-b833-31526fb281f8 0xc00296d9e7 0xc00296d9e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 06:32:51.833: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  1 06:32:51.833: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-484,SelfLink:/apis/apps/v1/namespaces/deployment-484/replicasets/nginx-deployment-7b8c6f4498,UID:bd883fc7-cd3b-4a45-af8d-8329c8aefe95,ResourceVersion:4252,Generation:3,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4307350-fc40-4ae6-b833-31526fb281f8 0xc00296dab7 0xc00296dab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar  1 06:32:51.849: INFO: Pod "nginx-deployment-55fb7cb77f-5pbh8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5pbh8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-5pbh8,UID:8fdf7147-7cf2-49e9-8cbb-c35a0ed923aa,ResourceVersion:4254,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc0026247e0 0xc0026247e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.849: INFO: Pod "nginx-deployment-55fb7cb77f-5rbrq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5rbrq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-5rbrq,UID:19659825-9ef3-434b-bc8c-50005dd39e3c,ResourceVersion:4257,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc0026248f0 0xc0026248f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.849: INFO: Pod "nginx-deployment-55fb7cb77f-8qd9q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8qd9q,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-8qd9q,UID:5ba9effb-8949-4879-ab49-a8d4394bf038,ResourceVersion:4253,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002624a00 0xc002624a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.849: INFO: Pod "nginx-deployment-55fb7cb77f-bjhvt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bjhvt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-bjhvt,UID:2f01a2d9-3d81-4716-a189-354f028e0ace,ResourceVersion:4258,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002624b10 0xc002624b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.850: INFO: Pod "nginx-deployment-55fb7cb77f-bv7tn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bv7tn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-bv7tn,UID:b05a8287-fbf5-4f91-a33c-75d373a1518a,ResourceVersion:4194,Generation:0,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.17/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002624c30 0xc002624c31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:,StartTime:2020-03-01 06:32:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.850: INFO: Pod "nginx-deployment-55fb7cb77f-dp5vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dp5vw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-dp5vw,UID:097ba05e-626f-47bf-a3c6-7603af795a48,ResourceVersion:4256,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002624d90 0xc002624d91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.850: INFO: Pod "nginx-deployment-55fb7cb77f-fc2q2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fc2q2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-fc2q2,UID:7e18f7ef-172d-48f9-9d9a-94536f2b5710,ResourceVersion:4189,Generation:0,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002624eb0 0xc002624eb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002624f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002624f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:,StartTime:2020-03-01 06:32:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.850: INFO: Pod "nginx-deployment-55fb7cb77f-gcmzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gcmzg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-gcmzg,UID:0362ffe7-9fa6-423d-bf2c-bec7ba53ef8b,ResourceVersion:4196,Generation:0,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.20/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002625020 0xc002625021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026250b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:,StartTime:2020-03-01 06:32:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.850: INFO: Pod "nginx-deployment-55fb7cb77f-kb5mc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-kb5mc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-kb5mc,UID:461af6a1-ba86-4555-a3fb-d88dc6f42c1c,ResourceVersion:4230,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002625180 0xc002625181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026251f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-55fb7cb77f-lhwqg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lhwqg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-lhwqg,UID:1cfa76f3-0e88-4748-9d1b-f1789529df7e,ResourceVersion:4265,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002625290 0xc002625291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-55fb7cb77f-p4hpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-p4hpj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-p4hpj,UID:ac36e7d3-0bea-4f9e-b25c-3421f95d7a37,ResourceVersion:4187,Generation:0,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.19/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc0026253b0 0xc0026253b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:,StartTime:2020-03-01 06:32:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-55fb7cb77f-tvnst" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tvnst,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-tvnst,UID:5cd15c7f-5f8e-44d0-8ca5-01478a113e6c,ResourceVersion:4259,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002625510 0xc002625511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026255a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-55fb7cb77f-vn45f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vn45f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-55fb7cb77f-vn45f,UID:11c4080f-a6e8-4cf5-b30e-06c487df45bf,ResourceVersion:4197,Generation:0,CreationTimestamp:2020-03-01 06:32:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 1b44e7cf-4972-4a7b-a07e-f4613d3736dd 0xc002625630 0xc002625631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026256a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026256c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:50 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:,StartTime:2020-03-01 06:32:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-7b8c6f4498-2cp9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2cp9n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-2cp9n,UID:98b13353-3f82-4674-9fa1-b26df08b5675,ResourceVersion:4228,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625790 0xc002625791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026257f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-7b8c6f4498-47zkm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-47zkm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-47zkm,UID:1918a775-b550-480f-b5ad-79061acc91c7,ResourceVersion:4111,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.12/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc0026258a0 0xc0026258a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:192.168.3.12,StartTime:2020-03-01 06:32:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7c97d5b0d31c2987aa96c9718253700dbd03763e1f39c426f49a0596c5789966}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.851: INFO: Pod "nginx-deployment-7b8c6f4498-9nsgv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9nsgv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-9nsgv,UID:f360cbfc-d5a6-4f2b-b9a1-c94035ffcec0,ResourceVersion:4240,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc0026259f0 0xc0026259f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-fptl4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fptl4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-fptl4,UID:6be43348-3c78-417d-a289-a43ab7178fa5,ResourceVersion:4222,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625af0 0xc002625af1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-gdkvg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gdkvg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-gdkvg,UID:c55bf1e2-971f-4e46-b8ff-1170a7babd1b,ResourceVersion:4117,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625c00 0xc002625c01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:192.168.3.13,StartTime:2020-03-01 06:32:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0df9ecb8f7fedc4151268749997a5d2918919a485e9e7ce8aa3df9d896179e9b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-hc4fr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hc4fr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-hc4fr,UID:78fde4da-8472-4738-9ed4-ab9e6403811a,ResourceVersion:4129,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.18/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625d60 0xc002625d61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:192.168.2.18,StartTime:2020-03-01 06:32:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:48 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6f5064857a9b11656d698aae214930a4f0f04c4a587df84c7c6ae6e2dc1c37e1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-j78l8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j78l8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-j78l8,UID:484015df-ec86-4f15-8156-e08bfc1b42a2,ResourceVersion:4234,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625eb0 0xc002625eb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002625f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002625f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:,StartTime:2020-03-01 06:32:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-jwrnw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jwrnw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-jwrnw,UID:1095367d-92a9-4e37-b295-4285b9fc2a07,ResourceVersion:4250,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002625ff0 0xc002625ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:,StartTime:2020-03-01 06:32:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-jx2lv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jx2lv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-jx2lv,UID:566a63a1-9945-42d0-a767-03dcde31998e,ResourceVersion:4085,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78140 0xc002b78141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b781a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b781c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:192.168.2.15,StartTime:2020-03-01 06:32:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://db29c0a0e19ca80d474f21b82ce3138cdb426d88f675554a47066b800eed34f6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.852: INFO: Pod "nginx-deployment-7b8c6f4498-kh8zk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kh8zk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-kh8zk,UID:ab45dce1-83b1-47ac-84f4-e3a3048c72aa,ResourceVersion:4220,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78290 0xc002b78291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b782f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:,StartTime:2020-03-01 06:32:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-kszzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kszzg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-kszzg,UID:15a44047-248b-4200-a58d-0845d1211e1d,ResourceVersion:4238,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b783d0 0xc002b783d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-ktrmj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ktrmj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-ktrmj,UID:41603ecc-be74-45b5-8fde-a505d5c2366e,ResourceVersion:4245,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b784d0 0xc002b784d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:,StartTime:2020-03-01 06:32:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-kw2kf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kw2kf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-kw2kf,UID:79d62468-99b5-40e7-b186-e3ce4a37fdf6,ResourceVersion:4120,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78620 0xc002b78621}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b786a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:192.168.3.11,StartTime:2020-03-01 06:32:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://42546f1d9adb35adb811dab3b7e5a64c15d82105fc5103395b56634255f98763}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-lm85q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lm85q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-lm85q,UID:5e27c781-9bf2-4e69-abcb-e1f23e390c95,ResourceVersion:4262,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78770 0xc002b78771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b787d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b787f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:,StartTime:2020-03-01 06:32:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-nc56n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nc56n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-nc56n,UID:5767683b-2bd7-4f98-9218-7b12570bed1a,ResourceVersion:4239,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b788b0 0xc002b788b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.853: INFO: Pod "nginx-deployment-7b8c6f4498-pr9wx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pr9wx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-pr9wx,UID:3ac48b8a-f458-4754-8690-0ccfdd5de704,ResourceVersion:4126,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b789c0 0xc002b789c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:192.168.2.16,StartTime:2020-03-01 06:32:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:48 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://450b5a83079ce635fbd5a9104f9e59c7fbdf56902e104c3a675d0e02b3aea971}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.854: INFO: Pod "nginx-deployment-7b8c6f4498-s47nm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s47nm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-s47nm,UID:cb26346c-1f04-46f2-bd42-bba30d9d0dce,ResourceVersion:4108,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78b30 0xc002b78b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:192.168.1.14,StartTime:2020-03-01 06:32:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4bc4f72e3ce7ef95611c2bd078e1bca325f65e97ad283c11b2929f2f2bc4fc93}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.854: INFO: Pod "nginx-deployment-7b8c6f4498-vsd8d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vsd8d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-vsd8d,UID:121c8b8d-a9da-4abb-992b-8f37cc6e0fb4,ResourceVersion:4105,Generation:0,CreationTimestamp:2020-03-01 06:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78c90 0xc002b78c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:192.168.1.15,StartTime:2020-03-01 06:32:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-03-01 06:32:48 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f3c5026e46dc821d255a8ad6432d5c235467780dbb45e435a6f524051f746404}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.854: INFO: Pod "nginx-deployment-7b8c6f4498-wznjw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wznjw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-wznjw,UID:e8868ea2-11f2-4033-82d7-a658f81ca88c,ResourceVersion:4243,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78e00 0xc002b78e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 06:32:51.854: INFO: Pod "nginx-deployment-7b8c6f4498-xtxxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xtxxc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-484,SelfLink:/api/v1/namespaces/deployment-484/pods/nginx-deployment-7b8c6f4498-xtxxc,UID:b31d07ba-b2ae-47f3-b6b5-d93d0d71e81e,ResourceVersion:4249,Generation:0,CreationTimestamp:2020-03-01 06:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 bd883fc7-cd3b-4a45-af8d-8329c8aefe95 0xc002b78f00 0xc002b78f01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l9jk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9jk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9jk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b78f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b78f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:32:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:32:51.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-484" for this suite.
Mar  1 06:32:59.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:33:00.074: INFO: namespace deployment-484 deletion completed in 8.209156208s

• [SLOW TEST:14.499 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:33:00.074: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-l2dc
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 06:33:00.130: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-l2dc" in namespace "subpath-9559" to be "success or failure"
Mar  1 06:33:00.134: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.277521ms
Mar  1 06:33:02.138: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007292757s
Mar  1 06:33:04.142: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 4.011306418s
Mar  1 06:33:06.146: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 6.015307463s
Mar  1 06:33:08.149: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 8.018488277s
Mar  1 06:33:10.152: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 10.021853489s
Mar  1 06:33:12.156: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 12.025351013s
Mar  1 06:33:14.159: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 14.029007942s
Mar  1 06:33:16.162: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 16.031886161s
Mar  1 06:33:18.166: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 18.035521311s
Mar  1 06:33:20.169: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 20.039092365s
Mar  1 06:33:22.173: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Running", Reason="", readiness=true. Elapsed: 22.04297236s
Mar  1 06:33:24.176: INFO: Pod "pod-subpath-test-downwardapi-l2dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046169815s
STEP: Saw pod success
Mar  1 06:33:24.176: INFO: Pod "pod-subpath-test-downwardapi-l2dc" satisfied condition "success or failure"
Mar  1 06:33:24.179: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-subpath-test-downwardapi-l2dc container test-container-subpath-downwardapi-l2dc: <nil>
STEP: delete the pod
Mar  1 06:33:24.197: INFO: Waiting for pod pod-subpath-test-downwardapi-l2dc to disappear
Mar  1 06:33:24.200: INFO: Pod pod-subpath-test-downwardapi-l2dc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-l2dc
Mar  1 06:33:24.200: INFO: Deleting pod "pod-subpath-test-downwardapi-l2dc" in namespace "subpath-9559"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:33:24.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9559" for this suite.
Mar  1 06:33:30.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:33:30.306: INFO: namespace subpath-9559 deletion completed in 6.098878123s

• [SLOW TEST:30.232 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:33:30.307: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:33:34.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-460" for this suite.
Mar  1 06:34:24.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:34:24.468: INFO: namespace kubelet-test-460 deletion completed in 50.097380035s

• [SLOW TEST:54.160 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:34:24.468: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-84c8f887-3906-41f5-992a-459c9544e3c3
STEP: Creating a pod to test consume configMaps
Mar  1 06:34:24.515: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58" in namespace "projected-7066" to be "success or failure"
Mar  1 06:34:24.519: INFO: Pod "pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58": Phase="Pending", Reason="", readiness=false. Elapsed: 3.552639ms
Mar  1 06:34:26.523: INFO: Pod "pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007405376s
Mar  1 06:34:28.528: INFO: Pod "pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012339195s
STEP: Saw pod success
Mar  1 06:34:28.528: INFO: Pod "pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58" satisfied condition "success or failure"
Mar  1 06:34:28.530: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:34:28.561: INFO: Waiting for pod pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58 to disappear
Mar  1 06:34:28.564: INFO: Pod pod-projected-configmaps-65200259-55cd-47b2-a61a-fc01fe0c1e58 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:34:28.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7066" for this suite.
Mar  1 06:34:34.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:34:34.663: INFO: namespace projected-7066 deletion completed in 6.094582119s

• [SLOW TEST:10.195 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:34:34.664: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  1 06:34:34.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4834,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 06:34:34.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4835,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 06:34:34.723: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4836,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  1 06:34:44.749: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4858,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 06:34:44.749: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4859,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  1 06:34:44.749: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3319,SelfLink:/api/v1/namespaces/watch-3319/configmaps/e2e-watch-test-label-changed,UID:bc713576-2653-49ae-9acf-f9f8637ad947,ResourceVersion:4860,Generation:0,CreationTimestamp:2020-03-01 06:34:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:34:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3319" for this suite.
Mar  1 06:34:50.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:34:50.880: INFO: namespace watch-3319 deletion completed in 6.12586518s

• [SLOW TEST:16.216 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:34:50.880: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  1 06:34:53.968: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:34:53.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4582" for this suite.
Mar  1 06:35:00.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:35:00.105: INFO: namespace container-runtime-4582 deletion completed in 6.114513011s

• [SLOW TEST:9.225 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:35:00.106: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:35:00.152: INFO: (0) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 5.853813ms)
Mar  1 06:35:00.155: INFO: (1) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.52704ms)
Mar  1 06:35:00.159: INFO: (2) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.155687ms)
Mar  1 06:35:00.163: INFO: (3) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.396222ms)
Mar  1 06:35:00.168: INFO: (4) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.676618ms)
Mar  1 06:35:00.172: INFO: (5) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.990138ms)
Mar  1 06:35:00.175: INFO: (6) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.682636ms)
Mar  1 06:35:00.185: INFO: (7) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 9.915507ms)
Mar  1 06:35:00.189: INFO: (8) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.365793ms)
Mar  1 06:35:00.192: INFO: (9) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.317752ms)
Mar  1 06:35:00.195: INFO: (10) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.978629ms)
Mar  1 06:35:00.199: INFO: (11) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.466118ms)
Mar  1 06:35:00.202: INFO: (12) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.209317ms)
Mar  1 06:35:00.206: INFO: (13) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.56869ms)
Mar  1 06:35:00.209: INFO: (14) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.476792ms)
Mar  1 06:35:00.214: INFO: (15) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 5.076461ms)
Mar  1 06:35:00.218: INFO: (16) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.807365ms)
Mar  1 06:35:00.222: INFO: (17) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.178271ms)
Mar  1 06:35:00.226: INFO: (18) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.864407ms)
Mar  1 06:35:00.230: INFO: (19) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.689306ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:35:00.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4265" for this suite.
Mar  1 06:35:06.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:35:06.364: INFO: namespace proxy-4265 deletion completed in 6.1302843s

• [SLOW TEST:6.258 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:35:06.365: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-cw6g
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 06:35:06.424: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cw6g" in namespace "subpath-2215" to be "success or failure"
Mar  1 06:35:06.430: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Pending", Reason="", readiness=false. Elapsed: 6.14512ms
Mar  1 06:35:08.433: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00975712s
Mar  1 06:35:10.439: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 4.015245937s
Mar  1 06:35:12.442: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 6.018651639s
Mar  1 06:35:14.446: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 8.022140008s
Mar  1 06:35:16.449: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 10.025081725s
Mar  1 06:35:18.453: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 12.029307015s
Mar  1 06:35:20.466: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 14.042865232s
Mar  1 06:35:22.470: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 16.046494795s
Mar  1 06:35:24.473: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 18.04967673s
Mar  1 06:35:26.477: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Running", Reason="", readiness=true. Elapsed: 20.053362211s
Mar  1 06:35:28.480: INFO: Pod "pod-subpath-test-configmap-cw6g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.056455533s
STEP: Saw pod success
Mar  1 06:35:28.480: INFO: Pod "pod-subpath-test-configmap-cw6g" satisfied condition "success or failure"
Mar  1 06:35:28.482: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-subpath-test-configmap-cw6g container test-container-subpath-configmap-cw6g: <nil>
STEP: delete the pod
Mar  1 06:35:28.501: INFO: Waiting for pod pod-subpath-test-configmap-cw6g to disappear
Mar  1 06:35:28.503: INFO: Pod pod-subpath-test-configmap-cw6g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cw6g
Mar  1 06:35:28.503: INFO: Deleting pod "pod-subpath-test-configmap-cw6g" in namespace "subpath-2215"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:35:28.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2215" for this suite.
Mar  1 06:35:34.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:35:34.717: INFO: namespace subpath-2215 deletion completed in 6.208686675s

• [SLOW TEST:28.352 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:35:34.717: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar  1 06:35:34.773: INFO: Pod name pod-release: Found 0 pods out of 1
Mar  1 06:35:39.777: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:35:40.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1677" for this suite.
Mar  1 06:35:46.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:35:46.918: INFO: namespace replication-controller-1677 deletion completed in 6.121213491s

• [SLOW TEST:12.200 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:35:46.918: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  1 06:35:57.011: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.011: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.156: INFO: Exec stderr: ""
Mar  1 06:35:57.157: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.157: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.299: INFO: Exec stderr: ""
Mar  1 06:35:57.299: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.299: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.427: INFO: Exec stderr: ""
Mar  1 06:35:57.427: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.427: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.560: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  1 06:35:57.560: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.560: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.695: INFO: Exec stderr: ""
Mar  1 06:35:57.695: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.695: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:57.819: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  1 06:35:57.819: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:57.819: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:58.001: INFO: Exec stderr: ""
Mar  1 06:35:58.001: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:58.001: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:58.220: INFO: Exec stderr: ""
Mar  1 06:35:58.221: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:58.221: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:58.388: INFO: Exec stderr: ""
Mar  1 06:35:58.388: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1633 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:35:58.388: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:35:58.551: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:35:58.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1633" for this suite.
Mar  1 06:36:36.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:36:36.665: INFO: namespace e2e-kubelet-etc-hosts-1633 deletion completed in 38.108290055s

• [SLOW TEST:49.747 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:36:36.666: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:36:36.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d" in namespace "downward-api-2598" to be "success or failure"
Mar  1 06:36:36.708: INFO: Pod "downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.780091ms
Mar  1 06:36:38.712: INFO: Pod "downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006533534s
Mar  1 06:36:40.716: INFO: Pod "downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010464744s
STEP: Saw pod success
Mar  1 06:36:40.716: INFO: Pod "downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d" satisfied condition "success or failure"
Mar  1 06:36:40.721: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d container client-container: <nil>
STEP: delete the pod
Mar  1 06:36:40.743: INFO: Waiting for pod downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d to disappear
Mar  1 06:36:40.746: INFO: Pod downwardapi-volume-89082865-12e2-4102-96a4-dd84b7da789d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:36:40.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2598" for this suite.
Mar  1 06:36:46.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:36:46.865: INFO: namespace downward-api-2598 deletion completed in 6.112740023s

• [SLOW TEST:10.199 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:36:46.866: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  1 06:36:49.923: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:36:49.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-967" for this suite.
Mar  1 06:36:55.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:36:56.059: INFO: namespace container-runtime-967 deletion completed in 6.11873767s

• [SLOW TEST:9.193 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:36:56.059: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  1 06:36:59.110: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:36:59.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3905" for this suite.
Mar  1 06:37:05.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:37:05.234: INFO: namespace container-runtime-3905 deletion completed in 6.108754228s

• [SLOW TEST:9.175 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:37:05.234: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:37:05.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609" in namespace "downward-api-6943" to be "success or failure"
Mar  1 06:37:05.283: INFO: Pod "downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609": Phase="Pending", Reason="", readiness=false. Elapsed: 5.347927ms
Mar  1 06:37:07.287: INFO: Pod "downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009426838s
Mar  1 06:37:09.291: INFO: Pod "downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012658691s
STEP: Saw pod success
Mar  1 06:37:09.291: INFO: Pod "downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609" satisfied condition "success or failure"
Mar  1 06:37:09.294: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609 container client-container: <nil>
STEP: delete the pod
Mar  1 06:37:09.317: INFO: Waiting for pod downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609 to disappear
Mar  1 06:37:09.320: INFO: Pod downwardapi-volume-1fb8e36b-79e1-44c8-9f1b-ef7f0d619609 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:37:09.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6943" for this suite.
Mar  1 06:37:15.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:37:15.433: INFO: namespace downward-api-6943 deletion completed in 6.108808899s

• [SLOW TEST:10.199 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:37:15.435: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 06:37:15.478: INFO: Waiting up to 5m0s for pod "pod-9f810578-5d61-4238-a3ab-5864c2e82d2d" in namespace "emptydir-3573" to be "success or failure"
Mar  1 06:37:15.487: INFO: Pod "pod-9f810578-5d61-4238-a3ab-5864c2e82d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.129958ms
Mar  1 06:37:17.490: INFO: Pod "pod-9f810578-5d61-4238-a3ab-5864c2e82d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012622768s
Mar  1 06:37:19.493: INFO: Pod "pod-9f810578-5d61-4238-a3ab-5864c2e82d2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01570836s
STEP: Saw pod success
Mar  1 06:37:19.494: INFO: Pod "pod-9f810578-5d61-4238-a3ab-5864c2e82d2d" satisfied condition "success or failure"
Mar  1 06:37:19.496: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-9f810578-5d61-4238-a3ab-5864c2e82d2d container test-container: <nil>
STEP: delete the pod
Mar  1 06:37:19.513: INFO: Waiting for pod pod-9f810578-5d61-4238-a3ab-5864c2e82d2d to disappear
Mar  1 06:37:19.515: INFO: Pod pod-9f810578-5d61-4238-a3ab-5864c2e82d2d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:37:19.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3573" for this suite.
Mar  1 06:37:25.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:37:25.626: INFO: namespace emptydir-3573 deletion completed in 6.106306735s

• [SLOW TEST:10.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:37:25.626: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:37:25.659: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:37:29.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7056" for this suite.
Mar  1 06:38:19.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:38:19.793: INFO: namespace pods-7056 deletion completed in 50.100190487s

• [SLOW TEST:54.167 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:38:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:38:19.831: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70" in namespace "downward-api-7316" to be "success or failure"
Mar  1 06:38:19.836: INFO: Pod "downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70": Phase="Pending", Reason="", readiness=false. Elapsed: 5.676866ms
Mar  1 06:38:21.840: INFO: Pod "downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009577896s
Mar  1 06:38:23.845: INFO: Pod "downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013855891s
STEP: Saw pod success
Mar  1 06:38:23.845: INFO: Pod "downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70" satisfied condition "success or failure"
Mar  1 06:38:23.847: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70 container client-container: <nil>
STEP: delete the pod
Mar  1 06:38:23.873: INFO: Waiting for pod downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70 to disappear
Mar  1 06:38:23.875: INFO: Pod downwardapi-volume-4a2534e4-ea6d-41de-b4bd-42128db8bb70 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:38:23.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7316" for this suite.
Mar  1 06:38:29.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:38:29.998: INFO: namespace downward-api-7316 deletion completed in 6.117877952s

• [SLOW TEST:10.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:38:29.999: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-9215
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9215 to expose endpoints map[]
Mar  1 06:38:30.060: INFO: successfully validated that service multi-endpoint-test in namespace services-9215 exposes endpoints map[] (4.21899ms elapsed)
STEP: Creating pod pod1 in namespace services-9215
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9215 to expose endpoints map[pod1:[100]]
Mar  1 06:38:33.096: INFO: successfully validated that service multi-endpoint-test in namespace services-9215 exposes endpoints map[pod1:[100]] (3.029442135s elapsed)
STEP: Creating pod pod2 in namespace services-9215
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9215 to expose endpoints map[pod1:[100] pod2:[101]]
Mar  1 06:38:36.134: INFO: successfully validated that service multi-endpoint-test in namespace services-9215 exposes endpoints map[pod1:[100] pod2:[101]] (3.032634476s elapsed)
STEP: Deleting pod pod1 in namespace services-9215
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9215 to expose endpoints map[pod2:[101]]
Mar  1 06:38:37.157: INFO: successfully validated that service multi-endpoint-test in namespace services-9215 exposes endpoints map[pod2:[101]] (1.014374786s elapsed)
STEP: Deleting pod pod2 in namespace services-9215
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9215 to expose endpoints map[]
Mar  1 06:38:38.172: INFO: successfully validated that service multi-endpoint-test in namespace services-9215 exposes endpoints map[] (1.007649058s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:38:38.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9215" for this suite.
Mar  1 06:38:44.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:38:44.318: INFO: namespace services-9215 deletion completed in 6.11549029s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:14.319 seconds]
[sig-network] Services
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:38:44.322: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-56c381ef-7cec-4504-a832-e9b3e6c2b6ea
STEP: Creating a pod to test consume configMaps
Mar  1 06:38:44.362: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a" in namespace "configmap-1619" to be "success or failure"
Mar  1 06:38:44.365: INFO: Pod "pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.754701ms
Mar  1 06:38:46.371: INFO: Pod "pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008467111s
Mar  1 06:38:48.383: INFO: Pod "pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020698448s
STEP: Saw pod success
Mar  1 06:38:48.383: INFO: Pod "pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a" satisfied condition "success or failure"
Mar  1 06:38:48.390: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:38:48.411: INFO: Waiting for pod pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a to disappear
Mar  1 06:38:48.414: INFO: Pod pod-configmaps-3d04ded3-81fa-4cae-bc25-148d60fe105a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:38:48.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1619" for this suite.
Mar  1 06:38:54.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:38:54.560: INFO: namespace configmap-1619 deletion completed in 6.141878183s

• [SLOW TEST:10.239 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:38:54.560: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  1 06:38:54.616: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5779,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 06:38:54.617: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5779,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  1 06:39:04.623: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5802,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 06:39:04.623: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5802,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  1 06:39:14.629: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5823,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 06:39:14.630: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5823,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  1 06:39:24.642: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5844,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 06:39:24.642: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-a,UID:768a5b08-773c-4bc6-a211-23cb672e3aae,ResourceVersion:5844,Generation:0,CreationTimestamp:2020-03-01 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  1 06:39:34.648: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-b,UID:bb53d671-a8f3-4c8d-b607-f0f8a19c5687,ResourceVersion:5865,Generation:0,CreationTimestamp:2020-03-01 06:39:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 06:39:34.648: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-b,UID:bb53d671-a8f3-4c8d-b607-f0f8a19c5687,ResourceVersion:5865,Generation:0,CreationTimestamp:2020-03-01 06:39:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  1 06:39:44.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-b,UID:bb53d671-a8f3-4c8d-b607-f0f8a19c5687,ResourceVersion:5885,Generation:0,CreationTimestamp:2020-03-01 06:39:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 06:39:44.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8931,SelfLink:/api/v1/namespaces/watch-8931/configmaps/e2e-watch-test-configmap-b,UID:bb53d671-a8f3-4c8d-b607-f0f8a19c5687,ResourceVersion:5885,Generation:0,CreationTimestamp:2020-03-01 06:39:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:39:54.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8931" for this suite.
Mar  1 06:40:00.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:40:00.803: INFO: namespace watch-8931 deletion completed in 6.142174404s

• [SLOW TEST:66.243 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:40:00.808: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-clfz
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 06:40:00.864: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-clfz" in namespace "subpath-1367" to be "success or failure"
Mar  1 06:40:00.873: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.35184ms
Mar  1 06:40:02.876: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011704902s
Mar  1 06:40:04.880: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 4.015213957s
Mar  1 06:40:06.883: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 6.018899378s
Mar  1 06:40:08.887: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 8.022448317s
Mar  1 06:40:10.891: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 10.026521868s
Mar  1 06:40:12.894: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 12.029772585s
Mar  1 06:40:14.898: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 14.033325713s
Mar  1 06:40:16.902: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 16.037335914s
Mar  1 06:40:18.905: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 18.040926783s
Mar  1 06:40:20.909: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Running", Reason="", readiness=true. Elapsed: 20.044552514s
Mar  1 06:40:22.912: INFO: Pod "pod-subpath-test-secret-clfz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.047496884s
STEP: Saw pod success
Mar  1 06:40:22.912: INFO: Pod "pod-subpath-test-secret-clfz" satisfied condition "success or failure"
Mar  1 06:40:22.914: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-subpath-test-secret-clfz container test-container-subpath-secret-clfz: <nil>
STEP: delete the pod
Mar  1 06:40:22.932: INFO: Waiting for pod pod-subpath-test-secret-clfz to disappear
Mar  1 06:40:22.941: INFO: Pod pod-subpath-test-secret-clfz no longer exists
STEP: Deleting pod pod-subpath-test-secret-clfz
Mar  1 06:40:22.941: INFO: Deleting pod "pod-subpath-test-secret-clfz" in namespace "subpath-1367"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:40:22.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1367" for this suite.
Mar  1 06:40:28.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:40:29.044: INFO: namespace subpath-1367 deletion completed in 6.095332004s

• [SLOW TEST:28.237 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:40:29.046: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Mar  1 06:40:29.075: INFO: namespace kubectl-5480
Mar  1 06:40:29.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-5480'
Mar  1 06:40:29.743: INFO: stderr: ""
Mar  1 06:40:29.743: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 06:40:30.750: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:40:30.750: INFO: Found 0 / 1
Mar  1 06:40:31.747: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:40:31.747: INFO: Found 0 / 1
Mar  1 06:40:32.747: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:40:32.747: INFO: Found 0 / 1
Mar  1 06:40:33.747: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:40:33.747: INFO: Found 1 / 1
Mar  1 06:40:33.747: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 06:40:33.754: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 06:40:33.754: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 06:40:33.754: INFO: wait on redis-master startup in kubectl-5480 
Mar  1 06:40:33.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-gzqds redis-master --namespace=kubectl-5480'
Mar  1 06:40:33.869: INFO: stderr: ""
Mar  1 06:40:33.869: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 06:40:33.094 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 06:40:33.094 # Server started, Redis version 3.2.12\n1:M 01 Mar 06:40:33.094 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 06:40:33.094 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  1 06:40:33.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5480'
Mar  1 06:40:33.982: INFO: stderr: ""
Mar  1 06:40:33.982: INFO: stdout: "service/rm2 exposed\n"
Mar  1 06:40:33.987: INFO: Service rm2 in namespace kubectl-5480 found.
STEP: exposing service
Mar  1 06:40:35.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5480'
Mar  1 06:40:36.124: INFO: stderr: ""
Mar  1 06:40:36.124: INFO: stdout: "service/rm3 exposed\n"
Mar  1 06:40:36.127: INFO: Service rm3 in namespace kubectl-5480 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:40:38.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5480" for this suite.
Mar  1 06:41:00.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:41:00.236: INFO: namespace kubectl-5480 deletion completed in 22.095880334s

• [SLOW TEST:31.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:41:00.236: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Mar  1 06:41:00.282: INFO: Waiting up to 5m0s for pod "var-expansion-0e87cffa-751e-418e-8f73-a5a676018740" in namespace "var-expansion-611" to be "success or failure"
Mar  1 06:41:00.286: INFO: Pod "var-expansion-0e87cffa-751e-418e-8f73-a5a676018740": Phase="Pending", Reason="", readiness=false. Elapsed: 3.510593ms
Mar  1 06:41:02.289: INFO: Pod "var-expansion-0e87cffa-751e-418e-8f73-a5a676018740": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006647503s
Mar  1 06:41:04.292: INFO: Pod "var-expansion-0e87cffa-751e-418e-8f73-a5a676018740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009770257s
STEP: Saw pod success
Mar  1 06:41:04.292: INFO: Pod "var-expansion-0e87cffa-751e-418e-8f73-a5a676018740" satisfied condition "success or failure"
Mar  1 06:41:04.294: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod var-expansion-0e87cffa-751e-418e-8f73-a5a676018740 container dapi-container: <nil>
STEP: delete the pod
Mar  1 06:41:04.315: INFO: Waiting for pod var-expansion-0e87cffa-751e-418e-8f73-a5a676018740 to disappear
Mar  1 06:41:04.318: INFO: Pod var-expansion-0e87cffa-751e-418e-8f73-a5a676018740 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:41:04.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-611" for this suite.
Mar  1 06:41:10.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:41:10.427: INFO: namespace var-expansion-611 deletion completed in 6.103430205s

• [SLOW TEST:10.191 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:41:10.427: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:41:36.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3710" for this suite.
Mar  1 06:41:42.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:41:42.691: INFO: namespace namespaces-3710 deletion completed in 6.130966228s
STEP: Destroying namespace "nsdeletetest-3093" for this suite.
Mar  1 06:41:42.694: INFO: Namespace nsdeletetest-3093 was already deleted
STEP: Destroying namespace "nsdeletetest-8260" for this suite.
Mar  1 06:41:48.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:41:48.803: INFO: namespace nsdeletetest-8260 deletion completed in 6.108880788s

• [SLOW TEST:38.376 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:41:48.803: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:41:48.893: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 06:41:48.910: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:48.912: INFO: Number of nodes with available pods: 0
Mar  1 06:41:48.912: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:41:49.919: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:49.923: INFO: Number of nodes with available pods: 0
Mar  1 06:41:49.923: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:41:50.918: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:50.921: INFO: Number of nodes with available pods: 0
Mar  1 06:41:50.921: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:41:51.918: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:51.921: INFO: Number of nodes with available pods: 3
Mar  1 06:41:51.921: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  1 06:41:51.958: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:51.958: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:51.958: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:51.969: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:52.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:52.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:52.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:52.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:53.975: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:53.975: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:53.975: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:53.980: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:54.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:54.973: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:54.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:54.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:54.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:55.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:55.973: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:55.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:55.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:55.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:56.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:56.973: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:56.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:56.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:56.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:57.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:57.974: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:57.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:57.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:57.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:58.975: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:58.975: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:58.975: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:58.975: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:58.980: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:41:59.973: INFO: Wrong image for pod: daemon-set-2qjx6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:59.973: INFO: Pod daemon-set-2qjx6 is not available
Mar  1 06:41:59.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:59.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:41:59.980: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:00.973: INFO: Pod daemon-set-8s57r is not available
Mar  1 06:42:00.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:00.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:00.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:01.973: INFO: Pod daemon-set-8s57r is not available
Mar  1 06:42:01.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:01.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:01.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:02.974: INFO: Pod daemon-set-8s57r is not available
Mar  1 06:42:02.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:02.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:02.981: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:03.973: INFO: Pod daemon-set-8s57r is not available
Mar  1 06:42:03.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:03.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:03.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:04.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:04.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:04.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:05.978: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:05.978: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:05.978: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:05.982: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:06.975: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:06.975: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:06.975: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:06.980: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:07.975: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:07.975: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:07.975: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:07.980: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:08.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:08.973: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:08.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:08.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:09.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:09.973: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:09.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:09.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:10.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:10.974: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:10.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:10.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:11.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:11.974: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:11.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:11.982: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:12.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:12.974: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:12.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:12.981: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:13.979: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:13.979: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:13.979: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:13.984: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:14.974: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:14.974: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:14.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:14.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:15.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:15.973: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:15.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:15.977: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:16.973: INFO: Wrong image for pod: daemon-set-rr8b5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:16.973: INFO: Pod daemon-set-rr8b5 is not available
Mar  1 06:42:16.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:16.977: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:17.977: INFO: Pod daemon-set-fb96d is not available
Mar  1 06:42:17.977: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:17.982: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:18.973: INFO: Pod daemon-set-fb96d is not available
Mar  1 06:42:18.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:18.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:19.976: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:19.981: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:20.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:20.973: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:20.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:21.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:21.974: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:21.981: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:22.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:22.974: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:22.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:23.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:23.973: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:23.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:24.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:24.973: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:24.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:25.974: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:25.974: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:25.979: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:26.973: INFO: Wrong image for pod: daemon-set-z4l2x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Mar  1 06:42:26.973: INFO: Pod daemon-set-z4l2x is not available
Mar  1 06:42:26.977: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:27.973: INFO: Pod daemon-set-qn4fd is not available
Mar  1 06:42:27.978: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  1 06:42:27.982: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:27.985: INFO: Number of nodes with available pods: 2
Mar  1 06:42:27.986: INFO: Node alex-slot1-v3-vsp2-node-group-efb81104b7 is running more than one daemon pod
Mar  1 06:42:28.991: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:28.994: INFO: Number of nodes with available pods: 2
Mar  1 06:42:28.994: INFO: Node alex-slot1-v3-vsp2-node-group-efb81104b7 is running more than one daemon pod
Mar  1 06:42:29.991: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:42:29.995: INFO: Number of nodes with available pods: 3
Mar  1 06:42:29.995: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3067, will wait for the garbage collector to delete the pods
Mar  1 06:42:30.068: INFO: Deleting DaemonSet.extensions daemon-set took: 6.39842ms
Mar  1 06:42:30.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.287176ms
Mar  1 06:42:37.172: INFO: Number of nodes with available pods: 0
Mar  1 06:42:37.172: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 06:42:37.175: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3067/daemonsets","resourceVersion":"6492"},"items":null}

Mar  1 06:42:37.177: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3067/pods","resourceVersion":"6492"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:42:37.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3067" for this suite.
Mar  1 06:42:43.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:42:43.377: INFO: namespace daemonsets-3067 deletion completed in 6.164703549s

• [SLOW TEST:54.574 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:42:43.378: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Mar  1 06:42:43.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 api-versions'
Mar  1 06:42:43.519: INFO: stderr: ""
Mar  1 06:42:43.519: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nhelm.ccp.cisco.com/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:42:43.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6774" for this suite.
Mar  1 06:42:49.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:42:49.647: INFO: namespace kubectl-6774 deletion completed in 6.122454678s

• [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:42:49.648: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:42:49.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a" in namespace "downward-api-4387" to be "success or failure"
Mar  1 06:42:49.714: INFO: Pod "downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.369798ms
Mar  1 06:42:51.718: INFO: Pod "downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013276101s
Mar  1 06:42:53.721: INFO: Pod "downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016490927s
STEP: Saw pod success
Mar  1 06:42:53.721: INFO: Pod "downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a" satisfied condition "success or failure"
Mar  1 06:42:53.723: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a container client-container: <nil>
STEP: delete the pod
Mar  1 06:42:53.741: INFO: Waiting for pod downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a to disappear
Mar  1 06:42:53.743: INFO: Pod downwardapi-volume-9ae43b63-ece8-4250-876f-3e842440612a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:42:53.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4387" for this suite.
Mar  1 06:42:59.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:42:59.848: INFO: namespace downward-api-4387 deletion completed in 6.099968162s

• [SLOW TEST:10.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:42:59.848: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0301 06:43:09.911882      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 06:43:09.911: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:43:09.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-820" for this suite.
Mar  1 06:43:15.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:43:16.031: INFO: namespace gc-820 deletion completed in 6.115081948s

• [SLOW TEST:16.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:43:16.031: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:43:16.069: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36" in namespace "downward-api-7245" to be "success or failure"
Mar  1 06:43:16.071: INFO: Pod "downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366008ms
Mar  1 06:43:18.075: INFO: Pod "downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006545862s
Mar  1 06:43:20.079: INFO: Pod "downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009915264s
STEP: Saw pod success
Mar  1 06:43:20.079: INFO: Pod "downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36" satisfied condition "success or failure"
Mar  1 06:43:20.081: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36 container client-container: <nil>
STEP: delete the pod
Mar  1 06:43:20.104: INFO: Waiting for pod downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36 to disappear
Mar  1 06:43:20.106: INFO: Pod downwardapi-volume-ddf7ce9b-d745-423f-ad46-ad4b69afda36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:43:20.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7245" for this suite.
Mar  1 06:43:26.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:43:26.214: INFO: namespace downward-api-7245 deletion completed in 6.102952697s

• [SLOW TEST:10.183 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:43:26.214: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 06:43:26.285: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:26.292: INFO: Number of nodes with available pods: 0
Mar  1 06:43:26.292: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:27.297: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:27.300: INFO: Number of nodes with available pods: 0
Mar  1 06:43:27.300: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:28.296: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:28.299: INFO: Number of nodes with available pods: 0
Mar  1 06:43:28.300: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:29.296: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:29.300: INFO: Number of nodes with available pods: 3
Mar  1 06:43:29.300: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  1 06:43:29.316: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:29.320: INFO: Number of nodes with available pods: 2
Mar  1 06:43:29.320: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:30.326: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:30.328: INFO: Number of nodes with available pods: 2
Mar  1 06:43:30.328: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:31.325: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:31.328: INFO: Number of nodes with available pods: 2
Mar  1 06:43:31.328: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:32.325: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:32.328: INFO: Number of nodes with available pods: 2
Mar  1 06:43:32.328: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:33.325: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:33.329: INFO: Number of nodes with available pods: 2
Mar  1 06:43:33.329: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:34.327: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:34.330: INFO: Number of nodes with available pods: 2
Mar  1 06:43:34.330: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:35.326: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:35.329: INFO: Number of nodes with available pods: 2
Mar  1 06:43:35.329: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:36.326: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:36.328: INFO: Number of nodes with available pods: 2
Mar  1 06:43:36.328: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:37.325: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:37.328: INFO: Number of nodes with available pods: 2
Mar  1 06:43:37.328: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:38.326: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:38.330: INFO: Number of nodes with available pods: 2
Mar  1 06:43:38.330: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:39.327: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:39.330: INFO: Number of nodes with available pods: 2
Mar  1 06:43:39.330: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:43:40.327: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 06:43:40.331: INFO: Number of nodes with available pods: 3
Mar  1 06:43:40.331: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-296, will wait for the garbage collector to delete the pods
Mar  1 06:43:40.392: INFO: Deleting DaemonSet.extensions daemon-set took: 5.926807ms
Mar  1 06:43:40.792: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.210437ms
Mar  1 06:43:47.495: INFO: Number of nodes with available pods: 0
Mar  1 06:43:47.495: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 06:43:47.498: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-296/daemonsets","resourceVersion":"6856"},"items":null}

Mar  1 06:43:47.500: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-296/pods","resourceVersion":"6856"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:43:47.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-296" for this suite.
Mar  1 06:43:53.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:43:53.643: INFO: namespace daemonsets-296 deletion completed in 6.127782363s

• [SLOW TEST:27.429 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:43:53.643: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-88b8184a-5a67-4051-a2b9-0e537a9d4ba3
STEP: Creating a pod to test consume secrets
Mar  1 06:43:53.696: INFO: Waiting up to 5m0s for pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8" in namespace "secrets-1911" to be "success or failure"
Mar  1 06:43:53.703: INFO: Pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.145082ms
Mar  1 06:43:55.707: INFO: Pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01163951s
Mar  1 06:43:57.711: INFO: Pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014952389s
Mar  1 06:43:59.714: INFO: Pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018091155s
STEP: Saw pod success
Mar  1 06:43:59.714: INFO: Pod "pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8" satisfied condition "success or failure"
Mar  1 06:43:59.716: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8 container secret-env-test: <nil>
STEP: delete the pod
Mar  1 06:43:59.742: INFO: Waiting for pod pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8 to disappear
Mar  1 06:43:59.745: INFO: Pod pod-secrets-7ed0ca40-0dd1-4423-90bb-d72c74a5c5a8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:43:59.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1911" for this suite.
Mar  1 06:44:05.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:44:05.865: INFO: namespace secrets-1911 deletion completed in 6.113145126s

• [SLOW TEST:12.222 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:44:05.866: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-258/secret-test-4a15b845-1372-4de6-805c-ea19cad65c2c
STEP: Creating a pod to test consume secrets
Mar  1 06:44:05.907: INFO: Waiting up to 5m0s for pod "pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0" in namespace "secrets-258" to be "success or failure"
Mar  1 06:44:05.911: INFO: Pod "pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.523937ms
Mar  1 06:44:07.914: INFO: Pod "pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006913943s
Mar  1 06:44:09.917: INFO: Pod "pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010500247s
STEP: Saw pod success
Mar  1 06:44:09.918: INFO: Pod "pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0" satisfied condition "success or failure"
Mar  1 06:44:09.920: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0 container env-test: <nil>
STEP: delete the pod
Mar  1 06:44:09.950: INFO: Waiting for pod pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0 to disappear
Mar  1 06:44:09.961: INFO: Pod pod-configmaps-992ad9b4-566c-4a38-8386-2570cd9809f0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:44:09.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-258" for this suite.
Mar  1 06:44:15.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:44:16.074: INFO: namespace secrets-258 deletion completed in 6.106878711s

• [SLOW TEST:10.208 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:44:16.075: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8c5q
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 06:44:16.127: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8c5q" in namespace "subpath-8429" to be "success or failure"
Mar  1 06:44:16.130: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Pending", Reason="", readiness=false. Elapsed: 3.560788ms
Mar  1 06:44:18.135: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008165953s
Mar  1 06:44:20.138: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 4.011569565s
Mar  1 06:44:22.143: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 6.016362167s
Mar  1 06:44:24.147: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 8.019823048s
Mar  1 06:44:26.150: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 10.023395496s
Mar  1 06:44:28.154: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 12.026841586s
Mar  1 06:44:30.158: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 14.030661162s
Mar  1 06:44:32.161: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 16.034143774s
Mar  1 06:44:34.164: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 18.037267508s
Mar  1 06:44:36.167: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 20.040567189s
Mar  1 06:44:38.179: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Running", Reason="", readiness=true. Elapsed: 22.052131808s
Mar  1 06:44:40.183: INFO: Pod "pod-subpath-test-configmap-8c5q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056218498s
STEP: Saw pod success
Mar  1 06:44:40.183: INFO: Pod "pod-subpath-test-configmap-8c5q" satisfied condition "success or failure"
Mar  1 06:44:40.185: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-subpath-test-configmap-8c5q container test-container-subpath-configmap-8c5q: <nil>
STEP: delete the pod
Mar  1 06:44:40.205: INFO: Waiting for pod pod-subpath-test-configmap-8c5q to disappear
Mar  1 06:44:40.208: INFO: Pod pod-subpath-test-configmap-8c5q no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8c5q
Mar  1 06:44:40.208: INFO: Deleting pod "pod-subpath-test-configmap-8c5q" in namespace "subpath-8429"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:44:40.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8429" for this suite.
Mar  1 06:44:46.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:44:46.323: INFO: namespace subpath-8429 deletion completed in 6.109797522s

• [SLOW TEST:30.248 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:44:46.323: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-3d3985ac-96fa-442e-99d2-075655e55b4d
STEP: Creating a pod to test consume secrets
Mar  1 06:44:46.369: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690" in namespace "projected-2581" to be "success or failure"
Mar  1 06:44:46.373: INFO: Pod "pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805887ms
Mar  1 06:44:48.376: INFO: Pod "pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006857371s
Mar  1 06:44:50.380: INFO: Pod "pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010328546s
STEP: Saw pod success
Mar  1 06:44:50.380: INFO: Pod "pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690" satisfied condition "success or failure"
Mar  1 06:44:50.382: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 06:44:50.405: INFO: Waiting for pod pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690 to disappear
Mar  1 06:44:50.408: INFO: Pod pod-projected-secrets-07389538-dd70-4824-87ca-30f449db8690 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:44:50.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2581" for this suite.
Mar  1 06:44:56.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:44:56.516: INFO: namespace projected-2581 deletion completed in 6.101627751s

• [SLOW TEST:10.193 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:44:56.516: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar  1 06:44:56.555: INFO: Waiting up to 5m0s for pod "downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26" in namespace "downward-api-3983" to be "success or failure"
Mar  1 06:44:56.559: INFO: Pod "downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26": Phase="Pending", Reason="", readiness=false. Elapsed: 3.537373ms
Mar  1 06:44:58.566: INFO: Pod "downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010757255s
Mar  1 06:45:00.569: INFO: Pod "downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014071172s
STEP: Saw pod success
Mar  1 06:45:00.569: INFO: Pod "downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26" satisfied condition "success or failure"
Mar  1 06:45:00.571: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26 container dapi-container: <nil>
STEP: delete the pod
Mar  1 06:45:00.592: INFO: Waiting for pod downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26 to disappear
Mar  1 06:45:00.597: INFO: Pod downward-api-0b779d30-f8a1-4e06-837a-c89063ce9f26 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:45:00.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3983" for this suite.
Mar  1 06:45:06.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:45:06.701: INFO: namespace downward-api-3983 deletion completed in 6.099065503s

• [SLOW TEST:10.185 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:45:06.704: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 06:45:11.283: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d3bd826d-add2-49e4-8066-e03c03c49b0a"
Mar  1 06:45:11.283: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d3bd826d-add2-49e4-8066-e03c03c49b0a" in namespace "pods-2987" to be "terminated due to deadline exceeded"
Mar  1 06:45:11.286: INFO: Pod "pod-update-activedeadlineseconds-d3bd826d-add2-49e4-8066-e03c03c49b0a": Phase="Running", Reason="", readiness=true. Elapsed: 2.282171ms
Mar  1 06:45:13.289: INFO: Pod "pod-update-activedeadlineseconds-d3bd826d-add2-49e4-8066-e03c03c49b0a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.005209538s
Mar  1 06:45:13.289: INFO: Pod "pod-update-activedeadlineseconds-d3bd826d-add2-49e4-8066-e03c03c49b0a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:45:13.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2987" for this suite.
Mar  1 06:45:19.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:45:19.394: INFO: namespace pods-2987 deletion completed in 6.100263545s

• [SLOW TEST:12.690 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:45:19.395: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-9d0a025b-abcc-4ecc-9a42-0809c46acce0 in namespace container-probe-6033
Mar  1 06:45:23.441: INFO: Started pod test-webserver-9d0a025b-abcc-4ecc-9a42-0809c46acce0 in namespace container-probe-6033
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 06:45:23.443: INFO: Initial restart count of pod test-webserver-9d0a025b-abcc-4ecc-9a42-0809c46acce0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:49:23.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6033" for this suite.
Mar  1 06:49:29.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:49:30.005: INFO: namespace container-probe-6033 deletion completed in 6.124793665s

• [SLOW TEST:250.610 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:49:30.005: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-9c7ec790-b7a8-4edc-83fa-1a549b99632f
STEP: Creating a pod to test consume configMaps
Mar  1 06:49:30.051: INFO: Waiting up to 5m0s for pod "pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199" in namespace "configmap-2862" to be "success or failure"
Mar  1 06:49:30.059: INFO: Pod "pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199": Phase="Pending", Reason="", readiness=false. Elapsed: 8.395382ms
Mar  1 06:49:32.062: INFO: Pod "pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01167883s
Mar  1 06:49:34.067: INFO: Pod "pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015820115s
STEP: Saw pod success
Mar  1 06:49:34.067: INFO: Pod "pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199" satisfied condition "success or failure"
Mar  1 06:49:34.069: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:49:34.093: INFO: Waiting for pod pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199 to disappear
Mar  1 06:49:34.096: INFO: Pod pod-configmaps-c319f7f1-cf51-4294-b416-f596a918f199 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:49:34.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2862" for this suite.
Mar  1 06:49:40.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:49:40.205: INFO: namespace configmap-2862 deletion completed in 6.103800065s

• [SLOW TEST:10.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:49:40.207: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-5179
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5179 to expose endpoints map[]
Mar  1 06:49:40.255: INFO: Get endpoints failed (4.554902ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  1 06:49:41.259: INFO: successfully validated that service endpoint-test2 in namespace services-5179 exposes endpoints map[] (1.008040507s elapsed)
STEP: Creating pod pod1 in namespace services-5179
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5179 to expose endpoints map[pod1:[80]]
Mar  1 06:49:44.305: INFO: successfully validated that service endpoint-test2 in namespace services-5179 exposes endpoints map[pod1:[80]] (3.03632342s elapsed)
STEP: Creating pod pod2 in namespace services-5179
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5179 to expose endpoints map[pod1:[80] pod2:[80]]
Mar  1 06:49:48.359: INFO: successfully validated that service endpoint-test2 in namespace services-5179 exposes endpoints map[pod1:[80] pod2:[80]] (4.049191847s elapsed)
STEP: Deleting pod pod1 in namespace services-5179
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5179 to expose endpoints map[pod2:[80]]
Mar  1 06:49:49.379: INFO: successfully validated that service endpoint-test2 in namespace services-5179 exposes endpoints map[pod2:[80]] (1.015513268s elapsed)
STEP: Deleting pod pod2 in namespace services-5179
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5179 to expose endpoints map[]
Mar  1 06:49:50.389: INFO: successfully validated that service endpoint-test2 in namespace services-5179 exposes endpoints map[] (1.005951174s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:49:50.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5179" for this suite.
Mar  1 06:50:12.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:50:12.542: INFO: namespace services-5179 deletion completed in 22.110248111s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:32.335 seconds]
[sig-network] Services
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:50:12.542: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:50:16.617: INFO: Waiting up to 5m0s for pod "client-envvars-d765e07d-9da0-4478-8236-c6e822406e71" in namespace "pods-7891" to be "success or failure"
Mar  1 06:50:16.622: INFO: Pod "client-envvars-d765e07d-9da0-4478-8236-c6e822406e71": Phase="Pending", Reason="", readiness=false. Elapsed: 5.187128ms
Mar  1 06:50:18.626: INFO: Pod "client-envvars-d765e07d-9da0-4478-8236-c6e822406e71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00921765s
Mar  1 06:50:20.629: INFO: Pod "client-envvars-d765e07d-9da0-4478-8236-c6e822406e71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012380778s
STEP: Saw pod success
Mar  1 06:50:20.629: INFO: Pod "client-envvars-d765e07d-9da0-4478-8236-c6e822406e71" satisfied condition "success or failure"
Mar  1 06:50:20.633: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod client-envvars-d765e07d-9da0-4478-8236-c6e822406e71 container env3cont: <nil>
STEP: delete the pod
Mar  1 06:50:20.658: INFO: Waiting for pod client-envvars-d765e07d-9da0-4478-8236-c6e822406e71 to disappear
Mar  1 06:50:20.661: INFO: Pod client-envvars-d765e07d-9da0-4478-8236-c6e822406e71 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:50:20.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7891" for this suite.
Mar  1 06:50:58.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:50:58.798: INFO: namespace pods-7891 deletion completed in 38.131367841s

• [SLOW TEST:46.256 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:50:58.799: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e98bcc02-fd99-4e25-903e-95699e3f0eab
STEP: Creating a pod to test consume configMaps
Mar  1 06:50:58.835: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232" in namespace "projected-8166" to be "success or failure"
Mar  1 06:50:58.841: INFO: Pod "pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232": Phase="Pending", Reason="", readiness=false. Elapsed: 5.913515ms
Mar  1 06:51:00.845: INFO: Pod "pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009611305s
Mar  1 06:51:02.849: INFO: Pod "pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013411922s
STEP: Saw pod success
Mar  1 06:51:02.849: INFO: Pod "pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232" satisfied condition "success or failure"
Mar  1 06:51:02.852: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:51:02.877: INFO: Waiting for pod pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232 to disappear
Mar  1 06:51:02.880: INFO: Pod pod-projected-configmaps-986a6089-b523-4db5-bd6e-d0fef6f08232 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:51:02.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8166" for this suite.
Mar  1 06:51:08.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:51:09.001: INFO: namespace projected-8166 deletion completed in 6.117025202s

• [SLOW TEST:10.202 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:51:09.003: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:51:09.037: INFO: Creating deployment "test-recreate-deployment"
Mar  1 06:51:09.040: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  1 06:51:09.049: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar  1 06:51:11.055: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  1 06:51:11.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718642269, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718642269, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718642269, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718642269, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 06:51:13.061: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  1 06:51:13.066: INFO: Updating deployment test-recreate-deployment
Mar  1 06:51:13.066: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar  1 06:51:13.141: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8798,SelfLink:/apis/apps/v1/namespaces/deployment-8798/deployments/test-recreate-deployment,UID:107285e9-9470-4ab6-93f3-5d5eb3c5d801,ResourceVersion:8158,Generation:2,CreationTimestamp:2020-03-01 06:51:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-03-01 06:51:13 +0000 UTC 2020-03-01 06:51:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-03-01 06:51:13 +0000 UTC 2020-03-01 06:51:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  1 06:51:13.145: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-8798,SelfLink:/apis/apps/v1/namespaces/deployment-8798/replicasets/test-recreate-deployment-5c8c9cc69d,UID:8e961535-a3cd-432b-b241-6d316518c02c,ResourceVersion:8157,Generation:1,CreationTimestamp:2020-03-01 06:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 107285e9-9470-4ab6-93f3-5d5eb3c5d801 0xc00375c427 0xc00375c428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 06:51:13.145: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  1 06:51:13.145: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-8798,SelfLink:/apis/apps/v1/namespaces/deployment-8798/replicasets/test-recreate-deployment-6df85df6b9,UID:02bc97cd-33d3-4c51-8cfc-97326c34aa35,ResourceVersion:8147,Generation:2,CreationTimestamp:2020-03-01 06:51:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 107285e9-9470-4ab6-93f3-5d5eb3c5d801 0xc00375c4e7 0xc00375c4e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 06:51:13.149: INFO: Pod "test-recreate-deployment-5c8c9cc69d-kl7vz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-kl7vz,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-8798,SelfLink:/api/v1/namespaces/deployment-8798/pods/test-recreate-deployment-5c8c9cc69d-kl7vz,UID:50a65bae-9933-4a79-be3c-a4703af37e5c,ResourceVersion:8159,Generation:0,CreationTimestamp:2020-03-01 06:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 8e961535-a3cd-432b-b241-6d316518c02c 0xc0023864d7 0xc0023864d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pfc6q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pfc6q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pfc6q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-efb81104b7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002386540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002386560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:51:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:51:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:51:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 06:51:13 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.8,PodIP:,StartTime:2020-03-01 06:51:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:51:13.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8798" for this suite.
Mar  1 06:51:19.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:51:19.261: INFO: namespace deployment-8798 deletion completed in 6.106988597s

• [SLOW TEST:10.259 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:51:19.261: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:51:23.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1159" for this suite.
Mar  1 06:52:09.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:52:09.434: INFO: namespace kubelet-test-1159 deletion completed in 46.106026877s

• [SLOW TEST:50.172 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:52:09.435: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar  1 06:52:09.468: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:52:13.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4624" for this suite.
Mar  1 06:52:19.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:52:19.747: INFO: namespace init-container-4624 deletion completed in 6.098589865s

• [SLOW TEST:10.312 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:52:19.748: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 06:52:19.788: INFO: Waiting up to 5m0s for pod "pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c" in namespace "emptydir-2661" to be "success or failure"
Mar  1 06:52:19.796: INFO: Pod "pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.081507ms
Mar  1 06:52:21.802: INFO: Pod "pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01412438s
Mar  1 06:52:23.805: INFO: Pod "pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017575589s
STEP: Saw pod success
Mar  1 06:52:23.805: INFO: Pod "pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c" satisfied condition "success or failure"
Mar  1 06:52:23.808: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c container test-container: <nil>
STEP: delete the pod
Mar  1 06:52:23.831: INFO: Waiting for pod pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c to disappear
Mar  1 06:52:23.839: INFO: Pod pod-a591fbaa-d778-4c74-b7a1-537a5ce5e94c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:52:23.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2661" for this suite.
Mar  1 06:52:29.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:52:29.962: INFO: namespace emptydir-2661 deletion completed in 6.118373353s

• [SLOW TEST:10.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:52:29.962: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-35a7a5c2-f471-4ec0-81d8-25330f86eef0 in namespace container-probe-9022
Mar  1 06:52:34.024: INFO: Started pod busybox-35a7a5c2-f471-4ec0-81d8-25330f86eef0 in namespace container-probe-9022
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 06:52:34.026: INFO: Initial restart count of pod busybox-35a7a5c2-f471-4ec0-81d8-25330f86eef0 is 0
Mar  1 06:53:22.114: INFO: Restart count of pod container-probe-9022/busybox-35a7a5c2-f471-4ec0-81d8-25330f86eef0 is now 1 (48.088039839s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:53:22.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9022" for this suite.
Mar  1 06:53:28.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:53:28.262: INFO: namespace container-probe-9022 deletion completed in 6.1262559s

• [SLOW TEST:58.300 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:53:28.264: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Mar  1 06:53:28.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-9251'
Mar  1 06:53:29.025: INFO: stderr: ""
Mar  1 06:53:29.025: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 06:53:29.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9251'
Mar  1 06:53:29.139: INFO: stderr: ""
Mar  1 06:53:29.139: INFO: stdout: "update-demo-nautilus-f8gd4 update-demo-nautilus-g5swf "
Mar  1 06:53:29.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-f8gd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:29.240: INFO: stderr: ""
Mar  1 06:53:29.240: INFO: stdout: ""
Mar  1 06:53:29.240: INFO: update-demo-nautilus-f8gd4 is created but not running
Mar  1 06:53:34.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9251'
Mar  1 06:53:34.352: INFO: stderr: ""
Mar  1 06:53:34.352: INFO: stdout: "update-demo-nautilus-f8gd4 update-demo-nautilus-g5swf "
Mar  1 06:53:34.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-f8gd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:34.460: INFO: stderr: ""
Mar  1 06:53:34.460: INFO: stdout: "true"
Mar  1 06:53:34.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-f8gd4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:34.561: INFO: stderr: ""
Mar  1 06:53:34.561: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 06:53:34.561: INFO: validating pod update-demo-nautilus-f8gd4
Mar  1 06:53:34.566: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 06:53:34.566: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 06:53:34.566: INFO: update-demo-nautilus-f8gd4 is verified up and running
Mar  1 06:53:34.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-g5swf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:34.681: INFO: stderr: ""
Mar  1 06:53:34.681: INFO: stdout: "true"
Mar  1 06:53:34.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-g5swf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:34.803: INFO: stderr: ""
Mar  1 06:53:34.804: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 06:53:34.804: INFO: validating pod update-demo-nautilus-g5swf
Mar  1 06:53:34.809: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 06:53:34.809: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 06:53:34.809: INFO: update-demo-nautilus-g5swf is verified up and running
STEP: rolling-update to new replication controller
Mar  1 06:53:34.812: INFO: scanned /root for discovery docs: <nil>
Mar  1 06:53:34.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9251'
Mar  1 06:53:57.290: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 06:53:57.290: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 06:53:57.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9251'
Mar  1 06:53:57.395: INFO: stderr: ""
Mar  1 06:53:57.395: INFO: stdout: "update-demo-kitten-5lcd2 update-demo-kitten-x2rqv "
Mar  1 06:53:57.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-kitten-5lcd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:57.491: INFO: stderr: ""
Mar  1 06:53:57.491: INFO: stdout: "true"
Mar  1 06:53:57.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-kitten-5lcd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:57.596: INFO: stderr: ""
Mar  1 06:53:57.596: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 06:53:57.596: INFO: validating pod update-demo-kitten-5lcd2
Mar  1 06:53:57.600: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 06:53:57.600: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 06:53:57.600: INFO: update-demo-kitten-5lcd2 is verified up and running
Mar  1 06:53:57.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-kitten-x2rqv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:57.706: INFO: stderr: ""
Mar  1 06:53:57.706: INFO: stdout: "true"
Mar  1 06:53:57.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-kitten-x2rqv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9251'
Mar  1 06:53:57.814: INFO: stderr: ""
Mar  1 06:53:57.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 06:53:57.814: INFO: validating pod update-demo-kitten-x2rqv
Mar  1 06:53:57.818: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 06:53:57.818: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 06:53:57.818: INFO: update-demo-kitten-x2rqv is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:53:57.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9251" for this suite.
Mar  1 06:54:19.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:54:19.952: INFO: namespace kubectl-9251 deletion completed in 22.129530249s

• [SLOW TEST:51.688 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:54:19.952: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:54:19.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437" in namespace "projected-614" to be "success or failure"
Mar  1 06:54:20.004: INFO: Pod "downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437": Phase="Pending", Reason="", readiness=false. Elapsed: 6.808799ms
Mar  1 06:54:22.009: INFO: Pod "downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011935267s
Mar  1 06:54:24.013: INFO: Pod "downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016060027s
STEP: Saw pod success
Mar  1 06:54:24.013: INFO: Pod "downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437" satisfied condition "success or failure"
Mar  1 06:54:24.016: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437 container client-container: <nil>
STEP: delete the pod
Mar  1 06:54:24.040: INFO: Waiting for pod downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437 to disappear
Mar  1 06:54:24.051: INFO: Pod downwardapi-volume-71dc6551-ab25-4da0-b8df-fd6d9c35c437 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:54:24.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-614" for this suite.
Mar  1 06:54:30.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:54:30.166: INFO: namespace projected-614 deletion completed in 6.109789397s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:54:30.166: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 06:54:30.203: INFO: Waiting up to 5m0s for pod "pod-8943138c-b7d1-4637-8dbb-a8825eef343d" in namespace "emptydir-6162" to be "success or failure"
Mar  1 06:54:30.209: INFO: Pod "pod-8943138c-b7d1-4637-8dbb-a8825eef343d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.752122ms
Mar  1 06:54:32.213: INFO: Pod "pod-8943138c-b7d1-4637-8dbb-a8825eef343d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009064274s
Mar  1 06:54:34.217: INFO: Pod "pod-8943138c-b7d1-4637-8dbb-a8825eef343d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013387911s
STEP: Saw pod success
Mar  1 06:54:34.217: INFO: Pod "pod-8943138c-b7d1-4637-8dbb-a8825eef343d" satisfied condition "success or failure"
Mar  1 06:54:34.220: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-8943138c-b7d1-4637-8dbb-a8825eef343d container test-container: <nil>
STEP: delete the pod
Mar  1 06:54:34.236: INFO: Waiting for pod pod-8943138c-b7d1-4637-8dbb-a8825eef343d to disappear
Mar  1 06:54:34.241: INFO: Pod pod-8943138c-b7d1-4637-8dbb-a8825eef343d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:54:34.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6162" for this suite.
Mar  1 06:54:40.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:54:40.361: INFO: namespace emptydir-6162 deletion completed in 6.115360423s

• [SLOW TEST:10.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:54:40.361: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-fa3d4ee8-2dca-4bd0-b16b-dbac41a740aa
STEP: Creating a pod to test consume configMaps
Mar  1 06:54:40.407: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064" in namespace "configmap-8255" to be "success or failure"
Mar  1 06:54:40.417: INFO: Pod "pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064": Phase="Pending", Reason="", readiness=false. Elapsed: 9.352941ms
Mar  1 06:54:42.421: INFO: Pod "pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014130528s
Mar  1 06:54:44.425: INFO: Pod "pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01754073s
STEP: Saw pod success
Mar  1 06:54:44.425: INFO: Pod "pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064" satisfied condition "success or failure"
Mar  1 06:54:44.427: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 06:54:44.451: INFO: Waiting for pod pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064 to disappear
Mar  1 06:54:44.458: INFO: Pod pod-configmaps-3c2b95be-f1fb-40f8-a238-d05b0d431064 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:54:44.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8255" for this suite.
Mar  1 06:54:50.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:54:50.585: INFO: namespace configmap-8255 deletion completed in 6.121066984s

• [SLOW TEST:10.223 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:54:50.586: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 06:54:50.629: INFO: Waiting up to 5m0s for pod "pod-0b4fbadd-3925-42ef-8c20-52110146a0b3" in namespace "emptydir-3040" to be "success or failure"
Mar  1 06:54:50.643: INFO: Pod "pod-0b4fbadd-3925-42ef-8c20-52110146a0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.903997ms
Mar  1 06:54:52.647: INFO: Pod "pod-0b4fbadd-3925-42ef-8c20-52110146a0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01893412s
Mar  1 06:54:54.653: INFO: Pod "pod-0b4fbadd-3925-42ef-8c20-52110146a0b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024139887s
STEP: Saw pod success
Mar  1 06:54:54.653: INFO: Pod "pod-0b4fbadd-3925-42ef-8c20-52110146a0b3" satisfied condition "success or failure"
Mar  1 06:54:54.655: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-0b4fbadd-3925-42ef-8c20-52110146a0b3 container test-container: <nil>
STEP: delete the pod
Mar  1 06:54:54.678: INFO: Waiting for pod pod-0b4fbadd-3925-42ef-8c20-52110146a0b3 to disappear
Mar  1 06:54:54.680: INFO: Pod pod-0b4fbadd-3925-42ef-8c20-52110146a0b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:54:54.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3040" for this suite.
Mar  1 06:55:00.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:00.796: INFO: namespace emptydir-3040 deletion completed in 6.110775963s

• [SLOW TEST:10.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:00.796: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-81d94833-f8d5-4412-bd15-051283bdd051
STEP: Creating a pod to test consume secrets
Mar  1 06:55:00.846: INFO: Waiting up to 5m0s for pod "pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea" in namespace "secrets-5699" to be "success or failure"
Mar  1 06:55:00.851: INFO: Pod "pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.373466ms
Mar  1 06:55:02.855: INFO: Pod "pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009005115s
Mar  1 06:55:04.858: INFO: Pod "pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012504346s
STEP: Saw pod success
Mar  1 06:55:04.858: INFO: Pod "pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea" satisfied condition "success or failure"
Mar  1 06:55:04.861: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 06:55:04.880: INFO: Waiting for pod pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea to disappear
Mar  1 06:55:04.884: INFO: Pod pod-secrets-3503377b-e2b5-4aaf-ace3-cd3cc57686ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:55:04.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5699" for this suite.
Mar  1 06:55:10.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:10.997: INFO: namespace secrets-5699 deletion completed in 6.106782417s

• [SLOW TEST:10.201 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:10.998: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-430.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-430.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 06:55:23.090: INFO: DNS probes using dns-430/dns-test-fdf6e245-45d7-4e99-beff-764539bb767e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:55:23.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-430" for this suite.
Mar  1 06:55:29.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:29.227: INFO: namespace dns-430 deletion completed in 6.112093494s

• [SLOW TEST:18.230 seconds]
[sig-network] DNS
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:29.228: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 06:55:29.268: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c" in namespace "downward-api-3264" to be "success or failure"
Mar  1 06:55:29.273: INFO: Pod "downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.167145ms
Mar  1 06:55:31.278: INFO: Pod "downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009424316s
Mar  1 06:55:33.281: INFO: Pod "downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012890034s
STEP: Saw pod success
Mar  1 06:55:33.281: INFO: Pod "downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c" satisfied condition "success or failure"
Mar  1 06:55:33.286: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c container client-container: <nil>
STEP: delete the pod
Mar  1 06:55:33.318: INFO: Waiting for pod downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c to disappear
Mar  1 06:55:33.322: INFO: Pod downwardapi-volume-9c0eecb7-ee2a-4dba-9586-d12f1425059c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:55:33.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3264" for this suite.
Mar  1 06:55:39.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:39.433: INFO: namespace downward-api-3264 deletion completed in 6.106867331s

• [SLOW TEST:10.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:39.434: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  1 06:55:45.489: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0301 06:55:45.489260      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 06:55:45.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6834" for this suite.
Mar  1 06:55:51.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:51.587: INFO: namespace gc-6834 deletion completed in 6.093453453s

• [SLOW TEST:12.153 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:51.587: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-77604ab1-0661-4964-aec3-042186a62f38
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:55:51.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2946" for this suite.
Mar  1 06:55:57.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:55:57.723: INFO: namespace configmap-2946 deletion completed in 6.098414205s

• [SLOW TEST:6.136 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:55:57.724: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 06:55:57.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3450'
Mar  1 06:55:57.867: INFO: stderr: ""
Mar  1 06:55:57.867: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Mar  1 06:55:57.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete pods e2e-test-nginx-pod --namespace=kubectl-3450'
Mar  1 06:56:10.146: INFO: stderr: ""
Mar  1 06:56:10.146: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:56:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3450" for this suite.
Mar  1 06:56:16.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:56:16.258: INFO: namespace kubectl-3450 deletion completed in 6.098168783s

• [SLOW TEST:18.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:56:16.258: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7759
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 06:56:16.289: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 06:56:42.367: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.1.44 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7759 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:56:42.367: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:56:43.513: INFO: Found all expected endpoints: [netserver-0]
Mar  1 06:56:43.517: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.2.62 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7759 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:56:43.517: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:56:44.666: INFO: Found all expected endpoints: [netserver-1]
Mar  1 06:56:44.669: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.3.46 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7759 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 06:56:44.669: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 06:56:45.821: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:56:45.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7759" for this suite.
Mar  1 06:57:07.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:57:07.937: INFO: namespace pod-network-test-7759 deletion completed in 22.110795171s

• [SLOW TEST:51.679 seconds]
[sig-network] Networking
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:57:07.938: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3047
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3047
STEP: Deleting pre-stop pod
Mar  1 06:57:23.025: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:57:23.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3047" for this suite.
Mar  1 06:58:01.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:58:01.168: INFO: namespace prestop-3047 deletion completed in 38.12627222s

• [SLOW TEST:53.230 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:58:01.168: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Mar  1 06:58:01.213: INFO: Waiting up to 5m0s for pod "var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d" in namespace "var-expansion-4947" to be "success or failure"
Mar  1 06:58:01.220: INFO: Pod "var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.281273ms
Mar  1 06:58:03.224: INFO: Pod "var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010321548s
Mar  1 06:58:05.228: INFO: Pod "var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014277947s
STEP: Saw pod success
Mar  1 06:58:05.228: INFO: Pod "var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d" satisfied condition "success or failure"
Mar  1 06:58:05.231: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d container dapi-container: <nil>
STEP: delete the pod
Mar  1 06:58:05.255: INFO: Waiting for pod var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d to disappear
Mar  1 06:58:05.257: INFO: Pod var-expansion-90c84fe7-9a2b-47ea-ba93-4b4523af7a8d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:58:05.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4947" for this suite.
Mar  1 06:58:11.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:58:11.367: INFO: namespace var-expansion-4947 deletion completed in 6.102515868s

• [SLOW TEST:10.199 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:58:11.368: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar  1 06:58:11.410: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 06:58:11.419: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 06:58:11.421: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-6fb930ab0d before test
Mar  1 06:58:11.428: INFO: calico-node-8ggds from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.428: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 06:58:11.428: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-zspqz from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 06:58:11.428: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 06:58:11.428: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 06:58:11.428: INFO: metallb-speaker-44ttb from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.428: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 06:58:11.429: INFO: sonobuoy-e2e-job-308a46a6de9c4747 from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 06:58:11.429: INFO: 	Container e2e ready: true, restart count 0
Mar  1 06:58:11.429: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 06:58:11.429: INFO: kube-proxy-bkgxj from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.429: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 06:58:11.429: INFO: nvidia-device-plugin-daemonset-xbjk6 from kube-system started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.429: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 06:58:11.429: INFO: nginx-ingress-controller-8kfvp from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.429: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 06:58:11.429: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-a8be7057d2 before test
Mar  1 06:58:11.437: INFO: kube-proxy-sjww6 from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 06:58:11.437: INFO: nvidia-device-plugin-daemonset-r6b54 from kube-system started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 06:58:11.437: INFO: metallb-controller-96757c68d-dn24g from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container metallb-controller ready: true, restart count 0
Mar  1 06:58:11.437: INFO: ccp-helm-operator-6598fbf77f-ft7kl from ccp started at 2020-03-01 06:17:24 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container ccp-helm-operator ready: true, restart count 0
Mar  1 06:58:11.437: INFO: calico-node-jqnrt from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 06:58:11.437: INFO: nginx-ingress-controller-vnw2g from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 06:58:11.437: INFO: cert-manager-776cdb5c5f-d9zdb from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container cert-manager ready: true, restart count 0
Mar  1 06:58:11.437: INFO: metallb-speaker-rgpsr from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 06:58:11.437: INFO: nginx-ingress-default-backend-754f987b55-tzph2 from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Mar  1 06:58:11.437: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-6klrg from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 06:58:11.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 06:58:11.437: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 06:58:11.437: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-efb81104b7 before test
Mar  1 06:58:11.444: INFO: kube-proxy-v5fqd from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 06:58:11.444: INFO: metallb-speaker-jqpk8 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 06:58:11.444: INFO: nvidia-device-plugin-daemonset-hbrcb from kube-system started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 06:58:11.444: INFO: sonobuoy from sonobuoy started at 2020-03-01 06:25:42 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  1 06:58:11.444: INFO: calico-node-8l2tf from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 06:58:11.444: INFO: nginx-ingress-controller-mdqc5 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 06:58:11.444: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-27jpq from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 06:58:11.444: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 06:58:11.444: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f81bd9f5fd7001], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:58:12.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9314" for this suite.
Mar  1 06:58:18.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:58:18.589: INFO: namespace sched-pred-9314 deletion completed in 6.115294078s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.222 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:58:18.590: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:58:18.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2031" for this suite.
Mar  1 06:58:24.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:58:24.730: INFO: namespace services-2031 deletion completed in 6.09375094s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.140 seconds]
[sig-network] Services
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:58:24.730: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 06:58:28.791: INFO: DNS probes using dns-test-5700abfe-07fd-424e-9904-f3f4bd31a0b3 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 06:58:32.833: INFO: File wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:32.836: INFO: File jessie_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:32.836: INFO: Lookups using dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e failed for: [wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local jessie_udp@dns-test-service-3.dns-984.svc.cluster.local]

Mar  1 06:58:37.840: INFO: File wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:37.844: INFO: File jessie_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:37.844: INFO: Lookups using dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e failed for: [wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local jessie_udp@dns-test-service-3.dns-984.svc.cluster.local]

Mar  1 06:58:42.841: INFO: File wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:42.844: INFO: File jessie_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:42.844: INFO: Lookups using dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e failed for: [wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local jessie_udp@dns-test-service-3.dns-984.svc.cluster.local]

Mar  1 06:58:47.840: INFO: File wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:47.844: INFO: File jessie_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:47.844: INFO: Lookups using dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e failed for: [wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local jessie_udp@dns-test-service-3.dns-984.svc.cluster.local]

Mar  1 06:58:52.840: INFO: File wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:52.844: INFO: File jessie_udp@dns-test-service-3.dns-984.svc.cluster.local from pod  dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  1 06:58:52.844: INFO: Lookups using dns-984/dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e failed for: [wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local jessie_udp@dns-test-service-3.dns-984.svc.cluster.local]

Mar  1 06:58:57.846: INFO: DNS probes using dns-test-fc664b7c-22f7-48a5-93aa-d781c75f312e succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-984.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-984.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 06:59:01.940: INFO: DNS probes using dns-test-84648d86-2f8d-4c48-b665-bcf45ec67f4d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:59:01.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-984" for this suite.
Mar  1 06:59:08.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:59:08.176: INFO: namespace dns-984 deletion completed in 6.166103941s

• [SLOW TEST:43.446 seconds]
[sig-network] DNS
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:59:08.176: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 06:59:08.240: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  1 06:59:08.255: INFO: Number of nodes with available pods: 0
Mar  1 06:59:08.255: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  1 06:59:08.284: INFO: Number of nodes with available pods: 0
Mar  1 06:59:08.284: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:09.286: INFO: Number of nodes with available pods: 0
Mar  1 06:59:09.286: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:10.287: INFO: Number of nodes with available pods: 0
Mar  1 06:59:10.287: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:11.288: INFO: Number of nodes with available pods: 1
Mar  1 06:59:11.288: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  1 06:59:11.304: INFO: Number of nodes with available pods: 1
Mar  1 06:59:11.304: INFO: Number of running nodes: 0, number of available pods: 1
Mar  1 06:59:12.308: INFO: Number of nodes with available pods: 0
Mar  1 06:59:12.308: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  1 06:59:12.321: INFO: Number of nodes with available pods: 0
Mar  1 06:59:12.322: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:13.325: INFO: Number of nodes with available pods: 0
Mar  1 06:59:13.325: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:14.326: INFO: Number of nodes with available pods: 0
Mar  1 06:59:14.326: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:15.326: INFO: Number of nodes with available pods: 0
Mar  1 06:59:15.326: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:16.325: INFO: Number of nodes with available pods: 0
Mar  1 06:59:16.325: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:17.325: INFO: Number of nodes with available pods: 0
Mar  1 06:59:17.325: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:18.325: INFO: Number of nodes with available pods: 0
Mar  1 06:59:18.325: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 06:59:19.325: INFO: Number of nodes with available pods: 1
Mar  1 06:59:19.325: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3319, will wait for the garbage collector to delete the pods
Mar  1 06:59:19.389: INFO: Deleting DaemonSet.extensions daemon-set took: 5.569553ms
Mar  1 06:59:19.789: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.414726ms
Mar  1 06:59:23.292: INFO: Number of nodes with available pods: 0
Mar  1 06:59:23.292: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 06:59:23.294: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3319/daemonsets","resourceVersion":"10214"},"items":null}

Mar  1 06:59:23.296: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3319/pods","resourceVersion":"10214"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 06:59:23.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3319" for this suite.
Mar  1 06:59:29.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 06:59:29.546: INFO: namespace daemonsets-3319 deletion completed in 6.221216757s

• [SLOW TEST:21.371 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 06:59:29.547: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2400
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2400
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2400
Mar  1 06:59:29.602: INFO: Found 0 stateful pods, waiting for 1
Mar  1 06:59:39.605: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  1 06:59:39.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 06:59:39.878: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 06:59:39.878: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 06:59:39.878: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 06:59:39.882: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 06:59:49.887: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 06:59:49.887: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 06:59:49.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999514s
Mar  1 06:59:50.914: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991100975s
Mar  1 06:59:51.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.986485297s
Mar  1 06:59:52.921: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982832622s
Mar  1 06:59:53.925: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979171862s
Mar  1 06:59:54.929: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975114004s
Mar  1 06:59:55.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971239152s
Mar  1 06:59:56.937: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967440964s
Mar  1 06:59:57.941: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.963884701s
Mar  1 06:59:58.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.060102ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2400
Mar  1 06:59:59.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:00:00.202: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:00:00.202: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:00:00.202: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:00:00.205: INFO: Found 1 stateful pods, waiting for 3
Mar  1 07:00:10.209: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:00:10.209: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:00:10.209: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  1 07:00:10.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:00:10.482: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 07:00:10.482: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:00:10.482: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:00:10.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:00:10.785: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 07:00:10.785: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:00:10.785: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:00:10.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:00:11.108: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 07:00:11.108: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:00:11.108: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:00:11.108: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:00:11.111: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  1 07:00:21.117: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:00:21.117: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:00:21.117: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:00:21.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999364s
Mar  1 07:00:22.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994574368s
Mar  1 07:00:23.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990300064s
Mar  1 07:00:24.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985997489s
Mar  1 07:00:25.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982465974s
Mar  1 07:00:26.151: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977614561s
Mar  1 07:00:27.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973512765s
Mar  1 07:00:28.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968759927s
Mar  1 07:00:29.164: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965111203s
Mar  1 07:00:30.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.493555ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2400
Mar  1 07:00:31.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:00:31.422: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:00:31.422: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:00:31.422: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:00:31.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:00:31.670: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:00:31.670: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:00:31.670: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:00:31.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-2400 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:00:31.935: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:00:31.935: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:00:31.935: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:00:31.935: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar  1 07:01:01.949: INFO: Deleting all statefulset in ns statefulset-2400
Mar  1 07:01:01.952: INFO: Scaling statefulset ss to 0
Mar  1 07:01:01.961: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:01:01.964: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:01:01.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2400" for this suite.
Mar  1 07:01:08.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:01:08.111: INFO: namespace statefulset-2400 deletion completed in 6.123357422s

• [SLOW TEST:98.564 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:01:08.112: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 07:01:08.153: INFO: Waiting up to 5m0s for pod "pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04" in namespace "emptydir-2641" to be "success or failure"
Mar  1 07:01:08.157: INFO: Pod "pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04": Phase="Pending", Reason="", readiness=false. Elapsed: 3.634529ms
Mar  1 07:01:10.160: INFO: Pod "pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007176208s
Mar  1 07:01:12.164: INFO: Pod "pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010385623s
STEP: Saw pod success
Mar  1 07:01:12.164: INFO: Pod "pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04" satisfied condition "success or failure"
Mar  1 07:01:12.166: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04 container test-container: <nil>
STEP: delete the pod
Mar  1 07:01:12.190: INFO: Waiting for pod pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04 to disappear
Mar  1 07:01:12.193: INFO: Pod pod-2a99a1e7-8198-4e15-907c-c5ae413cbc04 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:01:12.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2641" for this suite.
Mar  1 07:01:18.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:01:18.370: INFO: namespace emptydir-2641 deletion completed in 6.166798692s

• [SLOW TEST:10.258 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:01:18.370: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-861f8e62-8656-4b45-b6be-3c487dc8e713
STEP: Creating configMap with name cm-test-opt-upd-0a900a24-5c04-4221-9a9c-38369bfa01cb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-861f8e62-8656-4b45-b6be-3c487dc8e713
STEP: Updating configmap cm-test-opt-upd-0a900a24-5c04-4221-9a9c-38369bfa01cb
STEP: Creating configMap with name cm-test-opt-create-34bdc5b8-5f8a-475e-b74d-904a54a5478a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:02:44.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-734" for this suite.
Mar  1 07:03:06.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:07.025: INFO: namespace configmap-734 deletion completed in 22.106957902s

• [SLOW TEST:108.655 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:07.025: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  1 07:03:07.069: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2370,SelfLink:/api/v1/namespaces/watch-2370/configmaps/e2e-watch-test-watch-closed,UID:8c9a11db-8e1e-4c83-831f-d4056f69954c,ResourceVersion:10941,Generation:0,CreationTimestamp:2020-03-01 07:03:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 07:03:07.069: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2370,SelfLink:/api/v1/namespaces/watch-2370/configmaps/e2e-watch-test-watch-closed,UID:8c9a11db-8e1e-4c83-831f-d4056f69954c,ResourceVersion:10942,Generation:0,CreationTimestamp:2020-03-01 07:03:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  1 07:03:07.083: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2370,SelfLink:/api/v1/namespaces/watch-2370/configmaps/e2e-watch-test-watch-closed,UID:8c9a11db-8e1e-4c83-831f-d4056f69954c,ResourceVersion:10943,Generation:0,CreationTimestamp:2020-03-01 07:03:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 07:03:07.084: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2370,SelfLink:/api/v1/namespaces/watch-2370/configmaps/e2e-watch-test-watch-closed,UID:8c9a11db-8e1e-4c83-831f-d4056f69954c,ResourceVersion:10944,Generation:0,CreationTimestamp:2020-03-01 07:03:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:03:07.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2370" for this suite.
Mar  1 07:03:13.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:13.201: INFO: namespace watch-2370 deletion completed in 6.112327601s

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:13.202: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-3e45e1e2-d05b-473e-8e85-d24fb596bdc5
STEP: Creating a pod to test consume secrets
Mar  1 07:03:13.249: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098" in namespace "projected-7274" to be "success or failure"
Mar  1 07:03:13.256: INFO: Pod "pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098": Phase="Pending", Reason="", readiness=false. Elapsed: 6.837528ms
Mar  1 07:03:15.259: INFO: Pod "pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01073766s
Mar  1 07:03:17.264: INFO: Pod "pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01483339s
STEP: Saw pod success
Mar  1 07:03:17.264: INFO: Pod "pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098" satisfied condition "success or failure"
Mar  1 07:03:17.267: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:03:17.288: INFO: Waiting for pod pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098 to disappear
Mar  1 07:03:17.293: INFO: Pod pod-projected-secrets-fd417033-86b4-4c78-815c-20f15d808098 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:03:17.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7274" for this suite.
Mar  1 07:03:23.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:23.405: INFO: namespace projected-7274 deletion completed in 6.106707435s

• [SLOW TEST:10.203 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:23.407: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar  1 07:03:23.439: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 07:03:23.447: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 07:03:23.449: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-6fb930ab0d before test
Mar  1 07:03:23.456: INFO: kube-proxy-bkgxj from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:03:23.456: INFO: nvidia-device-plugin-daemonset-xbjk6 from kube-system started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:03:23.456: INFO: metallb-speaker-44ttb from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:03:23.456: INFO: sonobuoy-e2e-job-308a46a6de9c4747 from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container e2e ready: true, restart count 0
Mar  1 07:03:23.456: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 07:03:23.456: INFO: nginx-ingress-controller-8kfvp from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:03:23.456: INFO: calico-node-8ggds from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:03:23.456: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-zspqz from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 07:03:23.456: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 07:03:23.456: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:03:23.456: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-a8be7057d2 before test
Mar  1 07:03:23.464: INFO: ccp-helm-operator-6598fbf77f-ft7kl from ccp started at 2020-03-01 06:17:24 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container ccp-helm-operator ready: true, restart count 0
Mar  1 07:03:23.464: INFO: calico-node-jqnrt from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:03:23.464: INFO: nginx-ingress-controller-vnw2g from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:03:23.464: INFO: cert-manager-776cdb5c5f-d9zdb from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container cert-manager ready: true, restart count 0
Mar  1 07:03:23.464: INFO: metallb-speaker-rgpsr from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:03:23.464: INFO: nginx-ingress-default-backend-754f987b55-tzph2 from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Mar  1 07:03:23.464: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-6klrg from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 07:03:23.464: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:03:23.464: INFO: kube-proxy-sjww6 from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:03:23.464: INFO: nvidia-device-plugin-daemonset-r6b54 from kube-system started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:03:23.464: INFO: metallb-controller-96757c68d-dn24g from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.464: INFO: 	Container metallb-controller ready: true, restart count 0
Mar  1 07:03:23.464: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-efb81104b7 before test
Mar  1 07:03:23.473: INFO: calico-node-8l2tf from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:03:23.473: INFO: nginx-ingress-controller-mdqc5 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:03:23.473: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-27jpq from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 07:03:23.473: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:03:23.473: INFO: kube-proxy-v5fqd from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:03:23.473: INFO: metallb-speaker-jqpk8 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:03:23.473: INFO: nvidia-device-plugin-daemonset-hbrcb from kube-system started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:03:23.473: INFO: sonobuoy from sonobuoy started at 2020-03-01 06:25:42 +0000 UTC (1 container statuses recorded)
Mar  1 07:03:23.473: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-008c4469-6c2b-4e1a-89f9-165fd7b3d3a0 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-008c4469-6c2b-4e1a-89f9-165fd7b3d3a0 off the node alex-slot1-v3-vsp2-node-group-a8be7057d2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-008c4469-6c2b-4e1a-89f9-165fd7b3d3a0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:03:31.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4945" for this suite.
Mar  1 07:03:41.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:41.710: INFO: namespace sched-pred-4945 deletion completed in 10.137689276s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:18.303 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:41.711: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:03:41.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-142'
Mar  1 07:03:42.320: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 07:03:42.320: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Mar  1 07:03:42.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete jobs e2e-test-nginx-job --namespace=kubectl-142'
Mar  1 07:03:42.443: INFO: stderr: ""
Mar  1 07:03:42.443: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:03:42.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-142" for this suite.
Mar  1 07:03:48.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:48.559: INFO: namespace kubectl-142 deletion completed in 6.108935745s

• [SLOW TEST:6.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:48.560: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-16168154-5628-442b-b8db-8d3ee0c339cb
STEP: Creating a pod to test consume configMaps
Mar  1 07:03:48.615: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae" in namespace "configmap-4337" to be "success or failure"
Mar  1 07:03:48.619: INFO: Pod "pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.372517ms
Mar  1 07:03:50.622: INFO: Pod "pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006386079s
Mar  1 07:03:52.625: INFO: Pod "pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009706591s
STEP: Saw pod success
Mar  1 07:03:52.625: INFO: Pod "pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae" satisfied condition "success or failure"
Mar  1 07:03:52.627: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:03:52.645: INFO: Waiting for pod pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae to disappear
Mar  1 07:03:52.648: INFO: Pod pod-configmaps-4d56fce3-3c4b-4c1b-8589-6d2c156a86ae no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:03:52.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4337" for this suite.
Mar  1 07:03:58.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:03:58.756: INFO: namespace configmap-4337 deletion completed in 6.103714238s

• [SLOW TEST:10.196 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:03:58.756: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar  1 07:04:02.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec pod-sharedvolume-ab8b8284-6cb4-483c-a304-7a2864f5feb1 -c busybox-main-container --namespace=emptydir-7794 -- cat /usr/share/volumeshare/shareddata.txt'
Mar  1 07:04:03.069: INFO: stderr: ""
Mar  1 07:04:03.069: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:04:03.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7794" for this suite.
Mar  1 07:04:09.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:04:09.187: INFO: namespace emptydir-7794 deletion completed in 6.111618039s

• [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:04:09.187: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 07:04:09.248: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:09.250: INFO: Number of nodes with available pods: 0
Mar  1 07:04:09.251: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:10.257: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:10.260: INFO: Number of nodes with available pods: 0
Mar  1 07:04:10.260: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:11.258: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:11.261: INFO: Number of nodes with available pods: 0
Mar  1 07:04:11.261: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:12.257: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:12.260: INFO: Number of nodes with available pods: 3
Mar  1 07:04:12.260: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  1 07:04:12.293: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:12.302: INFO: Number of nodes with available pods: 2
Mar  1 07:04:12.303: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:13.308: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:13.311: INFO: Number of nodes with available pods: 2
Mar  1 07:04:13.311: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:14.309: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:14.313: INFO: Number of nodes with available pods: 2
Mar  1 07:04:14.313: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:15.308: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:15.311: INFO: Number of nodes with available pods: 3
Mar  1 07:04:15.311: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3086, will wait for the garbage collector to delete the pods
Mar  1 07:04:15.376: INFO: Deleting DaemonSet.extensions daemon-set took: 6.976172ms
Mar  1 07:04:15.777: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.352453ms
Mar  1 07:04:27.080: INFO: Number of nodes with available pods: 0
Mar  1 07:04:27.080: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 07:04:27.084: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3086/daemonsets","resourceVersion":"11331"},"items":null}

Mar  1 07:04:27.086: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3086/pods","resourceVersion":"11331"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:04:27.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3086" for this suite.
Mar  1 07:04:33.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:04:33.202: INFO: namespace daemonsets-3086 deletion completed in 6.101488808s

• [SLOW TEST:24.015 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:04:33.204: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:04:33.234: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  1 07:04:33.245: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  1 07:04:38.249: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 07:04:38.250: INFO: Creating deployment "test-rolling-update-deployment"
Mar  1 07:04:38.255: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  1 07:04:38.260: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  1 07:04:40.267: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  1 07:04:40.269: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643078, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643078, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643078, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643078, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:04:42.273: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar  1 07:04:42.282: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5464,SelfLink:/apis/apps/v1/namespaces/deployment-5464/deployments/test-rolling-update-deployment,UID:fc85ec9e-b8fb-49d9-9e53-ce261a96eb84,ResourceVersion:11437,Generation:1,CreationTimestamp:2020-03-01 07:04:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-01 07:04:38 +0000 UTC 2020-03-01 07:04:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-01 07:04:40 +0000 UTC 2020-03-01 07:04:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 07:04:42.285: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-5464,SelfLink:/apis/apps/v1/namespaces/deployment-5464/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:6f292648-fc6b-4551-a51f-c99276f17d8a,ResourceVersion:11426,Generation:1,CreationTimestamp:2020-03-01 07:04:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fc85ec9e-b8fb-49d9-9e53-ce261a96eb84 0xc001f559b7 0xc001f559b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 07:04:42.285: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  1 07:04:42.285: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5464,SelfLink:/apis/apps/v1/namespaces/deployment-5464/replicasets/test-rolling-update-controller,UID:8ccdf04e-8a39-4483-ba85-d9f6b417501e,ResourceVersion:11436,Generation:2,CreationTimestamp:2020-03-01 07:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fc85ec9e-b8fb-49d9-9e53-ce261a96eb84 0xc001f558e7 0xc001f558e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 07:04:42.289: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-5qkfn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-5qkfn,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-5464,SelfLink:/api/v1/namespaces/deployment-5464/pods/test-rolling-update-deployment-79f6b9d75c-5qkfn,UID:22016e28-1ce6-465e-80b1-ef4db2921be8,ResourceVersion:11425,Generation:0,CreationTimestamp:2020-03-01 07:04:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.58/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 6f292648-fc6b-4551-a51f-c99276f17d8a 0xc0029e4777 0xc0029e4778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-k5r6m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-k5r6m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-k5r6m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029e47e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029e4800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:04:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:04:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:04:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:04:38 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:192.168.3.58,StartTime:2020-03-01 07:04:38 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-01 07:04:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e2d9a5dc9cbfa76316c876f873d4e99a4c44b46c9c79a757c832a647596cff0c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:04:42.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5464" for this suite.
Mar  1 07:04:48.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:04:48.399: INFO: namespace deployment-5464 deletion completed in 6.105617308s

• [SLOW TEST:15.196 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:04:48.401: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-2c69c328-0935-4515-9dae-9c1e9baefbe1
STEP: Creating a pod to test consume secrets
Mar  1 07:04:48.450: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff" in namespace "projected-110" to be "success or failure"
Mar  1 07:04:48.453: INFO: Pod "pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739024ms
Mar  1 07:04:50.457: INFO: Pod "pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006753419s
Mar  1 07:04:52.460: INFO: Pod "pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010015209s
STEP: Saw pod success
Mar  1 07:04:52.461: INFO: Pod "pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff" satisfied condition "success or failure"
Mar  1 07:04:52.463: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:04:52.485: INFO: Waiting for pod pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff to disappear
Mar  1 07:04:52.487: INFO: Pod pod-projected-secrets-813119a4-71e3-46fc-9192-846b60da51ff no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:04:52.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-110" for this suite.
Mar  1 07:04:58.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:04:58.613: INFO: namespace projected-110 deletion completed in 6.120165486s

• [SLOW TEST:10.212 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:04:58.614: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:04:58.682: INFO: Create a RollingUpdate DaemonSet
Mar  1 07:04:58.690: INFO: Check that daemon pods launch on every node of the cluster
Mar  1 07:04:58.701: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:58.707: INFO: Number of nodes with available pods: 0
Mar  1 07:04:58.707: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:04:59.713: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:04:59.716: INFO: Number of nodes with available pods: 0
Mar  1 07:04:59.716: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:05:00.713: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:05:00.716: INFO: Number of nodes with available pods: 0
Mar  1 07:05:00.716: INFO: Node alex-slot1-v3-vsp2-node-group-6fb930ab0d is running more than one daemon pod
Mar  1 07:05:01.713: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:05:01.717: INFO: Number of nodes with available pods: 3
Mar  1 07:05:01.718: INFO: Number of running nodes: 3, number of available pods: 3
Mar  1 07:05:01.718: INFO: Update the DaemonSet to trigger a rollout
Mar  1 07:05:01.724: INFO: Updating DaemonSet daemon-set
Mar  1 07:05:07.741: INFO: Roll back the DaemonSet before rollout is complete
Mar  1 07:05:07.747: INFO: Updating DaemonSet daemon-set
Mar  1 07:05:07.747: INFO: Make sure DaemonSet rollback is complete
Mar  1 07:05:07.754: INFO: Wrong image for pod: daemon-set-hzpkn. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar  1 07:05:07.754: INFO: Pod daemon-set-hzpkn is not available
Mar  1 07:05:07.773: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:05:08.778: INFO: Wrong image for pod: daemon-set-hzpkn. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Mar  1 07:05:08.778: INFO: Pod daemon-set-hzpkn is not available
Mar  1 07:05:08.782: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  1 07:05:09.778: INFO: Pod daemon-set-6qjlh is not available
Mar  1 07:05:09.782: INFO: DaemonSet pods can't tolerate node alex-slot1-v3-vsp2-master-gro-455a452f9d with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7683, will wait for the garbage collector to delete the pods
Mar  1 07:05:09.846: INFO: Deleting DaemonSet.extensions daemon-set took: 5.410392ms
Mar  1 07:05:10.247: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.359521ms
Mar  1 07:05:17.150: INFO: Number of nodes with available pods: 0
Mar  1 07:05:17.150: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 07:05:17.154: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7683/daemonsets","resourceVersion":"11656"},"items":null}

Mar  1 07:05:17.159: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7683/pods","resourceVersion":"11656"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:05:17.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7683" for this suite.
Mar  1 07:05:23.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:05:23.283: INFO: namespace daemonsets-7683 deletion completed in 6.100563504s

• [SLOW TEST:24.670 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:05:23.284: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar  1 07:05:27.851: INFO: Successfully updated pod "annotationupdate3675d937-18d4-4d66-bddc-cd94f1488aa4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:05:29.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3502" for this suite.
Mar  1 07:05:51.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:05:52.003: INFO: namespace projected-3502 deletion completed in 22.127323882s

• [SLOW TEST:28.719 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:05:52.003: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-a65a21c9-267e-4512-a8bb-0fd61770bf12
STEP: Creating a pod to test consume configMaps
Mar  1 07:05:52.046: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b" in namespace "projected-5070" to be "success or failure"
Mar  1 07:05:52.048: INFO: Pod "pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.446519ms
Mar  1 07:05:54.052: INFO: Pod "pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006285093s
Mar  1 07:05:56.056: INFO: Pod "pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010187699s
STEP: Saw pod success
Mar  1 07:05:56.056: INFO: Pod "pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b" satisfied condition "success or failure"
Mar  1 07:05:56.058: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:05:56.081: INFO: Waiting for pod pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b to disappear
Mar  1 07:05:56.086: INFO: Pod pod-projected-configmaps-dcc7ee0a-1dbd-4dad-bc11-a2b5f4a75a6b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:05:56.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5070" for this suite.
Mar  1 07:06:02.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:06:02.200: INFO: namespace projected-5070 deletion completed in 6.109980761s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:06:02.202: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar  1 07:06:06.777: INFO: Successfully updated pod "labelsupdate7a947e39-38a5-4567-b162-75d0aab6a4e7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:06:08.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6099" for this suite.
Mar  1 07:06:30.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:06:30.922: INFO: namespace projected-6099 deletion completed in 22.116888256s

• [SLOW TEST:28.720 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:06:30.924: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:06:56.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8559" for this suite.
Mar  1 07:07:02.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:07:02.277: INFO: namespace container-runtime-8559 deletion completed in 6.106883528s

• [SLOW TEST:31.353 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:07:02.277: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 07:07:06.839: INFO: Successfully updated pod "pod-update-2d7ce226-f8b5-4271-ab7f-5d3385202405"
STEP: verifying the updated pod is in kubernetes
Mar  1 07:07:06.846: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:07:06.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8119" for this suite.
Mar  1 07:07:28.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:07:28.982: INFO: namespace pods-8119 deletion completed in 22.131810036s

• [SLOW TEST:26.705 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:07:28.989: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:07:29.021: INFO: Creating ReplicaSet my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736
Mar  1 07:07:29.028: INFO: Pod name my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736: Found 0 pods out of 1
Mar  1 07:07:34.032: INFO: Pod name my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736: Found 1 pods out of 1
Mar  1 07:07:34.032: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736" is running
Mar  1 07:07:34.036: INFO: Pod "my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736-zg6qg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:07:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:07:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:07:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:07:29 +0000 UTC Reason: Message:}])
Mar  1 07:07:34.036: INFO: Trying to dial the pod
Mar  1 07:07:39.049: INFO: Controller my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736: Got expected result from replica 1 [my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736-zg6qg]: "my-hostname-basic-dc2fc1fa-794d-464d-a2c1-f92f69029736-zg6qg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:07:39.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9788" for this suite.
Mar  1 07:07:45.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:07:45.185: INFO: namespace replicaset-9788 deletion completed in 6.130238163s

• [SLOW TEST:16.197 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:07:45.187: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6724, will wait for the garbage collector to delete the pods
Mar  1 07:07:49.288: INFO: Deleting Job.batch foo took: 7.393432ms
Mar  1 07:07:49.388: INFO: Terminating Job.batch foo pods took: 100.217814ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:08:30.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6724" for this suite.
Mar  1 07:08:36.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:08:36.206: INFO: namespace job-6724 deletion completed in 6.106931506s

• [SLOW TEST:51.019 seconds]
[sig-apps] Job
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:08:36.206: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7776
I0301 07:08:36.242580      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7776, replica count: 1
I0301 07:08:37.293864      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 07:08:38.294092      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 07:08:39.294283      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 07:08:39.407: INFO: Created: latency-svc-qsgks
Mar  1 07:08:39.417: INFO: Got endpoints: latency-svc-qsgks [22.977822ms]
Mar  1 07:08:39.434: INFO: Created: latency-svc-gqzkn
Mar  1 07:08:39.438: INFO: Got endpoints: latency-svc-gqzkn [21.154612ms]
Mar  1 07:08:39.448: INFO: Created: latency-svc-c9nq9
Mar  1 07:08:39.451: INFO: Got endpoints: latency-svc-c9nq9 [33.645792ms]
Mar  1 07:08:39.461: INFO: Created: latency-svc-nqkm6
Mar  1 07:08:39.463: INFO: Got endpoints: latency-svc-nqkm6 [44.790999ms]
Mar  1 07:08:39.480: INFO: Created: latency-svc-hts44
Mar  1 07:08:39.484: INFO: Got endpoints: latency-svc-hts44 [66.062893ms]
Mar  1 07:08:39.505: INFO: Created: latency-svc-8j4jz
Mar  1 07:08:39.505: INFO: Got endpoints: latency-svc-8j4jz [87.391762ms]
Mar  1 07:08:39.531: INFO: Created: latency-svc-9ffxq
Mar  1 07:08:39.546: INFO: Got endpoints: latency-svc-9ffxq [127.070739ms]
Mar  1 07:08:39.548: INFO: Created: latency-svc-fxhsj
Mar  1 07:08:39.557: INFO: Got endpoints: latency-svc-fxhsj [139.272845ms]
Mar  1 07:08:39.581: INFO: Created: latency-svc-r952z
Mar  1 07:08:39.581: INFO: Got endpoints: latency-svc-r952z [162.414357ms]
Mar  1 07:08:39.599: INFO: Created: latency-svc-vk9fz
Mar  1 07:08:39.604: INFO: Got endpoints: latency-svc-vk9fz [185.611093ms]
Mar  1 07:08:39.623: INFO: Created: latency-svc-p9hrr
Mar  1 07:08:39.629: INFO: Got endpoints: latency-svc-p9hrr [210.516923ms]
Mar  1 07:08:39.647: INFO: Created: latency-svc-96m29
Mar  1 07:08:39.651: INFO: Got endpoints: latency-svc-96m29 [232.851663ms]
Mar  1 07:08:39.668: INFO: Created: latency-svc-b24xw
Mar  1 07:08:39.673: INFO: Got endpoints: latency-svc-b24xw [254.208729ms]
Mar  1 07:08:39.687: INFO: Created: latency-svc-8g88s
Mar  1 07:08:39.697: INFO: Got endpoints: latency-svc-8g88s [278.03965ms]
Mar  1 07:08:39.707: INFO: Created: latency-svc-rzw52
Mar  1 07:08:39.711: INFO: Got endpoints: latency-svc-rzw52 [292.834415ms]
Mar  1 07:08:39.726: INFO: Created: latency-svc-xhl8d
Mar  1 07:08:39.729: INFO: Got endpoints: latency-svc-xhl8d [310.655183ms]
Mar  1 07:08:39.748: INFO: Created: latency-svc-5qxpq
Mar  1 07:08:39.758: INFO: Got endpoints: latency-svc-5qxpq [319.528318ms]
Mar  1 07:08:39.764: INFO: Created: latency-svc-qjxl9
Mar  1 07:08:39.767: INFO: Got endpoints: latency-svc-qjxl9 [316.214244ms]
Mar  1 07:08:39.786: INFO: Created: latency-svc-275x7
Mar  1 07:08:39.788: INFO: Got endpoints: latency-svc-275x7 [325.037835ms]
Mar  1 07:08:39.799: INFO: Created: latency-svc-sc8c7
Mar  1 07:08:39.803: INFO: Got endpoints: latency-svc-sc8c7 [319.396276ms]
Mar  1 07:08:39.817: INFO: Created: latency-svc-4qlvn
Mar  1 07:08:39.822: INFO: Got endpoints: latency-svc-4qlvn [316.029394ms]
Mar  1 07:08:39.844: INFO: Created: latency-svc-mpbhx
Mar  1 07:08:39.849: INFO: Got endpoints: latency-svc-mpbhx [303.73892ms]
Mar  1 07:08:39.884: INFO: Created: latency-svc-tq2w8
Mar  1 07:08:39.888: INFO: Got endpoints: latency-svc-tq2w8 [330.305828ms]
Mar  1 07:08:39.903: INFO: Created: latency-svc-8wlls
Mar  1 07:08:39.917: INFO: Got endpoints: latency-svc-8wlls [336.183059ms]
Mar  1 07:08:40.014: INFO: Created: latency-svc-gfcgv
Mar  1 07:08:40.023: INFO: Got endpoints: latency-svc-gfcgv [418.674783ms]
Mar  1 07:08:40.040: INFO: Created: latency-svc-kgfl6
Mar  1 07:08:40.055: INFO: Got endpoints: latency-svc-kgfl6 [425.551747ms]
Mar  1 07:08:40.056: INFO: Created: latency-svc-np7q9
Mar  1 07:08:40.057: INFO: Got endpoints: latency-svc-np7q9 [405.499672ms]
Mar  1 07:08:40.077: INFO: Created: latency-svc-w2vpl
Mar  1 07:08:40.083: INFO: Got endpoints: latency-svc-w2vpl [409.765559ms]
Mar  1 07:08:40.098: INFO: Created: latency-svc-2lk2z
Mar  1 07:08:40.101: INFO: Got endpoints: latency-svc-2lk2z [404.414459ms]
Mar  1 07:08:40.132: INFO: Created: latency-svc-grc2k
Mar  1 07:08:40.149: INFO: Got endpoints: latency-svc-grc2k [437.777882ms]
Mar  1 07:08:40.151: INFO: Created: latency-svc-n4xjt
Mar  1 07:08:40.155: INFO: Got endpoints: latency-svc-n4xjt [425.394537ms]
Mar  1 07:08:40.172: INFO: Created: latency-svc-zjwvb
Mar  1 07:08:40.177: INFO: Got endpoints: latency-svc-zjwvb [419.247143ms]
Mar  1 07:08:40.190: INFO: Created: latency-svc-qwgk6
Mar  1 07:08:40.202: INFO: Got endpoints: latency-svc-qwgk6 [434.58428ms]
Mar  1 07:08:40.206: INFO: Created: latency-svc-cgqc7
Mar  1 07:08:40.207: INFO: Got endpoints: latency-svc-cgqc7 [418.881097ms]
Mar  1 07:08:40.225: INFO: Created: latency-svc-hklbl
Mar  1 07:08:40.228: INFO: Got endpoints: latency-svc-hklbl [424.295541ms]
Mar  1 07:08:40.253: INFO: Created: latency-svc-sdflh
Mar  1 07:08:40.257: INFO: Got endpoints: latency-svc-sdflh [435.657573ms]
Mar  1 07:08:40.269: INFO: Created: latency-svc-l4fnz
Mar  1 07:08:40.274: INFO: Got endpoints: latency-svc-l4fnz [424.355452ms]
Mar  1 07:08:40.293: INFO: Created: latency-svc-g4mk5
Mar  1 07:08:40.299: INFO: Got endpoints: latency-svc-g4mk5 [410.972544ms]
Mar  1 07:08:40.307: INFO: Created: latency-svc-6g7cb
Mar  1 07:08:40.314: INFO: Got endpoints: latency-svc-6g7cb [396.223086ms]
Mar  1 07:08:40.333: INFO: Created: latency-svc-xx9tr
Mar  1 07:08:40.336: INFO: Got endpoints: latency-svc-xx9tr [313.020901ms]
Mar  1 07:08:40.367: INFO: Created: latency-svc-t6dwg
Mar  1 07:08:40.374: INFO: Got endpoints: latency-svc-t6dwg [318.958107ms]
Mar  1 07:08:40.384: INFO: Created: latency-svc-lqz5t
Mar  1 07:08:40.390: INFO: Got endpoints: latency-svc-lqz5t [332.015833ms]
Mar  1 07:08:40.403: INFO: Created: latency-svc-vb2ps
Mar  1 07:08:40.412: INFO: Got endpoints: latency-svc-vb2ps [37.728783ms]
Mar  1 07:08:40.428: INFO: Created: latency-svc-gbncf
Mar  1 07:08:40.438: INFO: Got endpoints: latency-svc-gbncf [355.532477ms]
Mar  1 07:08:40.452: INFO: Created: latency-svc-2bws7
Mar  1 07:08:40.459: INFO: Got endpoints: latency-svc-2bws7 [357.372834ms]
Mar  1 07:08:40.468: INFO: Created: latency-svc-ch28j
Mar  1 07:08:40.489: INFO: Got endpoints: latency-svc-ch28j [339.668269ms]
Mar  1 07:08:40.498: INFO: Created: latency-svc-6vh79
Mar  1 07:08:40.507: INFO: Got endpoints: latency-svc-6vh79 [352.217313ms]
Mar  1 07:08:40.525: INFO: Created: latency-svc-nn67t
Mar  1 07:08:40.525: INFO: Got endpoints: latency-svc-nn67t [347.878997ms]
Mar  1 07:08:40.540: INFO: Created: latency-svc-zvr27
Mar  1 07:08:40.545: INFO: Got endpoints: latency-svc-zvr27 [342.682007ms]
Mar  1 07:08:40.558: INFO: Created: latency-svc-t5fzs
Mar  1 07:08:40.563: INFO: Got endpoints: latency-svc-t5fzs [356.546481ms]
Mar  1 07:08:40.585: INFO: Created: latency-svc-r7x8k
Mar  1 07:08:40.619: INFO: Got endpoints: latency-svc-r7x8k [390.49069ms]
Mar  1 07:08:40.620: INFO: Created: latency-svc-v2tfh
Mar  1 07:08:40.625: INFO: Got endpoints: latency-svc-v2tfh [368.119792ms]
Mar  1 07:08:40.644: INFO: Created: latency-svc-psqbv
Mar  1 07:08:40.645: INFO: Got endpoints: latency-svc-psqbv [371.629311ms]
Mar  1 07:08:40.666: INFO: Created: latency-svc-5s68g
Mar  1 07:08:40.675: INFO: Got endpoints: latency-svc-5s68g [375.836538ms]
Mar  1 07:08:40.695: INFO: Created: latency-svc-5925j
Mar  1 07:08:40.697: INFO: Got endpoints: latency-svc-5925j [383.024315ms]
Mar  1 07:08:40.738: INFO: Created: latency-svc-b8xsb
Mar  1 07:08:40.741: INFO: Got endpoints: latency-svc-b8xsb [405.157052ms]
Mar  1 07:08:40.765: INFO: Created: latency-svc-8bmwh
Mar  1 07:08:40.773: INFO: Got endpoints: latency-svc-8bmwh [383.326532ms]
Mar  1 07:08:40.783: INFO: Created: latency-svc-5f6kl
Mar  1 07:08:40.813: INFO: Created: latency-svc-4sdhm
Mar  1 07:08:40.818: INFO: Got endpoints: latency-svc-5f6kl [406.131321ms]
Mar  1 07:08:40.843: INFO: Created: latency-svc-5mhgp
Mar  1 07:08:40.871: INFO: Got endpoints: latency-svc-4sdhm [432.280285ms]
Mar  1 07:08:40.873: INFO: Created: latency-svc-r7hgr
Mar  1 07:08:40.891: INFO: Created: latency-svc-jnkqc
Mar  1 07:08:40.907: INFO: Created: latency-svc-4dxwq
Mar  1 07:08:40.912: INFO: Got endpoints: latency-svc-5mhgp [453.821676ms]
Mar  1 07:08:40.928: INFO: Created: latency-svc-6l9wk
Mar  1 07:08:40.939: INFO: Created: latency-svc-mrj6h
Mar  1 07:08:40.968: INFO: Got endpoints: latency-svc-r7hgr [478.906008ms]
Mar  1 07:08:40.970: INFO: Created: latency-svc-9799g
Mar  1 07:08:40.982: INFO: Created: latency-svc-fq7ll
Mar  1 07:08:41.001: INFO: Created: latency-svc-9qw4f
Mar  1 07:08:41.016: INFO: Got endpoints: latency-svc-jnkqc [508.553103ms]
Mar  1 07:08:41.020: INFO: Created: latency-svc-qptfn
Mar  1 07:08:41.046: INFO: Created: latency-svc-s4jf6
Mar  1 07:08:41.074: INFO: Got endpoints: latency-svc-4dxwq [549.025928ms]
Mar  1 07:08:41.075: INFO: Created: latency-svc-6m872
Mar  1 07:08:41.093: INFO: Created: latency-svc-dr7bl
Mar  1 07:08:41.111: INFO: Created: latency-svc-sxw5x
Mar  1 07:08:41.112: INFO: Got endpoints: latency-svc-6l9wk [566.750414ms]
Mar  1 07:08:41.125: INFO: Created: latency-svc-hstpp
Mar  1 07:08:41.147: INFO: Created: latency-svc-86wwf
Mar  1 07:08:41.165: INFO: Created: latency-svc-bmrq2
Mar  1 07:08:41.166: INFO: Got endpoints: latency-svc-mrj6h [602.429133ms]
Mar  1 07:08:41.192: INFO: Created: latency-svc-kxtjw
Mar  1 07:08:41.207: INFO: Created: latency-svc-mfn5l
Mar  1 07:08:41.220: INFO: Got endpoints: latency-svc-9799g [601.738608ms]
Mar  1 07:08:41.222: INFO: Created: latency-svc-fhbq7
Mar  1 07:08:41.250: INFO: Created: latency-svc-ws9fg
Mar  1 07:08:41.272: INFO: Got endpoints: latency-svc-fq7ll [646.60479ms]
Mar  1 07:08:41.276: INFO: Created: latency-svc-gvkhb
Mar  1 07:08:41.312: INFO: Created: latency-svc-jrdct
Mar  1 07:08:41.315: INFO: Got endpoints: latency-svc-9qw4f [669.462644ms]
Mar  1 07:08:41.339: INFO: Created: latency-svc-ljmc2
Mar  1 07:08:41.363: INFO: Got endpoints: latency-svc-qptfn [687.610982ms]
Mar  1 07:08:41.389: INFO: Created: latency-svc-lk5kg
Mar  1 07:08:41.420: INFO: Got endpoints: latency-svc-s4jf6 [723.280686ms]
Mar  1 07:08:41.442: INFO: Created: latency-svc-mzfln
Mar  1 07:08:41.462: INFO: Got endpoints: latency-svc-6m872 [720.11465ms]
Mar  1 07:08:41.483: INFO: Created: latency-svc-gmrs9
Mar  1 07:08:41.512: INFO: Got endpoints: latency-svc-dr7bl [738.149884ms]
Mar  1 07:08:41.540: INFO: Created: latency-svc-9p4dn
Mar  1 07:08:41.563: INFO: Got endpoints: latency-svc-sxw5x [744.89367ms]
Mar  1 07:08:41.598: INFO: Created: latency-svc-458pq
Mar  1 07:08:41.612: INFO: Got endpoints: latency-svc-hstpp [741.559147ms]
Mar  1 07:08:41.652: INFO: Created: latency-svc-dvl8l
Mar  1 07:08:41.664: INFO: Got endpoints: latency-svc-86wwf [752.014ms]
Mar  1 07:08:41.692: INFO: Created: latency-svc-x8vxz
Mar  1 07:08:41.713: INFO: Got endpoints: latency-svc-bmrq2 [744.471371ms]
Mar  1 07:08:41.738: INFO: Created: latency-svc-mvmh5
Mar  1 07:08:41.762: INFO: Got endpoints: latency-svc-kxtjw [746.068206ms]
Mar  1 07:08:41.797: INFO: Created: latency-svc-vmlzf
Mar  1 07:08:41.812: INFO: Got endpoints: latency-svc-mfn5l [735.715743ms]
Mar  1 07:08:41.830: INFO: Created: latency-svc-qfcqd
Mar  1 07:08:41.873: INFO: Got endpoints: latency-svc-fhbq7 [760.913623ms]
Mar  1 07:08:41.900: INFO: Created: latency-svc-4c7sz
Mar  1 07:08:41.913: INFO: Got endpoints: latency-svc-ws9fg [746.827655ms]
Mar  1 07:08:41.947: INFO: Created: latency-svc-vjzcr
Mar  1 07:08:41.974: INFO: Got endpoints: latency-svc-gvkhb [753.158508ms]
Mar  1 07:08:42.015: INFO: Got endpoints: latency-svc-jrdct [743.257174ms]
Mar  1 07:08:42.018: INFO: Created: latency-svc-s7qh4
Mar  1 07:08:42.039: INFO: Created: latency-svc-bhltz
Mar  1 07:08:42.063: INFO: Got endpoints: latency-svc-ljmc2 [747.810339ms]
Mar  1 07:08:42.108: INFO: Created: latency-svc-4q27t
Mar  1 07:08:42.111: INFO: Got endpoints: latency-svc-lk5kg [748.201125ms]
Mar  1 07:08:42.137: INFO: Created: latency-svc-bqk28
Mar  1 07:08:42.162: INFO: Got endpoints: latency-svc-mzfln [741.104859ms]
Mar  1 07:08:42.199: INFO: Created: latency-svc-lt76q
Mar  1 07:08:42.215: INFO: Got endpoints: latency-svc-gmrs9 [753.016445ms]
Mar  1 07:08:42.243: INFO: Created: latency-svc-kddmz
Mar  1 07:08:42.268: INFO: Got endpoints: latency-svc-9p4dn [756.47565ms]
Mar  1 07:08:42.287: INFO: Created: latency-svc-d5vxh
Mar  1 07:08:42.327: INFO: Got endpoints: latency-svc-458pq [763.950112ms]
Mar  1 07:08:42.350: INFO: Created: latency-svc-vv5hm
Mar  1 07:08:42.363: INFO: Got endpoints: latency-svc-dvl8l [750.809098ms]
Mar  1 07:08:42.387: INFO: Created: latency-svc-zs5l8
Mar  1 07:08:42.413: INFO: Got endpoints: latency-svc-x8vxz [748.156614ms]
Mar  1 07:08:42.446: INFO: Created: latency-svc-6mj5w
Mar  1 07:08:42.463: INFO: Got endpoints: latency-svc-mvmh5 [750.49113ms]
Mar  1 07:08:42.491: INFO: Created: latency-svc-gzs8f
Mar  1 07:08:42.512: INFO: Got endpoints: latency-svc-vmlzf [750.232661ms]
Mar  1 07:08:42.533: INFO: Created: latency-svc-vt9rn
Mar  1 07:08:42.568: INFO: Got endpoints: latency-svc-qfcqd [755.667838ms]
Mar  1 07:08:42.597: INFO: Created: latency-svc-sptjm
Mar  1 07:08:42.612: INFO: Got endpoints: latency-svc-4c7sz [739.064554ms]
Mar  1 07:08:42.696: INFO: Got endpoints: latency-svc-vjzcr [783.202057ms]
Mar  1 07:08:42.723: INFO: Created: latency-svc-6kk94
Mar  1 07:08:42.740: INFO: Got endpoints: latency-svc-s7qh4 [766.76361ms]
Mar  1 07:08:42.750: INFO: Created: latency-svc-h829t
Mar  1 07:08:42.768: INFO: Got endpoints: latency-svc-bhltz [752.723102ms]
Mar  1 07:08:42.783: INFO: Created: latency-svc-75jgh
Mar  1 07:08:42.813: INFO: Got endpoints: latency-svc-4q27t [749.803854ms]
Mar  1 07:08:42.814: INFO: Created: latency-svc-j9dbt
Mar  1 07:08:42.841: INFO: Created: latency-svc-bx8ww
Mar  1 07:08:42.863: INFO: Got endpoints: latency-svc-bqk28 [751.62658ms]
Mar  1 07:08:42.887: INFO: Created: latency-svc-6tf9h
Mar  1 07:08:42.923: INFO: Got endpoints: latency-svc-lt76q [761.192449ms]
Mar  1 07:08:42.945: INFO: Created: latency-svc-bnjnp
Mar  1 07:08:42.964: INFO: Got endpoints: latency-svc-kddmz [748.648624ms]
Mar  1 07:08:42.991: INFO: Created: latency-svc-7cl8m
Mar  1 07:08:43.012: INFO: Got endpoints: latency-svc-d5vxh [744.062254ms]
Mar  1 07:08:43.038: INFO: Created: latency-svc-86w5x
Mar  1 07:08:43.062: INFO: Got endpoints: latency-svc-vv5hm [734.636032ms]
Mar  1 07:08:43.081: INFO: Created: latency-svc-qqcws
Mar  1 07:08:43.113: INFO: Got endpoints: latency-svc-zs5l8 [749.965702ms]
Mar  1 07:08:43.132: INFO: Created: latency-svc-992zz
Mar  1 07:08:43.166: INFO: Got endpoints: latency-svc-6mj5w [753.613607ms]
Mar  1 07:08:43.184: INFO: Created: latency-svc-wr9qs
Mar  1 07:08:43.218: INFO: Got endpoints: latency-svc-gzs8f [754.195848ms]
Mar  1 07:08:43.240: INFO: Created: latency-svc-xnxhm
Mar  1 07:08:43.262: INFO: Got endpoints: latency-svc-vt9rn [749.15699ms]
Mar  1 07:08:43.283: INFO: Created: latency-svc-qwdmn
Mar  1 07:08:43.312: INFO: Got endpoints: latency-svc-sptjm [744.049898ms]
Mar  1 07:08:43.340: INFO: Created: latency-svc-d9v9s
Mar  1 07:08:43.382: INFO: Got endpoints: latency-svc-6kk94 [769.015301ms]
Mar  1 07:08:43.403: INFO: Created: latency-svc-rbhf5
Mar  1 07:08:43.412: INFO: Got endpoints: latency-svc-h829t [715.689666ms]
Mar  1 07:08:43.435: INFO: Created: latency-svc-8pgth
Mar  1 07:08:43.465: INFO: Got endpoints: latency-svc-75jgh [724.68439ms]
Mar  1 07:08:43.495: INFO: Created: latency-svc-m6lnx
Mar  1 07:08:43.512: INFO: Got endpoints: latency-svc-j9dbt [743.874581ms]
Mar  1 07:08:43.530: INFO: Created: latency-svc-rfbdf
Mar  1 07:08:43.562: INFO: Got endpoints: latency-svc-bx8ww [749.223508ms]
Mar  1 07:08:43.589: INFO: Created: latency-svc-ztfth
Mar  1 07:08:43.612: INFO: Got endpoints: latency-svc-6tf9h [748.572041ms]
Mar  1 07:08:43.629: INFO: Created: latency-svc-rpw4l
Mar  1 07:08:43.665: INFO: Got endpoints: latency-svc-bnjnp [742.101786ms]
Mar  1 07:08:43.688: INFO: Created: latency-svc-pctrs
Mar  1 07:08:43.724: INFO: Got endpoints: latency-svc-7cl8m [760.60421ms]
Mar  1 07:08:43.746: INFO: Created: latency-svc-4fqjw
Mar  1 07:08:43.762: INFO: Got endpoints: latency-svc-86w5x [748.848231ms]
Mar  1 07:08:43.783: INFO: Created: latency-svc-xxqjh
Mar  1 07:08:43.814: INFO: Got endpoints: latency-svc-qqcws [751.973352ms]
Mar  1 07:08:43.842: INFO: Created: latency-svc-79jmx
Mar  1 07:08:43.863: INFO: Got endpoints: latency-svc-992zz [749.150865ms]
Mar  1 07:08:43.883: INFO: Created: latency-svc-p8n6k
Mar  1 07:08:43.925: INFO: Got endpoints: latency-svc-wr9qs [758.03512ms]
Mar  1 07:08:43.954: INFO: Created: latency-svc-kfjpn
Mar  1 07:08:43.964: INFO: Got endpoints: latency-svc-xnxhm [746.375013ms]
Mar  1 07:08:43.995: INFO: Created: latency-svc-n7hlc
Mar  1 07:08:44.013: INFO: Got endpoints: latency-svc-qwdmn [750.902401ms]
Mar  1 07:08:44.035: INFO: Created: latency-svc-dvhbd
Mar  1 07:08:44.063: INFO: Got endpoints: latency-svc-d9v9s [750.653104ms]
Mar  1 07:08:44.085: INFO: Created: latency-svc-8j5tv
Mar  1 07:08:44.113: INFO: Got endpoints: latency-svc-rbhf5 [731.308939ms]
Mar  1 07:08:44.141: INFO: Created: latency-svc-gzkcb
Mar  1 07:08:44.173: INFO: Got endpoints: latency-svc-8pgth [761.475956ms]
Mar  1 07:08:44.195: INFO: Created: latency-svc-vnrsh
Mar  1 07:08:44.215: INFO: Got endpoints: latency-svc-m6lnx [749.71013ms]
Mar  1 07:08:44.242: INFO: Created: latency-svc-brvqm
Mar  1 07:08:44.265: INFO: Got endpoints: latency-svc-rfbdf [752.376497ms]
Mar  1 07:08:44.331: INFO: Got endpoints: latency-svc-ztfth [768.803301ms]
Mar  1 07:08:44.339: INFO: Created: latency-svc-r6ft6
Mar  1 07:08:44.375: INFO: Created: latency-svc-ddf7z
Mar  1 07:08:44.380: INFO: Got endpoints: latency-svc-rpw4l [768.678623ms]
Mar  1 07:08:44.416: INFO: Got endpoints: latency-svc-pctrs [750.592581ms]
Mar  1 07:08:44.420: INFO: Created: latency-svc-ftqt6
Mar  1 07:08:44.442: INFO: Created: latency-svc-prkrx
Mar  1 07:08:44.463: INFO: Got endpoints: latency-svc-4fqjw [738.279602ms]
Mar  1 07:08:44.485: INFO: Created: latency-svc-brnl9
Mar  1 07:08:44.527: INFO: Got endpoints: latency-svc-xxqjh [765.658852ms]
Mar  1 07:08:44.544: INFO: Created: latency-svc-6g85d
Mar  1 07:08:44.562: INFO: Got endpoints: latency-svc-79jmx [748.624193ms]
Mar  1 07:08:44.583: INFO: Created: latency-svc-b7mj6
Mar  1 07:08:44.612: INFO: Got endpoints: latency-svc-p8n6k [749.770328ms]
Mar  1 07:08:44.643: INFO: Created: latency-svc-4ckq9
Mar  1 07:08:44.662: INFO: Got endpoints: latency-svc-kfjpn [737.216783ms]
Mar  1 07:08:44.687: INFO: Created: latency-svc-rv2nq
Mar  1 07:08:44.713: INFO: Got endpoints: latency-svc-n7hlc [748.412394ms]
Mar  1 07:08:44.735: INFO: Created: latency-svc-7c59x
Mar  1 07:08:44.763: INFO: Got endpoints: latency-svc-dvhbd [749.723023ms]
Mar  1 07:08:44.790: INFO: Created: latency-svc-f9c2q
Mar  1 07:08:44.812: INFO: Got endpoints: latency-svc-8j5tv [749.461448ms]
Mar  1 07:08:44.829: INFO: Created: latency-svc-jkhtj
Mar  1 07:08:44.873: INFO: Got endpoints: latency-svc-gzkcb [759.566379ms]
Mar  1 07:08:44.896: INFO: Created: latency-svc-mp9j7
Mar  1 07:08:44.911: INFO: Got endpoints: latency-svc-vnrsh [738.179466ms]
Mar  1 07:08:44.941: INFO: Created: latency-svc-xv9h2
Mar  1 07:08:44.963: INFO: Got endpoints: latency-svc-brvqm [748.379831ms]
Mar  1 07:08:44.989: INFO: Created: latency-svc-gtlbl
Mar  1 07:08:45.015: INFO: Got endpoints: latency-svc-r6ft6 [750.243305ms]
Mar  1 07:08:45.038: INFO: Created: latency-svc-khqh6
Mar  1 07:08:45.070: INFO: Got endpoints: latency-svc-ddf7z [738.839065ms]
Mar  1 07:08:45.105: INFO: Created: latency-svc-99fd6
Mar  1 07:08:45.113: INFO: Got endpoints: latency-svc-ftqt6 [732.448481ms]
Mar  1 07:08:45.132: INFO: Created: latency-svc-tpxn6
Mar  1 07:08:45.163: INFO: Got endpoints: latency-svc-prkrx [746.834575ms]
Mar  1 07:08:45.182: INFO: Created: latency-svc-f89tr
Mar  1 07:08:45.226: INFO: Got endpoints: latency-svc-brnl9 [763.576023ms]
Mar  1 07:08:45.251: INFO: Created: latency-svc-vd55g
Mar  1 07:08:45.266: INFO: Got endpoints: latency-svc-6g85d [738.882978ms]
Mar  1 07:08:45.311: INFO: Created: latency-svc-bd5sh
Mar  1 07:08:45.314: INFO: Got endpoints: latency-svc-b7mj6 [751.63356ms]
Mar  1 07:08:45.357: INFO: Created: latency-svc-c2sfx
Mar  1 07:08:45.361: INFO: Got endpoints: latency-svc-4ckq9 [748.459744ms]
Mar  1 07:08:45.387: INFO: Created: latency-svc-pwk27
Mar  1 07:08:45.414: INFO: Got endpoints: latency-svc-rv2nq [751.933114ms]
Mar  1 07:08:45.440: INFO: Created: latency-svc-wqk74
Mar  1 07:08:45.466: INFO: Got endpoints: latency-svc-7c59x [753.384227ms]
Mar  1 07:08:45.496: INFO: Created: latency-svc-2v45w
Mar  1 07:08:45.512: INFO: Got endpoints: latency-svc-f9c2q [749.217992ms]
Mar  1 07:08:45.535: INFO: Created: latency-svc-89zv6
Mar  1 07:08:45.571: INFO: Got endpoints: latency-svc-jkhtj [758.873088ms]
Mar  1 07:08:45.592: INFO: Created: latency-svc-w2czf
Mar  1 07:08:45.612: INFO: Got endpoints: latency-svc-mp9j7 [739.141204ms]
Mar  1 07:08:45.633: INFO: Created: latency-svc-skv7f
Mar  1 07:08:45.662: INFO: Got endpoints: latency-svc-xv9h2 [750.193346ms]
Mar  1 07:08:45.691: INFO: Created: latency-svc-tgvgl
Mar  1 07:08:45.713: INFO: Got endpoints: latency-svc-gtlbl [749.171618ms]
Mar  1 07:08:45.737: INFO: Created: latency-svc-7krnx
Mar  1 07:08:45.768: INFO: Got endpoints: latency-svc-khqh6 [753.172554ms]
Mar  1 07:08:45.815: INFO: Created: latency-svc-7mbbw
Mar  1 07:08:45.820: INFO: Got endpoints: latency-svc-99fd6 [750.246555ms]
Mar  1 07:08:45.848: INFO: Created: latency-svc-krc28
Mar  1 07:08:45.863: INFO: Got endpoints: latency-svc-tpxn6 [750.258552ms]
Mar  1 07:08:45.884: INFO: Created: latency-svc-4tcfn
Mar  1 07:08:45.917: INFO: Got endpoints: latency-svc-f89tr [754.623137ms]
Mar  1 07:08:45.940: INFO: Created: latency-svc-p6jfg
Mar  1 07:08:45.962: INFO: Got endpoints: latency-svc-vd55g [735.70024ms]
Mar  1 07:08:45.984: INFO: Created: latency-svc-xjp7b
Mar  1 07:08:46.014: INFO: Got endpoints: latency-svc-bd5sh [746.56657ms]
Mar  1 07:08:46.057: INFO: Created: latency-svc-8zpv6
Mar  1 07:08:46.065: INFO: Got endpoints: latency-svc-c2sfx [750.79293ms]
Mar  1 07:08:46.094: INFO: Created: latency-svc-tkslr
Mar  1 07:08:46.113: INFO: Got endpoints: latency-svc-pwk27 [751.667781ms]
Mar  1 07:08:46.134: INFO: Created: latency-svc-9n64b
Mar  1 07:08:46.163: INFO: Got endpoints: latency-svc-wqk74 [748.999827ms]
Mar  1 07:08:46.193: INFO: Created: latency-svc-glgd4
Mar  1 07:08:46.213: INFO: Got endpoints: latency-svc-2v45w [747.150581ms]
Mar  1 07:08:46.235: INFO: Created: latency-svc-ws9xd
Mar  1 07:08:46.262: INFO: Got endpoints: latency-svc-89zv6 [750.43484ms]
Mar  1 07:08:46.292: INFO: Created: latency-svc-bxzbf
Mar  1 07:08:46.311: INFO: Got endpoints: latency-svc-w2czf [739.352152ms]
Mar  1 07:08:46.327: INFO: Created: latency-svc-frwzz
Mar  1 07:08:46.364: INFO: Got endpoints: latency-svc-skv7f [751.994446ms]
Mar  1 07:08:46.404: INFO: Created: latency-svc-pctm6
Mar  1 07:08:46.418: INFO: Got endpoints: latency-svc-tgvgl [756.19007ms]
Mar  1 07:08:46.446: INFO: Created: latency-svc-992t6
Mar  1 07:08:46.465: INFO: Got endpoints: latency-svc-7krnx [752.585063ms]
Mar  1 07:08:46.499: INFO: Created: latency-svc-fnmxv
Mar  1 07:08:46.513: INFO: Got endpoints: latency-svc-7mbbw [744.877791ms]
Mar  1 07:08:46.533: INFO: Created: latency-svc-t96s6
Mar  1 07:08:46.566: INFO: Got endpoints: latency-svc-krc28 [745.332385ms]
Mar  1 07:08:46.588: INFO: Created: latency-svc-s68vb
Mar  1 07:08:46.612: INFO: Got endpoints: latency-svc-4tcfn [748.405489ms]
Mar  1 07:08:46.634: INFO: Created: latency-svc-wr4kw
Mar  1 07:08:46.663: INFO: Got endpoints: latency-svc-p6jfg [745.176167ms]
Mar  1 07:08:46.683: INFO: Created: latency-svc-nmt44
Mar  1 07:08:46.723: INFO: Got endpoints: latency-svc-xjp7b [759.921864ms]
Mar  1 07:08:46.746: INFO: Created: latency-svc-qcc8b
Mar  1 07:08:46.762: INFO: Got endpoints: latency-svc-8zpv6 [747.414653ms]
Mar  1 07:08:46.804: INFO: Created: latency-svc-s7qfn
Mar  1 07:08:46.819: INFO: Got endpoints: latency-svc-tkslr [753.290324ms]
Mar  1 07:08:46.852: INFO: Created: latency-svc-ghjkg
Mar  1 07:08:46.867: INFO: Got endpoints: latency-svc-9n64b [753.405605ms]
Mar  1 07:08:46.893: INFO: Created: latency-svc-89x7x
Mar  1 07:08:46.914: INFO: Got endpoints: latency-svc-glgd4 [751.015764ms]
Mar  1 07:08:46.954: INFO: Created: latency-svc-d76t7
Mar  1 07:08:46.964: INFO: Got endpoints: latency-svc-ws9xd [750.654198ms]
Mar  1 07:08:47.104: INFO: Got endpoints: latency-svc-frwzz [793.417568ms]
Mar  1 07:08:47.104: INFO: Got endpoints: latency-svc-bxzbf [841.562017ms]
Mar  1 07:08:47.123: INFO: Created: latency-svc-8gkvs
Mar  1 07:08:47.125: INFO: Got endpoints: latency-svc-pctm6 [760.783678ms]
Mar  1 07:08:47.154: INFO: Created: latency-svc-9pc7m
Mar  1 07:08:47.181: INFO: Created: latency-svc-xvckh
Mar  1 07:08:47.182: INFO: Got endpoints: latency-svc-992t6 [762.809204ms]
Mar  1 07:08:47.214: INFO: Created: latency-svc-c98b2
Mar  1 07:08:47.226: INFO: Got endpoints: latency-svc-fnmxv [760.266527ms]
Mar  1 07:08:47.228: INFO: Created: latency-svc-dv9sh
Mar  1 07:08:47.246: INFO: Created: latency-svc-98dds
Mar  1 07:08:47.265: INFO: Got endpoints: latency-svc-t96s6 [751.673524ms]
Mar  1 07:08:47.316: INFO: Got endpoints: latency-svc-s68vb [750.532844ms]
Mar  1 07:08:47.363: INFO: Got endpoints: latency-svc-wr4kw [750.987154ms]
Mar  1 07:08:47.414: INFO: Got endpoints: latency-svc-nmt44 [750.440773ms]
Mar  1 07:08:47.471: INFO: Got endpoints: latency-svc-qcc8b [748.380572ms]
Mar  1 07:08:47.518: INFO: Got endpoints: latency-svc-s7qfn [755.746179ms]
Mar  1 07:08:47.565: INFO: Got endpoints: latency-svc-ghjkg [746.912114ms]
Mar  1 07:08:47.612: INFO: Got endpoints: latency-svc-89x7x [744.652458ms]
Mar  1 07:08:47.664: INFO: Got endpoints: latency-svc-d76t7 [749.251606ms]
Mar  1 07:08:47.716: INFO: Got endpoints: latency-svc-8gkvs [751.543768ms]
Mar  1 07:08:47.765: INFO: Got endpoints: latency-svc-9pc7m [660.676968ms]
Mar  1 07:08:47.814: INFO: Got endpoints: latency-svc-xvckh [709.985882ms]
Mar  1 07:08:47.899: INFO: Got endpoints: latency-svc-c98b2 [773.550037ms]
Mar  1 07:08:47.915: INFO: Got endpoints: latency-svc-dv9sh [733.668527ms]
Mar  1 07:08:47.964: INFO: Got endpoints: latency-svc-98dds [738.012668ms]
Mar  1 07:08:47.964: INFO: Latencies: [21.154612ms 33.645792ms 37.728783ms 44.790999ms 66.062893ms 87.391762ms 127.070739ms 139.272845ms 162.414357ms 185.611093ms 210.516923ms 232.851663ms 254.208729ms 278.03965ms 292.834415ms 303.73892ms 310.655183ms 313.020901ms 316.029394ms 316.214244ms 318.958107ms 319.396276ms 319.528318ms 325.037835ms 330.305828ms 332.015833ms 336.183059ms 339.668269ms 342.682007ms 347.878997ms 352.217313ms 355.532477ms 356.546481ms 357.372834ms 368.119792ms 371.629311ms 375.836538ms 383.024315ms 383.326532ms 390.49069ms 396.223086ms 404.414459ms 405.157052ms 405.499672ms 406.131321ms 409.765559ms 410.972544ms 418.674783ms 418.881097ms 419.247143ms 424.295541ms 424.355452ms 425.394537ms 425.551747ms 432.280285ms 434.58428ms 435.657573ms 437.777882ms 453.821676ms 478.906008ms 508.553103ms 549.025928ms 566.750414ms 601.738608ms 602.429133ms 646.60479ms 660.676968ms 669.462644ms 687.610982ms 709.985882ms 715.689666ms 720.11465ms 723.280686ms 724.68439ms 731.308939ms 732.448481ms 733.668527ms 734.636032ms 735.70024ms 735.715743ms 737.216783ms 738.012668ms 738.149884ms 738.179466ms 738.279602ms 738.839065ms 738.882978ms 739.064554ms 739.141204ms 739.352152ms 741.104859ms 741.559147ms 742.101786ms 743.257174ms 743.874581ms 744.049898ms 744.062254ms 744.471371ms 744.652458ms 744.877791ms 744.89367ms 745.176167ms 745.332385ms 746.068206ms 746.375013ms 746.56657ms 746.827655ms 746.834575ms 746.912114ms 747.150581ms 747.414653ms 747.810339ms 748.156614ms 748.201125ms 748.379831ms 748.380572ms 748.405489ms 748.412394ms 748.459744ms 748.572041ms 748.624193ms 748.648624ms 748.848231ms 748.999827ms 749.150865ms 749.15699ms 749.171618ms 749.217992ms 749.223508ms 749.251606ms 749.461448ms 749.71013ms 749.723023ms 749.770328ms 749.803854ms 749.965702ms 750.193346ms 750.232661ms 750.243305ms 750.246555ms 750.258552ms 750.43484ms 750.440773ms 750.49113ms 750.532844ms 750.592581ms 750.653104ms 750.654198ms 750.79293ms 750.809098ms 750.902401ms 750.987154ms 751.015764ms 751.543768ms 751.62658ms 751.63356ms 751.667781ms 751.673524ms 751.933114ms 751.973352ms 751.994446ms 752.014ms 752.376497ms 752.585063ms 752.723102ms 753.016445ms 753.158508ms 753.172554ms 753.290324ms 753.384227ms 753.405605ms 753.613607ms 754.195848ms 754.623137ms 755.667838ms 755.746179ms 756.19007ms 756.47565ms 758.03512ms 758.873088ms 759.566379ms 759.921864ms 760.266527ms 760.60421ms 760.783678ms 760.913623ms 761.192449ms 761.475956ms 762.809204ms 763.576023ms 763.950112ms 765.658852ms 766.76361ms 768.678623ms 768.803301ms 769.015301ms 773.550037ms 783.202057ms 793.417568ms 841.562017ms]
Mar  1 07:08:47.964: INFO: 50 %ile: 744.89367ms
Mar  1 07:08:47.964: INFO: 90 %ile: 759.566379ms
Mar  1 07:08:47.964: INFO: 99 %ile: 793.417568ms
Mar  1 07:08:47.965: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:08:47.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7776" for this suite.
Mar  1 07:09:03.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:09:04.159: INFO: namespace svc-latency-7776 deletion completed in 16.184099003s

• [SLOW TEST:27.953 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:09:04.161: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  1 07:09:07.237: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:09:07.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3585" for this suite.
Mar  1 07:09:13.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:09:13.391: INFO: namespace container-runtime-3585 deletion completed in 6.125990128s

• [SLOW TEST:9.229 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:09:13.392: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:09:13.455: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d" in namespace "projected-9323" to be "success or failure"
Mar  1 07:09:13.463: INFO: Pod "downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.630685ms
Mar  1 07:09:15.467: INFO: Pod "downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011391174s
Mar  1 07:09:17.473: INFO: Pod "downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018029133s
STEP: Saw pod success
Mar  1 07:09:17.473: INFO: Pod "downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d" satisfied condition "success or failure"
Mar  1 07:09:17.477: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d container client-container: <nil>
STEP: delete the pod
Mar  1 07:09:17.502: INFO: Waiting for pod downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d to disappear
Mar  1 07:09:17.504: INFO: Pod downwardapi-volume-8b40634e-9229-4e49-a1cf-1b059e90b45d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:09:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9323" for this suite.
Mar  1 07:09:23.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:09:23.654: INFO: namespace projected-9323 deletion completed in 6.145220457s

• [SLOW TEST:10.263 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:09:23.654: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:09:27.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1884" for this suite.
Mar  1 07:10:11.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:10:11.824: INFO: namespace kubelet-test-1884 deletion completed in 44.099770979s

• [SLOW TEST:48.170 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:10:11.826: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-24dea78e-24b9-48a2-ab04-e78880078053
STEP: Creating secret with name secret-projected-all-test-volume-e1d098eb-2c20-4521-9e1e-231f4ebb6133
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  1 07:10:11.886: INFO: Waiting up to 5m0s for pod "projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f" in namespace "projected-3285" to be "success or failure"
Mar  1 07:10:11.892: INFO: Pod "projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.132735ms
Mar  1 07:10:13.896: INFO: Pod "projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00995035s
Mar  1 07:10:15.900: INFO: Pod "projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013738251s
STEP: Saw pod success
Mar  1 07:10:15.900: INFO: Pod "projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f" satisfied condition "success or failure"
Mar  1 07:10:15.903: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  1 07:10:15.927: INFO: Waiting for pod projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f to disappear
Mar  1 07:10:15.930: INFO: Pod projected-volume-1d9f418f-44b3-495c-a224-6561e6d5bb1f no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:10:15.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3285" for this suite.
Mar  1 07:10:21.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:10:22.093: INFO: namespace projected-3285 deletion completed in 6.158127693s

• [SLOW TEST:10.267 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:10:22.094: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-85381f8d-1d14-45a0-9239-6090a772f5f9
STEP: Creating a pod to test consume secrets
Mar  1 07:10:22.136: INFO: Waiting up to 5m0s for pod "pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039" in namespace "secrets-7062" to be "success or failure"
Mar  1 07:10:22.145: INFO: Pod "pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039": Phase="Pending", Reason="", readiness=false. Elapsed: 9.757354ms
Mar  1 07:10:24.150: INFO: Pod "pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013936963s
Mar  1 07:10:26.153: INFO: Pod "pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017649249s
STEP: Saw pod success
Mar  1 07:10:26.153: INFO: Pod "pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039" satisfied condition "success or failure"
Mar  1 07:10:26.156: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:10:26.181: INFO: Waiting for pod pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039 to disappear
Mar  1 07:10:26.183: INFO: Pod pod-secrets-00f6daae-c98c-4ca9-b571-ad7b45f57039 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:10:26.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7062" for this suite.
Mar  1 07:10:32.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:10:32.301: INFO: namespace secrets-7062 deletion completed in 6.1135804s

• [SLOW TEST:10.207 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:10:32.305: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:10:32.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d" in namespace "projected-6595" to be "success or failure"
Mar  1 07:10:32.348: INFO: Pod "downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.592653ms
Mar  1 07:10:34.355: INFO: Pod "downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01226629s
Mar  1 07:10:36.359: INFO: Pod "downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016106307s
STEP: Saw pod success
Mar  1 07:10:36.359: INFO: Pod "downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d" satisfied condition "success or failure"
Mar  1 07:10:36.361: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d container client-container: <nil>
STEP: delete the pod
Mar  1 07:10:36.383: INFO: Waiting for pod downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d to disappear
Mar  1 07:10:36.386: INFO: Pod downwardapi-volume-6bf9b7ee-833c-4006-84c2-8104a307064d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:10:36.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6595" for this suite.
Mar  1 07:10:42.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:10:42.508: INFO: namespace projected-6595 deletion completed in 6.1115136s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:10:42.508: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8821
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Mar  1 07:10:42.566: INFO: Found 0 stateful pods, waiting for 3
Mar  1 07:10:52.569: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:10:52.569: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:10:52.569: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 07:10:52.597: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  1 07:11:02.632: INFO: Updating stateful set ss2
Mar  1 07:11:02.636: INFO: Waiting for Pod statefulset-8821/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Mar  1 07:11:12.707: INFO: Found 2 stateful pods, waiting for 3
Mar  1 07:11:22.711: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:11:22.711: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:11:22.711: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  1 07:11:22.735: INFO: Updating stateful set ss2
Mar  1 07:11:22.743: INFO: Waiting for Pod statefulset-8821/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar  1 07:11:32.769: INFO: Updating stateful set ss2
Mar  1 07:11:32.793: INFO: Waiting for StatefulSet statefulset-8821/ss2 to complete update
Mar  1 07:11:32.793: INFO: Waiting for Pod statefulset-8821/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar  1 07:11:42.800: INFO: Deleting all statefulset in ns statefulset-8821
Mar  1 07:11:42.804: INFO: Scaling statefulset ss2 to 0
Mar  1 07:12:02.824: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:12:02.826: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:12:02.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8821" for this suite.
Mar  1 07:12:08.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:12:08.952: INFO: namespace statefulset-8821 deletion completed in 6.111831716s

• [SLOW TEST:86.444 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:12:08.956: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8519
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 07:12:08.983: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 07:12:33.063: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.1.62:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8519 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:12:33.064: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:12:33.214: INFO: Found all expected endpoints: [netserver-0]
Mar  1 07:12:33.218: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.2.77:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8519 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:12:33.218: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:12:33.358: INFO: Found all expected endpoints: [netserver-1]
Mar  1 07:12:33.361: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.3.73:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8519 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:12:33.361: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:12:33.505: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:12:33.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8519" for this suite.
Mar  1 07:12:55.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:12:55.618: INFO: namespace pod-network-test-8519 deletion completed in 22.107272029s

• [SLOW TEST:46.662 seconds]
[sig-network] Networking
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:12:55.619: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar  1 07:12:55.660: INFO: Waiting up to 5m0s for pod "downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa" in namespace "downward-api-9970" to be "success or failure"
Mar  1 07:12:55.667: INFO: Pod "downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.714418ms
Mar  1 07:12:57.670: INFO: Pod "downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009790085s
Mar  1 07:12:59.674: INFO: Pod "downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013159138s
STEP: Saw pod success
Mar  1 07:12:59.674: INFO: Pod "downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa" satisfied condition "success or failure"
Mar  1 07:12:59.676: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:12:59.712: INFO: Waiting for pod downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa to disappear
Mar  1 07:12:59.715: INFO: Pod downward-api-721c5f33-eb2c-4f66-a03b-40e319a3bfaa no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:12:59.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9970" for this suite.
Mar  1 07:13:05.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:13:05.838: INFO: namespace downward-api-9970 deletion completed in 6.119593105s

• [SLOW TEST:10.219 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:13:05.839: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Mar  1 07:13:06.911: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:13:06.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0301 07:13:06.911166      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-1886" for this suite.
Mar  1 07:13:12.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:13:13.036: INFO: namespace gc-1886 deletion completed in 6.120029606s

• [SLOW TEST:7.197 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:13:13.043: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-18b45d17-1871-4dcb-92bb-f5bfa92321c2
STEP: Creating secret with name s-test-opt-upd-aa87fc98-e914-48b8-82fe-603cb09add9c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-18b45d17-1871-4dcb-92bb-f5bfa92321c2
STEP: Updating secret s-test-opt-upd-aa87fc98-e914-48b8-82fe-603cb09add9c
STEP: Creating secret with name s-test-opt-create-2e458126-44ed-417f-a421-4db4f39fe476
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:13:21.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9872" for this suite.
Mar  1 07:13:43.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:13:43.338: INFO: namespace projected-9872 deletion completed in 22.1165862s

• [SLOW TEST:30.295 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:13:43.339: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 07:13:43.384: INFO: Waiting up to 5m0s for pod "pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315" in namespace "emptydir-8313" to be "success or failure"
Mar  1 07:13:43.387: INFO: Pod "pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.914899ms
Mar  1 07:13:45.390: INFO: Pod "pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006218286s
Mar  1 07:13:47.394: INFO: Pod "pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009963519s
STEP: Saw pod success
Mar  1 07:13:47.394: INFO: Pod "pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315" satisfied condition "success or failure"
Mar  1 07:13:47.397: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315 container test-container: <nil>
STEP: delete the pod
Mar  1 07:13:47.422: INFO: Waiting for pod pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315 to disappear
Mar  1 07:13:47.425: INFO: Pod pod-6a0055a6-08f8-46b1-b3e2-5d2d22014315 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:13:47.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8313" for this suite.
Mar  1 07:13:53.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:13:53.533: INFO: namespace emptydir-8313 deletion completed in 6.103921426s

• [SLOW TEST:10.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:13:53.534: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 07:13:53.571: INFO: Waiting up to 5m0s for pod "pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36" in namespace "emptydir-9748" to be "success or failure"
Mar  1 07:13:53.574: INFO: Pod "pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36": Phase="Pending", Reason="", readiness=false. Elapsed: 3.161797ms
Mar  1 07:13:55.577: INFO: Pod "pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006367283s
Mar  1 07:13:57.581: INFO: Pod "pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009708152s
STEP: Saw pod success
Mar  1 07:13:57.581: INFO: Pod "pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36" satisfied condition "success or failure"
Mar  1 07:13:57.583: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36 container test-container: <nil>
STEP: delete the pod
Mar  1 07:13:57.602: INFO: Waiting for pod pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36 to disappear
Mar  1 07:13:57.605: INFO: Pod pod-95582c82-a43b-4f2d-ad2d-d28455eb6c36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:13:57.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9748" for this suite.
Mar  1 07:14:03.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:14:03.721: INFO: namespace emptydir-9748 deletion completed in 6.112833235s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:14:03.723: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-997
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-997
STEP: Creating statefulset with conflicting port in namespace statefulset-997
STEP: Waiting until pod test-pod will start running in namespace statefulset-997
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-997
Mar  1 07:14:07.816: INFO: Observed stateful pod in namespace: statefulset-997, name: ss-0, uid: 2a07cec2-b9b7-4aa6-95f3-dea96a56de5e, status phase: Pending. Waiting for statefulset controller to delete.
Mar  1 07:14:08.059: INFO: Observed stateful pod in namespace: statefulset-997, name: ss-0, uid: 2a07cec2-b9b7-4aa6-95f3-dea96a56de5e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 07:14:08.065: INFO: Observed stateful pod in namespace: statefulset-997, name: ss-0, uid: 2a07cec2-b9b7-4aa6-95f3-dea96a56de5e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 07:14:08.074: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-997
STEP: Removing pod with conflicting port in namespace statefulset-997
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-997 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar  1 07:14:12.123: INFO: Deleting all statefulset in ns statefulset-997
Mar  1 07:14:12.126: INFO: Scaling statefulset ss to 0
Mar  1 07:14:22.149: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:14:22.152: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:14:22.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-997" for this suite.
Mar  1 07:14:28.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:14:28.292: INFO: namespace statefulset-997 deletion completed in 6.117235064s

• [SLOW TEST:24.569 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:14:28.292: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-317/configmap-test-697d1869-ad61-4c2e-892a-6a67fdde3109
STEP: Creating a pod to test consume configMaps
Mar  1 07:14:28.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468" in namespace "configmap-317" to be "success or failure"
Mar  1 07:14:28.342: INFO: Pod "pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468": Phase="Pending", Reason="", readiness=false. Elapsed: 5.547736ms
Mar  1 07:14:30.346: INFO: Pod "pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009070104s
Mar  1 07:14:32.349: INFO: Pod "pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01230301s
STEP: Saw pod success
Mar  1 07:14:32.349: INFO: Pod "pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468" satisfied condition "success or failure"
Mar  1 07:14:32.351: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468 container env-test: <nil>
STEP: delete the pod
Mar  1 07:14:32.372: INFO: Waiting for pod pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468 to disappear
Mar  1 07:14:32.375: INFO: Pod pod-configmaps-5f6161d7-1d41-4d59-8272-ea650736b468 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:14:32.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-317" for this suite.
Mar  1 07:14:38.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:14:38.502: INFO: namespace configmap-317 deletion completed in 6.12130032s

• [SLOW TEST:10.210 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:14:38.504: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-70a1f06b-c455-4b98-9f6c-0173c2eccbfd
STEP: Creating a pod to test consume configMaps
Mar  1 07:14:38.554: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca" in namespace "projected-2280" to be "success or failure"
Mar  1 07:14:38.558: INFO: Pod "pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041346ms
Mar  1 07:14:40.561: INFO: Pod "pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007079506s
Mar  1 07:14:42.566: INFO: Pod "pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011392971s
STEP: Saw pod success
Mar  1 07:14:42.566: INFO: Pod "pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca" satisfied condition "success or failure"
Mar  1 07:14:42.569: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:14:42.596: INFO: Waiting for pod pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca to disappear
Mar  1 07:14:42.598: INFO: Pod pod-projected-configmaps-d88ffb7f-96a1-414b-9ca9-81afb578cbca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:14:42.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2280" for this suite.
Mar  1 07:14:48.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:14:48.733: INFO: namespace projected-2280 deletion completed in 6.129552277s

• [SLOW TEST:10.230 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:14:48.734: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:14:48.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6375'
Mar  1 07:14:49.337: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 07:14:49.337: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Mar  1 07:14:49.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6375'
Mar  1 07:14:49.450: INFO: stderr: ""
Mar  1 07:14:49.450: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:14:49.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6375" for this suite.
Mar  1 07:14:55.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:14:55.582: INFO: namespace kubectl-6375 deletion completed in 6.126926827s

• [SLOW TEST:6.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:14:55.587: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 07:14:55.624: INFO: Waiting up to 5m0s for pod "pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34" in namespace "emptydir-1902" to be "success or failure"
Mar  1 07:14:55.628: INFO: Pod "pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34": Phase="Pending", Reason="", readiness=false. Elapsed: 3.026717ms
Mar  1 07:14:57.631: INFO: Pod "pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34": Phase="Running", Reason="", readiness=true. Elapsed: 2.006138427s
Mar  1 07:14:59.634: INFO: Pod "pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009818379s
STEP: Saw pod success
Mar  1 07:14:59.634: INFO: Pod "pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34" satisfied condition "success or failure"
Mar  1 07:14:59.637: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34 container test-container: <nil>
STEP: delete the pod
Mar  1 07:14:59.655: INFO: Waiting for pod pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34 to disappear
Mar  1 07:14:59.657: INFO: Pod pod-5b4bfc48-b350-4fdf-9b8d-1ea56d7f6a34 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:14:59.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1902" for this suite.
Mar  1 07:15:05.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:15:05.782: INFO: namespace emptydir-1902 deletion completed in 6.120978692s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:15:05.783: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:15:05.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 version'
Mar  1 07:15:05.921: INFO: stderr: ""
Mar  1 07:15:05.921: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:20:18Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:11:50Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:15:05.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8479" for this suite.
Mar  1 07:15:11.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:15:12.055: INFO: namespace kubectl-8479 deletion completed in 6.127987578s

• [SLOW TEST:6.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:15:12.055: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Mar  1 07:15:12.092: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  1 07:15:12.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:12.363: INFO: stderr: ""
Mar  1 07:15:12.363: INFO: stdout: "service/redis-slave created\n"
Mar  1 07:15:12.363: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  1 07:15:12.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:12.648: INFO: stderr: ""
Mar  1 07:15:12.648: INFO: stdout: "service/redis-master created\n"
Mar  1 07:15:12.649: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  1 07:15:12.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:12.951: INFO: stderr: ""
Mar  1 07:15:12.951: INFO: stdout: "service/frontend created\n"
Mar  1 07:15:12.952: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  1 07:15:12.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:13.217: INFO: stderr: ""
Mar  1 07:15:13.217: INFO: stdout: "deployment.apps/frontend created\n"
Mar  1 07:15:13.217: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  1 07:15:13.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:13.443: INFO: stderr: ""
Mar  1 07:15:13.443: INFO: stdout: "deployment.apps/redis-master created\n"
Mar  1 07:15:13.443: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  1 07:15:13.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-1679'
Mar  1 07:15:13.727: INFO: stderr: ""
Mar  1 07:15:13.727: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Mar  1 07:15:13.727: INFO: Waiting for all frontend pods to be Running.
Mar  1 07:15:33.780: INFO: Waiting for frontend to serve content.
Mar  1 07:15:33.801: INFO: Trying to add a new entry to the guestbook.
Mar  1 07:15:33.819: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  1 07:15:33.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:33.995: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:33.995: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 07:15:33.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:34.129: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:34.129: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 07:15:34.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:34.283: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:34.283: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 07:15:34.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:34.415: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:34.415: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 07:15:34.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:34.526: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:34.526: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 07:15:34.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-1679'
Mar  1 07:15:34.634: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:15:34.634: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:15:34.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1679" for this suite.
Mar  1 07:17:38.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:17:38.760: INFO: namespace kubectl-1679 deletion completed in 2m4.12095618s

• [SLOW TEST:146.705 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:17:38.761: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar  1 07:17:38.791: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:17:42.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1796" for this suite.
Mar  1 07:17:48.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:17:48.158: INFO: namespace init-container-1796 deletion completed in 6.127249145s

• [SLOW TEST:9.397 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:17:48.159: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Mar  1 07:17:48.207: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Mar  1 07:17:48.566: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar  1 07:17:50.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:17:52.619: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:17:54.619: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:17:56.619: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:17:58.619: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718643869, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:18:02.649: INFO: Waited 2.02164788s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:18:03.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4868" for this suite.
Mar  1 07:18:09.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:18:09.423: INFO: namespace aggregator-4868 deletion completed in 6.193495774s

• [SLOW TEST:21.264 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:18:09.423: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:18:09.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a" in namespace "downward-api-3958" to be "success or failure"
Mar  1 07:18:09.459: INFO: Pod "downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.221429ms
Mar  1 07:18:11.461: INFO: Pod "downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005103102s
Mar  1 07:18:13.466: INFO: Pod "downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009324449s
STEP: Saw pod success
Mar  1 07:18:13.466: INFO: Pod "downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a" satisfied condition "success or failure"
Mar  1 07:18:13.468: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a container client-container: <nil>
STEP: delete the pod
Mar  1 07:18:13.486: INFO: Waiting for pod downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a to disappear
Mar  1 07:18:13.489: INFO: Pod downwardapi-volume-2e5baaad-6401-4adb-8b8e-6712956b619a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:18:13.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3958" for this suite.
Mar  1 07:18:19.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:18:19.591: INFO: namespace downward-api-3958 deletion completed in 6.097954418s

• [SLOW TEST:10.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:18:19.592: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  1 07:18:29.694: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:18:29.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0301 07:18:29.694551      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8811" for this suite.
Mar  1 07:18:35.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:18:35.809: INFO: namespace gc-8811 deletion completed in 6.11015812s

• [SLOW TEST:16.218 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:18:35.811: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  1 07:18:35.851: INFO: Waiting up to 5m0s for pod "pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b" in namespace "emptydir-7957" to be "success or failure"
Mar  1 07:18:35.854: INFO: Pod "pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653118ms
Mar  1 07:18:37.863: INFO: Pod "pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011521003s
Mar  1 07:18:39.868: INFO: Pod "pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016483268s
STEP: Saw pod success
Mar  1 07:18:39.868: INFO: Pod "pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b" satisfied condition "success or failure"
Mar  1 07:18:39.871: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b container test-container: <nil>
STEP: delete the pod
Mar  1 07:18:39.935: INFO: Waiting for pod pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b to disappear
Mar  1 07:18:39.942: INFO: Pod pod-d0367aa0-9d9d-462f-8b0c-9609903b1e3b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:18:39.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7957" for this suite.
Mar  1 07:18:45.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:18:46.071: INFO: namespace emptydir-7957 deletion completed in 6.120460078s

• [SLOW TEST:10.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:18:46.072: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vgnsf in namespace proxy-6098
I0301 07:18:46.123328      16 runners.go:180] Created replication controller with name: proxy-service-vgnsf, namespace: proxy-6098, replica count: 1
I0301 07:18:47.173849      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 07:18:48.174085      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 07:18:49.174366      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 07:18:50.174687      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:51.174989      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:52.175313      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:53.175770      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:54.176200      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:55.176525      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 07:18:56.176738      16 runners.go:180] proxy-service-vgnsf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 07:18:56.180: INFO: setup took 10.078998323s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  1 07:18:56.190: INFO: (0) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 10.378764ms)
Mar  1 07:18:56.191: INFO: (0) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 10.751426ms)
Mar  1 07:18:56.191: INFO: (0) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 10.913656ms)
Mar  1 07:18:56.191: INFO: (0) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 11.323801ms)
Mar  1 07:18:56.191: INFO: (0) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 11.363918ms)
Mar  1 07:18:56.197: INFO: (0) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 16.822715ms)
Mar  1 07:18:56.197: INFO: (0) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 16.745637ms)
Mar  1 07:18:56.197: INFO: (0) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 16.588993ms)
Mar  1 07:18:56.198: INFO: (0) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 17.505693ms)
Mar  1 07:18:56.198: INFO: (0) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 17.546863ms)
Mar  1 07:18:56.198: INFO: (0) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 17.858122ms)
Mar  1 07:18:56.198: INFO: (0) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 18.451525ms)
Mar  1 07:18:56.199: INFO: (0) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 18.545372ms)
Mar  1 07:18:56.199: INFO: (0) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 19.149542ms)
Mar  1 07:18:56.201: INFO: (0) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 20.879459ms)
Mar  1 07:18:56.202: INFO: (0) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 22.159108ms)
Mar  1 07:18:56.208: INFO: (1) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 5.669994ms)
Mar  1 07:18:56.208: INFO: (1) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 5.666181ms)
Mar  1 07:18:56.211: INFO: (1) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 8.29601ms)
Mar  1 07:18:56.211: INFO: (1) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 8.668802ms)
Mar  1 07:18:56.212: INFO: (1) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 9.182114ms)
Mar  1 07:18:56.212: INFO: (1) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 8.995206ms)
Mar  1 07:18:56.212: INFO: (1) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.798508ms)
Mar  1 07:18:56.213: INFO: (1) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 9.674296ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 12.030053ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 12.08195ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 12.559031ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 12.303ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 12.417373ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 12.513522ms)
Mar  1 07:18:56.215: INFO: (1) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 12.772237ms)
Mar  1 07:18:56.216: INFO: (1) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 13.501246ms)
Mar  1 07:18:56.221: INFO: (2) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 4.258747ms)
Mar  1 07:18:56.221: INFO: (2) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 4.739731ms)
Mar  1 07:18:56.222: INFO: (2) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 5.611383ms)
Mar  1 07:18:56.223: INFO: (2) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 5.624247ms)
Mar  1 07:18:56.223: INFO: (2) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 5.704843ms)
Mar  1 07:18:56.225: INFO: (2) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 7.790492ms)
Mar  1 07:18:56.225: INFO: (2) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 8.395861ms)
Mar  1 07:18:56.225: INFO: (2) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 8.215272ms)
Mar  1 07:18:56.227: INFO: (2) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 10.25006ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 10.92133ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 10.981485ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 11.069568ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 11.293132ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 11.106857ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 11.2863ms)
Mar  1 07:18:56.228: INFO: (2) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 11.204907ms)
Mar  1 07:18:56.234: INFO: (3) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 5.537397ms)
Mar  1 07:18:56.234: INFO: (3) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 5.343874ms)
Mar  1 07:18:56.234: INFO: (3) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 5.241849ms)
Mar  1 07:18:56.237: INFO: (3) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 8.83534ms)
Mar  1 07:18:56.237: INFO: (3) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 8.849383ms)
Mar  1 07:18:56.238: INFO: (3) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 8.878697ms)
Mar  1 07:18:56.238: INFO: (3) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 9.596259ms)
Mar  1 07:18:56.238: INFO: (3) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 9.665215ms)
Mar  1 07:18:56.240: INFO: (3) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 11.096642ms)
Mar  1 07:18:56.240: INFO: (3) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 11.253843ms)
Mar  1 07:18:56.240: INFO: (3) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 11.454522ms)
Mar  1 07:18:56.241: INFO: (3) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 13.057491ms)
Mar  1 07:18:56.242: INFO: (3) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 13.115122ms)
Mar  1 07:18:56.242: INFO: (3) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 13.228644ms)
Mar  1 07:18:56.242: INFO: (3) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 13.213668ms)
Mar  1 07:18:56.242: INFO: (3) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 13.387131ms)
Mar  1 07:18:56.250: INFO: (4) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 7.081112ms)
Mar  1 07:18:56.251: INFO: (4) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 8.271914ms)
Mar  1 07:18:56.251: INFO: (4) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.281942ms)
Mar  1 07:18:56.252: INFO: (4) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 9.400552ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 10.039938ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.940096ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 9.911529ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 10.567919ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 10.659364ms)
Mar  1 07:18:56.253: INFO: (4) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 10.689148ms)
Mar  1 07:18:56.254: INFO: (4) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 10.766181ms)
Mar  1 07:18:56.254: INFO: (4) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 11.022923ms)
Mar  1 07:18:56.254: INFO: (4) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 11.081147ms)
Mar  1 07:18:56.254: INFO: (4) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 11.528885ms)
Mar  1 07:18:56.254: INFO: (4) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 11.143268ms)
Mar  1 07:18:56.255: INFO: (4) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 12.566918ms)
Mar  1 07:18:56.262: INFO: (5) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 6.207909ms)
Mar  1 07:18:56.263: INFO: (5) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 6.903484ms)
Mar  1 07:18:56.263: INFO: (5) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 6.836603ms)
Mar  1 07:18:56.265: INFO: (5) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 9.419913ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 10.132869ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 10.724228ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 10.958544ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 11.059239ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 10.716198ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 10.629942ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 10.573079ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 11.348769ms)
Mar  1 07:18:56.266: INFO: (5) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 10.93501ms)
Mar  1 07:18:56.267: INFO: (5) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 11.06148ms)
Mar  1 07:18:56.267: INFO: (5) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 10.971147ms)
Mar  1 07:18:56.268: INFO: (5) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 13.486616ms)
Mar  1 07:18:56.275: INFO: (6) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.550728ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 8.101863ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 8.397867ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 8.144009ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 8.5186ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 8.26143ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.82626ms)
Mar  1 07:18:56.277: INFO: (6) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 8.464944ms)
Mar  1 07:18:56.278: INFO: (6) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 8.504235ms)
Mar  1 07:18:56.278: INFO: (6) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.358658ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.701851ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 9.743262ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 9.825011ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 10.393536ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 10.456429ms)
Mar  1 07:18:56.279: INFO: (6) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 9.961353ms)
Mar  1 07:18:56.282: INFO: (7) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 3.10102ms)
Mar  1 07:18:56.283: INFO: (7) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 3.475531ms)
Mar  1 07:18:56.284: INFO: (7) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 5.008269ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 6.633418ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.772571ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.734611ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 7.088733ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 7.33752ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 7.187176ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 7.913277ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 7.715059ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 8.262428ms)
Mar  1 07:18:56.287: INFO: (7) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 8.009422ms)
Mar  1 07:18:56.288: INFO: (7) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 8.049775ms)
Mar  1 07:18:56.288: INFO: (7) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 8.322754ms)
Mar  1 07:18:56.288: INFO: (7) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 8.861042ms)
Mar  1 07:18:56.295: INFO: (8) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 6.199697ms)
Mar  1 07:18:56.297: INFO: (8) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 7.855449ms)
Mar  1 07:18:56.297: INFO: (8) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.405103ms)
Mar  1 07:18:56.299: INFO: (8) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 9.86801ms)
Mar  1 07:18:56.299: INFO: (8) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.432048ms)
Mar  1 07:18:56.299: INFO: (8) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 9.93888ms)
Mar  1 07:18:56.301: INFO: (8) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 11.72609ms)
Mar  1 07:18:56.301: INFO: (8) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 12.138046ms)
Mar  1 07:18:56.301: INFO: (8) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 11.602886ms)
Mar  1 07:18:56.301: INFO: (8) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 12.829575ms)
Mar  1 07:18:56.303: INFO: (8) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 12.911381ms)
Mar  1 07:18:56.303: INFO: (8) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 13.744342ms)
Mar  1 07:18:56.303: INFO: (8) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 13.401376ms)
Mar  1 07:18:56.304: INFO: (8) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 14.674739ms)
Mar  1 07:18:56.305: INFO: (8) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 15.710812ms)
Mar  1 07:18:56.307: INFO: (8) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 18.157452ms)
Mar  1 07:18:56.313: INFO: (9) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 5.012317ms)
Mar  1 07:18:56.313: INFO: (9) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 5.339296ms)
Mar  1 07:18:56.315: INFO: (9) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.392977ms)
Mar  1 07:18:56.315: INFO: (9) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 6.793413ms)
Mar  1 07:18:56.315: INFO: (9) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 6.82272ms)
Mar  1 07:18:56.316: INFO: (9) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.022958ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 8.87827ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.277853ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 9.946725ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 9.268195ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 9.781965ms)
Mar  1 07:18:56.317: INFO: (9) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.466987ms)
Mar  1 07:18:56.319: INFO: (9) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 11.439958ms)
Mar  1 07:18:56.319: INFO: (9) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 12.336985ms)
Mar  1 07:18:56.320: INFO: (9) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 11.590401ms)
Mar  1 07:18:56.322: INFO: (9) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 14.318578ms)
Mar  1 07:18:56.326: INFO: (10) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 4.423112ms)
Mar  1 07:18:56.327: INFO: (10) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 4.109197ms)
Mar  1 07:18:56.327: INFO: (10) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 4.525652ms)
Mar  1 07:18:56.328: INFO: (10) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 5.460079ms)
Mar  1 07:18:56.328: INFO: (10) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 5.791281ms)
Mar  1 07:18:56.328: INFO: (10) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 5.391101ms)
Mar  1 07:18:56.328: INFO: (10) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 5.972046ms)
Mar  1 07:18:56.329: INFO: (10) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 5.700543ms)
Mar  1 07:18:56.329: INFO: (10) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 6.178804ms)
Mar  1 07:18:56.329: INFO: (10) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 5.814544ms)
Mar  1 07:18:56.329: INFO: (10) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 6.873579ms)
Mar  1 07:18:56.331: INFO: (10) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 8.598198ms)
Mar  1 07:18:56.332: INFO: (10) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 8.780567ms)
Mar  1 07:18:56.332: INFO: (10) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 8.578405ms)
Mar  1 07:18:56.332: INFO: (10) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 9.484589ms)
Mar  1 07:18:56.333: INFO: (10) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 9.829137ms)
Mar  1 07:18:56.339: INFO: (11) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 6.211076ms)
Mar  1 07:18:56.339: INFO: (11) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 6.268177ms)
Mar  1 07:18:56.339: INFO: (11) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 5.918803ms)
Mar  1 07:18:56.339: INFO: (11) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 6.118923ms)
Mar  1 07:18:56.340: INFO: (11) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.713814ms)
Mar  1 07:18:56.340: INFO: (11) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 6.844647ms)
Mar  1 07:18:56.341: INFO: (11) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 7.338315ms)
Mar  1 07:18:56.341: INFO: (11) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 7.273477ms)
Mar  1 07:18:56.342: INFO: (11) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.917566ms)
Mar  1 07:18:56.342: INFO: (11) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.213028ms)
Mar  1 07:18:56.342: INFO: (11) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 8.745592ms)
Mar  1 07:18:56.342: INFO: (11) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 8.819052ms)
Mar  1 07:18:56.342: INFO: (11) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 9.116301ms)
Mar  1 07:18:56.343: INFO: (11) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 9.961209ms)
Mar  1 07:18:56.343: INFO: (11) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 9.913714ms)
Mar  1 07:18:56.343: INFO: (11) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 9.813095ms)
Mar  1 07:18:56.355: INFO: (12) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 11.55743ms)
Mar  1 07:18:56.357: INFO: (12) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 13.334747ms)
Mar  1 07:18:56.358: INFO: (12) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 14.200967ms)
Mar  1 07:18:56.427: INFO: (12) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 83.517292ms)
Mar  1 07:18:56.431: INFO: (12) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 87.488219ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 88.222568ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 88.200925ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 88.037842ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 88.30168ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 88.172678ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 88.524539ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 88.360989ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 88.377544ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 88.555368ms)
Mar  1 07:18:56.432: INFO: (12) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 88.411511ms)
Mar  1 07:18:56.448: INFO: (12) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 104.021275ms)
Mar  1 07:18:56.459: INFO: (13) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 11.167354ms)
Mar  1 07:18:56.460: INFO: (13) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 11.239663ms)
Mar  1 07:18:56.460: INFO: (13) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 11.705054ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 12.587409ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 12.734157ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 12.654974ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 12.542519ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 13.21ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 12.973984ms)
Mar  1 07:18:56.461: INFO: (13) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 12.957463ms)
Mar  1 07:18:56.468: INFO: (13) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 19.403412ms)
Mar  1 07:18:56.473: INFO: (13) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 24.43695ms)
Mar  1 07:18:56.473: INFO: (13) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 24.766018ms)
Mar  1 07:18:56.473: INFO: (13) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 24.781093ms)
Mar  1 07:18:56.474: INFO: (13) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 25.589112ms)
Mar  1 07:18:56.474: INFO: (13) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 26.024102ms)
Mar  1 07:18:56.484: INFO: (14) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 9.426299ms)
Mar  1 07:18:56.484: INFO: (14) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 9.551964ms)
Mar  1 07:18:56.484: INFO: (14) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.766573ms)
Mar  1 07:18:56.484: INFO: (14) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 9.782291ms)
Mar  1 07:18:56.484: INFO: (14) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 9.815456ms)
Mar  1 07:18:56.485: INFO: (14) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.602889ms)
Mar  1 07:18:56.485: INFO: (14) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 9.855242ms)
Mar  1 07:18:56.485: INFO: (14) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 10.104767ms)
Mar  1 07:18:56.485: INFO: (14) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.537162ms)
Mar  1 07:18:56.485: INFO: (14) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 10.125217ms)
Mar  1 07:18:56.486: INFO: (14) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 11.180129ms)
Mar  1 07:18:56.486: INFO: (14) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 11.606908ms)
Mar  1 07:18:56.487: INFO: (14) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 11.655854ms)
Mar  1 07:18:56.487: INFO: (14) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 11.596893ms)
Mar  1 07:18:56.487: INFO: (14) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 11.744335ms)
Mar  1 07:18:56.489: INFO: (14) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 13.745678ms)
Mar  1 07:18:56.497: INFO: (15) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 7.758756ms)
Mar  1 07:18:56.497: INFO: (15) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 8.164568ms)
Mar  1 07:18:56.497: INFO: (15) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 8.01227ms)
Mar  1 07:18:56.498: INFO: (15) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 8.237843ms)
Mar  1 07:18:56.500: INFO: (15) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 10.765204ms)
Mar  1 07:18:56.500: INFO: (15) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 10.707658ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 11.325291ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 11.271046ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 11.414278ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 11.642478ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 11.621588ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 11.490205ms)
Mar  1 07:18:56.501: INFO: (15) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 11.566874ms)
Mar  1 07:18:56.505: INFO: (15) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 16.305678ms)
Mar  1 07:18:56.505: INFO: (15) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 15.930518ms)
Mar  1 07:18:56.505: INFO: (15) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 16.038277ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 9.466388ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 9.556827ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 9.610486ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 9.566659ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 9.593824ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.644996ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 9.812277ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.682977ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 10.012252ms)
Mar  1 07:18:56.515: INFO: (16) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 10.077067ms)
Mar  1 07:18:56.518: INFO: (16) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 12.399713ms)
Mar  1 07:18:56.519: INFO: (16) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 12.88762ms)
Mar  1 07:18:56.519: INFO: (16) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 13.270546ms)
Mar  1 07:18:56.519: INFO: (16) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 13.033298ms)
Mar  1 07:18:56.519: INFO: (16) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 13.644594ms)
Mar  1 07:18:56.520: INFO: (16) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 14.267236ms)
Mar  1 07:18:56.527: INFO: (17) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 6.589592ms)
Mar  1 07:18:56.533: INFO: (17) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 12.722588ms)
Mar  1 07:18:56.533: INFO: (17) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 13.330313ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 12.984745ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 12.814904ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 12.929033ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 12.894277ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 13.332594ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 13.498566ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 13.030964ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 13.022862ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 13.483871ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 13.17937ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 13.228594ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 13.488878ms)
Mar  1 07:18:56.534: INFO: (17) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 14.046755ms)
Mar  1 07:18:56.538: INFO: (18) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 3.522266ms)
Mar  1 07:18:56.539: INFO: (18) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 4.460908ms)
Mar  1 07:18:56.539: INFO: (18) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 4.501331ms)
Mar  1 07:18:56.539: INFO: (18) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 4.546116ms)
Mar  1 07:18:56.539: INFO: (18) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 4.707723ms)
Mar  1 07:18:56.539: INFO: (18) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 4.606425ms)
Mar  1 07:18:56.541: INFO: (18) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 6.458128ms)
Mar  1 07:18:56.541: INFO: (18) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 6.617368ms)
Mar  1 07:18:56.541: INFO: (18) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 6.857987ms)
Mar  1 07:18:56.541: INFO: (18) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 6.800092ms)
Mar  1 07:18:56.542: INFO: (18) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 6.8254ms)
Mar  1 07:18:56.542: INFO: (18) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 7.145923ms)
Mar  1 07:18:56.542: INFO: (18) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 7.236129ms)
Mar  1 07:18:56.542: INFO: (18) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 7.374194ms)
Mar  1 07:18:56.542: INFO: (18) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 7.179182ms)
Mar  1 07:18:56.543: INFO: (18) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 8.082731ms)
Mar  1 07:18:56.553: INFO: (19) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:462/proxy/: tls qux (200; 10.312588ms)
Mar  1 07:18:56.553: INFO: (19) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.762878ms)
Mar  1 07:18:56.553: INFO: (19) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 8.315262ms)
Mar  1 07:18:56.553: INFO: (19) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname1/proxy/: foo (200; 9.60202ms)
Mar  1 07:18:56.553: INFO: (19) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:162/proxy/: bar (200; 9.02298ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">... (200; 8.495895ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/http:proxy-service-vgnsf-vqzhs:160/proxy/: foo (200; 5.022246ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs:1080/proxy/rewriteme">test<... (200; 9.208825ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname1/proxy/: foo (200; 10.110244ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/proxy-service-vgnsf-vqzhs/proxy/rewriteme">test</a> (200; 8.684461ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:460/proxy/: tls baz (200; 4.966464ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/services/http:proxy-service-vgnsf:portname2/proxy/: bar (200; 9.496585ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/: <a href="/api/v1/namespaces/proxy-6098/pods/https:proxy-service-vgnsf-vqzhs:443/proxy/tlsrewritem... (200; 9.840421ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname1/proxy/: tls baz (200; 9.389762ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/services/proxy-service-vgnsf:portname2/proxy/: bar (200; 9.245568ms)
Mar  1 07:18:56.554: INFO: (19) /api/v1/namespaces/proxy-6098/services/https:proxy-service-vgnsf:tlsportname2/proxy/: tls qux (200; 9.790694ms)
STEP: deleting ReplicationController proxy-service-vgnsf in namespace proxy-6098, will wait for the garbage collector to delete the pods
Mar  1 07:18:56.615: INFO: Deleting ReplicationController proxy-service-vgnsf took: 7.128958ms
Mar  1 07:18:57.015: INFO: Terminating ReplicationController proxy-service-vgnsf pods took: 400.233959ms
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:19:07.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6098" for this suite.
Mar  1 07:19:13.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:19:13.614: INFO: namespace proxy-6098 deletion completed in 6.09363388s

• [SLOW TEST:27.542 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:19:13.620: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-220aed2c-d7fa-4c90-af04-b6eb5414d286
STEP: Creating configMap with name cm-test-opt-upd-0c0c1655-720b-4b01-9c03-901ce05a8675
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-220aed2c-d7fa-4c90-af04-b6eb5414d286
STEP: Updating configmap cm-test-opt-upd-0c0c1655-720b-4b01-9c03-901ce05a8675
STEP: Creating configMap with name cm-test-opt-create-7cbe3463-857e-4901-aa66-0ff1fcff43a8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:19:21.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8887" for this suite.
Mar  1 07:19:43.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:19:43.880: INFO: namespace projected-8887 deletion completed in 22.115747775s

• [SLOW TEST:30.260 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:19:43.880: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:19:43.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456" in namespace "projected-383" to be "success or failure"
Mar  1 07:19:43.928: INFO: Pod "downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456": Phase="Pending", Reason="", readiness=false. Elapsed: 6.241871ms
Mar  1 07:19:45.932: INFO: Pod "downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009344341s
Mar  1 07:19:47.935: INFO: Pod "downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01238084s
STEP: Saw pod success
Mar  1 07:19:47.935: INFO: Pod "downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456" satisfied condition "success or failure"
Mar  1 07:19:47.940: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456 container client-container: <nil>
STEP: delete the pod
Mar  1 07:19:47.975: INFO: Waiting for pod downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456 to disappear
Mar  1 07:19:47.978: INFO: Pod downwardapi-volume-02129f06-5b2d-4f31-b29f-f2ee189d1456 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:19:47.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-383" for this suite.
Mar  1 07:19:53.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:19:54.085: INFO: namespace projected-383 deletion completed in 6.103853557s

• [SLOW TEST:10.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:19:54.086: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar  1 07:19:54.124: INFO: Waiting up to 5m0s for pod "downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b" in namespace "downward-api-7365" to be "success or failure"
Mar  1 07:19:54.131: INFO: Pod "downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.307611ms
Mar  1 07:19:56.134: INFO: Pod "downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010243502s
Mar  1 07:19:58.138: INFO: Pod "downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013695869s
STEP: Saw pod success
Mar  1 07:19:58.138: INFO: Pod "downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b" satisfied condition "success or failure"
Mar  1 07:19:58.140: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:19:58.165: INFO: Waiting for pod downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b to disappear
Mar  1 07:19:58.167: INFO: Pod downward-api-549f4b72-afaa-48d8-97d3-dd06aea44b1b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:19:58.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7365" for this suite.
Mar  1 07:20:04.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:20:04.284: INFO: namespace downward-api-7365 deletion completed in 6.112745537s

• [SLOW TEST:10.198 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:20:04.286: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Mar  1 07:20:04.340: INFO: Waiting up to 5m0s for pod "client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54" in namespace "containers-1237" to be "success or failure"
Mar  1 07:20:04.344: INFO: Pod "client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54": Phase="Pending", Reason="", readiness=false. Elapsed: 3.394025ms
Mar  1 07:20:06.347: INFO: Pod "client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00669428s
Mar  1 07:20:08.351: INFO: Pod "client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011367992s
STEP: Saw pod success
Mar  1 07:20:08.352: INFO: Pod "client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54" satisfied condition "success or failure"
Mar  1 07:20:08.354: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54 container test-container: <nil>
STEP: delete the pod
Mar  1 07:20:08.374: INFO: Waiting for pod client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54 to disappear
Mar  1 07:20:08.377: INFO: Pod client-containers-97786ede-03ab-4c36-bcd6-6c25a72eaa54 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:20:08.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1237" for this suite.
Mar  1 07:20:14.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:20:14.489: INFO: namespace containers-1237 deletion completed in 6.10802053s

• [SLOW TEST:10.204 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:20:14.490: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-4e684ea2-c848-4cf7-909d-f4546ffd4a39
STEP: Creating a pod to test consume secrets
Mar  1 07:20:14.540: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87" in namespace "projected-153" to be "success or failure"
Mar  1 07:20:14.547: INFO: Pod "pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87": Phase="Pending", Reason="", readiness=false. Elapsed: 6.894426ms
Mar  1 07:20:16.549: INFO: Pod "pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00987029s
Mar  1 07:20:18.553: INFO: Pod "pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013112441s
STEP: Saw pod success
Mar  1 07:20:18.553: INFO: Pod "pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87" satisfied condition "success or failure"
Mar  1 07:20:18.556: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:20:18.578: INFO: Waiting for pod pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87 to disappear
Mar  1 07:20:18.583: INFO: Pod pod-projected-secrets-b3393101-2602-45c7-83f3-28ac2a140a87 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:20:18.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-153" for this suite.
Mar  1 07:20:24.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:20:24.690: INFO: namespace projected-153 deletion completed in 6.101732959s

• [SLOW TEST:10.200 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:20:24.690: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar  1 07:20:24.991: INFO: Pod name wrapped-volume-race-7c5ff75e-d932-4696-b6f5-5d92b1172978: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7c5ff75e-d932-4696-b6f5-5d92b1172978 in namespace emptydir-wrapper-3690, will wait for the garbage collector to delete the pods
Mar  1 07:20:41.104: INFO: Deleting ReplicationController wrapped-volume-race-7c5ff75e-d932-4696-b6f5-5d92b1172978 took: 8.658884ms
Mar  1 07:20:41.506: INFO: Terminating ReplicationController wrapped-volume-race-7c5ff75e-d932-4696-b6f5-5d92b1172978 pods took: 401.891488ms
STEP: Creating RC which spawns configmap-volume pods
Mar  1 07:21:19.521: INFO: Pod name wrapped-volume-race-1af916d0-419c-4aa4-960f-d9ad921622ec: Found 0 pods out of 5
Mar  1 07:21:24.527: INFO: Pod name wrapped-volume-race-1af916d0-419c-4aa4-960f-d9ad921622ec: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1af916d0-419c-4aa4-960f-d9ad921622ec in namespace emptydir-wrapper-3690, will wait for the garbage collector to delete the pods
Mar  1 07:21:36.606: INFO: Deleting ReplicationController wrapped-volume-race-1af916d0-419c-4aa4-960f-d9ad921622ec took: 7.258433ms
Mar  1 07:21:37.107: INFO: Terminating ReplicationController wrapped-volume-race-1af916d0-419c-4aa4-960f-d9ad921622ec pods took: 500.22325ms
STEP: Creating RC which spawns configmap-volume pods
Mar  1 07:22:18.125: INFO: Pod name wrapped-volume-race-02f412d3-cbb3-4d59-8832-66c0d9c531ed: Found 0 pods out of 5
Mar  1 07:22:23.132: INFO: Pod name wrapped-volume-race-02f412d3-cbb3-4d59-8832-66c0d9c531ed: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-02f412d3-cbb3-4d59-8832-66c0d9c531ed in namespace emptydir-wrapper-3690, will wait for the garbage collector to delete the pods
Mar  1 07:22:35.211: INFO: Deleting ReplicationController wrapped-volume-race-02f412d3-cbb3-4d59-8832-66c0d9c531ed took: 6.234205ms
Mar  1 07:22:35.615: INFO: Terminating ReplicationController wrapped-volume-race-02f412d3-cbb3-4d59-8832-66c0d9c531ed pods took: 404.189252ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:23:18.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3690" for this suite.
Mar  1 07:23:24.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:23:24.518: INFO: namespace emptydir-wrapper-3690 deletion completed in 6.102367569s

• [SLOW TEST:179.829 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:23:24.520: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar  1 07:23:24.569: INFO: Waiting up to 5m0s for pod "downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07" in namespace "downward-api-158" to be "success or failure"
Mar  1 07:23:24.574: INFO: Pod "downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07": Phase="Pending", Reason="", readiness=false. Elapsed: 5.332089ms
Mar  1 07:23:26.578: INFO: Pod "downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00951408s
Mar  1 07:23:28.582: INFO: Pod "downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01293475s
STEP: Saw pod success
Mar  1 07:23:28.582: INFO: Pod "downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07" satisfied condition "success or failure"
Mar  1 07:23:28.589: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07 container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:23:28.613: INFO: Waiting for pod downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07 to disappear
Mar  1 07:23:28.616: INFO: Pod downward-api-b264e36e-988e-4005-a70b-6e6070a2ab07 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:23:28.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-158" for this suite.
Mar  1 07:23:34.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:23:34.726: INFO: namespace downward-api-158 deletion completed in 6.104399308s

• [SLOW TEST:10.207 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:23:34.726: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7e1de61c-644b-4df7-938a-5c31d28c3906
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7e1de61c-644b-4df7-938a-5c31d28c3906
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:25:05.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5625" for this suite.
Mar  1 07:25:27.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:25:27.361: INFO: namespace projected-5625 deletion completed in 22.109790616s

• [SLOW TEST:112.634 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:25:27.361: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0301 07:26:07.424622      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 07:26:07.424: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:26:07.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6375" for this suite.
Mar  1 07:26:13.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:26:13.545: INFO: namespace gc-6375 deletion completed in 6.115885844s

• [SLOW TEST:46.184 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:26:13.545: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-231a63e1-60f4-4e42-947b-d2d1a3aeff2a
STEP: Creating a pod to test consume secrets
Mar  1 07:26:13.589: INFO: Waiting up to 5m0s for pod "pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e" in namespace "secrets-8303" to be "success or failure"
Mar  1 07:26:13.593: INFO: Pod "pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.640319ms
Mar  1 07:26:15.596: INFO: Pod "pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006762461s
Mar  1 07:26:17.599: INFO: Pod "pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0099945s
STEP: Saw pod success
Mar  1 07:26:17.600: INFO: Pod "pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e" satisfied condition "success or failure"
Mar  1 07:26:17.602: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:26:17.619: INFO: Waiting for pod pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e to disappear
Mar  1 07:26:17.622: INFO: Pod pod-secrets-283b1c0b-59c8-4749-8cf4-3a460348528e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:26:17.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8303" for this suite.
Mar  1 07:26:23.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:26:23.727: INFO: namespace secrets-8303 deletion completed in 6.101652023s

• [SLOW TEST:10.182 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:26:23.729: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 07:26:23.776: INFO: Waiting up to 5m0s for pod "pod-92a42030-349b-451b-ba88-aa40befd20f4" in namespace "emptydir-5761" to be "success or failure"
Mar  1 07:26:23.780: INFO: Pod "pod-92a42030-349b-451b-ba88-aa40befd20f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.33153ms
Mar  1 07:26:25.784: INFO: Pod "pod-92a42030-349b-451b-ba88-aa40befd20f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00790105s
Mar  1 07:26:27.788: INFO: Pod "pod-92a42030-349b-451b-ba88-aa40befd20f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011547413s
STEP: Saw pod success
Mar  1 07:26:27.788: INFO: Pod "pod-92a42030-349b-451b-ba88-aa40befd20f4" satisfied condition "success or failure"
Mar  1 07:26:27.790: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-92a42030-349b-451b-ba88-aa40befd20f4 container test-container: <nil>
STEP: delete the pod
Mar  1 07:26:27.817: INFO: Waiting for pod pod-92a42030-349b-451b-ba88-aa40befd20f4 to disappear
Mar  1 07:26:27.820: INFO: Pod pod-92a42030-349b-451b-ba88-aa40befd20f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:26:27.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5761" for this suite.
Mar  1 07:26:33.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:26:33.941: INFO: namespace emptydir-5761 deletion completed in 6.117485116s

• [SLOW TEST:10.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:26:33.942: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar  1 07:26:33.980: INFO: PodSpec: initContainers in spec.initContainers
Mar  1 07:27:19.870: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3400ecc2-8919-41a4-a3c5-49073ebb25d0", GenerateName:"", Namespace:"init-container-4897", SelfLink:"/api/v1/namespaces/init-container-4897/pods/pod-init-3400ecc2-8919-41a4-a3c5-49073ebb25d0", UID:"3974a341-65a1-4045-90c9-c0bee1a833ca", ResourceVersion:"18710", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718644394, loc:(*time.Location)(0x7ed1a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"980955741"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.2.101/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-npmsc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003698400), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npmsc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npmsc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npmsc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0032d22a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-slot1-v3-vsp2-node-group-efb81104b7", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002fe8060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032d2320)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032d2340)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0032d2348), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0032d234c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718644394, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718644394, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718644394, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718644394, loc:(*time.Location)(0x7ed1a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.128.8", PodIP:"192.168.2.101", StartTime:(*v1.Time)(0xc002650280), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002900230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0029002a0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://35e407a9fbce77c44a46a8454cea062c07f070f90af6000f5375b6cfb031bbd6"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026502c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026502a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:27:19.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4897" for this suite.
Mar  1 07:27:41.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:27:42.011: INFO: namespace init-container-4897 deletion completed in 22.12956651s

• [SLOW TEST:68.069 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:27:42.011: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Mar  1 07:27:42.075: INFO: Waiting up to 5m0s for pod "downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4" in namespace "downward-api-3504" to be "success or failure"
Mar  1 07:27:42.082: INFO: Pod "downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.482594ms
Mar  1 07:27:44.085: INFO: Pod "downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010667661s
Mar  1 07:27:46.088: INFO: Pod "downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013724644s
STEP: Saw pod success
Mar  1 07:27:46.088: INFO: Pod "downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4" satisfied condition "success or failure"
Mar  1 07:27:46.091: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4 container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:27:46.108: INFO: Waiting for pod downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4 to disappear
Mar  1 07:27:46.111: INFO: Pod downward-api-cee6e1f8-4dfa-4109-bb52-22cde4d033f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:27:46.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3504" for this suite.
Mar  1 07:27:52.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:27:52.211: INFO: namespace downward-api-3504 deletion completed in 6.096022109s

• [SLOW TEST:10.200 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:27:52.212: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:27:52.253: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2" in namespace "downward-api-5057" to be "success or failure"
Mar  1 07:27:52.266: INFO: Pod "downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.380573ms
Mar  1 07:27:54.269: INFO: Pod "downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015872489s
Mar  1 07:27:56.273: INFO: Pod "downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019153706s
STEP: Saw pod success
Mar  1 07:27:56.273: INFO: Pod "downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2" satisfied condition "success or failure"
Mar  1 07:27:56.275: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2 container client-container: <nil>
STEP: delete the pod
Mar  1 07:27:56.311: INFO: Waiting for pod downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2 to disappear
Mar  1 07:27:56.314: INFO: Pod downwardapi-volume-b57ac62b-3795-4c29-91b4-7325455f97f2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:27:56.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5057" for this suite.
Mar  1 07:28:02.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:28:02.445: INFO: namespace downward-api-5057 deletion completed in 6.125193414s

• [SLOW TEST:10.233 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:28:02.446: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Mar  1 07:28:02.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-2302'
Mar  1 07:28:03.256: INFO: stderr: ""
Mar  1 07:28:03.256: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 07:28:03.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:03.353: INFO: stderr: ""
Mar  1 07:28:03.353: INFO: stdout: "update-demo-nautilus-gkqj4 update-demo-nautilus-tgpz2 "
Mar  1 07:28:03.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-gkqj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:03.461: INFO: stderr: ""
Mar  1 07:28:03.461: INFO: stdout: ""
Mar  1 07:28:03.461: INFO: update-demo-nautilus-gkqj4 is created but not running
Mar  1 07:28:08.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:08.561: INFO: stderr: ""
Mar  1 07:28:08.561: INFO: stdout: "update-demo-nautilus-gkqj4 update-demo-nautilus-tgpz2 "
Mar  1 07:28:08.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-gkqj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:08.666: INFO: stderr: ""
Mar  1 07:28:08.666: INFO: stdout: "true"
Mar  1 07:28:08.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-gkqj4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:08.763: INFO: stderr: ""
Mar  1 07:28:08.763: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 07:28:08.763: INFO: validating pod update-demo-nautilus-gkqj4
Mar  1 07:28:08.768: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 07:28:08.768: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 07:28:08.768: INFO: update-demo-nautilus-gkqj4 is verified up and running
Mar  1 07:28:08.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:08.868: INFO: stderr: ""
Mar  1 07:28:08.868: INFO: stdout: "true"
Mar  1 07:28:08.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:08.971: INFO: stderr: ""
Mar  1 07:28:08.971: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 07:28:08.971: INFO: validating pod update-demo-nautilus-tgpz2
Mar  1 07:28:08.980: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 07:28:08.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 07:28:08.980: INFO: update-demo-nautilus-tgpz2 is verified up and running
STEP: scaling down the replication controller
Mar  1 07:28:08.983: INFO: scanned /root for discovery docs: <nil>
Mar  1 07:28:08.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2302'
Mar  1 07:28:09.122: INFO: stderr: ""
Mar  1 07:28:09.122: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 07:28:09.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:09.227: INFO: stderr: ""
Mar  1 07:28:09.227: INFO: stdout: "update-demo-nautilus-gkqj4 update-demo-nautilus-tgpz2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  1 07:28:14.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:14.334: INFO: stderr: ""
Mar  1 07:28:14.334: INFO: stdout: "update-demo-nautilus-tgpz2 "
Mar  1 07:28:14.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:14.444: INFO: stderr: ""
Mar  1 07:28:14.444: INFO: stdout: "true"
Mar  1 07:28:14.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:14.550: INFO: stderr: ""
Mar  1 07:28:14.550: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 07:28:14.550: INFO: validating pod update-demo-nautilus-tgpz2
Mar  1 07:28:14.554: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 07:28:14.554: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 07:28:14.554: INFO: update-demo-nautilus-tgpz2 is verified up and running
STEP: scaling up the replication controller
Mar  1 07:28:14.556: INFO: scanned /root for discovery docs: <nil>
Mar  1 07:28:14.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2302'
Mar  1 07:28:15.697: INFO: stderr: ""
Mar  1 07:28:15.697: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 07:28:15.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:15.799: INFO: stderr: ""
Mar  1 07:28:15.799: INFO: stdout: "update-demo-nautilus-7tk9f update-demo-nautilus-tgpz2 "
Mar  1 07:28:15.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-7tk9f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:15.901: INFO: stderr: ""
Mar  1 07:28:15.901: INFO: stdout: ""
Mar  1 07:28:15.901: INFO: update-demo-nautilus-7tk9f is created but not running
Mar  1 07:28:20.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2302'
Mar  1 07:28:21.008: INFO: stderr: ""
Mar  1 07:28:21.008: INFO: stdout: "update-demo-nautilus-7tk9f update-demo-nautilus-tgpz2 "
Mar  1 07:28:21.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-7tk9f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:21.130: INFO: stderr: ""
Mar  1 07:28:21.130: INFO: stdout: "true"
Mar  1 07:28:21.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-7tk9f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:21.237: INFO: stderr: ""
Mar  1 07:28:21.237: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 07:28:21.237: INFO: validating pod update-demo-nautilus-7tk9f
Mar  1 07:28:21.243: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 07:28:21.244: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 07:28:21.244: INFO: update-demo-nautilus-7tk9f is verified up and running
Mar  1 07:28:21.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:21.346: INFO: stderr: ""
Mar  1 07:28:21.346: INFO: stdout: "true"
Mar  1 07:28:21.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods update-demo-nautilus-tgpz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2302'
Mar  1 07:28:21.440: INFO: stderr: ""
Mar  1 07:28:21.440: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 07:28:21.440: INFO: validating pod update-demo-nautilus-tgpz2
Mar  1 07:28:21.444: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 07:28:21.444: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 07:28:21.444: INFO: update-demo-nautilus-tgpz2 is verified up and running
STEP: using delete to clean up resources
Mar  1 07:28:21.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-2302'
Mar  1 07:28:21.548: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:28:21.548: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 07:28:21.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2302'
Mar  1 07:28:21.654: INFO: stderr: "No resources found.\n"
Mar  1 07:28:21.654: INFO: stdout: ""
Mar  1 07:28:21.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=update-demo --namespace=kubectl-2302 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 07:28:21.761: INFO: stderr: ""
Mar  1 07:28:21.761: INFO: stdout: "update-demo-nautilus-7tk9f\nupdate-demo-nautilus-tgpz2\n"
Mar  1 07:28:22.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2302'
Mar  1 07:28:22.375: INFO: stderr: "No resources found.\n"
Mar  1 07:28:22.375: INFO: stdout: ""
Mar  1 07:28:22.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=update-demo --namespace=kubectl-2302 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 07:28:22.492: INFO: stderr: ""
Mar  1 07:28:22.492: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:28:22.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2302" for this suite.
Mar  1 07:28:28.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:28:28.602: INFO: namespace kubectl-2302 deletion completed in 6.103684987s

• [SLOW TEST:26.157 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:28:28.604: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-089e6ae9-9c8a-419e-b045-83ef63dc6205
STEP: Creating secret with name s-test-opt-upd-1019ff58-c415-4f8c-81f8-ccccda4dff9e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-089e6ae9-9c8a-419e-b045-83ef63dc6205
STEP: Updating secret s-test-opt-upd-1019ff58-c415-4f8c-81f8-ccccda4dff9e
STEP: Creating secret with name s-test-opt-create-db45e508-5703-43b4-8bc6-df17c7eae787
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:29:53.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1802" for this suite.
Mar  1 07:30:15.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:30:15.307: INFO: namespace secrets-1802 deletion completed in 22.109808415s

• [SLOW TEST:106.704 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:30:15.309: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-be4a1edb-fa72-43e9-972f-959545ef209a
STEP: Creating a pod to test consume secrets
Mar  1 07:30:15.358: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb" in namespace "projected-559" to be "success or failure"
Mar  1 07:30:15.363: INFO: Pod "pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.267834ms
Mar  1 07:30:17.366: INFO: Pod "pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007858499s
Mar  1 07:30:19.370: INFO: Pod "pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011248317s
STEP: Saw pod success
Mar  1 07:30:19.370: INFO: Pod "pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb" satisfied condition "success or failure"
Mar  1 07:30:19.372: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:30:19.392: INFO: Waiting for pod pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb to disappear
Mar  1 07:30:19.395: INFO: Pod pod-projected-secrets-15c45639-1740-4429-a76c-d68346c33bdb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:30:19.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-559" for this suite.
Mar  1 07:30:25.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:30:25.501: INFO: namespace projected-559 deletion completed in 6.101166134s

• [SLOW TEST:10.192 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:30:25.501: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-3c610d67-70a7-4a8b-8011-eba8e872094e in namespace container-probe-2187
Mar  1 07:30:29.568: INFO: Started pod busybox-3c610d67-70a7-4a8b-8011-eba8e872094e in namespace container-probe-2187
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 07:30:29.570: INFO: Initial restart count of pod busybox-3c610d67-70a7-4a8b-8011-eba8e872094e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:34:30.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2187" for this suite.
Mar  1 07:34:36.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:34:36.130: INFO: namespace container-probe-2187 deletion completed in 6.101496639s

• [SLOW TEST:250.628 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:34:36.130: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7518/configmap-test-a729322f-32f0-4d86-aefb-4f4253ff8bc8
STEP: Creating a pod to test consume configMaps
Mar  1 07:34:36.166: INFO: Waiting up to 5m0s for pod "pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e" in namespace "configmap-7518" to be "success or failure"
Mar  1 07:34:36.175: INFO: Pod "pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.937714ms
Mar  1 07:34:38.179: INFO: Pod "pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012775807s
Mar  1 07:34:40.182: INFO: Pod "pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015999476s
STEP: Saw pod success
Mar  1 07:34:40.182: INFO: Pod "pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e" satisfied condition "success or failure"
Mar  1 07:34:40.184: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e container env-test: <nil>
STEP: delete the pod
Mar  1 07:34:40.206: INFO: Waiting for pod pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e to disappear
Mar  1 07:34:40.208: INFO: Pod pod-configmaps-c174558e-9292-4280-b6ee-594bd244d14e no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:34:40.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7518" for this suite.
Mar  1 07:34:46.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:34:46.311: INFO: namespace configmap-7518 deletion completed in 6.098464326s

• [SLOW TEST:10.181 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:34:46.312: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:34:46.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6535" for this suite.
Mar  1 07:34:52.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:34:52.477: INFO: namespace kubelet-test-6535 deletion completed in 6.10200946s

• [SLOW TEST:6.165 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:34:52.477: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:34:52.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f" in namespace "projected-6626" to be "success or failure"
Mar  1 07:34:52.526: INFO: Pod "downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.631056ms
Mar  1 07:34:54.530: INFO: Pod "downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010455119s
Mar  1 07:34:56.533: INFO: Pod "downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013589608s
STEP: Saw pod success
Mar  1 07:34:56.533: INFO: Pod "downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f" satisfied condition "success or failure"
Mar  1 07:34:56.535: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f container client-container: <nil>
STEP: delete the pod
Mar  1 07:34:56.565: INFO: Waiting for pod downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f to disappear
Mar  1 07:34:56.570: INFO: Pod downwardapi-volume-b26c2c01-5da4-4340-a67f-298cb2295b6f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:34:56.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6626" for this suite.
Mar  1 07:35:02.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:35:02.701: INFO: namespace projected-6626 deletion completed in 6.125785664s

• [SLOW TEST:10.224 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:35:02.702: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-cd7c4185-f626-4e99-8244-fc7f5fcbcbfd
STEP: Creating a pod to test consume secrets
Mar  1 07:35:02.807: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6" in namespace "projected-8330" to be "success or failure"
Mar  1 07:35:02.811: INFO: Pod "pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.643902ms
Mar  1 07:35:04.815: INFO: Pod "pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007143653s
Mar  1 07:35:06.817: INFO: Pod "pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009907123s
STEP: Saw pod success
Mar  1 07:35:06.817: INFO: Pod "pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6" satisfied condition "success or failure"
Mar  1 07:35:06.820: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:35:06.838: INFO: Waiting for pod pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6 to disappear
Mar  1 07:35:06.840: INFO: Pod pod-projected-secrets-8d24b9ea-18eb-4671-ab4d-315c977cd8d6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:35:06.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8330" for this suite.
Mar  1 07:35:12.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:35:12.951: INFO: namespace projected-8330 deletion completed in 6.106030026s

• [SLOW TEST:10.249 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:35:12.951: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:35:37.008: INFO: Container started at 2020-03-01 07:35:14 +0000 UTC, pod became ready at 2020-03-01 07:35:35 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:35:37.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8238" for this suite.
Mar  1 07:35:59.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:35:59.134: INFO: namespace container-probe-8238 deletion completed in 22.12142821s

• [SLOW TEST:46.183 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:35:59.134: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:35:59.188: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b" in namespace "projected-2972" to be "success or failure"
Mar  1 07:35:59.198: INFO: Pod "downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.829063ms
Mar  1 07:36:01.201: INFO: Pod "downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012796454s
Mar  1 07:36:03.204: INFO: Pod "downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016311567s
STEP: Saw pod success
Mar  1 07:36:03.204: INFO: Pod "downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b" satisfied condition "success or failure"
Mar  1 07:36:03.207: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b container client-container: <nil>
STEP: delete the pod
Mar  1 07:36:03.235: INFO: Waiting for pod downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b to disappear
Mar  1 07:36:03.237: INFO: Pod downwardapi-volume-04ef41a4-d83c-4a73-b7ac-d132c0f2ea7b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:36:03.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2972" for this suite.
Mar  1 07:36:09.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:36:09.345: INFO: namespace projected-2972 deletion completed in 6.102436854s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:36:09.345: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 07:36:17.430: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 07:36:17.441: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 07:36:19.441: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 07:36:19.445: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 07:36:21.441: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 07:36:21.445: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:36:21.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4561" for this suite.
Mar  1 07:36:43.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:36:43.561: INFO: namespace container-lifecycle-hook-4561 deletion completed in 22.109044851s

• [SLOW TEST:34.216 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:36:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:36:43.604: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82" in namespace "projected-9752" to be "success or failure"
Mar  1 07:36:43.606: INFO: Pod "downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626384ms
Mar  1 07:36:45.610: INFO: Pod "downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006121254s
Mar  1 07:36:47.613: INFO: Pod "downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009534669s
STEP: Saw pod success
Mar  1 07:36:47.613: INFO: Pod "downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82" satisfied condition "success or failure"
Mar  1 07:36:47.616: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82 container client-container: <nil>
STEP: delete the pod
Mar  1 07:36:47.636: INFO: Waiting for pod downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82 to disappear
Mar  1 07:36:47.638: INFO: Pod downwardapi-volume-4049b6b8-f0a7-4003-9b39-2a09bc22eb82 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:36:47.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9752" for this suite.
Mar  1 07:36:53.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:36:53.774: INFO: namespace projected-9752 deletion completed in 6.127388445s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:36:53.774: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar  1 07:36:58.342: INFO: Successfully updated pod "labelsupdateec3bed2b-ca1d-41e4-b2a9-70801c06d3b3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:37:00.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4654" for this suite.
Mar  1 07:37:22.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:37:22.480: INFO: namespace downward-api-4654 deletion completed in 22.103626824s

• [SLOW TEST:28.706 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:37:22.481: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:37:22.526: INFO: (0) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 6.620556ms)
Mar  1 07:37:22.529: INFO: (1) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.456809ms)
Mar  1 07:37:22.534: INFO: (2) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.18405ms)
Mar  1 07:37:22.537: INFO: (3) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.75108ms)
Mar  1 07:37:22.542: INFO: (4) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.196326ms)
Mar  1 07:37:22.546: INFO: (5) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.552396ms)
Mar  1 07:37:22.551: INFO: (6) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.59582ms)
Mar  1 07:37:22.555: INFO: (7) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.112596ms)
Mar  1 07:37:22.559: INFO: (8) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.467905ms)
Mar  1 07:37:22.565: INFO: (9) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 5.150765ms)
Mar  1 07:37:22.569: INFO: (10) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.66974ms)
Mar  1 07:37:22.574: INFO: (11) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.963163ms)
Mar  1 07:37:22.578: INFO: (12) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.444007ms)
Mar  1 07:37:22.582: INFO: (13) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.310726ms)
Mar  1 07:37:22.587: INFO: (14) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.586474ms)
Mar  1 07:37:22.591: INFO: (15) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.524313ms)
Mar  1 07:37:22.596: INFO: (16) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.229627ms)
Mar  1 07:37:22.600: INFO: (17) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.107262ms)
Mar  1 07:37:22.604: INFO: (18) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.573472ms)
Mar  1 07:37:22.609: INFO: (19) /api/v1/nodes/alex-slot1-v3-vsp2-node-group-6fb930ab0d/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.383993ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:37:22.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3917" for this suite.
Mar  1 07:37:28.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:37:28.713: INFO: namespace proxy-3917 deletion completed in 6.099959037s

• [SLOW TEST:6.233 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:37:28.714: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Mar  1 07:37:28.745: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-395293570 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:37:28.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7164" for this suite.
Mar  1 07:37:34.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:37:34.937: INFO: namespace kubectl-7164 deletion completed in 6.097498561s

• [SLOW TEST:6.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:37:34.937: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5496
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 07:37:34.968: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 07:37:59.073: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.114:8080/dial?request=hostName&protocol=http&host=192.168.1.79&port=8080&tries=1'] Namespace:pod-network-test-5496 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:37:59.073: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:37:59.218: INFO: Waiting for endpoints: map[]
Mar  1 07:37:59.221: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.114:8080/dial?request=hostName&protocol=http&host=192.168.2.106&port=8080&tries=1'] Namespace:pod-network-test-5496 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:37:59.221: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:37:59.376: INFO: Waiting for endpoints: map[]
Mar  1 07:37:59.379: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.3.114:8080/dial?request=hostName&protocol=http&host=192.168.3.113&port=8080&tries=1'] Namespace:pod-network-test-5496 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:37:59.379: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:37:59.528: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:37:59.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5496" for this suite.
Mar  1 07:38:21.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:38:21.649: INFO: namespace pod-network-test-5496 deletion completed in 22.116136205s

• [SLOW TEST:46.712 seconds]
[sig-network] Networking
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:38:21.649: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-41f1878f-0ac9-4384-8c21-cf1273a8b280
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:38:25.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3969" for this suite.
Mar  1 07:38:47.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:38:47.834: INFO: namespace configmap-3969 deletion completed in 22.097693354s

• [SLOW TEST:26.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:38:47.836: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-67ccb9e8-14fa-42a0-b87f-2d6db8e09dde
STEP: Creating a pod to test consume configMaps
Mar  1 07:38:47.886: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279" in namespace "projected-5053" to be "success or failure"
Mar  1 07:38:47.895: INFO: Pod "pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279": Phase="Pending", Reason="", readiness=false. Elapsed: 9.358727ms
Mar  1 07:38:49.899: INFO: Pod "pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012493071s
Mar  1 07:38:51.902: INFO: Pod "pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016048311s
STEP: Saw pod success
Mar  1 07:38:51.902: INFO: Pod "pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279" satisfied condition "success or failure"
Mar  1 07:38:51.905: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:38:51.926: INFO: Waiting for pod pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279 to disappear
Mar  1 07:38:51.928: INFO: Pod pod-projected-configmaps-d576db87-2e62-422e-be00-6cd623205279 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:38:51.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5053" for this suite.
Mar  1 07:38:57.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:38:58.041: INFO: namespace projected-5053 deletion completed in 6.108524294s

• [SLOW TEST:10.205 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:38:58.042: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  1 07:39:02.109: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-a1308151-b358-4596-871d-e30c5636ed62,GenerateName:,Namespace:events-3849,SelfLink:/api/v1/namespaces/events-3849/pods/send-events-a1308151-b358-4596-871d-e30c5636ed62,UID:261b7025-92bc-452d-8d2c-2cc42d5beee2,ResourceVersion:20743,Generation:0,CreationTimestamp:2020-03-01 07:38:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 86380088,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.115/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hkjml {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hkjml,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-hkjml true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-6fb930ab0d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003cec310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003cec330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:38:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:39:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:39:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:38:58 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.9,PodIP:192.168.3.115,StartTime:2020-03-01 07:38:58 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-03-01 07:38:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://de5316d1f0ab115a1b712da272bc6979dfecae25cb857e2ba9549a78b06745b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  1 07:39:04.113: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  1 07:39:06.116: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:39:06.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3849" for this suite.
Mar  1 07:39:48.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:39:48.272: INFO: namespace events-3849 deletion completed in 42.13900574s

• [SLOW TEST:50.230 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:39:48.272: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-865
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Mar  1 07:39:48.314: INFO: Found 0 stateful pods, waiting for 3
Mar  1 07:39:58.318: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:39:58.318: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:39:58.318: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:39:58.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-865 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:39:59.076: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 07:39:59.077: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:39:59.077: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 07:40:09.106: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  1 07:40:19.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-865 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:40:19.379: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:40:19.379: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:40:19.379: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:40:29.396: INFO: Waiting for StatefulSet statefulset-865/ss2 to complete update
Mar  1 07:40:29.396: INFO: Waiting for Pod statefulset-865/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar  1 07:40:29.396: INFO: Waiting for Pod statefulset-865/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Mar  1 07:40:39.402: INFO: Waiting for StatefulSet statefulset-865/ss2 to complete update
Mar  1 07:40:39.402: INFO: Waiting for Pod statefulset-865/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Mar  1 07:40:49.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-865 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:40:49.646: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 07:40:49.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:40:49.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:40:59.675: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  1 07:41:09.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-865 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:41:09.927: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 07:41:09.927: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:41:09.927: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:41:19.944: INFO: Waiting for StatefulSet statefulset-865/ss2 to complete update
Mar  1 07:41:19.944: INFO: Waiting for Pod statefulset-865/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Mar  1 07:41:19.944: INFO: Waiting for Pod statefulset-865/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Mar  1 07:41:29.950: INFO: Waiting for StatefulSet statefulset-865/ss2 to complete update
Mar  1 07:41:29.950: INFO: Waiting for Pod statefulset-865/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar  1 07:41:39.950: INFO: Deleting all statefulset in ns statefulset-865
Mar  1 07:41:39.953: INFO: Scaling statefulset ss2 to 0
Mar  1 07:42:19.966: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:42:19.969: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:42:19.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-865" for this suite.
Mar  1 07:42:26.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:42:26.103: INFO: namespace statefulset-865 deletion completed in 6.118819394s

• [SLOW TEST:157.831 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:42:26.105: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-3d27f6d5-8a96-44b0-8c28-601a90fd025d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3d27f6d5-8a96-44b0-8c28-601a90fd025d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:43:32.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4424" for this suite.
Mar  1 07:43:54.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:43:54.616: INFO: namespace configmap-4424 deletion completed in 22.124002414s

• [SLOW TEST:88.512 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:43:54.619: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:44:00.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8437" for this suite.
Mar  1 07:44:06.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:06.878: INFO: namespace namespaces-8437 deletion completed in 6.116085401s
STEP: Destroying namespace "nsdeletetest-8797" for this suite.
Mar  1 07:44:06.880: INFO: Namespace nsdeletetest-8797 was already deleted
STEP: Destroying namespace "nsdeletetest-4148" for this suite.
Mar  1 07:44:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:12.977: INFO: namespace nsdeletetest-4148 deletion completed in 6.096815933s

• [SLOW TEST:18.358 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:44:12.977: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:44:13.012: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar  1 07:44:14.055: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:44:15.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8474" for this suite.
Mar  1 07:44:21.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:21.220: INFO: namespace replication-controller-8474 deletion completed in 6.146307033s

• [SLOW TEST:8.243 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:44:21.225: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7ac2bf67-8736-464e-9f9b-05922051cff0
STEP: Creating a pod to test consume configMaps
Mar  1 07:44:21.282: INFO: Waiting up to 5m0s for pod "pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742" in namespace "configmap-2956" to be "success or failure"
Mar  1 07:44:21.291: INFO: Pod "pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742": Phase="Pending", Reason="", readiness=false. Elapsed: 8.303354ms
Mar  1 07:44:23.294: INFO: Pod "pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011753606s
Mar  1 07:44:25.298: INFO: Pod "pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015188531s
STEP: Saw pod success
Mar  1 07:44:25.298: INFO: Pod "pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742" satisfied condition "success or failure"
Mar  1 07:44:25.301: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:44:25.324: INFO: Waiting for pod pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742 to disappear
Mar  1 07:44:25.327: INFO: Pod pod-configmaps-579672ab-f9c0-460c-ba34-1e0fdc030742 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:44:25.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2956" for this suite.
Mar  1 07:44:31.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:31.434: INFO: namespace configmap-2956 deletion completed in 6.10268618s

• [SLOW TEST:10.209 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:44:31.434: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Mar  1 07:44:36.011: INFO: Successfully updated pod "annotationupdate3a5200bd-051e-46b6-baa2-b1def1dd1f05"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:44:38.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9120" for this suite.
Mar  1 07:44:56.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:56.151: INFO: namespace downward-api-9120 deletion completed in 18.115639826s

• [SLOW TEST:24.717 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:44:56.153: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:44:56.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1935'
Mar  1 07:44:56.297: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 07:44:56.297: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar  1 07:44:56.311: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  1 07:44:56.320: INFO: scanned /root for discovery docs: <nil>
Mar  1 07:44:56.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1935'
Mar  1 07:45:12.177: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 07:45:12.177: INFO: stdout: "Created e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600\nScaling up e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  1 07:45:12.177: INFO: stdout: "Created e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600\nScaling up e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  1 07:45:12.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-1935'
Mar  1 07:45:12.300: INFO: stderr: ""
Mar  1 07:45:12.300: INFO: stdout: "e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600-v9w5l "
Mar  1 07:45:12.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600-v9w5l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1935'
Mar  1 07:45:12.399: INFO: stderr: ""
Mar  1 07:45:12.399: INFO: stdout: "true"
Mar  1 07:45:12.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600-v9w5l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1935'
Mar  1 07:45:12.502: INFO: stderr: ""
Mar  1 07:45:12.502: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar  1 07:45:12.502: INFO: e2e-test-nginx-rc-fde7df6adc15dfed512879eae70d3600-v9w5l is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Mar  1 07:45:12.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete rc e2e-test-nginx-rc --namespace=kubectl-1935'
Mar  1 07:45:12.608: INFO: stderr: ""
Mar  1 07:45:12.608: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:45:12.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1935" for this suite.
Mar  1 07:45:18.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:18.730: INFO: namespace kubectl-1935 deletion completed in 6.116455184s

• [SLOW TEST:22.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:45:18.731: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:45:18.782: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar  1 07:45:23.785: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 07:45:23.786: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  1 07:45:25.789: INFO: Creating deployment "test-rollover-deployment"
Mar  1 07:45:25.797: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  1 07:45:27.807: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  1 07:45:27.813: INFO: Ensure that both replica sets have 1 created replica
Mar  1 07:45:27.817: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  1 07:45:27.822: INFO: Updating deployment test-rollover-deployment
Mar  1 07:45:27.822: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  1 07:45:29.829: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  1 07:45:29.834: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  1 07:45:29.841: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:29.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645528, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:31.848: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:31.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645530, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:33.848: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:33.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645530, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:35.847: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:35.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645530, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:37.847: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:37.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645530, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:39.848: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 07:45:39.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645530, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718645526, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 07:45:41.847: INFO: 
Mar  1 07:45:41.847: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar  1 07:45:41.855: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8667,SelfLink:/apis/apps/v1/namespaces/deployment-8667/deployments/test-rollover-deployment,UID:a1b99690-a331-4c42-88d0-67e3219a6f42,ResourceVersion:22244,Generation:2,CreationTimestamp:2020-03-01 07:45:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-01 07:45:26 +0000 UTC 2020-03-01 07:45:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-01 07:45:40 +0000 UTC 2020-03-01 07:45:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 07:45:41.859: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-8667,SelfLink:/apis/apps/v1/namespaces/deployment-8667/replicasets/test-rollover-deployment-854595fc44,UID:40ed8ab2-6b68-4185-9c3a-0dffddc6ee99,ResourceVersion:22233,Generation:2,CreationTimestamp:2020-03-01 07:45:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a1b99690-a331-4c42-88d0-67e3219a6f42 0xc0033a7f47 0xc0033a7f48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 07:45:41.859: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  1 07:45:41.859: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8667,SelfLink:/apis/apps/v1/namespaces/deployment-8667/replicasets/test-rollover-controller,UID:5cfced4b-ac4b-4422-9060-910467f7d041,ResourceVersion:22242,Generation:2,CreationTimestamp:2020-03-01 07:45:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a1b99690-a331-4c42-88d0-67e3219a6f42 0xc0033a7e77 0xc0033a7e78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 07:45:41.860: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-8667,SelfLink:/apis/apps/v1/namespaces/deployment-8667/replicasets/test-rollover-deployment-9b8b997cf,UID:fde85351-12cb-4cf6-99c0-c6720a0dc81d,ResourceVersion:22199,Generation:2,CreationTimestamp:2020-03-01 07:45:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a1b99690-a331-4c42-88d0-67e3219a6f42 0xc003cec010 0xc003cec011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 07:45:41.863: INFO: Pod "test-rollover-deployment-854595fc44-kp7ch" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-kp7ch,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-8667,SelfLink:/api/v1/namespaces/deployment-8667/pods/test-rollover-deployment-854595fc44-kp7ch,UID:5470e13c-75ad-4b7a-b16a-8437aa015226,ResourceVersion:22211,Generation:0,CreationTimestamp:2020-03-01 07:45:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.87/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 40ed8ab2-6b68-4185-9c3a-0dffddc6ee99 0xc00375c5e7 0xc00375c5e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bwxhl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bwxhl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bwxhl true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00375c6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00375c710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:45:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:45:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:45:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:45:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:192.168.1.87,StartTime:2020-03-01 07:45:28 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-01 07:45:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d517bc0a73132b58e2757feac424457558dd01da42c32f57bcc5bf6e6d3f194f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:45:41.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8667" for this suite.
Mar  1 07:45:47.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:48.006: INFO: namespace deployment-8667 deletion completed in 6.136946652s

• [SLOW TEST:29.275 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:45:48.006: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 07:45:56.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:45:56.101: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:45:58.102: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:45:58.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:00.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:00.104: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:02.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:02.104: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:04.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:04.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:06.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:06.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:08.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:08.104: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:10.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:10.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:12.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:12.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 07:46:14.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 07:46:14.104: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:46:14.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3222" for this suite.
Mar  1 07:46:36.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:36.227: INFO: namespace container-lifecycle-hook-3222 deletion completed in 22.110081765s

• [SLOW TEST:48.221 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:46:36.228: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  1 07:46:36.286: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9433,SelfLink:/api/v1/namespaces/watch-9433/configmaps/e2e-watch-test-resource-version,UID:daba0590-865b-4403-8bf7-8f63936be758,ResourceVersion:22442,Generation:0,CreationTimestamp:2020-03-01 07:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 07:46:36.286: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9433,SelfLink:/api/v1/namespaces/watch-9433/configmaps/e2e-watch-test-resource-version,UID:daba0590-865b-4403-8bf7-8f63936be758,ResourceVersion:22443,Generation:0,CreationTimestamp:2020-03-01 07:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:46:36.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9433" for this suite.
Mar  1 07:46:42.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:42.411: INFO: namespace watch-9433 deletion completed in 6.121108288s

• [SLOW TEST:6.184 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:46:42.412: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 07:46:50.490: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:46:50.495: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:46:52.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:46:52.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:46:54.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:46:54.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:46:56.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:46:56.498: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:46:58.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:46:58.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:00.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:00.498: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:02.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:02.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:04.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:04.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:06.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:06.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:08.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:08.498: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:10.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:10.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:12.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:12.498: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:14.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:14.498: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:16.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:16.499: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:47:18.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:47:18.498: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:47:18.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5820" for this suite.
Mar  1 07:47:40.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:47:40.626: INFO: namespace container-lifecycle-hook-5820 deletion completed in 22.122715556s

• [SLOW TEST:58.215 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:47:40.629: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4132
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 07:47:40.663: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 07:48:04.746: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.116:8080/dial?request=hostName&protocol=udp&host=192.168.2.115&port=8081&tries=1'] Namespace:pod-network-test-4132 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:48:04.746: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:48:04.904: INFO: Waiting for endpoints: map[]
Mar  1 07:48:04.908: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.116:8080/dial?request=hostName&protocol=udp&host=192.168.3.124&port=8081&tries=1'] Namespace:pod-network-test-4132 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:48:04.908: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:48:05.082: INFO: Waiting for endpoints: map[]
Mar  1 07:48:05.085: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.116:8080/dial?request=hostName&protocol=udp&host=192.168.1.89&port=8081&tries=1'] Namespace:pod-network-test-4132 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:48:05.085: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
Mar  1 07:48:05.243: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:48:05.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4132" for this suite.
Mar  1 07:48:27.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:48:27.363: INFO: namespace pod-network-test-4132 deletion completed in 22.114515628s

• [SLOW TEST:46.734 seconds]
[sig-network] Networking
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:48:27.366: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-f4d0ea61-2262-4f26-a982-2b2134b45fa8
STEP: Creating a pod to test consume secrets
Mar  1 07:48:27.421: INFO: Waiting up to 5m0s for pod "pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a" in namespace "secrets-5490" to be "success or failure"
Mar  1 07:48:27.442: INFO: Pod "pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a": Phase="Pending", Reason="", readiness=false. Elapsed: 21.09605ms
Mar  1 07:48:29.446: INFO: Pod "pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024439512s
Mar  1 07:48:31.449: INFO: Pod "pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028046147s
STEP: Saw pod success
Mar  1 07:48:31.449: INFO: Pod "pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a" satisfied condition "success or failure"
Mar  1 07:48:31.452: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:48:31.471: INFO: Waiting for pod pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a to disappear
Mar  1 07:48:31.473: INFO: Pod pod-secrets-20a1d649-6721-4b9d-bc61-6e28bf91d18a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:48:31.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5490" for this suite.
Mar  1 07:48:37.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:48:37.567: INFO: namespace secrets-5490 deletion completed in 6.091024627s

• [SLOW TEST:10.201 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:48:37.568: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-157e48b6-4bb6-47c8-9ea8-0bc37e6c6934
STEP: Creating a pod to test consume secrets
Mar  1 07:48:37.613: INFO: Waiting up to 5m0s for pod "pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61" in namespace "secrets-827" to be "success or failure"
Mar  1 07:48:37.617: INFO: Pod "pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142459ms
Mar  1 07:48:39.620: INFO: Pod "pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006884083s
Mar  1 07:48:41.623: INFO: Pod "pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00995887s
STEP: Saw pod success
Mar  1 07:48:41.623: INFO: Pod "pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61" satisfied condition "success or failure"
Mar  1 07:48:41.626: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:48:41.650: INFO: Waiting for pod pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61 to disappear
Mar  1 07:48:41.653: INFO: Pod pod-secrets-4c90eacf-0712-4ced-b653-2fada5ed4b61 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:48:41.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-827" for this suite.
Mar  1 07:48:47.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:48:47.755: INFO: namespace secrets-827 deletion completed in 6.097293223s

• [SLOW TEST:10.188 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:48:47.755: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:48:52.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5846" for this suite.
Mar  1 07:49:14.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:14.927: INFO: namespace replication-controller-5846 deletion completed in 22.105780767s

• [SLOW TEST:27.172 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:49:14.929: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-8e3dbe6f-48e1-4fdb-b574-b315ef40d123
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:49:14.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9866" for this suite.
Mar  1 07:49:20.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:21.092: INFO: namespace secrets-9866 deletion completed in 6.12128585s

• [SLOW TEST:6.163 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:49:21.092: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Mar  1 07:49:21.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-4070'
Mar  1 07:49:21.395: INFO: stderr: ""
Mar  1 07:49:21.395: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Mar  1 07:49:22.399: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:49:22.399: INFO: Found 0 / 1
Mar  1 07:49:23.399: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:49:23.399: INFO: Found 0 / 1
Mar  1 07:49:24.399: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:49:24.399: INFO: Found 1 / 1
Mar  1 07:49:24.399: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 07:49:24.402: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:49:24.402: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  1 07:49:24.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070'
Mar  1 07:49:24.537: INFO: stderr: ""
Mar  1 07:49:24.537: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 07:49:23.251 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 07:49:23.251 # Server started, Redis version 3.2.12\n1:M 01 Mar 07:49:23.251 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 07:49:23.251 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  1 07:49:24.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070 --tail=1'
Mar  1 07:49:24.644: INFO: stderr: ""
Mar  1 07:49:24.644: INFO: stdout: "1:M 01 Mar 07:49:23.251 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  1 07:49:24.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070 --limit-bytes=1'
Mar  1 07:49:24.773: INFO: stderr: ""
Mar  1 07:49:24.773: INFO: stdout: " "
STEP: exposing timestamps
Mar  1 07:49:24.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070 --tail=1 --timestamps'
Mar  1 07:49:24.891: INFO: stderr: ""
Mar  1 07:49:24.891: INFO: stdout: "2020-03-01T07:49:23.251736459Z 1:M 01 Mar 07:49:23.251 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  1 07:49:27.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070 --since=1s'
Mar  1 07:49:27.523: INFO: stderr: ""
Mar  1 07:49:27.524: INFO: stdout: ""
Mar  1 07:49:27.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 logs redis-master-7bhqn redis-master --namespace=kubectl-4070 --since=24h'
Mar  1 07:49:27.645: INFO: stderr: ""
Mar  1 07:49:27.645: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 07:49:23.251 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 07:49:23.251 # Server started, Redis version 3.2.12\n1:M 01 Mar 07:49:23.251 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 07:49:23.251 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Mar  1 07:49:27.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-4070'
Mar  1 07:49:27.754: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:49:27.754: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  1 07:49:27.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4070'
Mar  1 07:49:27.872: INFO: stderr: "No resources found.\n"
Mar  1 07:49:27.872: INFO: stdout: ""
Mar  1 07:49:27.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=nginx --namespace=kubectl-4070 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 07:49:27.995: INFO: stderr: ""
Mar  1 07:49:27.995: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:49:27.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4070" for this suite.
Mar  1 07:49:50.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:50.120: INFO: namespace kubectl-4070 deletion completed in 22.119846509s

• [SLOW TEST:29.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:49:50.123: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 07:49:50.164: INFO: Waiting up to 5m0s for pod "pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e" in namespace "emptydir-8732" to be "success or failure"
Mar  1 07:49:50.166: INFO: Pod "pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399624ms
Mar  1 07:49:52.170: INFO: Pod "pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006206645s
Mar  1 07:49:54.174: INFO: Pod "pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009783789s
STEP: Saw pod success
Mar  1 07:49:54.174: INFO: Pod "pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e" satisfied condition "success or failure"
Mar  1 07:49:54.177: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e container test-container: <nil>
STEP: delete the pod
Mar  1 07:49:54.196: INFO: Waiting for pod pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e to disappear
Mar  1 07:49:54.205: INFO: Pod pod-1c8a1f07-fb42-4656-8c74-ddcedbbf823e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:49:54.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8732" for this suite.
Mar  1 07:50:00.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:00.323: INFO: namespace emptydir-8732 deletion completed in 6.113179987s

• [SLOW TEST:10.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:50:00.324: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:50:04.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1629" for this suite.
Mar  1 07:50:10.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:10.508: INFO: namespace kubelet-test-1629 deletion completed in 6.132186447s

• [SLOW TEST:10.184 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:50:10.511: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Mar  1 07:50:10.566: INFO: Waiting up to 5m0s for pod "var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e" in namespace "var-expansion-1964" to be "success or failure"
Mar  1 07:50:10.574: INFO: Pod "var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0631ms
Mar  1 07:50:12.578: INFO: Pod "var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011670119s
Mar  1 07:50:14.582: INFO: Pod "var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015198712s
STEP: Saw pod success
Mar  1 07:50:14.582: INFO: Pod "var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e" satisfied condition "success or failure"
Mar  1 07:50:14.583: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:50:14.602: INFO: Waiting for pod var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e to disappear
Mar  1 07:50:14.604: INFO: Pod var-expansion-88e2a8a6-76f4-4178-b9eb-2bf6c877f17e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:50:14.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1964" for this suite.
Mar  1 07:50:20.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:20.721: INFO: namespace var-expansion-1964 deletion completed in 6.113039728s

• [SLOW TEST:10.211 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:50:20.724: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:50:26.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9645" for this suite.
Mar  1 07:50:32.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:32.483: INFO: namespace watch-9645 deletion completed in 6.201676486s

• [SLOW TEST:11.760 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:50:32.483: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:50:32.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4193'
Mar  1 07:50:33.206: INFO: stderr: ""
Mar  1 07:50:33.206: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  1 07:50:38.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pod e2e-test-nginx-pod --namespace=kubectl-4193 -o json'
Mar  1 07:50:38.357: INFO: stderr: ""
Mar  1 07:50:38.357: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.3.128/32\"\n        },\n        \"creationTimestamp\": \"2020-03-01T07:50:33Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4193\",\n        \"resourceVersion\": \"23369\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4193/pods/e2e-test-nginx-pod\",\n        \"uid\": \"23403b6a-692b-4ad8-8fe8-9cc0fa7b0d94\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xj6lf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"alex-slot1-v3-vsp2-node-group-6fb930ab0d\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xj6lf\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xj6lf\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-01T07:50:33Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-01T07:50:35Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-01T07:50:35Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-01T07:50:33Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://188743814ae7a4715fb9ca1787e2e3ebfb0b00c23b91de8eb02dfcfeb1722129\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-01T07:50:34Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.128.9\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.3.128\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-01T07:50:33Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  1 07:50:38.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 replace -f - --namespace=kubectl-4193'
Mar  1 07:50:38.623: INFO: stderr: ""
Mar  1 07:50:38.623: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Mar  1 07:50:38.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete pods e2e-test-nginx-pod --namespace=kubectl-4193'
Mar  1 07:50:47.082: INFO: stderr: ""
Mar  1 07:50:47.082: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:50:47.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4193" for this suite.
Mar  1 07:50:53.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:53.195: INFO: namespace kubectl-4193 deletion completed in 6.10606809s

• [SLOW TEST:20.712 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:50:53.196: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Mar  1 07:50:53.235: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5008" to be "success or failure"
Mar  1 07:50:53.247: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030065ms
Mar  1 07:50:55.251: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016585262s
Mar  1 07:50:57.254: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019932907s
STEP: Saw pod success
Mar  1 07:50:57.255: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  1 07:50:57.257: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  1 07:50:57.279: INFO: Waiting for pod pod-host-path-test to disappear
Mar  1 07:50:57.283: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:50:57.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5008" for this suite.
Mar  1 07:51:03.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:03.406: INFO: namespace hostpath-5008 deletion completed in 6.116179906s

• [SLOW TEST:10.210 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:51:03.407: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Mar  1 07:51:03.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 cluster-info'
Mar  1 07:51:03.565: INFO: stderr: ""
Mar  1 07:51:03.566: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:51:03.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7491" for this suite.
Mar  1 07:51:09.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:09.673: INFO: namespace kubectl-7491 deletion completed in 6.102383723s

• [SLOW TEST:6.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:51:09.673: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  1 07:51:09.713: INFO: Waiting up to 5m0s for pod "pod-83215fbe-a09b-4de4-a59f-931fa2ccb673" in namespace "emptydir-1537" to be "success or failure"
Mar  1 07:51:09.716: INFO: Pod "pod-83215fbe-a09b-4de4-a59f-931fa2ccb673": Phase="Pending", Reason="", readiness=false. Elapsed: 3.111962ms
Mar  1 07:51:11.719: INFO: Pod "pod-83215fbe-a09b-4de4-a59f-931fa2ccb673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00675619s
Mar  1 07:51:13.723: INFO: Pod "pod-83215fbe-a09b-4de4-a59f-931fa2ccb673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010357851s
STEP: Saw pod success
Mar  1 07:51:13.723: INFO: Pod "pod-83215fbe-a09b-4de4-a59f-931fa2ccb673" satisfied condition "success or failure"
Mar  1 07:51:13.725: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod pod-83215fbe-a09b-4de4-a59f-931fa2ccb673 container test-container: <nil>
STEP: delete the pod
Mar  1 07:51:13.752: INFO: Waiting for pod pod-83215fbe-a09b-4de4-a59f-931fa2ccb673 to disappear
Mar  1 07:51:13.757: INFO: Pod pod-83215fbe-a09b-4de4-a59f-931fa2ccb673 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:51:13.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1537" for this suite.
Mar  1 07:51:19.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:19.869: INFO: namespace emptydir-1537 deletion completed in 6.107951991s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:51:19.871: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:51:19.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272" in namespace "projected-6539" to be "success or failure"
Mar  1 07:51:19.922: INFO: Pod "downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272": Phase="Pending", Reason="", readiness=false. Elapsed: 7.792165ms
Mar  1 07:51:21.925: INFO: Pod "downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011357296s
Mar  1 07:51:23.929: INFO: Pod "downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01488639s
STEP: Saw pod success
Mar  1 07:51:23.929: INFO: Pod "downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272" satisfied condition "success or failure"
Mar  1 07:51:23.932: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272 container client-container: <nil>
STEP: delete the pod
Mar  1 07:51:23.954: INFO: Waiting for pod downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272 to disappear
Mar  1 07:51:23.956: INFO: Pod downwardapi-volume-d9b46916-108a-460f-ad47-53c4698ad272 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:51:23.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6539" for this suite.
Mar  1 07:51:29.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:30.080: INFO: namespace projected-6539 deletion completed in 6.118084407s

• [SLOW TEST:10.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:51:30.081: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1317.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1317.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 225.109.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.109.225_udp@PTR;check="$$(dig +tcp +noall +answer +search 225.109.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.109.225_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1317.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1317.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1317.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1317.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1317.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 225.109.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.109.225_udp@PTR;check="$$(dig +tcp +noall +answer +search 225.109.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.109.225_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 07:51:44.174: INFO: Unable to read wheezy_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.178: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.182: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.185: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.214: INFO: Unable to read jessie_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.219: INFO: Unable to read jessie_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.222: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.225: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:44.246: INFO: Lookups using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 failed for: [wheezy_udp@dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_udp@dns-test-service.dns-1317.svc.cluster.local jessie_tcp@dns-test-service.dns-1317.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local]

Mar  1 07:51:49.251: INFO: Unable to read wheezy_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.254: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.257: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.260: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.281: INFO: Unable to read jessie_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.284: INFO: Unable to read jessie_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.288: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.291: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:49.309: INFO: Lookups using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 failed for: [wheezy_udp@dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_udp@dns-test-service.dns-1317.svc.cluster.local jessie_tcp@dns-test-service.dns-1317.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local]

Mar  1 07:51:54.250: INFO: Unable to read wheezy_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.254: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.259: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.263: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.298: INFO: Unable to read jessie_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.303: INFO: Unable to read jessie_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.309: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.315: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:54.339: INFO: Lookups using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 failed for: [wheezy_udp@dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_udp@dns-test-service.dns-1317.svc.cluster.local jessie_tcp@dns-test-service.dns-1317.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local]

Mar  1 07:51:59.252: INFO: Unable to read wheezy_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.257: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.262: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.266: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.299: INFO: Unable to read jessie_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.304: INFO: Unable to read jessie_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.307: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.310: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:51:59.344: INFO: Lookups using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 failed for: [wheezy_udp@dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_udp@dns-test-service.dns-1317.svc.cluster.local jessie_tcp@dns-test-service.dns-1317.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local]

Mar  1 07:52:04.255: INFO: Unable to read wheezy_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.260: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.264: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.269: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.301: INFO: Unable to read jessie_udp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.309: INFO: Unable to read jessie_tcp@dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.313: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.318: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local from pod dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657: the server could not find the requested resource (get pods dns-test-6b50112e-3878-469d-95e0-aa5392d35657)
Mar  1 07:52:04.342: INFO: Lookups using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 failed for: [wheezy_udp@dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@dns-test-service.dns-1317.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_udp@dns-test-service.dns-1317.svc.cluster.local jessie_tcp@dns-test-service.dns-1317.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1317.svc.cluster.local]

Mar  1 07:52:09.301: INFO: DNS probes using dns-1317/dns-test-6b50112e-3878-469d-95e0-aa5392d35657 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:52:09.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1317" for this suite.
Mar  1 07:52:15.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:15.586: INFO: namespace dns-1317 deletion completed in 6.1119345s

• [SLOW TEST:45.505 seconds]
[sig-network] DNS
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:52:15.586: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar  1 07:52:15.631: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  1 07:52:24.664: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:52:24.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5570" for this suite.
Mar  1 07:52:30.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:30.774: INFO: namespace pods-5570 deletion completed in 6.103122125s

• [SLOW TEST:15.188 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:52:30.774: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Mar  1 07:52:30.817: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:52:34.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4133" for this suite.
Mar  1 07:52:56.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:57.064: INFO: namespace init-container-4133 deletion completed in 22.114111725s

• [SLOW TEST:26.290 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:52:57.065: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 07:52:57.103: INFO: Waiting up to 5m0s for pod "pod-8cd57519-0fd4-461e-b6ef-664492b48472" in namespace "emptydir-3335" to be "success or failure"
Mar  1 07:52:57.107: INFO: Pod "pod-8cd57519-0fd4-461e-b6ef-664492b48472": Phase="Pending", Reason="", readiness=false. Elapsed: 4.371168ms
Mar  1 07:52:59.110: INFO: Pod "pod-8cd57519-0fd4-461e-b6ef-664492b48472": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007778936s
Mar  1 07:53:01.115: INFO: Pod "pod-8cd57519-0fd4-461e-b6ef-664492b48472": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012710273s
STEP: Saw pod success
Mar  1 07:53:01.115: INFO: Pod "pod-8cd57519-0fd4-461e-b6ef-664492b48472" satisfied condition "success or failure"
Mar  1 07:53:01.118: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-8cd57519-0fd4-461e-b6ef-664492b48472 container test-container: <nil>
STEP: delete the pod
Mar  1 07:53:01.140: INFO: Waiting for pod pod-8cd57519-0fd4-461e-b6ef-664492b48472 to disappear
Mar  1 07:53:01.149: INFO: Pod pod-8cd57519-0fd4-461e-b6ef-664492b48472 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:53:01.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3335" for this suite.
Mar  1 07:53:07.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:07.254: INFO: namespace emptydir-3335 deletion completed in 6.099801795s

• [SLOW TEST:10.189 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:53:07.254: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6645.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6645.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6645.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6645.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6645.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6645.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 07:53:11.343: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-6645/dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825: the server could not find the requested resource (get pods dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825)
Mar  1 07:53:11.346: INFO: Unable to read jessie_udp@PodARecord from pod dns-6645/dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825: the server could not find the requested resource (get pods dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825)
Mar  1 07:53:11.349: INFO: Unable to read jessie_tcp@PodARecord from pod dns-6645/dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825: the server could not find the requested resource (get pods dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825)
Mar  1 07:53:11.349: INFO: Lookups using dns-6645/dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825 failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar  1 07:53:16.375: INFO: DNS probes using dns-6645/dns-test-c3c9852f-17b8-420f-b270-4e3d3b788825 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:53:16.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6645" for this suite.
Mar  1 07:53:22.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:22.513: INFO: namespace dns-6645 deletion completed in 6.105525979s

• [SLOW TEST:15.259 seconds]
[sig-network] DNS
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:53:22.515: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40
Mar  1 07:53:22.564: INFO: Pod name my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40: Found 0 pods out of 1
Mar  1 07:53:27.568: INFO: Pod name my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40: Found 1 pods out of 1
Mar  1 07:53:27.568: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40" are running
Mar  1 07:53:27.570: INFO: Pod "my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40-vv8lj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:53:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:53:25 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:53:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-01 07:53:23 +0000 UTC Reason: Message:}])
Mar  1 07:53:27.570: INFO: Trying to dial the pod
Mar  1 07:53:32.581: INFO: Controller my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40: Got expected result from replica 1 [my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40-vv8lj]: "my-hostname-basic-24bf8b2a-7a7f-4159-aaea-97d96c237c40-vv8lj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:53:32.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4850" for this suite.
Mar  1 07:53:38.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:38.706: INFO: namespace replication-controller-4850 deletion completed in 6.120881461s

• [SLOW TEST:16.192 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:53:38.712: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:53:38.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1831" for this suite.
Mar  1 07:54:00.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:01.003: INFO: namespace pods-1831 deletion completed in 22.234306301s

• [SLOW TEST:22.291 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:54:01.004: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Mar  1 07:54:01.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-4709'
Mar  1 07:54:01.290: INFO: stderr: ""
Mar  1 07:54:01.291: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 07:54:02.295: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:02.295: INFO: Found 0 / 1
Mar  1 07:54:03.293: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:03.293: INFO: Found 0 / 1
Mar  1 07:54:04.295: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:04.295: INFO: Found 1 / 1
Mar  1 07:54:04.295: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  1 07:54:04.297: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:04.297: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 07:54:04.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 patch pod redis-master-khfrx --namespace=kubectl-4709 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  1 07:54:04.403: INFO: stderr: ""
Mar  1 07:54:04.403: INFO: stdout: "pod/redis-master-khfrx patched\n"
STEP: checking annotations
Mar  1 07:54:04.407: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:04.407: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:54:04.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4709" for this suite.
Mar  1 07:54:26.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:26.517: INFO: namespace kubectl-4709 deletion completed in 22.105684009s

• [SLOW TEST:25.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:54:26.521: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd in namespace container-probe-4610
Mar  1 07:54:30.564: INFO: Started pod liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd in namespace container-probe-4610
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 07:54:30.567: INFO: Initial restart count of pod liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is 0
Mar  1 07:54:44.593: INFO: Restart count of pod container-probe-4610/liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is now 1 (14.026147017s elapsed)
Mar  1 07:55:04.634: INFO: Restart count of pod container-probe-4610/liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is now 2 (34.067288803s elapsed)
Mar  1 07:55:24.667: INFO: Restart count of pod container-probe-4610/liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is now 3 (54.099635365s elapsed)
Mar  1 07:55:46.714: INFO: Restart count of pod container-probe-4610/liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is now 4 (1m16.147170176s elapsed)
Mar  1 07:56:54.827: INFO: Restart count of pod container-probe-4610/liveness-882daeb4-b143-4c5c-8f54-6c1bb5c436bd is now 5 (2m24.259872607s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:56:54.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4610" for this suite.
Mar  1 07:57:00.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:00.955: INFO: namespace container-probe-4610 deletion completed in 6.11453267s

• [SLOW TEST:154.435 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:57:00.959: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f5c51f18-a4b1-49ea-80cc-f8bd90e5b9a4
STEP: Creating a pod to test consume configMaps
Mar  1 07:57:01.008: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36" in namespace "projected-6263" to be "success or failure"
Mar  1 07:57:01.013: INFO: Pod "pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36": Phase="Pending", Reason="", readiness=false. Elapsed: 5.440219ms
Mar  1 07:57:03.017: INFO: Pod "pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009053929s
Mar  1 07:57:05.021: INFO: Pod "pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012877135s
STEP: Saw pod success
Mar  1 07:57:05.021: INFO: Pod "pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36" satisfied condition "success or failure"
Mar  1 07:57:05.024: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-a8be7057d2 pod pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:57:05.047: INFO: Waiting for pod pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36 to disappear
Mar  1 07:57:05.052: INFO: Pod pod-projected-configmaps-8b70134b-2754-42c2-af69-52a1ad5a7a36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:57:05.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6263" for this suite.
Mar  1 07:57:11.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:11.169: INFO: namespace projected-6263 deletion completed in 6.105861788s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:57:11.170: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Mar  1 07:57:11.203: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 07:57:11.212: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 07:57:11.214: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-6fb930ab0d before test
Mar  1 07:57:11.222: INFO: kube-proxy-bkgxj from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.222: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:57:11.222: INFO: nvidia-device-plugin-daemonset-xbjk6 from kube-system started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.222: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:57:11.222: INFO: metallb-speaker-44ttb from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.222: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:57:11.222: INFO: sonobuoy-e2e-job-308a46a6de9c4747 from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 07:57:11.222: INFO: 	Container e2e ready: true, restart count 0
Mar  1 07:57:11.222: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 07:57:11.222: INFO: nginx-ingress-controller-8kfvp from ccp started at 2020-03-01 06:19:27 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.222: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:57:11.222: INFO: calico-node-8ggds from kube-system started at 2020-03-01 06:19:17 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.223: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:57:11.223: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-zspqz from sonobuoy started at 2020-03-01 06:25:47 +0000 UTC (2 container statuses recorded)
Mar  1 07:57:11.223: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  1 07:57:11.223: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:57:11.223: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-a8be7057d2 before test
Mar  1 07:57:11.231: INFO: metallb-speaker-rgpsr from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:57:11.231: INFO: nginx-ingress-default-backend-754f987b55-tzph2 from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Mar  1 07:57:11.231: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-6klrg from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  1 07:57:11.231: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:57:11.231: INFO: kube-proxy-sjww6 from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:57:11.231: INFO: nvidia-device-plugin-daemonset-r6b54 from kube-system started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:57:11.231: INFO: metallb-controller-96757c68d-dn24g from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container metallb-controller ready: true, restart count 0
Mar  1 07:57:11.231: INFO: calico-node-jqnrt from kube-system started at 2020-03-01 06:16:46 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:57:11.231: INFO: nginx-ingress-controller-vnw2g from ccp started at 2020-03-01 06:17:00 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:57:11.231: INFO: cert-manager-776cdb5c5f-d9zdb from ccp started at 2020-03-01 06:17:09 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container cert-manager ready: true, restart count 0
Mar  1 07:57:11.231: INFO: ccp-helm-operator-6598fbf77f-ft7kl from ccp started at 2020-03-01 06:17:24 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.231: INFO: 	Container ccp-helm-operator ready: true, restart count 0
Mar  1 07:57:11.231: INFO: 
Logging pods the kubelet thinks is on node alex-slot1-v3-vsp2-node-group-efb81104b7 before test
Mar  1 07:57:11.239: INFO: sonobuoy from sonobuoy started at 2020-03-01 06:25:42 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  1 07:57:11.240: INFO: nvidia-device-plugin-daemonset-hbrcb from kube-system started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Mar  1 07:57:11.240: INFO: nginx-ingress-controller-mdqc5 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:57:11.240: INFO: sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-27jpq from sonobuoy started at 2020-03-01 06:25:48 +0000 UTC (2 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  1 07:57:11.240: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  1 07:57:11.240: INFO: calico-node-8l2tf from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:57:11.240: INFO: metallb-speaker-jqpk8 from ccp started at 2020-03-01 06:18:18 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container metallb-speaker ready: true, restart count 0
Mar  1 07:57:11.240: INFO: kube-proxy-v5fqd from kube-system started at 2020-03-01 06:18:03 +0000 UTC (1 container statuses recorded)
Mar  1 07:57:11.240: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node alex-slot1-v3-vsp2-node-group-6fb930ab0d
STEP: verifying the node has the label node alex-slot1-v3-vsp2-node-group-a8be7057d2
STEP: verifying the node has the label node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.303: INFO: Pod ccp-helm-operator-6598fbf77f-ft7kl requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod cert-manager-776cdb5c5f-d9zdb requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod metallb-controller-96757c68d-dn24g requesting resource cpu=100m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod metallb-speaker-44ttb requesting resource cpu=100m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod metallb-speaker-jqpk8 requesting resource cpu=100m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod metallb-speaker-rgpsr requesting resource cpu=100m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod nginx-ingress-controller-8kfvp requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod nginx-ingress-controller-mdqc5 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod nginx-ingress-controller-vnw2g requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod nginx-ingress-default-backend-754f987b55-tzph2 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod calico-node-8ggds requesting resource cpu=250m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod calico-node-8l2tf requesting resource cpu=250m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod calico-node-jqnrt requesting resource cpu=250m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod kube-proxy-bkgxj requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod kube-proxy-sjww6 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod kube-proxy-v5fqd requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod nvidia-device-plugin-daemonset-hbrcb requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod nvidia-device-plugin-daemonset-r6b54 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod nvidia-device-plugin-daemonset-xbjk6 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod sonobuoy requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod sonobuoy-e2e-job-308a46a6de9c4747 requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
Mar  1 07:57:11.304: INFO: Pod sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-27jpq requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-efb81104b7
Mar  1 07:57:11.304: INFO: Pod sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-6klrg requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-a8be7057d2
Mar  1 07:57:11.304: INFO: Pod sonobuoy-systemd-logs-daemon-set-91e4774d6fbb488c-zspqz requesting resource cpu=0m on Node alex-slot1-v3-vsp2-node-group-6fb930ab0d
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1.15f81f12249e47b1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7558/filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1 to alex-slot1-v3-vsp2-node-group-efb81104b7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1.15f81f12667ac3bf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1.15f81f126dfcfd96], Reason = [Created], Message = [Created container filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1.15f81f127b428be2], Reason = [Started], Message = [Started container filler-pod-459b38b4-696a-41e2-b255-ffab93bfa8c1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39.15f81f1223da01c1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7558/filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39 to alex-slot1-v3-vsp2-node-group-a8be7057d2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39.15f81f1275b7318a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39.15f81f127e5c8c15], Reason = [Created], Message = [Created container filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39.15f81f128ace73af], Reason = [Started], Message = [Started container filler-pod-bb47428f-5265-4bd1-ac20-5aedaa49ab39]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c.15f81f12241c7486], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7558/filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c to alex-slot1-v3-vsp2-node-group-6fb930ab0d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c.15f81f1251012f38], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c.15f81f1259e6bdcd], Reason = [Created], Message = [Created container filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c.15f81f1266a05a3b], Reason = [Started], Message = [Started container filler-pod-e31554bd-a6dc-405a-9e3c-ab557040963c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f81f131425e5ae], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node alex-slot1-v3-vsp2-node-group-6fb930ab0d
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node alex-slot1-v3-vsp2-node-group-a8be7057d2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node alex-slot1-v3-vsp2-node-group-efb81104b7
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:57:16.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7558" for this suite.
Mar  1 07:57:22.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:22.520: INFO: namespace sched-pred-7558 deletion completed in 6.096083669s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.350 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:57:22.520: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 07:57:22.624: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"246b5bf8-30d0-4d3c-a822-712993920cbc", Controller:(*bool)(0xc0032d364a), BlockOwnerDeletion:(*bool)(0xc0032d364b)}}
Mar  1 07:57:22.632: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6157e253-fb4e-485c-8c47-6f98c9b4c02f", Controller:(*bool)(0xc0032d3826), BlockOwnerDeletion:(*bool)(0xc0032d3827)}}
Mar  1 07:57:22.643: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"dc00b64f-47e4-4af0-a25b-7234e5a5a510", Controller:(*bool)(0xc002c76496), BlockOwnerDeletion:(*bool)(0xc002c76497)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:57:27.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4795" for this suite.
Mar  1 07:57:33.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:33.766: INFO: namespace gc-4795 deletion completed in 6.098914029s

• [SLOW TEST:11.246 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:57:33.767: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:57:33.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3" in namespace "projected-2629" to be "success or failure"
Mar  1 07:57:33.816: INFO: Pod "downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.275359ms
Mar  1 07:57:35.820: INFO: Pod "downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006859444s
Mar  1 07:57:37.823: INFO: Pod "downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010043415s
STEP: Saw pod success
Mar  1 07:57:37.823: INFO: Pod "downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3" satisfied condition "success or failure"
Mar  1 07:57:37.826: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3 container client-container: <nil>
STEP: delete the pod
Mar  1 07:57:37.843: INFO: Waiting for pod downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3 to disappear
Mar  1 07:57:37.845: INFO: Pod downwardapi-volume-f9af0c44-ac18-449f-9411-01f4aaa698f3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:57:37.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2629" for this suite.
Mar  1 07:57:43.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:43.956: INFO: namespace projected-2629 deletion completed in 6.106308655s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:57:43.956: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar  1 07:58:14.538: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0301 07:58:14.538214      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:58:14.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5947" for this suite.
Mar  1 07:58:20.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:58:20.667: INFO: namespace gc-5947 deletion completed in 6.125527008s

• [SLOW TEST:36.711 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:58:20.667: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Mar  1 07:58:20.711: INFO: Waiting up to 5m0s for pod "client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9" in namespace "containers-32" to be "success or failure"
Mar  1 07:58:20.716: INFO: Pod "client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.652209ms
Mar  1 07:58:22.719: INFO: Pod "client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007727819s
Mar  1 07:58:24.723: INFO: Pod "client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011398533s
STEP: Saw pod success
Mar  1 07:58:24.723: INFO: Pod "client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9" satisfied condition "success or failure"
Mar  1 07:58:24.725: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9 container test-container: <nil>
STEP: delete the pod
Mar  1 07:58:24.740: INFO: Waiting for pod client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9 to disappear
Mar  1 07:58:24.742: INFO: Pod client-containers-c03cc5ce-0a9b-4b1f-9f39-c0bee27d20d9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:58:24.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-32" for this suite.
Mar  1 07:58:30.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:58:30.863: INFO: namespace containers-32 deletion completed in 6.116819091s

• [SLOW TEST:10.196 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:58:30.865: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2e151116-882b-43e1-86d3-0bcb774286fe
STEP: Creating a pod to test consume configMaps
Mar  1 07:58:30.913: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848" in namespace "configmap-9736" to be "success or failure"
Mar  1 07:58:30.919: INFO: Pod "pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848": Phase="Pending", Reason="", readiness=false. Elapsed: 6.002911ms
Mar  1 07:58:32.923: INFO: Pod "pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009398051s
Mar  1 07:58:34.925: INFO: Pod "pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012343635s
STEP: Saw pod success
Mar  1 07:58:34.926: INFO: Pod "pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848" satisfied condition "success or failure"
Mar  1 07:58:34.928: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-6fb930ab0d pod pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:58:34.953: INFO: Waiting for pod pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848 to disappear
Mar  1 07:58:34.955: INFO: Pod pod-configmaps-f2d2743f-82f5-421a-8c02-c7101f16c848 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:58:34.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9736" for this suite.
Mar  1 07:58:40.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:58:41.086: INFO: namespace configmap-9736 deletion completed in 6.125026305s

• [SLOW TEST:10.221 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:58:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 07:59:41.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4686" for this suite.
Mar  1 07:59:57.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:59:57.252: INFO: namespace container-probe-4686 deletion completed in 16.109840151s

• [SLOW TEST:76.164 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 07:59:57.253: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-705
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-705
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-705
Mar  1 07:59:57.301: INFO: Found 0 stateful pods, waiting for 1
Mar  1 08:00:07.306: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  1 08:00:07.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:07.564: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 08:00:07.564: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:07.564: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:07.568: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 08:00:17.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:17.573: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:00:17.585: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:17.585: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:17.585: INFO: 
Mar  1 08:00:17.585: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  1 08:00:18.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995915378s
Mar  1 08:00:19.593: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992082224s
Mar  1 08:00:20.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988042716s
Mar  1 08:00:21.603: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983943523s
Mar  1 08:00:22.609: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978136734s
Mar  1 08:00:23.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972335229s
Mar  1 08:00:24.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966932285s
Mar  1 08:00:25.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962696235s
Mar  1 08:00:26.628: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.370652ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-705
Mar  1 08:00:27.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:27.871: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Mar  1 08:00:27.871: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:27.871: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:27.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:28.110: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  1 08:00:28.110: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:28.110: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:28.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:28.389: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  1 08:00:28.389: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:28.389: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:28.394: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:00:28.394: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:00:28.394: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  1 08:00:28.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:28.643: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 08:00:28.643: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:28.643: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:28.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:28.895: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 08:00:28.895: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:28.895: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:28.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 exec --namespace=statefulset-705 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:29.145: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Mar  1 08:00:29.145: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:29.145: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:29.145: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:00:29.149: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  1 08:00:39.155: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.155: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.155: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.164: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:39.164: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:39.164: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:39.164: INFO: ss-2  alex-slot1-v3-vsp2-node-group-a8be7057d2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:39.164: INFO: 
Mar  1 08:00:39.164: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:00:40.173: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:40.173: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:40.173: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:40.173: INFO: ss-2  alex-slot1-v3-vsp2-node-group-a8be7057d2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:40.173: INFO: 
Mar  1 08:00:40.173: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:00:41.178: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:41.178: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:41.178: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:41.178: INFO: 
Mar  1 08:00:41.178: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:42.182: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:42.182: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:42.182: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:42.182: INFO: 
Mar  1 08:00:42.182: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:43.188: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:43.188: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:43.188: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:43.189: INFO: 
Mar  1 08:00:43.189: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:44.193: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:44.193: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:44.193: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:44.193: INFO: 
Mar  1 08:00:44.193: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:45.197: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:45.197: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:45.197: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:45.197: INFO: 
Mar  1 08:00:45.197: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:46.200: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:46.200: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:46.200: INFO: ss-1  alex-slot1-v3-vsp2-node-group-6fb930ab0d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:18 +0000 UTC  }]
Mar  1 08:00:46.201: INFO: 
Mar  1 08:00:46.201: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:00:47.204: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Mar  1 08:00:47.204: INFO: ss-0  alex-slot1-v3-vsp2-node-group-efb81104b7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:00:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 07:59:57 +0000 UTC  }]
Mar  1 08:00:47.204: INFO: 
Mar  1 08:00:47.204: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  1 08:00:48.208: INFO: Verifying statefulset ss doesn't scale past 0 for another 955.501963ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-705
Mar  1 08:00:49.211: INFO: Scaling statefulset ss to 0
Mar  1 08:00:49.219: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Mar  1 08:00:49.221: INFO: Deleting all statefulset in ns statefulset-705
Mar  1 08:00:49.222: INFO: Scaling statefulset ss to 0
Mar  1 08:00:49.230: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:00:49.232: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:00:49.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-705" for this suite.
Mar  1 08:00:55.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:00:55.366: INFO: namespace statefulset-705 deletion completed in 6.117742505s

• [SLOW TEST:58.112 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:00:55.367: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:00:55.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad" in namespace "downward-api-8655" to be "success or failure"
Mar  1 08:00:55.418: INFO: Pod "downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad": Phase="Pending", Reason="", readiness=false. Elapsed: 11.20005ms
Mar  1 08:00:57.422: INFO: Pod "downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014850675s
Mar  1 08:00:59.425: INFO: Pod "downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018158722s
STEP: Saw pod success
Mar  1 08:00:59.425: INFO: Pod "downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad" satisfied condition "success or failure"
Mar  1 08:00:59.428: INFO: Trying to get logs from node alex-slot1-v3-vsp2-node-group-efb81104b7 pod downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad container client-container: <nil>
STEP: delete the pod
Mar  1 08:00:59.451: INFO: Waiting for pod downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad to disappear
Mar  1 08:00:59.454: INFO: Pod downwardapi-volume-aed7c892-220e-4997-8b6e-84035aafb6ad no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:00:59.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8655" for this suite.
Mar  1 08:01:05.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:01:05.564: INFO: namespace downward-api-8655 deletion completed in 6.105679768s

• [SLOW TEST:10.198 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:01:05.567: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 08:01:05.596: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:01:06.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-860" for this suite.
Mar  1 08:01:12.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:01:12.819: INFO: namespace custom-resource-definition-860 deletion completed in 6.105946211s

• [SLOW TEST:7.252 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:01:12.820: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Mar  1 08:01:12.855: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-395293570 proxy --unix-socket=/tmp/kubectl-proxy-unix018490685/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:01:12.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8982" for this suite.
Mar  1 08:01:18.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:01:19.067: INFO: namespace kubectl-8982 deletion completed in 6.115764456s

• [SLOW TEST:6.247 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:01:19.067: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 08:01:27.148: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:27.156: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:29.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:29.160: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:31.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:31.160: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:33.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:33.159: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:35.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:35.159: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:37.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:37.159: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:39.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:39.160: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:01:41.156: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:01:41.159: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:01:41.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7612" for this suite.
Mar  1 08:02:03.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:02:03.275: INFO: namespace container-lifecycle-hook-7612 deletion completed in 22.09895068s

• [SLOW TEST:44.208 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:02:03.275: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Mar  1 08:02:03.833: INFO: created pod pod-service-account-defaultsa
Mar  1 08:02:03.833: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  1 08:02:03.840: INFO: created pod pod-service-account-mountsa
Mar  1 08:02:03.840: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  1 08:02:03.847: INFO: created pod pod-service-account-nomountsa
Mar  1 08:02:03.847: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  1 08:02:03.858: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  1 08:02:03.858: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  1 08:02:03.873: INFO: created pod pod-service-account-mountsa-mountspec
Mar  1 08:02:03.873: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  1 08:02:03.878: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  1 08:02:03.878: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  1 08:02:03.897: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  1 08:02:03.897: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  1 08:02:03.910: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  1 08:02:03.910: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  1 08:02:03.933: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  1 08:02:03.933: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:02:03.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4762" for this suite.
Mar  1 08:02:10.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:02:10.160: INFO: namespace svcaccounts-4762 deletion completed in 6.198295862s

• [SLOW TEST:6.885 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:02:10.160: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Mar  1 08:02:10.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 create -f - --namespace=kubectl-3325'
Mar  1 08:02:11.021: INFO: stderr: ""
Mar  1 08:02:11.021: INFO: stdout: "pod/pause created\n"
Mar  1 08:02:11.021: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  1 08:02:11.022: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3325" to be "running and ready"
Mar  1 08:02:11.034: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.403859ms
Mar  1 08:02:13.037: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015786722s
Mar  1 08:02:15.041: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.019507465s
Mar  1 08:02:15.041: INFO: Pod "pause" satisfied condition "running and ready"
Mar  1 08:02:15.041: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  1 08:02:15.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 label pods pause testing-label=testing-label-value --namespace=kubectl-3325'
Mar  1 08:02:15.165: INFO: stderr: ""
Mar  1 08:02:15.165: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  1 08:02:15.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pod pause -L testing-label --namespace=kubectl-3325'
Mar  1 08:02:15.278: INFO: stderr: ""
Mar  1 08:02:15.278: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  1 08:02:15.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 label pods pause testing-label- --namespace=kubectl-3325'
Mar  1 08:02:15.399: INFO: stderr: ""
Mar  1 08:02:15.399: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  1 08:02:15.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pod pause -L testing-label --namespace=kubectl-3325'
Mar  1 08:02:15.498: INFO: stderr: ""
Mar  1 08:02:15.498: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Mar  1 08:02:15.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 delete --grace-period=0 --force -f - --namespace=kubectl-3325'
Mar  1 08:02:15.608: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:02:15.608: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  1 08:02:15.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get rc,svc -l name=pause --no-headers --namespace=kubectl-3325'
Mar  1 08:02:15.721: INFO: stderr: "No resources found.\n"
Mar  1 08:02:15.721: INFO: stdout: ""
Mar  1 08:02:15.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-395293570 get pods -l name=pause --namespace=kubectl-3325 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 08:02:15.821: INFO: stderr: ""
Mar  1 08:02:15.821: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:02:15.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3325" for this suite.
Mar  1 08:02:21.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:02:21.961: INFO: namespace kubectl-3325 deletion completed in 6.134080804s

• [SLOW TEST:11.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Mar  1 08:02:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-395293570
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Mar  1 08:02:22.013: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  1 08:02:27.016: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 08:02:27.016: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Mar  1 08:02:29.041: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6033,SelfLink:/apis/apps/v1/namespaces/deployment-6033/deployments/test-cleanup-deployment,UID:5f225b88-a828-4f31-9564-2dc038b6ddf8,ResourceVersion:25961,Generation:1,CreationTimestamp:2020-03-01 08:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-03-01 08:02:27 +0000 UTC 2020-03-01 08:02:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-03-01 08:02:29 +0000 UTC 2020-03-01 08:02:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 08:02:29.044: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-6033,SelfLink:/apis/apps/v1/namespaces/deployment-6033/replicasets/test-cleanup-deployment-55bbcbc84c,UID:345d8885-c5e4-4d46-ba00-b8904a426156,ResourceVersion:25951,Generation:1,CreationTimestamp:2020-03-01 08:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5f225b88-a828-4f31-9564-2dc038b6ddf8 0xc002f747e7 0xc002f747e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 08:02:29.048: INFO: Pod "test-cleanup-deployment-55bbcbc84c-6ctm9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-6ctm9,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-6033,SelfLink:/api/v1/namespaces/deployment-6033/pods/test-cleanup-deployment-55bbcbc84c-6ctm9,UID:ce24bd88-6ed4-431e-86da-0ec9487f54b2,ResourceVersion:25950,Generation:0,CreationTimestamp:2020-03-01 08:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.102/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 345d8885-c5e4-4d46-ba00-b8904a426156 0xc003d27ed7 0xc003d27ed8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jksft {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jksft,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jksft true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-slot1-v3-vsp2-node-group-a8be7057d2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003d27f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003d27f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:02:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:02:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:02:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-01 08:02:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.128.7,PodIP:192.168.1.102,StartTime:2020-03-01 08:02:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-03-01 08:02:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e43734811c760778641be02a075745f093185eb17bfea0f80f88e8004808512f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Mar  1 08:02:29.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6033" for this suite.
Mar  1 08:02:35.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:02:35.182: INFO: namespace deployment-6033 deletion completed in 6.128668735s

• [SLOW TEST:13.221 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMar  1 08:02:35.184: INFO: Running AfterSuite actions on all nodes
Mar  1 08:02:35.184: INFO: Running AfterSuite actions on node 1
Mar  1 08:02:35.184: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5776.786 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h36m18.792172094s
Test Suite Passed
