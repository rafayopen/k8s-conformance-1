I0820 02:04:20.405483      18 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-136865096
I0820 02:04:20.405587      18 e2e.go:241] Starting e2e run "bccfc2c9-d1f3-449d-8062-79288d9fb431" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566266659 - Will randomize all specs
Will run 215 of 4413 specs

Aug 20 02:04:20.629: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:04:20.631: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 20 02:04:20.644: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 20 02:04:20.667: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 20 02:04:20.667: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Aug 20 02:04:20.667: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 20 02:04:20.673: INFO: e2e test version: v1.15.2
Aug 20 02:04:20.674: INFO: kube-apiserver version: v1.15.2
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:04:20.674: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
Aug 20 02:04:20.709: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f303cfb1-bec2-4aef-9984-3ecaf2caff32
STEP: Creating a pod to test consume configMaps
Aug 20 02:04:20.722: INFO: Waiting up to 5m0s for pod "pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516" in namespace "configmap-5818" to be "success or failure"
Aug 20 02:04:20.724: INFO: Pod "pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17496ms
Aug 20 02:04:22.728: INFO: Pod "pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005592146s
Aug 20 02:04:24.731: INFO: Pod "pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008616252s
STEP: Saw pod success
Aug 20 02:04:24.731: INFO: Pod "pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516" satisfied condition "success or failure"
Aug 20 02:04:24.733: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:04:24.774: INFO: Waiting for pod pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516 to disappear
Aug 20 02:04:24.779: INFO: Pod pod-configmaps-c3d1652e-db2d-4aaf-9f3b-d66c678ae516 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:04:24.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5818" for this suite.
Aug 20 02:04:30.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:04:30.916: INFO: namespace configmap-5818 deletion completed in 6.131942425s

• [SLOW TEST:10.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:04:30.916: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-9j44
STEP: Creating a pod to test atomic-volume-subpath
Aug 20 02:04:30.970: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9j44" in namespace "subpath-6164" to be "success or failure"
Aug 20 02:04:30.973: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072864ms
Aug 20 02:04:32.976: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 2.005455131s
Aug 20 02:04:34.980: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 4.009633838s
Aug 20 02:04:36.985: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 6.01474001s
Aug 20 02:04:38.989: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 8.018247963s
Aug 20 02:04:40.992: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 10.021922011s
Aug 20 02:04:42.996: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 12.025373289s
Aug 20 02:04:45.001: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 14.030100915s
Aug 20 02:04:47.004: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 16.033416103s
Aug 20 02:04:49.008: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 18.037141551s
Aug 20 02:04:51.012: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Running", Reason="", readiness=true. Elapsed: 20.041296946s
Aug 20 02:04:53.015: INFO: Pod "pod-subpath-test-secret-9j44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.044620858s
STEP: Saw pod success
Aug 20 02:04:53.015: INFO: Pod "pod-subpath-test-secret-9j44" satisfied condition "success or failure"
Aug 20 02:04:53.018: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-subpath-test-secret-9j44 container test-container-subpath-secret-9j44: <nil>
STEP: delete the pod
Aug 20 02:04:53.035: INFO: Waiting for pod pod-subpath-test-secret-9j44 to disappear
Aug 20 02:04:53.038: INFO: Pod pod-subpath-test-secret-9j44 no longer exists
STEP: Deleting pod pod-subpath-test-secret-9j44
Aug 20 02:04:53.038: INFO: Deleting pod "pod-subpath-test-secret-9j44" in namespace "subpath-6164"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:04:53.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6164" for this suite.
Aug 20 02:04:59.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:04:59.167: INFO: namespace subpath-6164 deletion completed in 6.122960654s

• [SLOW TEST:28.251 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:04:59.167: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:04:59.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a" in namespace "projected-1654" to be "success or failure"
Aug 20 02:04:59.217: INFO: Pod "downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032409ms
Aug 20 02:05:01.220: INFO: Pod "downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a": Phase="Running", Reason="", readiness=true. Elapsed: 2.008806675s
Aug 20 02:05:03.224: INFO: Pod "downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012285762s
STEP: Saw pod success
Aug 20 02:05:03.224: INFO: Pod "downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a" satisfied condition "success or failure"
Aug 20 02:05:03.227: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a container client-container: <nil>
STEP: delete the pod
Aug 20 02:05:03.242: INFO: Waiting for pod downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a to disappear
Aug 20 02:05:03.245: INFO: Pod downwardapi-volume-0ea2bb67-df48-4dbd-be27-ede86099076a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:05:03.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1654" for this suite.
Aug 20 02:05:09.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:05:09.358: INFO: namespace projected-1654 deletion completed in 6.110040839s

• [SLOW TEST:10.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:05:09.359: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5810/configmap-test-9207b129-45bd-487a-a2b7-a90c1d162e0f
STEP: Creating a pod to test consume configMaps
Aug 20 02:05:09.401: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff" in namespace "configmap-5810" to be "success or failure"
Aug 20 02:05:09.403: INFO: Pod "pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.189627ms
Aug 20 02:05:11.407: INFO: Pod "pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006002597s
Aug 20 02:05:13.410: INFO: Pod "pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009385505s
STEP: Saw pod success
Aug 20 02:05:13.410: INFO: Pod "pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff" satisfied condition "success or failure"
Aug 20 02:05:13.413: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff container env-test: <nil>
STEP: delete the pod
Aug 20 02:05:13.427: INFO: Waiting for pod pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff to disappear
Aug 20 02:05:13.429: INFO: Pod pod-configmaps-6c4796cd-b57d-4f27-a362-120210126eff no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:05:13.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5810" for this suite.
Aug 20 02:05:19.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:05:19.548: INFO: namespace configmap-5810 deletion completed in 6.11551782s

• [SLOW TEST:10.189 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:05:19.549: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:05:19.604: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f2470db9-0fd6-4454-91ea-f3e45fa53164", Controller:(*bool)(0xc0009afe46), BlockOwnerDeletion:(*bool)(0xc0009afe47)}}
Aug 20 02:05:19.621: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d5075d1d-6cb9-4574-914d-561f49bb9045", Controller:(*bool)(0xc0012e630e), BlockOwnerDeletion:(*bool)(0xc0012e630f)}}
Aug 20 02:05:19.627: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"092f6c76-7ec4-4af7-97c5-a396ff9ea753", Controller:(*bool)(0xc000e041fe), BlockOwnerDeletion:(*bool)(0xc000e041ff)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:05:24.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2375" for this suite.
Aug 20 02:05:30.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:05:30.741: INFO: namespace gc-2375 deletion completed in 6.102182725s

• [SLOW TEST:11.192 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:05:30.741: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 20 02:05:33.307: INFO: Successfully updated pod "annotationupdate0309ec63-de76-4d52-962f-11e1b66081c8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:05:35.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2637" for this suite.
Aug 20 02:05:57.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:05:57.476: INFO: namespace downward-api-2637 deletion completed in 22.144858521s

• [SLOW TEST:26.735 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:05:57.476: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-35efc113-20bd-4979-a5c2-66a8619fe2e5
STEP: Creating a pod to test consume configMaps
Aug 20 02:05:57.518: INFO: Waiting up to 5m0s for pod "pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98" in namespace "configmap-9331" to be "success or failure"
Aug 20 02:05:57.520: INFO: Pod "pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258491ms
Aug 20 02:05:59.523: INFO: Pod "pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98": Phase="Running", Reason="", readiness=true. Elapsed: 2.005249774s
Aug 20 02:06:01.527: INFO: Pod "pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008950472s
STEP: Saw pod success
Aug 20 02:06:01.527: INFO: Pod "pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98" satisfied condition "success or failure"
Aug 20 02:06:01.530: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:06:01.549: INFO: Waiting for pod pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98 to disappear
Aug 20 02:06:01.552: INFO: Pod pod-configmaps-41e5d03a-83ab-458a-99e7-657396969c98 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:06:01.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9331" for this suite.
Aug 20 02:06:07.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:06:07.695: INFO: namespace configmap-9331 deletion completed in 6.121493458s

• [SLOW TEST:10.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:06:07.695: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 20 02:06:07.733: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 20 02:06:08.112: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Aug 20 02:06:10.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:12.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:14.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:16.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:18.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:20.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:22.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:24.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701863568, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:06:27.285: INFO: Waited 1.126220995s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:06:27.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
Aug 20 02:06:27.770: INFO: Condition Ready of node ip-172-31-1-253 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-08-20 02:06:27 +0000 UTC}]. Failure
Aug 20 02:06:29.775: INFO: Condition Ready of node ip-172-31-1-253 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-08-20 02:06:27 +0000 UTC}]. Failure
Aug 20 02:06:31.775: INFO: Condition Ready of node ip-172-31-1-253 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-08-20 02:06:27 +0000 UTC}]. Failure
Aug 20 02:06:33.776: INFO: Condition Ready of node ip-172-31-1-253 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-08-20 02:06:27 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2019-08-20 02:06:32 +0000 UTC}]. Failure
Aug 20 02:06:35.775: INFO: Condition Ready of node ip-172-31-1-253 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-08-20 02:06:27 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2019-08-20 02:06:32 +0000 UTC}]. Failure
Aug 20 02:06:37.778: INFO: Condition Ready of node ip-172-31-1-253 is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-08-20 02:06:32 +0000 UTC}]. Failure
Aug 20 02:06:39.777: INFO: Condition Ready of node ip-172-31-1-253 is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-08-20 02:06:32 +0000 UTC}]. Failure
Aug 20 02:06:41.775: INFO: Condition Ready of node ip-172-31-1-253 is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-08-20 02:06:32 +0000 UTC}]. Failure
STEP: Destroying namespace "aggregator-7088" for this suite.
Aug 20 02:06:49.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:06:49.913: INFO: namespace aggregator-7088 deletion completed in 6.133133766s

• [SLOW TEST:42.218 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:06:49.913: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 20 02:07:30.035: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0820 02:07:30.035779      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:07:30.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6159" for this suite.
Aug 20 02:07:36.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:07:36.224: INFO: namespace gc-6159 deletion completed in 6.184702107s

• [SLOW TEST:46.311 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:07:36.225: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:07:36.314: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:07:37.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3255" for this suite.
Aug 20 02:07:43.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:07:43.522: INFO: namespace custom-resource-definition-3255 deletion completed in 6.126422611s

• [SLOW TEST:7.297 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:07:43.522: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-906222da-70f5-4625-8c1a-827b60fd83cf
STEP: Creating a pod to test consume secrets
Aug 20 02:07:43.570: INFO: Waiting up to 5m0s for pod "pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f" in namespace "secrets-6681" to be "success or failure"
Aug 20 02:07:43.572: INFO: Pod "pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005669ms
Aug 20 02:07:45.575: INFO: Pod "pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f": Phase="Running", Reason="", readiness=true. Elapsed: 2.005380086s
Aug 20 02:07:47.578: INFO: Pod "pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008590228s
STEP: Saw pod success
Aug 20 02:07:47.578: INFO: Pod "pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f" satisfied condition "success or failure"
Aug 20 02:07:47.581: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f container secret-env-test: <nil>
STEP: delete the pod
Aug 20 02:07:47.612: INFO: Waiting for pod pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f to disappear
Aug 20 02:07:47.615: INFO: Pod pod-secrets-3303de71-98df-4ae8-88e4-309b2dcaed2f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:07:47.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6681" for this suite.
Aug 20 02:07:53.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:07:53.723: INFO: namespace secrets-6681 deletion completed in 6.104627882s

• [SLOW TEST:10.201 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:07:53.723: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 20 02:07:53.769: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2147" to be "success or failure"
Aug 20 02:07:53.772: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220121ms
Aug 20 02:07:55.775: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005782051s
Aug 20 02:07:57.781: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011209421s
STEP: Saw pod success
Aug 20 02:07:57.781: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 20 02:07:57.784: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 20 02:07:57.800: INFO: Waiting for pod pod-host-path-test to disappear
Aug 20 02:07:57.802: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:07:57.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2147" for this suite.
Aug 20 02:08:03.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:08:03.933: INFO: namespace hostpath-2147 deletion completed in 6.126827338s

• [SLOW TEST:10.209 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:08:03.933: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-150c6af5-6742-46f3-b6b8-bf3355e27f5a
STEP: Creating a pod to test consume secrets
Aug 20 02:08:03.984: INFO: Waiting up to 5m0s for pod "pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6" in namespace "secrets-8155" to be "success or failure"
Aug 20 02:08:03.987: INFO: Pod "pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26429ms
Aug 20 02:08:05.991: INFO: Pod "pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006691294s
STEP: Saw pod success
Aug 20 02:08:05.991: INFO: Pod "pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6" satisfied condition "success or failure"
Aug 20 02:08:05.993: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 02:08:06.011: INFO: Waiting for pod pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6 to disappear
Aug 20 02:08:06.013: INFO: Pod pod-secrets-4167f814-0d59-4b66-8e52-9a37514430f6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:08:06.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8155" for this suite.
Aug 20 02:08:12.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:08:12.134: INFO: namespace secrets-8155 deletion completed in 6.116430239s

• [SLOW TEST:8.201 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:08:12.134: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1097
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 20 02:08:12.224: INFO: Found 0 stateful pods, waiting for 3
Aug 20 02:08:22.228: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:08:22.228: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:08:22.228: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 20 02:08:22.257: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 20 02:08:32.291: INFO: Updating stateful set ss2
Aug 20 02:08:32.297: INFO: Waiting for Pod statefulset-1097/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 20 02:08:42.338: INFO: Found 1 stateful pods, waiting for 3
Aug 20 02:08:52.343: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:08:52.343: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:08:52.343: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 20 02:08:52.370: INFO: Updating stateful set ss2
Aug 20 02:08:52.378: INFO: Waiting for Pod statefulset-1097/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:09:02.406: INFO: Updating stateful set ss2
Aug 20 02:09:02.415: INFO: Waiting for StatefulSet statefulset-1097/ss2 to complete update
Aug 20 02:09:02.415: INFO: Waiting for Pod statefulset-1097/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 20 02:09:12.423: INFO: Deleting all statefulset in ns statefulset-1097
Aug 20 02:09:12.427: INFO: Scaling statefulset ss2 to 0
Aug 20 02:09:32.442: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:09:32.446: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:09:32.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1097" for this suite.
Aug 20 02:09:38.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:09:38.624: INFO: namespace statefulset-1097 deletion completed in 6.155296376s

• [SLOW TEST:86.490 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:09:38.624: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-bh6p
STEP: Creating a pod to test atomic-volume-subpath
Aug 20 02:09:38.698: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bh6p" in namespace "subpath-1093" to be "success or failure"
Aug 20 02:09:38.701: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314571ms
Aug 20 02:09:40.704: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 2.005706008s
Aug 20 02:09:42.708: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 4.009269903s
Aug 20 02:09:44.711: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 6.012547453s
Aug 20 02:09:46.715: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 8.016371975s
Aug 20 02:09:48.718: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 10.020157767s
Aug 20 02:09:50.722: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 12.023653392s
Aug 20 02:09:52.728: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 14.030072221s
Aug 20 02:09:54.732: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 16.0334014s
Aug 20 02:09:56.735: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 18.036641144s
Aug 20 02:09:58.738: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Running", Reason="", readiness=true. Elapsed: 20.040137263s
Aug 20 02:10:00.742: INFO: Pod "pod-subpath-test-projected-bh6p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043727458s
STEP: Saw pod success
Aug 20 02:10:00.742: INFO: Pod "pod-subpath-test-projected-bh6p" satisfied condition "success or failure"
Aug 20 02:10:00.745: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-subpath-test-projected-bh6p container test-container-subpath-projected-bh6p: <nil>
STEP: delete the pod
Aug 20 02:10:00.771: INFO: Waiting for pod pod-subpath-test-projected-bh6p to disappear
Aug 20 02:10:00.775: INFO: Pod pod-subpath-test-projected-bh6p no longer exists
STEP: Deleting pod pod-subpath-test-projected-bh6p
Aug 20 02:10:00.775: INFO: Deleting pod "pod-subpath-test-projected-bh6p" in namespace "subpath-1093"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:10:00.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1093" for this suite.
Aug 20 02:10:06.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:10:06.912: INFO: namespace subpath-1093 deletion completed in 6.128447887s

• [SLOW TEST:28.288 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:10:06.912: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:10:10.982: INFO: Waiting up to 5m0s for pod "client-envvars-18416636-47eb-4382-bb21-374147f21f63" in namespace "pods-3028" to be "success or failure"
Aug 20 02:10:10.985: INFO: Pod "client-envvars-18416636-47eb-4382-bb21-374147f21f63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.736923ms
Aug 20 02:10:12.988: INFO: Pod "client-envvars-18416636-47eb-4382-bb21-374147f21f63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006190663s
STEP: Saw pod success
Aug 20 02:10:12.988: INFO: Pod "client-envvars-18416636-47eb-4382-bb21-374147f21f63" satisfied condition "success or failure"
Aug 20 02:10:12.991: INFO: Trying to get logs from node ip-172-31-23-37 pod client-envvars-18416636-47eb-4382-bb21-374147f21f63 container env3cont: <nil>
STEP: delete the pod
Aug 20 02:10:13.016: INFO: Waiting for pod client-envvars-18416636-47eb-4382-bb21-374147f21f63 to disappear
Aug 20 02:10:13.019: INFO: Pod client-envvars-18416636-47eb-4382-bb21-374147f21f63 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:10:13.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3028" for this suite.
Aug 20 02:10:59.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:10:59.168: INFO: namespace pods-3028 deletion completed in 46.145325501s

• [SLOW TEST:52.256 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:10:59.168: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-38c2f5cb-513c-49b2-815a-37f05941b990
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-38c2f5cb-513c-49b2-815a-37f05941b990
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:11:03.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2419" for this suite.
Aug 20 02:11:25.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:11:25.393: INFO: namespace configmap-2419 deletion completed in 22.132147179s

• [SLOW TEST:26.225 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:11:25.394: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 20 02:11:25.425: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:11:28.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8738" for this suite.
Aug 20 02:11:34.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:11:34.530: INFO: namespace init-container-8738 deletion completed in 6.130299488s

• [SLOW TEST:9.136 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:11:34.530: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:11:40.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4658" for this suite.
Aug 20 02:11:46.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:11:46.357: INFO: namespace watch-4658 deletion completed in 6.220440341s

• [SLOW TEST:11.827 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:11:46.358: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:12:46.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5227" for this suite.
Aug 20 02:13:08.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:13:08.537: INFO: namespace container-probe-5227 deletion completed in 22.12330556s

• [SLOW TEST:82.180 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:13:08.538: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 20 02:13:08.575: INFO: Waiting up to 5m0s for pod "downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5" in namespace "downward-api-8570" to be "success or failure"
Aug 20 02:13:08.578: INFO: Pod "downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110575ms
Aug 20 02:13:10.581: INFO: Pod "downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005704076s
Aug 20 02:13:12.585: INFO: Pod "downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009273861s
STEP: Saw pod success
Aug 20 02:13:12.585: INFO: Pod "downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5" satisfied condition "success or failure"
Aug 20 02:13:12.588: INFO: Trying to get logs from node ip-172-31-23-37 pod downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5 container dapi-container: <nil>
STEP: delete the pod
Aug 20 02:13:12.609: INFO: Waiting for pod downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5 to disappear
Aug 20 02:13:12.612: INFO: Pod downward-api-03bd6ec5-50ad-4e99-9004-63f9ec8436a5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:13:12.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8570" for this suite.
Aug 20 02:13:18.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:13:18.767: INFO: namespace downward-api-8570 deletion completed in 6.150772393s

• [SLOW TEST:10.229 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:13:18.768: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4146
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4146
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4146
Aug 20 02:13:18.828: INFO: Found 0 stateful pods, waiting for 1
Aug 20 02:13:28.832: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 20 02:13:28.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:13:29.209: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:13:29.209: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:13:29.209: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 02:13:29.212: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 20 02:13:39.216: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 02:13:39.216: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:13:39.232: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999752s
Aug 20 02:13:40.236: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997216612s
Aug 20 02:13:41.240: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993617596s
Aug 20 02:13:42.244: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990103174s
Aug 20 02:13:43.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985768713s
Aug 20 02:13:44.252: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981446196s
Aug 20 02:13:45.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977606705s
Aug 20 02:13:46.259: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.974010321s
Aug 20 02:13:47.263: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.970276777s
Aug 20 02:13:48.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 966.325743ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4146
Aug 20 02:13:49.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:13:49.548: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:13:49.548: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:13:49.548: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:13:49.560: INFO: Found 2 stateful pods, waiting for 3
Aug 20 02:13:59.565: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:13:59.565: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:13:59.565: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 20 02:13:59.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:13:59.799: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:13:59.799: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:13:59.799: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 02:13:59.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:14:00.041: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:14:00.041: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:14:00.041: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 02:14:00.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:14:00.312: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:14:00.312: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:14:00.312: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 02:14:00.312: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:14:00.317: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 20 02:14:10.325: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 02:14:10.325: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 02:14:10.325: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 02:14:10.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999783s
Aug 20 02:14:11.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994745767s
Aug 20 02:14:12.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990120101s
Aug 20 02:14:13.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986257251s
Aug 20 02:14:14.354: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982415322s
Aug 20 02:14:15.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978645761s
Aug 20 02:14:16.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975183145s
Aug 20 02:14:17.365: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971237743s
Aug 20 02:14:18.369: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967734698s
Aug 20 02:14:19.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.068183ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4146
Aug 20 02:14:20.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:14:20.594: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:14:20.594: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:14:20.594: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:14:20.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:14:20.798: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:14:20.798: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:14:20.798: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:14:20.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-4146 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:14:21.063: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:14:21.063: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:14:21.063: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:14:21.063: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 20 02:14:41.084: INFO: Deleting all statefulset in ns statefulset-4146
Aug 20 02:14:41.088: INFO: Scaling statefulset ss to 0
Aug 20 02:14:41.098: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:14:41.101: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:14:41.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4146" for this suite.
Aug 20 02:14:47.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:14:47.235: INFO: namespace statefulset-4146 deletion completed in 6.11330648s

• [SLOW TEST:88.467 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:14:47.235: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:14:47.339: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 20 02:14:47.355: INFO: Number of nodes with available pods: 0
Aug 20 02:14:47.355: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:14:48.362: INFO: Number of nodes with available pods: 0
Aug 20 02:14:48.362: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:14:49.363: INFO: Number of nodes with available pods: 3
Aug 20 02:14:49.363: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 20 02:14:49.385: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:49.385: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:49.385: INFO: Wrong image for pod: daemon-set-tvvwv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:50.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:50.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:50.392: INFO: Wrong image for pod: daemon-set-tvvwv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:51.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:51.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:51.392: INFO: Wrong image for pod: daemon-set-tvvwv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:52.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:52.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:52.392: INFO: Wrong image for pod: daemon-set-tvvwv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:52.392: INFO: Pod daemon-set-tvvwv is not available
Aug 20 02:14:53.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:53.392: INFO: Pod daemon-set-6qvgr is not available
Aug 20 02:14:53.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:54.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:54.392: INFO: Pod daemon-set-6qvgr is not available
Aug 20 02:14:54.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:55.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:55.392: INFO: Pod daemon-set-6qvgr is not available
Aug 20 02:14:55.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:56.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:56.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:57.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:57.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:57.392: INFO: Pod daemon-set-jm8pp is not available
Aug 20 02:14:58.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:58.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:58.392: INFO: Pod daemon-set-jm8pp is not available
Aug 20 02:14:59.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:59.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:14:59.392: INFO: Pod daemon-set-jm8pp is not available
Aug 20 02:15:00.393: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:00.393: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:00.393: INFO: Pod daemon-set-jm8pp is not available
Aug 20 02:15:01.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:01.392: INFO: Wrong image for pod: daemon-set-jm8pp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:01.392: INFO: Pod daemon-set-jm8pp is not available
Aug 20 02:15:02.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:02.392: INFO: Pod daemon-set-n7bdg is not available
Aug 20 02:15:03.397: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:03.397: INFO: Pod daemon-set-n7bdg is not available
Aug 20 02:15:04.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:04.392: INFO: Pod daemon-set-n7bdg is not available
Aug 20 02:15:05.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:06.392: INFO: Wrong image for pod: daemon-set-49grc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 20 02:15:06.392: INFO: Pod daemon-set-49grc is not available
Aug 20 02:15:07.391: INFO: Pod daemon-set-8rn87 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 20 02:15:07.403: INFO: Number of nodes with available pods: 2
Aug 20 02:15:07.403: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:15:08.410: INFO: Number of nodes with available pods: 2
Aug 20 02:15:08.410: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:15:09.411: INFO: Number of nodes with available pods: 2
Aug 20 02:15:09.411: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:15:10.410: INFO: Number of nodes with available pods: 3
Aug 20 02:15:10.410: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2204, will wait for the garbage collector to delete the pods
Aug 20 02:15:10.482: INFO: Deleting DaemonSet.extensions daemon-set took: 7.348704ms
Aug 20 02:15:10.782: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.196399ms
Aug 20 02:15:21.785: INFO: Number of nodes with available pods: 0
Aug 20 02:15:21.785: INFO: Number of running nodes: 0, number of available pods: 0
Aug 20 02:15:21.787: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2204/daemonsets","resourceVersion":"4407"},"items":null}

Aug 20 02:15:21.790: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2204/pods","resourceVersion":"4407"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:15:21.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2204" for this suite.
Aug 20 02:15:27.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:15:27.905: INFO: namespace daemonsets-2204 deletion completed in 6.097369753s

• [SLOW TEST:40.670 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:15:27.905: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-10f1af5c-c560-4522-860f-74daaf725e2a
STEP: Creating secret with name secret-projected-all-test-volume-4ee33f4e-8667-4062-91f7-607a9806d0bb
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 20 02:15:27.959: INFO: Waiting up to 5m0s for pod "projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06" in namespace "projected-3910" to be "success or failure"
Aug 20 02:15:27.961: INFO: Pod "projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.163682ms
Aug 20 02:15:29.968: INFO: Pod "projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06": Phase="Running", Reason="", readiness=true. Elapsed: 2.008771604s
Aug 20 02:15:31.971: INFO: Pod "projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012355251s
STEP: Saw pod success
Aug 20 02:15:31.971: INFO: Pod "projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06" satisfied condition "success or failure"
Aug 20 02:15:31.973: INFO: Trying to get logs from node ip-172-31-23-37 pod projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 20 02:15:31.988: INFO: Waiting for pod projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06 to disappear
Aug 20 02:15:31.991: INFO: Pod projected-volume-c0c32cbd-229e-483f-a56b-c2ae3c1fda06 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:15:31.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3910" for this suite.
Aug 20 02:15:38.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:15:38.174: INFO: namespace projected-3910 deletion completed in 6.179398325s

• [SLOW TEST:10.269 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:15:38.175: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 20 02:15:38.214: INFO: Waiting up to 5m0s for pod "downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc" in namespace "downward-api-7056" to be "success or failure"
Aug 20 02:15:38.216: INFO: Pod "downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130925ms
Aug 20 02:15:40.220: INFO: Pod "downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006079254s
STEP: Saw pod success
Aug 20 02:15:40.220: INFO: Pod "downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc" satisfied condition "success or failure"
Aug 20 02:15:40.223: INFO: Trying to get logs from node ip-172-31-23-37 pod downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc container dapi-container: <nil>
STEP: delete the pod
Aug 20 02:15:40.238: INFO: Waiting for pod downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc to disappear
Aug 20 02:15:40.242: INFO: Pod downward-api-069366c4-8d34-48e0-83b8-9d7df4738afc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:15:40.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7056" for this suite.
Aug 20 02:15:46.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:15:46.383: INFO: namespace downward-api-7056 deletion completed in 6.136523088s

• [SLOW TEST:8.208 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:15:46.383: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:15:46.414: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 20 02:15:47.452: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:15:47.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8956" for this suite.
Aug 20 02:15:53.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:15:53.586: INFO: namespace replication-controller-8956 deletion completed in 6.126020596s

• [SLOW TEST:7.203 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:15:53.586: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 20 02:15:56.150: INFO: Successfully updated pod "labelsupdatecfb80e7c-c638-477d-b740-e066636af6a0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:15:58.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4907" for this suite.
Aug 20 02:16:20.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:16:20.369: INFO: namespace projected-4907 deletion completed in 22.201808176s

• [SLOW TEST:26.783 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:16:20.370: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1631
I0820 02:16:20.407947      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1631, replica count: 1
I0820 02:16:21.458428      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0820 02:16:22.458658      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 20 02:16:22.570: INFO: Created: latency-svc-2l8zb
Aug 20 02:16:22.578: INFO: Got endpoints: latency-svc-2l8zb [19.205871ms]
Aug 20 02:16:22.590: INFO: Created: latency-svc-h4rrd
Aug 20 02:16:22.595: INFO: Created: latency-svc-z2twb
Aug 20 02:16:22.598: INFO: Got endpoints: latency-svc-h4rrd [20.426429ms]
Aug 20 02:16:22.609: INFO: Created: latency-svc-b7xqk
Aug 20 02:16:22.610: INFO: Got endpoints: latency-svc-b7xqk [31.754939ms]
Aug 20 02:16:22.610: INFO: Got endpoints: latency-svc-z2twb [31.710225ms]
Aug 20 02:16:22.616: INFO: Created: latency-svc-s8r46
Aug 20 02:16:22.625: INFO: Got endpoints: latency-svc-s8r46 [46.699004ms]
Aug 20 02:16:22.627: INFO: Created: latency-svc-cg7wf
Aug 20 02:16:22.627: INFO: Got endpoints: latency-svc-cg7wf [48.964265ms]
Aug 20 02:16:22.633: INFO: Created: latency-svc-xkt45
Aug 20 02:16:22.635: INFO: Created: latency-svc-z9k62
Aug 20 02:16:22.639: INFO: Got endpoints: latency-svc-xkt45 [60.78754ms]
Aug 20 02:16:22.642: INFO: Created: latency-svc-8984p
Aug 20 02:16:22.645: INFO: Created: latency-svc-n6ncd
Aug 20 02:16:22.647: INFO: Got endpoints: latency-svc-z9k62 [68.53132ms]
Aug 20 02:16:22.647: INFO: Got endpoints: latency-svc-8984p [69.276719ms]
Aug 20 02:16:22.653: INFO: Created: latency-svc-7vgjv
Aug 20 02:16:22.659: INFO: Created: latency-svc-kk8x6
Aug 20 02:16:22.659: INFO: Got endpoints: latency-svc-n6ncd [80.651715ms]
Aug 20 02:16:22.664: INFO: Created: latency-svc-rtp4m
Aug 20 02:16:22.664: INFO: Got endpoints: latency-svc-kk8x6 [85.549724ms]
Aug 20 02:16:22.664: INFO: Got endpoints: latency-svc-7vgjv [85.137141ms]
Aug 20 02:16:22.670: INFO: Created: latency-svc-cttkl
Aug 20 02:16:22.670: INFO: Got endpoints: latency-svc-rtp4m [92.224924ms]
Aug 20 02:16:22.675: INFO: Created: latency-svc-pxrlm
Aug 20 02:16:22.677: INFO: Got endpoints: latency-svc-cttkl [99.266374ms]
Aug 20 02:16:22.681: INFO: Created: latency-svc-zwh9w
Aug 20 02:16:22.681: INFO: Got endpoints: latency-svc-pxrlm [103.189229ms]
Aug 20 02:16:22.687: INFO: Got endpoints: latency-svc-zwh9w [108.965585ms]
Aug 20 02:16:22.695: INFO: Created: latency-svc-gwvwm
Aug 20 02:16:22.695: INFO: Got endpoints: latency-svc-gwvwm [96.459624ms]
Aug 20 02:16:22.703: INFO: Created: latency-svc-psxwv
Aug 20 02:16:22.703: INFO: Got endpoints: latency-svc-psxwv [93.546654ms]
Aug 20 02:16:22.705: INFO: Created: latency-svc-b9zc2
Aug 20 02:16:22.710: INFO: Got endpoints: latency-svc-b9zc2 [100.120933ms]
Aug 20 02:16:22.713: INFO: Created: latency-svc-kv8tq
Aug 20 02:16:22.720: INFO: Created: latency-svc-8p69s
Aug 20 02:16:22.721: INFO: Got endpoints: latency-svc-kv8tq [95.816795ms]
Aug 20 02:16:22.728: INFO: Got endpoints: latency-svc-8p69s [101.141895ms]
Aug 20 02:16:22.729: INFO: Created: latency-svc-4cg8l
Aug 20 02:16:22.733: INFO: Got endpoints: latency-svc-4cg8l [94.3808ms]
Aug 20 02:16:22.743: INFO: Created: latency-svc-hf6l5
Aug 20 02:16:22.744: INFO: Got endpoints: latency-svc-hf6l5 [97.514282ms]
Aug 20 02:16:22.745: INFO: Created: latency-svc-vq8c4
Aug 20 02:16:22.747: INFO: Got endpoints: latency-svc-vq8c4 [99.449871ms]
Aug 20 02:16:22.768: INFO: Created: latency-svc-ctdpb
Aug 20 02:16:22.768: INFO: Created: latency-svc-qbrv2
Aug 20 02:16:22.769: INFO: Created: latency-svc-84f2d
Aug 20 02:16:22.774: INFO: Got endpoints: latency-svc-qbrv2 [26.936794ms]
Aug 20 02:16:22.774: INFO: Got endpoints: latency-svc-ctdpb [114.681775ms]
Aug 20 02:16:22.776: INFO: Created: latency-svc-6lwm9
Aug 20 02:16:22.779: INFO: Got endpoints: latency-svc-84f2d [115.475879ms]
Aug 20 02:16:22.780: INFO: Got endpoints: latency-svc-6lwm9 [116.029666ms]
Aug 20 02:16:22.786: INFO: Created: latency-svc-p2wvn
Aug 20 02:16:22.791: INFO: Got endpoints: latency-svc-p2wvn [121.257539ms]
Aug 20 02:16:22.805: INFO: Created: latency-svc-hzrg7
Aug 20 02:16:22.806: INFO: Got endpoints: latency-svc-hzrg7 [128.732237ms]
Aug 20 02:16:22.812: INFO: Created: latency-svc-qrk8q
Aug 20 02:16:22.821: INFO: Got endpoints: latency-svc-qrk8q [139.402ms]
Aug 20 02:16:22.822: INFO: Created: latency-svc-qrqpw
Aug 20 02:16:22.827: INFO: Created: latency-svc-7kzwm
Aug 20 02:16:22.829: INFO: Got endpoints: latency-svc-qrqpw [141.643813ms]
Aug 20 02:16:22.833: INFO: Got endpoints: latency-svc-7kzwm [138.496066ms]
Aug 20 02:16:22.836: INFO: Created: latency-svc-5gvq5
Aug 20 02:16:22.843: INFO: Got endpoints: latency-svc-5gvq5 [139.428282ms]
Aug 20 02:16:22.849: INFO: Created: latency-svc-8h4pn
Aug 20 02:16:22.851: INFO: Got endpoints: latency-svc-8h4pn [141.359608ms]
Aug 20 02:16:22.856: INFO: Created: latency-svc-vggxm
Aug 20 02:16:22.863: INFO: Created: latency-svc-znzpj
Aug 20 02:16:22.866: INFO: Created: latency-svc-2mngw
Aug 20 02:16:22.870: INFO: Created: latency-svc-8sz8f
Aug 20 02:16:22.875: INFO: Created: latency-svc-mjgf8
Aug 20 02:16:22.877: INFO: Got endpoints: latency-svc-vggxm [156.02965ms]
Aug 20 02:16:22.890: INFO: Created: latency-svc-9wjzg
Aug 20 02:16:22.893: INFO: Created: latency-svc-krfs9
Aug 20 02:16:22.901: INFO: Created: latency-svc-8s92g
Aug 20 02:16:22.906: INFO: Created: latency-svc-72j7v
Aug 20 02:16:22.910: INFO: Created: latency-svc-mfzvn
Aug 20 02:16:22.915: INFO: Created: latency-svc-tvct2
Aug 20 02:16:22.920: INFO: Created: latency-svc-jp6nz
Aug 20 02:16:22.924: INFO: Created: latency-svc-fvznq
Aug 20 02:16:22.926: INFO: Got endpoints: latency-svc-znzpj [197.416014ms]
Aug 20 02:16:22.931: INFO: Created: latency-svc-t6mxq
Aug 20 02:16:22.941: INFO: Created: latency-svc-xv44d
Aug 20 02:16:22.951: INFO: Created: latency-svc-2gf5n
Aug 20 02:16:22.958: INFO: Created: latency-svc-jwmbd
Aug 20 02:16:22.979: INFO: Got endpoints: latency-svc-2mngw [246.006853ms]
Aug 20 02:16:22.987: INFO: Created: latency-svc-trfj9
Aug 20 02:16:23.027: INFO: Got endpoints: latency-svc-8sz8f [282.767095ms]
Aug 20 02:16:23.036: INFO: Created: latency-svc-gw772
Aug 20 02:16:23.076: INFO: Got endpoints: latency-svc-mjgf8 [302.24603ms]
Aug 20 02:16:23.085: INFO: Created: latency-svc-sdpj8
Aug 20 02:16:23.126: INFO: Got endpoints: latency-svc-krfs9 [352.59843ms]
Aug 20 02:16:23.138: INFO: Created: latency-svc-4b5c7
Aug 20 02:16:23.176: INFO: Got endpoints: latency-svc-9wjzg [396.499504ms]
Aug 20 02:16:23.184: INFO: Created: latency-svc-w88n8
Aug 20 02:16:23.225: INFO: Got endpoints: latency-svc-8s92g [445.714827ms]
Aug 20 02:16:23.239: INFO: Created: latency-svc-xfsd5
Aug 20 02:16:23.275: INFO: Got endpoints: latency-svc-72j7v [484.188115ms]
Aug 20 02:16:23.285: INFO: Created: latency-svc-jd58q
Aug 20 02:16:23.326: INFO: Got endpoints: latency-svc-mfzvn [520.095624ms]
Aug 20 02:16:23.337: INFO: Created: latency-svc-c5fmq
Aug 20 02:16:23.375: INFO: Got endpoints: latency-svc-tvct2 [554.309184ms]
Aug 20 02:16:23.387: INFO: Created: latency-svc-cq6jx
Aug 20 02:16:23.426: INFO: Got endpoints: latency-svc-jp6nz [596.64514ms]
Aug 20 02:16:23.433: INFO: Created: latency-svc-62sd4
Aug 20 02:16:23.476: INFO: Got endpoints: latency-svc-fvznq [643.215249ms]
Aug 20 02:16:23.485: INFO: Created: latency-svc-g7vwk
Aug 20 02:16:23.525: INFO: Got endpoints: latency-svc-t6mxq [682.573928ms]
Aug 20 02:16:23.533: INFO: Created: latency-svc-4zddc
Aug 20 02:16:23.577: INFO: Got endpoints: latency-svc-xv44d [725.923172ms]
Aug 20 02:16:23.593: INFO: Created: latency-svc-9tzcm
Aug 20 02:16:23.630: INFO: Got endpoints: latency-svc-2gf5n [752.885917ms]
Aug 20 02:16:23.638: INFO: Created: latency-svc-6d5mq
Aug 20 02:16:23.676: INFO: Got endpoints: latency-svc-jwmbd [749.943393ms]
Aug 20 02:16:23.686: INFO: Created: latency-svc-qqqzl
Aug 20 02:16:23.725: INFO: Got endpoints: latency-svc-trfj9 [745.988139ms]
Aug 20 02:16:23.734: INFO: Created: latency-svc-bmwbw
Aug 20 02:16:23.777: INFO: Got endpoints: latency-svc-gw772 [750.273794ms]
Aug 20 02:16:23.785: INFO: Created: latency-svc-7xxs8
Aug 20 02:16:23.829: INFO: Got endpoints: latency-svc-sdpj8 [752.950359ms]
Aug 20 02:16:23.837: INFO: Created: latency-svc-8t9xg
Aug 20 02:16:23.877: INFO: Got endpoints: latency-svc-4b5c7 [750.400011ms]
Aug 20 02:16:23.893: INFO: Created: latency-svc-djnk8
Aug 20 02:16:23.929: INFO: Got endpoints: latency-svc-w88n8 [753.390781ms]
Aug 20 02:16:23.938: INFO: Created: latency-svc-zjvf9
Aug 20 02:16:23.978: INFO: Got endpoints: latency-svc-xfsd5 [752.467714ms]
Aug 20 02:16:23.986: INFO: Created: latency-svc-jvf7p
Aug 20 02:16:24.025: INFO: Got endpoints: latency-svc-jd58q [749.744449ms]
Aug 20 02:16:24.033: INFO: Created: latency-svc-f4smm
Aug 20 02:16:24.077: INFO: Got endpoints: latency-svc-c5fmq [751.36161ms]
Aug 20 02:16:24.086: INFO: Created: latency-svc-cln8q
Aug 20 02:16:24.126: INFO: Got endpoints: latency-svc-cq6jx [750.886772ms]
Aug 20 02:16:24.134: INFO: Created: latency-svc-zrw2t
Aug 20 02:16:24.177: INFO: Got endpoints: latency-svc-62sd4 [751.326675ms]
Aug 20 02:16:24.187: INFO: Created: latency-svc-9phrl
Aug 20 02:16:24.241: INFO: Got endpoints: latency-svc-g7vwk [764.493716ms]
Aug 20 02:16:24.252: INFO: Created: latency-svc-mfhqc
Aug 20 02:16:24.276: INFO: Got endpoints: latency-svc-4zddc [750.951827ms]
Aug 20 02:16:24.287: INFO: Created: latency-svc-d5fhf
Aug 20 02:16:24.325: INFO: Got endpoints: latency-svc-9tzcm [748.115629ms]
Aug 20 02:16:24.341: INFO: Created: latency-svc-5zmnj
Aug 20 02:16:24.375: INFO: Got endpoints: latency-svc-6d5mq [745.37436ms]
Aug 20 02:16:24.384: INFO: Created: latency-svc-wmngn
Aug 20 02:16:24.431: INFO: Got endpoints: latency-svc-qqqzl [754.967547ms]
Aug 20 02:16:24.441: INFO: Created: latency-svc-mdmw8
Aug 20 02:16:24.478: INFO: Got endpoints: latency-svc-bmwbw [752.503901ms]
Aug 20 02:16:24.486: INFO: Created: latency-svc-v72kn
Aug 20 02:16:24.525: INFO: Got endpoints: latency-svc-7xxs8 [747.940388ms]
Aug 20 02:16:24.533: INFO: Created: latency-svc-5cg9m
Aug 20 02:16:24.577: INFO: Got endpoints: latency-svc-8t9xg [747.593648ms]
Aug 20 02:16:24.584: INFO: Created: latency-svc-82bbp
Aug 20 02:16:24.625: INFO: Got endpoints: latency-svc-djnk8 [748.129034ms]
Aug 20 02:16:24.632: INFO: Created: latency-svc-b6t9d
Aug 20 02:16:24.676: INFO: Got endpoints: latency-svc-zjvf9 [747.217911ms]
Aug 20 02:16:24.684: INFO: Created: latency-svc-q7dnk
Aug 20 02:16:24.726: INFO: Got endpoints: latency-svc-jvf7p [747.81901ms]
Aug 20 02:16:24.734: INFO: Created: latency-svc-768bv
Aug 20 02:16:24.776: INFO: Got endpoints: latency-svc-f4smm [750.68835ms]
Aug 20 02:16:24.785: INFO: Created: latency-svc-v7z8j
Aug 20 02:16:24.825: INFO: Got endpoints: latency-svc-cln8q [747.908695ms]
Aug 20 02:16:24.834: INFO: Created: latency-svc-ddlgj
Aug 20 02:16:24.881: INFO: Got endpoints: latency-svc-zrw2t [754.607915ms]
Aug 20 02:16:24.889: INFO: Created: latency-svc-qfdpq
Aug 20 02:16:24.926: INFO: Got endpoints: latency-svc-9phrl [749.037854ms]
Aug 20 02:16:24.934: INFO: Created: latency-svc-fvb7g
Aug 20 02:16:24.977: INFO: Got endpoints: latency-svc-mfhqc [736.112944ms]
Aug 20 02:16:24.985: INFO: Created: latency-svc-57tsg
Aug 20 02:16:25.027: INFO: Got endpoints: latency-svc-d5fhf [750.224582ms]
Aug 20 02:16:25.036: INFO: Created: latency-svc-9hwsd
Aug 20 02:16:25.076: INFO: Got endpoints: latency-svc-5zmnj [750.486523ms]
Aug 20 02:16:25.084: INFO: Created: latency-svc-4f7zg
Aug 20 02:16:25.127: INFO: Got endpoints: latency-svc-wmngn [751.464717ms]
Aug 20 02:16:25.134: INFO: Created: latency-svc-dqfrg
Aug 20 02:16:25.176: INFO: Got endpoints: latency-svc-mdmw8 [745.287571ms]
Aug 20 02:16:25.185: INFO: Created: latency-svc-fpcz7
Aug 20 02:16:25.226: INFO: Got endpoints: latency-svc-v72kn [747.882845ms]
Aug 20 02:16:25.235: INFO: Created: latency-svc-tjcnl
Aug 20 02:16:25.275: INFO: Got endpoints: latency-svc-5cg9m [749.543034ms]
Aug 20 02:16:25.283: INFO: Created: latency-svc-nzdtn
Aug 20 02:16:25.326: INFO: Got endpoints: latency-svc-82bbp [749.728361ms]
Aug 20 02:16:25.335: INFO: Created: latency-svc-cmzmr
Aug 20 02:16:25.376: INFO: Got endpoints: latency-svc-b6t9d [750.444955ms]
Aug 20 02:16:25.383: INFO: Created: latency-svc-4zczm
Aug 20 02:16:25.425: INFO: Got endpoints: latency-svc-q7dnk [748.582375ms]
Aug 20 02:16:25.434: INFO: Created: latency-svc-bhprx
Aug 20 02:16:25.476: INFO: Got endpoints: latency-svc-768bv [750.449464ms]
Aug 20 02:16:25.484: INFO: Created: latency-svc-wqlr4
Aug 20 02:16:25.525: INFO: Got endpoints: latency-svc-v7z8j [749.16178ms]
Aug 20 02:16:25.534: INFO: Created: latency-svc-nmm8x
Aug 20 02:16:25.576: INFO: Got endpoints: latency-svc-ddlgj [750.146282ms]
Aug 20 02:16:25.584: INFO: Created: latency-svc-m727c
Aug 20 02:16:25.626: INFO: Got endpoints: latency-svc-qfdpq [745.211336ms]
Aug 20 02:16:25.633: INFO: Created: latency-svc-tlhds
Aug 20 02:16:25.676: INFO: Got endpoints: latency-svc-fvb7g [749.792225ms]
Aug 20 02:16:25.684: INFO: Created: latency-svc-ntp7j
Aug 20 02:16:25.725: INFO: Got endpoints: latency-svc-57tsg [747.83187ms]
Aug 20 02:16:25.733: INFO: Created: latency-svc-4z7v7
Aug 20 02:16:25.776: INFO: Got endpoints: latency-svc-9hwsd [749.109724ms]
Aug 20 02:16:25.784: INFO: Created: latency-svc-pg5zb
Aug 20 02:16:25.825: INFO: Got endpoints: latency-svc-4f7zg [749.395078ms]
Aug 20 02:16:25.833: INFO: Created: latency-svc-xb6rt
Aug 20 02:16:25.875: INFO: Got endpoints: latency-svc-dqfrg [748.765579ms]
Aug 20 02:16:25.883: INFO: Created: latency-svc-bkbx4
Aug 20 02:16:25.925: INFO: Got endpoints: latency-svc-fpcz7 [749.346802ms]
Aug 20 02:16:25.934: INFO: Created: latency-svc-qvg8v
Aug 20 02:16:25.976: INFO: Got endpoints: latency-svc-tjcnl [749.794983ms]
Aug 20 02:16:25.984: INFO: Created: latency-svc-gstq4
Aug 20 02:16:26.026: INFO: Got endpoints: latency-svc-nzdtn [750.646237ms]
Aug 20 02:16:26.035: INFO: Created: latency-svc-q5m47
Aug 20 02:16:26.076: INFO: Got endpoints: latency-svc-cmzmr [749.192344ms]
Aug 20 02:16:26.084: INFO: Created: latency-svc-j72tl
Aug 20 02:16:26.125: INFO: Got endpoints: latency-svc-4zczm [749.489654ms]
Aug 20 02:16:26.132: INFO: Created: latency-svc-77vn5
Aug 20 02:16:26.176: INFO: Got endpoints: latency-svc-bhprx [750.873129ms]
Aug 20 02:16:26.184: INFO: Created: latency-svc-2q9fl
Aug 20 02:16:26.225: INFO: Got endpoints: latency-svc-wqlr4 [748.675383ms]
Aug 20 02:16:26.234: INFO: Created: latency-svc-zrs7s
Aug 20 02:16:26.275: INFO: Got endpoints: latency-svc-nmm8x [749.9342ms]
Aug 20 02:16:26.283: INFO: Created: latency-svc-qp5r4
Aug 20 02:16:26.326: INFO: Got endpoints: latency-svc-m727c [749.961275ms]
Aug 20 02:16:26.333: INFO: Created: latency-svc-qjdsh
Aug 20 02:16:26.376: INFO: Got endpoints: latency-svc-tlhds [749.721951ms]
Aug 20 02:16:26.385: INFO: Created: latency-svc-65vbb
Aug 20 02:16:26.425: INFO: Got endpoints: latency-svc-ntp7j [749.503641ms]
Aug 20 02:16:26.433: INFO: Created: latency-svc-645v2
Aug 20 02:16:26.476: INFO: Got endpoints: latency-svc-4z7v7 [751.349406ms]
Aug 20 02:16:26.486: INFO: Created: latency-svc-df9pd
Aug 20 02:16:26.525: INFO: Got endpoints: latency-svc-pg5zb [749.016533ms]
Aug 20 02:16:26.533: INFO: Created: latency-svc-gr85k
Aug 20 02:16:26.575: INFO: Got endpoints: latency-svc-xb6rt [749.978229ms]
Aug 20 02:16:26.584: INFO: Created: latency-svc-lrl8m
Aug 20 02:16:26.626: INFO: Got endpoints: latency-svc-bkbx4 [750.052065ms]
Aug 20 02:16:26.634: INFO: Created: latency-svc-trchg
Aug 20 02:16:26.675: INFO: Got endpoints: latency-svc-qvg8v [750.049939ms]
Aug 20 02:16:26.683: INFO: Created: latency-svc-6kk58
Aug 20 02:16:26.725: INFO: Got endpoints: latency-svc-gstq4 [749.102727ms]
Aug 20 02:16:26.733: INFO: Created: latency-svc-nkl8s
Aug 20 02:16:26.776: INFO: Got endpoints: latency-svc-q5m47 [750.661556ms]
Aug 20 02:16:26.785: INFO: Created: latency-svc-5x7m9
Aug 20 02:16:26.825: INFO: Got endpoints: latency-svc-j72tl [749.582439ms]
Aug 20 02:16:26.834: INFO: Created: latency-svc-hsqlw
Aug 20 02:16:26.875: INFO: Got endpoints: latency-svc-77vn5 [750.036207ms]
Aug 20 02:16:26.884: INFO: Created: latency-svc-gk8k2
Aug 20 02:16:26.926: INFO: Got endpoints: latency-svc-2q9fl [750.019655ms]
Aug 20 02:16:26.935: INFO: Created: latency-svc-8wpwv
Aug 20 02:16:26.976: INFO: Got endpoints: latency-svc-zrs7s [750.906842ms]
Aug 20 02:16:26.984: INFO: Created: latency-svc-72tx2
Aug 20 02:16:27.033: INFO: Got endpoints: latency-svc-qp5r4 [757.897491ms]
Aug 20 02:16:27.041: INFO: Created: latency-svc-tldbt
Aug 20 02:16:27.076: INFO: Got endpoints: latency-svc-qjdsh [750.569074ms]
Aug 20 02:16:27.085: INFO: Created: latency-svc-sjw2l
Aug 20 02:16:27.128: INFO: Got endpoints: latency-svc-65vbb [751.746266ms]
Aug 20 02:16:27.138: INFO: Created: latency-svc-g59bl
Aug 20 02:16:27.175: INFO: Got endpoints: latency-svc-645v2 [749.968252ms]
Aug 20 02:16:27.183: INFO: Created: latency-svc-4dsjs
Aug 20 02:16:27.231: INFO: Got endpoints: latency-svc-df9pd [754.123607ms]
Aug 20 02:16:27.240: INFO: Created: latency-svc-zqnzz
Aug 20 02:16:27.275: INFO: Got endpoints: latency-svc-gr85k [750.157645ms]
Aug 20 02:16:27.282: INFO: Created: latency-svc-57f4c
Aug 20 02:16:27.326: INFO: Got endpoints: latency-svc-lrl8m [750.292746ms]
Aug 20 02:16:27.333: INFO: Created: latency-svc-f8dd9
Aug 20 02:16:27.376: INFO: Got endpoints: latency-svc-trchg [749.915723ms]
Aug 20 02:16:27.384: INFO: Created: latency-svc-gxkjw
Aug 20 02:16:27.425: INFO: Got endpoints: latency-svc-6kk58 [749.284245ms]
Aug 20 02:16:27.432: INFO: Created: latency-svc-ssp59
Aug 20 02:16:27.475: INFO: Got endpoints: latency-svc-nkl8s [750.466158ms]
Aug 20 02:16:27.484: INFO: Created: latency-svc-6lx68
Aug 20 02:16:27.525: INFO: Got endpoints: latency-svc-5x7m9 [748.959968ms]
Aug 20 02:16:27.535: INFO: Created: latency-svc-p5jd9
Aug 20 02:16:27.575: INFO: Got endpoints: latency-svc-hsqlw [749.893373ms]
Aug 20 02:16:27.583: INFO: Created: latency-svc-dczz5
Aug 20 02:16:27.625: INFO: Got endpoints: latency-svc-gk8k2 [750.226573ms]
Aug 20 02:16:27.634: INFO: Created: latency-svc-wjvq6
Aug 20 02:16:27.675: INFO: Got endpoints: latency-svc-8wpwv [749.452922ms]
Aug 20 02:16:27.684: INFO: Created: latency-svc-7cw9g
Aug 20 02:16:27.725: INFO: Got endpoints: latency-svc-72tx2 [749.054472ms]
Aug 20 02:16:27.733: INFO: Created: latency-svc-b5zjg
Aug 20 02:16:27.777: INFO: Got endpoints: latency-svc-tldbt [743.425471ms]
Aug 20 02:16:27.784: INFO: Created: latency-svc-tql6q
Aug 20 02:16:27.826: INFO: Got endpoints: latency-svc-sjw2l [750.195152ms]
Aug 20 02:16:27.836: INFO: Created: latency-svc-zmqm6
Aug 20 02:16:27.876: INFO: Got endpoints: latency-svc-g59bl [747.755579ms]
Aug 20 02:16:27.883: INFO: Created: latency-svc-hvckn
Aug 20 02:16:27.925: INFO: Got endpoints: latency-svc-4dsjs [749.603451ms]
Aug 20 02:16:27.934: INFO: Created: latency-svc-hx78m
Aug 20 02:16:27.976: INFO: Got endpoints: latency-svc-zqnzz [745.033913ms]
Aug 20 02:16:27.988: INFO: Created: latency-svc-z7lr8
Aug 20 02:16:28.025: INFO: Got endpoints: latency-svc-57f4c [750.014251ms]
Aug 20 02:16:28.033: INFO: Created: latency-svc-zj4jv
Aug 20 02:16:28.075: INFO: Got endpoints: latency-svc-f8dd9 [749.649669ms]
Aug 20 02:16:28.085: INFO: Created: latency-svc-cr7lh
Aug 20 02:16:28.126: INFO: Got endpoints: latency-svc-gxkjw [750.001526ms]
Aug 20 02:16:28.133: INFO: Created: latency-svc-mtjx5
Aug 20 02:16:28.175: INFO: Got endpoints: latency-svc-ssp59 [750.444228ms]
Aug 20 02:16:28.183: INFO: Created: latency-svc-26w8q
Aug 20 02:16:28.225: INFO: Got endpoints: latency-svc-6lx68 [749.694251ms]
Aug 20 02:16:28.234: INFO: Created: latency-svc-p6qgs
Aug 20 02:16:28.275: INFO: Got endpoints: latency-svc-p5jd9 [749.789963ms]
Aug 20 02:16:28.283: INFO: Created: latency-svc-24qw6
Aug 20 02:16:28.325: INFO: Got endpoints: latency-svc-dczz5 [750.005535ms]
Aug 20 02:16:28.333: INFO: Created: latency-svc-4522c
Aug 20 02:16:28.376: INFO: Got endpoints: latency-svc-wjvq6 [750.380361ms]
Aug 20 02:16:28.384: INFO: Created: latency-svc-km9vj
Aug 20 02:16:28.425: INFO: Got endpoints: latency-svc-7cw9g [749.695405ms]
Aug 20 02:16:28.433: INFO: Created: latency-svc-t2xfz
Aug 20 02:16:28.475: INFO: Got endpoints: latency-svc-b5zjg [749.711866ms]
Aug 20 02:16:28.483: INFO: Created: latency-svc-t5s9v
Aug 20 02:16:28.526: INFO: Got endpoints: latency-svc-tql6q [749.749117ms]
Aug 20 02:16:28.534: INFO: Created: latency-svc-lpj7j
Aug 20 02:16:28.575: INFO: Got endpoints: latency-svc-zmqm6 [749.029804ms]
Aug 20 02:16:28.593: INFO: Created: latency-svc-w2lzx
Aug 20 02:16:28.625: INFO: Got endpoints: latency-svc-hvckn [749.18447ms]
Aug 20 02:16:28.633: INFO: Created: latency-svc-jcxm5
Aug 20 02:16:28.675: INFO: Got endpoints: latency-svc-hx78m [750.321696ms]
Aug 20 02:16:28.684: INFO: Created: latency-svc-qndhj
Aug 20 02:16:28.725: INFO: Got endpoints: latency-svc-z7lr8 [749.694627ms]
Aug 20 02:16:28.733: INFO: Created: latency-svc-8czbx
Aug 20 02:16:28.776: INFO: Got endpoints: latency-svc-zj4jv [751.151587ms]
Aug 20 02:16:28.784: INFO: Created: latency-svc-p558n
Aug 20 02:16:28.826: INFO: Got endpoints: latency-svc-cr7lh [750.284164ms]
Aug 20 02:16:28.834: INFO: Created: latency-svc-pqfkv
Aug 20 02:16:28.876: INFO: Got endpoints: latency-svc-mtjx5 [750.034232ms]
Aug 20 02:16:28.887: INFO: Created: latency-svc-fwk8s
Aug 20 02:16:28.926: INFO: Got endpoints: latency-svc-26w8q [750.88417ms]
Aug 20 02:16:28.934: INFO: Created: latency-svc-wtm7v
Aug 20 02:16:28.975: INFO: Got endpoints: latency-svc-p6qgs [750.31453ms]
Aug 20 02:16:28.984: INFO: Created: latency-svc-wwrp5
Aug 20 02:16:29.027: INFO: Got endpoints: latency-svc-24qw6 [751.699589ms]
Aug 20 02:16:29.035: INFO: Created: latency-svc-hjbst
Aug 20 02:16:29.076: INFO: Got endpoints: latency-svc-4522c [750.85292ms]
Aug 20 02:16:29.084: INFO: Created: latency-svc-d5696
Aug 20 02:16:29.125: INFO: Got endpoints: latency-svc-km9vj [748.661549ms]
Aug 20 02:16:29.132: INFO: Created: latency-svc-lmdhq
Aug 20 02:16:29.175: INFO: Got endpoints: latency-svc-t2xfz [750.004776ms]
Aug 20 02:16:29.184: INFO: Created: latency-svc-q822n
Aug 20 02:16:29.225: INFO: Got endpoints: latency-svc-t5s9v [750.408173ms]
Aug 20 02:16:29.234: INFO: Created: latency-svc-m5z6z
Aug 20 02:16:29.275: INFO: Got endpoints: latency-svc-lpj7j [748.654972ms]
Aug 20 02:16:29.283: INFO: Created: latency-svc-wr4hc
Aug 20 02:16:29.325: INFO: Got endpoints: latency-svc-w2lzx [749.801671ms]
Aug 20 02:16:29.334: INFO: Created: latency-svc-gvh4q
Aug 20 02:16:29.376: INFO: Got endpoints: latency-svc-jcxm5 [750.749309ms]
Aug 20 02:16:29.384: INFO: Created: latency-svc-xtwq7
Aug 20 02:16:29.425: INFO: Got endpoints: latency-svc-qndhj [749.97154ms]
Aug 20 02:16:29.432: INFO: Created: latency-svc-5ncgw
Aug 20 02:16:29.476: INFO: Got endpoints: latency-svc-8czbx [750.419051ms]
Aug 20 02:16:29.485: INFO: Created: latency-svc-jvsdz
Aug 20 02:16:29.525: INFO: Got endpoints: latency-svc-p558n [748.936469ms]
Aug 20 02:16:29.534: INFO: Created: latency-svc-5mhs7
Aug 20 02:16:29.576: INFO: Got endpoints: latency-svc-pqfkv [750.209428ms]
Aug 20 02:16:29.584: INFO: Created: latency-svc-zplpx
Aug 20 02:16:29.626: INFO: Got endpoints: latency-svc-fwk8s [749.991743ms]
Aug 20 02:16:29.633: INFO: Created: latency-svc-xpstj
Aug 20 02:16:29.676: INFO: Got endpoints: latency-svc-wtm7v [749.243405ms]
Aug 20 02:16:29.683: INFO: Created: latency-svc-5689t
Aug 20 02:16:29.725: INFO: Got endpoints: latency-svc-wwrp5 [749.734377ms]
Aug 20 02:16:29.733: INFO: Created: latency-svc-l2xsl
Aug 20 02:16:29.777: INFO: Got endpoints: latency-svc-hjbst [749.567905ms]
Aug 20 02:16:29.785: INFO: Created: latency-svc-682wj
Aug 20 02:16:29.827: INFO: Got endpoints: latency-svc-d5696 [750.24363ms]
Aug 20 02:16:29.835: INFO: Created: latency-svc-ljmwr
Aug 20 02:16:29.875: INFO: Got endpoints: latency-svc-lmdhq [750.762779ms]
Aug 20 02:16:29.883: INFO: Created: latency-svc-s27gb
Aug 20 02:16:29.926: INFO: Got endpoints: latency-svc-q822n [751.14388ms]
Aug 20 02:16:29.935: INFO: Created: latency-svc-8kgsb
Aug 20 02:16:29.975: INFO: Got endpoints: latency-svc-m5z6z [749.956625ms]
Aug 20 02:16:29.983: INFO: Created: latency-svc-cljgl
Aug 20 02:16:30.026: INFO: Got endpoints: latency-svc-wr4hc [750.880359ms]
Aug 20 02:16:30.036: INFO: Created: latency-svc-wfjxc
Aug 20 02:16:30.076: INFO: Got endpoints: latency-svc-gvh4q [750.540344ms]
Aug 20 02:16:30.085: INFO: Created: latency-svc-jrgmb
Aug 20 02:16:30.126: INFO: Got endpoints: latency-svc-xtwq7 [750.529224ms]
Aug 20 02:16:30.135: INFO: Created: latency-svc-9cdx5
Aug 20 02:16:30.176: INFO: Got endpoints: latency-svc-5ncgw [750.771764ms]
Aug 20 02:16:30.186: INFO: Created: latency-svc-nv4c7
Aug 20 02:16:30.225: INFO: Got endpoints: latency-svc-jvsdz [749.508748ms]
Aug 20 02:16:30.234: INFO: Created: latency-svc-mmdw5
Aug 20 02:16:30.275: INFO: Got endpoints: latency-svc-5mhs7 [750.073238ms]
Aug 20 02:16:30.284: INFO: Created: latency-svc-vvshd
Aug 20 02:16:30.326: INFO: Got endpoints: latency-svc-zplpx [749.57588ms]
Aug 20 02:16:30.334: INFO: Created: latency-svc-6kddv
Aug 20 02:16:30.376: INFO: Got endpoints: latency-svc-xpstj [750.724964ms]
Aug 20 02:16:30.386: INFO: Created: latency-svc-bf8rm
Aug 20 02:16:30.425: INFO: Got endpoints: latency-svc-5689t [749.933403ms]
Aug 20 02:16:30.476: INFO: Got endpoints: latency-svc-l2xsl [750.508189ms]
Aug 20 02:16:30.529: INFO: Got endpoints: latency-svc-682wj [752.379283ms]
Aug 20 02:16:30.575: INFO: Got endpoints: latency-svc-ljmwr [748.813044ms]
Aug 20 02:16:30.627: INFO: Got endpoints: latency-svc-s27gb [751.383172ms]
Aug 20 02:16:30.677: INFO: Got endpoints: latency-svc-8kgsb [751.002682ms]
Aug 20 02:16:30.726: INFO: Got endpoints: latency-svc-cljgl [750.421535ms]
Aug 20 02:16:30.776: INFO: Got endpoints: latency-svc-wfjxc [749.486508ms]
Aug 20 02:16:30.826: INFO: Got endpoints: latency-svc-jrgmb [750.487712ms]
Aug 20 02:16:30.876: INFO: Got endpoints: latency-svc-9cdx5 [749.417062ms]
Aug 20 02:16:30.926: INFO: Got endpoints: latency-svc-nv4c7 [750.087804ms]
Aug 20 02:16:30.978: INFO: Got endpoints: latency-svc-mmdw5 [753.151461ms]
Aug 20 02:16:31.028: INFO: Got endpoints: latency-svc-vvshd [752.607301ms]
Aug 20 02:16:31.077: INFO: Got endpoints: latency-svc-6kddv [751.677312ms]
Aug 20 02:16:31.126: INFO: Got endpoints: latency-svc-bf8rm [749.474019ms]
Aug 20 02:16:31.126: INFO: Latencies: [20.426429ms 26.936794ms 31.710225ms 31.754939ms 46.699004ms 48.964265ms 60.78754ms 68.53132ms 69.276719ms 80.651715ms 85.137141ms 85.549724ms 92.224924ms 93.546654ms 94.3808ms 95.816795ms 96.459624ms 97.514282ms 99.266374ms 99.449871ms 100.120933ms 101.141895ms 103.189229ms 108.965585ms 114.681775ms 115.475879ms 116.029666ms 121.257539ms 128.732237ms 138.496066ms 139.402ms 139.428282ms 141.359608ms 141.643813ms 156.02965ms 197.416014ms 246.006853ms 282.767095ms 302.24603ms 352.59843ms 396.499504ms 445.714827ms 484.188115ms 520.095624ms 554.309184ms 596.64514ms 643.215249ms 682.573928ms 725.923172ms 736.112944ms 743.425471ms 745.033913ms 745.211336ms 745.287571ms 745.37436ms 745.988139ms 747.217911ms 747.593648ms 747.755579ms 747.81901ms 747.83187ms 747.882845ms 747.908695ms 747.940388ms 748.115629ms 748.129034ms 748.582375ms 748.654972ms 748.661549ms 748.675383ms 748.765579ms 748.813044ms 748.936469ms 748.959968ms 749.016533ms 749.029804ms 749.037854ms 749.054472ms 749.102727ms 749.109724ms 749.16178ms 749.18447ms 749.192344ms 749.243405ms 749.284245ms 749.346802ms 749.395078ms 749.417062ms 749.452922ms 749.474019ms 749.486508ms 749.489654ms 749.503641ms 749.508748ms 749.543034ms 749.567905ms 749.57588ms 749.582439ms 749.603451ms 749.649669ms 749.694251ms 749.694627ms 749.695405ms 749.711866ms 749.721951ms 749.728361ms 749.734377ms 749.744449ms 749.749117ms 749.789963ms 749.792225ms 749.794983ms 749.801671ms 749.893373ms 749.915723ms 749.933403ms 749.9342ms 749.943393ms 749.956625ms 749.961275ms 749.968252ms 749.97154ms 749.978229ms 749.991743ms 750.001526ms 750.004776ms 750.005535ms 750.014251ms 750.019655ms 750.034232ms 750.036207ms 750.049939ms 750.052065ms 750.073238ms 750.087804ms 750.146282ms 750.157645ms 750.195152ms 750.209428ms 750.224582ms 750.226573ms 750.24363ms 750.273794ms 750.284164ms 750.292746ms 750.31453ms 750.321696ms 750.380361ms 750.400011ms 750.408173ms 750.419051ms 750.421535ms 750.444228ms 750.444955ms 750.449464ms 750.466158ms 750.486523ms 750.487712ms 750.508189ms 750.529224ms 750.540344ms 750.569074ms 750.646237ms 750.661556ms 750.68835ms 750.724964ms 750.749309ms 750.762779ms 750.771764ms 750.85292ms 750.873129ms 750.880359ms 750.88417ms 750.886772ms 750.906842ms 750.951827ms 751.002682ms 751.14388ms 751.151587ms 751.326675ms 751.349406ms 751.36161ms 751.383172ms 751.464717ms 751.677312ms 751.699589ms 751.746266ms 752.379283ms 752.467714ms 752.503901ms 752.607301ms 752.885917ms 752.950359ms 753.151461ms 753.390781ms 754.123607ms 754.607915ms 754.967547ms 757.897491ms 764.493716ms]
Aug 20 02:16:31.126: INFO: 50 %ile: 749.694251ms
Aug 20 02:16:31.126: INFO: 90 %ile: 751.349406ms
Aug 20 02:16:31.126: INFO: 99 %ile: 757.897491ms
Aug 20 02:16:31.126: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:16:31.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1631" for this suite.
Aug 20 02:16:41.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:16:41.240: INFO: namespace svc-latency-1631 deletion completed in 10.105530325s

• [SLOW TEST:20.870 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:16:41.240: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 20 02:16:41.275: INFO: Waiting up to 5m0s for pod "pod-2a902a54-649d-4767-b84c-c7606c36cca3" in namespace "emptydir-9383" to be "success or failure"
Aug 20 02:16:41.277: INFO: Pod "pod-2a902a54-649d-4767-b84c-c7606c36cca3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041814ms
Aug 20 02:16:43.280: INFO: Pod "pod-2a902a54-649d-4767-b84c-c7606c36cca3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005215099s
Aug 20 02:16:45.284: INFO: Pod "pod-2a902a54-649d-4767-b84c-c7606c36cca3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008796404s
STEP: Saw pod success
Aug 20 02:16:45.284: INFO: Pod "pod-2a902a54-649d-4767-b84c-c7606c36cca3" satisfied condition "success or failure"
Aug 20 02:16:45.286: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-2a902a54-649d-4767-b84c-c7606c36cca3 container test-container: <nil>
STEP: delete the pod
Aug 20 02:16:45.301: INFO: Waiting for pod pod-2a902a54-649d-4767-b84c-c7606c36cca3 to disappear
Aug 20 02:16:45.303: INFO: Pod pod-2a902a54-649d-4767-b84c-c7606c36cca3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:16:45.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9383" for this suite.
Aug 20 02:16:51.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:16:51.494: INFO: namespace emptydir-9383 deletion completed in 6.187130048s

• [SLOW TEST:10.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:16:51.494: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 20 02:16:57.569: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:57.569: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:57.774: INFO: Exec stderr: ""
Aug 20 02:16:57.774: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:57.774: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.006: INFO: Exec stderr: ""
Aug 20 02:16:58.006: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.006: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.175: INFO: Exec stderr: ""
Aug 20 02:16:58.175: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.175: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.340: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 20 02:16:58.340: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.340: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.502: INFO: Exec stderr: ""
Aug 20 02:16:58.502: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.502: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.612: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 20 02:16:58.612: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.612: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.720: INFO: Exec stderr: ""
Aug 20 02:16:58.720: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.720: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.819: INFO: Exec stderr: ""
Aug 20 02:16:58.819: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.819: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:58.933: INFO: Exec stderr: ""
Aug 20 02:16:58.934: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4207 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:16:58.934: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:16:59.043: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:16:59.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4207" for this suite.
Aug 20 02:17:37.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:17:37.153: INFO: namespace e2e-kubelet-etc-hosts-4207 deletion completed in 38.105136169s

• [SLOW TEST:45.659 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:17:37.153: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:18:04.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4702" for this suite.
Aug 20 02:18:10.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:18:10.500: INFO: namespace container-runtime-4702 deletion completed in 6.116025975s

• [SLOW TEST:33.347 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:18:10.500: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:18:10.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb" in namespace "downward-api-9014" to be "success or failure"
Aug 20 02:18:10.542: INFO: Pod "downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.164019ms
Aug 20 02:18:12.545: INFO: Pod "downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005529431s
Aug 20 02:18:14.549: INFO: Pod "downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009237944s
STEP: Saw pod success
Aug 20 02:18:14.549: INFO: Pod "downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb" satisfied condition "success or failure"
Aug 20 02:18:14.551: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb container client-container: <nil>
STEP: delete the pod
Aug 20 02:18:14.580: INFO: Waiting for pod downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb to disappear
Aug 20 02:18:14.582: INFO: Pod downwardapi-volume-37f02bf8-acb6-43df-a8d1-78ca375cc2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:18:14.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9014" for this suite.
Aug 20 02:18:20.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:18:20.698: INFO: namespace downward-api-9014 deletion completed in 6.111530926s

• [SLOW TEST:10.198 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:18:20.698: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a40c5087-ecf8-41f3-8a44-4fa581ec3c28
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a40c5087-ecf8-41f3-8a44-4fa581ec3c28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:18:24.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1095" for this suite.
Aug 20 02:18:46.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:18:46.897: INFO: namespace projected-1095 deletion completed in 22.111128455s

• [SLOW TEST:26.199 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:18:46.897: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 20 02:18:46.936: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6444,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 20 02:18:46.936: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6444,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 20 02:18:56.944: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6461,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 20 02:18:56.944: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6461,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 20 02:19:06.961: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6479,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 20 02:19:06.962: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6479,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 20 02:19:16.969: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6496,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 20 02:19:16.969: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-a,UID:e796e64b-d9b8-470d-9238-1e50a7794c12,ResourceVersion:6496,Generation:0,CreationTimestamp:2019-08-20 02:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 20 02:19:26.979: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-b,UID:d9861fcf-3fb0-4de4-9c46-669c6bc67d80,ResourceVersion:6515,Generation:0,CreationTimestamp:2019-08-20 02:19:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 20 02:19:26.979: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-b,UID:d9861fcf-3fb0-4de4-9c46-669c6bc67d80,ResourceVersion:6515,Generation:0,CreationTimestamp:2019-08-20 02:19:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 20 02:19:36.986: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-b,UID:d9861fcf-3fb0-4de4-9c46-669c6bc67d80,ResourceVersion:6534,Generation:0,CreationTimestamp:2019-08-20 02:19:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 20 02:19:36.986: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3978,SelfLink:/api/v1/namespaces/watch-3978/configmaps/e2e-watch-test-configmap-b,UID:d9861fcf-3fb0-4de4-9c46-669c6bc67d80,ResourceVersion:6534,Generation:0,CreationTimestamp:2019-08-20 02:19:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:19:46.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3978" for this suite.
Aug 20 02:19:53.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:19:53.181: INFO: namespace watch-3978 deletion completed in 6.1899578s

• [SLOW TEST:66.284 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:19:53.182: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:19:53.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579" in namespace "downward-api-5017" to be "success or failure"
Aug 20 02:19:53.236: INFO: Pod "downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097957ms
Aug 20 02:19:55.240: INFO: Pod "downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007505708s
STEP: Saw pod success
Aug 20 02:19:55.240: INFO: Pod "downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579" satisfied condition "success or failure"
Aug 20 02:19:55.242: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579 container client-container: <nil>
STEP: delete the pod
Aug 20 02:19:55.259: INFO: Waiting for pod downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579 to disappear
Aug 20 02:19:55.262: INFO: Pod downwardapi-volume-0a0a6998-90b5-4a6e-aca4-73046ccd4579 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:19:55.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5017" for this suite.
Aug 20 02:20:01.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:20:01.445: INFO: namespace downward-api-5017 deletion completed in 6.179423804s

• [SLOW TEST:8.263 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:20:01.446: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-5b495634-8c02-44fd-8adc-a06774502410
STEP: Creating configMap with name cm-test-opt-upd-cec230c2-ae8b-4b65-8450-1d2e372a8c8b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5b495634-8c02-44fd-8adc-a06774502410
STEP: Updating configmap cm-test-opt-upd-cec230c2-ae8b-4b65-8450-1d2e372a8c8b
STEP: Creating configMap with name cm-test-opt-create-d5f8731c-d695-4a12-b262-421db479095a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:21:11.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9032" for this suite.
Aug 20 02:21:33.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:21:33.967: INFO: namespace configmap-9032 deletion completed in 22.10646145s

• [SLOW TEST:92.522 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:21:33.968: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 20 02:21:34.002: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-136865096 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:21:34.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4734" for this suite.
Aug 20 02:21:40.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:21:40.189: INFO: namespace kubectl-4734 deletion completed in 6.101730886s

• [SLOW TEST:6.221 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:21:40.189: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 20 02:21:42.754: INFO: Successfully updated pod "annotationupdate0d623901-3216-4638-bab0-86b4d0274e2a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:21:46.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7925" for this suite.
Aug 20 02:22:08.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:08.905: INFO: namespace projected-7925 deletion completed in 22.122578491s

• [SLOW TEST:28.715 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:08.905: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 02:22:08.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6236'
Aug 20 02:22:09.042: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 20 02:22:09.042: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug 20 02:22:09.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete jobs e2e-test-nginx-job --namespace=kubectl-6236'
Aug 20 02:22:09.157: INFO: stderr: ""
Aug 20 02:22:09.157: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:09.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6236" for this suite.
Aug 20 02:22:15.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:15.347: INFO: namespace kubectl-6236 deletion completed in 6.185492047s

• [SLOW TEST:6.442 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:15.347: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 20 02:22:15.407: INFO: Waiting up to 5m0s for pod "pod-5d3bd353-9578-407a-bb22-e71dc2a61596" in namespace "emptydir-8069" to be "success or failure"
Aug 20 02:22:15.410: INFO: Pod "pod-5d3bd353-9578-407a-bb22-e71dc2a61596": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723294ms
Aug 20 02:22:17.415: INFO: Pod "pod-5d3bd353-9578-407a-bb22-e71dc2a61596": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008256039s
STEP: Saw pod success
Aug 20 02:22:17.415: INFO: Pod "pod-5d3bd353-9578-407a-bb22-e71dc2a61596" satisfied condition "success or failure"
Aug 20 02:22:17.419: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-5d3bd353-9578-407a-bb22-e71dc2a61596 container test-container: <nil>
STEP: delete the pod
Aug 20 02:22:17.447: INFO: Waiting for pod pod-5d3bd353-9578-407a-bb22-e71dc2a61596 to disappear
Aug 20 02:22:17.456: INFO: Pod pod-5d3bd353-9578-407a-bb22-e71dc2a61596 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:17.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8069" for this suite.
Aug 20 02:22:23.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:23.618: INFO: namespace emptydir-8069 deletion completed in 6.15806355s

• [SLOW TEST:8.270 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:23.618: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 20 02:22:23.647: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-136865096 proxy --unix-socket=/tmp/kubectl-proxy-unix458431019/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:23.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1502" for this suite.
Aug 20 02:22:29.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:29.888: INFO: namespace kubectl-1502 deletion completed in 6.173590927s

• [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:29.888: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0820 02:22:30.958857      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 20 02:22:30.958: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:30.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-234" for this suite.
Aug 20 02:22:36.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:37.127: INFO: namespace gc-234 deletion completed in 6.163801049s

• [SLOW TEST:7.239 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:37.127: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:22:37.185: INFO: (0) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 19.397026ms)
Aug 20 02:22:37.189: INFO: (1) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.786327ms)
Aug 20 02:22:37.195: INFO: (2) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.089569ms)
Aug 20 02:22:37.200: INFO: (3) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.475292ms)
Aug 20 02:22:37.205: INFO: (4) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.378951ms)
Aug 20 02:22:37.210: INFO: (5) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.185664ms)
Aug 20 02:22:37.214: INFO: (6) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.921658ms)
Aug 20 02:22:37.218: INFO: (7) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.311497ms)
Aug 20 02:22:37.222: INFO: (8) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.902289ms)
Aug 20 02:22:37.227: INFO: (9) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.537495ms)
Aug 20 02:22:37.233: INFO: (10) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.91607ms)
Aug 20 02:22:37.237: INFO: (11) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.979047ms)
Aug 20 02:22:37.241: INFO: (12) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.95654ms)
Aug 20 02:22:37.245: INFO: (13) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.03321ms)
Aug 20 02:22:37.250: INFO: (14) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.42698ms)
Aug 20 02:22:37.255: INFO: (15) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.948957ms)
Aug 20 02:22:37.259: INFO: (16) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.411438ms)
Aug 20 02:22:37.265: INFO: (17) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.703441ms)
Aug 20 02:22:37.269: INFO: (18) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.263839ms)
Aug 20 02:22:37.274: INFO: (19) /api/v1/nodes/ip-172-31-1-253:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.274161ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:37.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8620" for this suite.
Aug 20 02:22:43.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:43.401: INFO: namespace proxy-8620 deletion completed in 6.122055562s

• [SLOW TEST:6.274 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:43.401: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 20 02:22:43.438: INFO: Waiting up to 5m0s for pod "pod-ccd98347-23a8-44d2-88f4-ca5123989eb6" in namespace "emptydir-7762" to be "success or failure"
Aug 20 02:22:43.441: INFO: Pod "pod-ccd98347-23a8-44d2-88f4-ca5123989eb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.333923ms
Aug 20 02:22:45.445: INFO: Pod "pod-ccd98347-23a8-44d2-88f4-ca5123989eb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006086845s
STEP: Saw pod success
Aug 20 02:22:45.445: INFO: Pod "pod-ccd98347-23a8-44d2-88f4-ca5123989eb6" satisfied condition "success or failure"
Aug 20 02:22:45.447: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-ccd98347-23a8-44d2-88f4-ca5123989eb6 container test-container: <nil>
STEP: delete the pod
Aug 20 02:22:45.462: INFO: Waiting for pod pod-ccd98347-23a8-44d2-88f4-ca5123989eb6 to disappear
Aug 20 02:22:45.464: INFO: Pod pod-ccd98347-23a8-44d2-88f4-ca5123989eb6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:45.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7762" for this suite.
Aug 20 02:22:51.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:22:51.666: INFO: namespace emptydir-7762 deletion completed in 6.197405086s

• [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:22:51.666: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 20 02:22:57.722: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0820 02:22:57.722590      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:22:57.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9732" for this suite.
Aug 20 02:23:03.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:23:03.917: INFO: namespace gc-9732 deletion completed in 6.191320551s

• [SLOW TEST:12.251 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:23:03.917: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 20 02:23:03.959: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 20 02:23:03.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:04.255: INFO: stderr: ""
Aug 20 02:23:04.255: INFO: stdout: "service/redis-slave created\n"
Aug 20 02:23:04.256: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 20 02:23:04.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:04.516: INFO: stderr: ""
Aug 20 02:23:04.516: INFO: stdout: "service/redis-master created\n"
Aug 20 02:23:04.516: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 20 02:23:04.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:04.710: INFO: stderr: ""
Aug 20 02:23:04.710: INFO: stdout: "service/frontend created\n"
Aug 20 02:23:04.710: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 20 02:23:04.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:04.897: INFO: stderr: ""
Aug 20 02:23:04.897: INFO: stdout: "deployment.apps/frontend created\n"
Aug 20 02:23:04.897: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 20 02:23:04.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:05.112: INFO: stderr: ""
Aug 20 02:23:05.112: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 20 02:23:05.112: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 20 02:23:05.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7777'
Aug 20 02:23:05.267: INFO: stderr: ""
Aug 20 02:23:05.267: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 20 02:23:05.267: INFO: Waiting for all frontend pods to be Running.
Aug 20 02:23:20.318: INFO: Waiting for frontend to serve content.
Aug 20 02:23:21.347: INFO: Trying to add a new entry to the guestbook.
Aug 20 02:23:21.361: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 20 02:23:21.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.460: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.460: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 20 02:23:21.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.572: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.572: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 20 02:23:21.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.695: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.695: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 20 02:23:21.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.801: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.801: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 20 02:23:21.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.878: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 20 02:23:21.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-7777'
Aug 20 02:23:21.957: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 02:23:21.958: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:23:21.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7777" for this suite.
Aug 20 02:23:59.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:24:00.143: INFO: namespace kubectl-7777 deletion completed in 38.182138169s

• [SLOW TEST:56.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:24:00.144: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:24:18.192: INFO: Container started at 2019-08-20 02:24:01 +0000 UTC, pod became ready at 2019-08-20 02:24:16 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:24:18.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7953" for this suite.
Aug 20 02:24:40.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:24:40.373: INFO: namespace container-probe-7953 deletion completed in 22.177368245s

• [SLOW TEST:40.229 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:24:40.373: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-5d7f1ae6-f14f-4c9c-913c-ed72d87cc7d9
STEP: Creating a pod to test consume secrets
Aug 20 02:24:40.415: INFO: Waiting up to 5m0s for pod "pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09" in namespace "secrets-3003" to be "success or failure"
Aug 20 02:24:40.417: INFO: Pod "pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181861ms
Aug 20 02:24:42.420: INFO: Pod "pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09": Phase="Running", Reason="", readiness=true. Elapsed: 2.005552643s
Aug 20 02:24:44.424: INFO: Pod "pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00915003s
STEP: Saw pod success
Aug 20 02:24:44.424: INFO: Pod "pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09" satisfied condition "success or failure"
Aug 20 02:24:44.426: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 02:24:44.448: INFO: Waiting for pod pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09 to disappear
Aug 20 02:24:44.456: INFO: Pod pod-secrets-6b17b4cf-41d9-4423-b0d9-5fcfc423cd09 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:24:44.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3003" for this suite.
Aug 20 02:24:50.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:24:50.576: INFO: namespace secrets-3003 deletion completed in 6.113627601s

• [SLOW TEST:10.202 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:24:50.576: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-771a8d9c-52b9-450f-bbb5-088f839d4829
STEP: Creating secret with name s-test-opt-upd-21e1db56-46dd-4b68-a50b-63527356821c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-771a8d9c-52b9-450f-bbb5-088f839d4829
STEP: Updating secret s-test-opt-upd-21e1db56-46dd-4b68-a50b-63527356821c
STEP: Creating secret with name s-test-opt-create-f69699f1-76aa-434a-826b-eebb03e5c567
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:24:54.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8591" for this suite.
Aug 20 02:25:16.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:25:16.808: INFO: namespace secrets-8591 deletion completed in 22.104633809s

• [SLOW TEST:26.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:25:16.809: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 20 02:25:16.847: INFO: Waiting up to 5m0s for pod "downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06" in namespace "downward-api-5985" to be "success or failure"
Aug 20 02:25:16.849: INFO: Pod "downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073537ms
Aug 20 02:25:18.852: INFO: Pod "downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005397477s
STEP: Saw pod success
Aug 20 02:25:18.852: INFO: Pod "downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06" satisfied condition "success or failure"
Aug 20 02:25:18.855: INFO: Trying to get logs from node ip-172-31-23-37 pod downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06 container dapi-container: <nil>
STEP: delete the pod
Aug 20 02:25:18.871: INFO: Waiting for pod downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06 to disappear
Aug 20 02:25:18.873: INFO: Pod downward-api-584122f3-d9fb-450e-9edc-df21f17ccc06 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:25:18.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5985" for this suite.
Aug 20 02:25:24.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:25:25.012: INFO: namespace downward-api-5985 deletion completed in 6.134321469s

• [SLOW TEST:8.203 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:25:25.012: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9896
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 20 02:25:25.079: INFO: Found 0 stateful pods, waiting for 3
Aug 20 02:25:35.083: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:25:35.083: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:25:35.083: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 02:25:35.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-9896 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:25:35.448: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:25:35.448: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:25:35.448: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 20 02:25:45.499: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 20 02:25:55.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-9896 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:25:55.704: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:25:55.704: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:25:55.704: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:26:05.724: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:26:05.724: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:05.724: INFO: Waiting for Pod statefulset-9896/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:05.724: INFO: Waiting for Pod statefulset-9896/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:15.732: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:26:15.732: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:15.732: INFO: Waiting for Pod statefulset-9896/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:25.737: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:26:25.737: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 20 02:26:35.732: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:26:35.732: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Aug 20 02:26:45.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-9896 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 02:26:45.942: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 02:26:45.942: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 02:26:45.942: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 02:26:55.977: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 20 02:27:05.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-9896 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 02:27:06.233: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 02:27:06.233: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 02:27:06.233: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 02:27:16.254: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:27:16.254: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 20 02:27:16.254: INFO: Waiting for Pod statefulset-9896/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 20 02:27:16.254: INFO: Waiting for Pod statefulset-9896/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 20 02:27:26.262: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
Aug 20 02:27:26.262: INFO: Waiting for Pod statefulset-9896/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 20 02:27:26.262: INFO: Waiting for Pod statefulset-9896/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 20 02:27:36.262: INFO: Waiting for StatefulSet statefulset-9896/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 20 02:27:46.262: INFO: Deleting all statefulset in ns statefulset-9896
Aug 20 02:27:46.267: INFO: Scaling statefulset ss2 to 0
Aug 20 02:28:06.283: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:28:06.288: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:28:06.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9896" for this suite.
Aug 20 02:28:12.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:28:12.416: INFO: namespace statefulset-9896 deletion completed in 6.108676093s

• [SLOW TEST:167.404 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:28:12.416: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9157.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9157.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9157.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9157.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9157.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9157.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9157.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9157.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9157.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9157.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 02:28:22.504: INFO: Unable to read wheezy_udp@dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.507: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.512: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.516: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.545: INFO: Unable to read jessie_udp@dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.548: INFO: Unable to read jessie_tcp@dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.551: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.554: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local from pod dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854: the server could not find the requested resource (get pods dns-test-27a33d19-3db4-4334-90be-563c09f3b854)
Aug 20 02:28:22.579: INFO: Lookups using dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854 failed for: [wheezy_udp@dns-test-service.dns-9157.svc.cluster.local wheezy_tcp@dns-test-service.dns-9157.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local jessie_udp@dns-test-service.dns-9157.svc.cluster.local jessie_tcp@dns-test-service.dns-9157.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9157.svc.cluster.local]

Aug 20 02:28:27.645: INFO: DNS probes using dns-9157/dns-test-27a33d19-3db4-4334-90be-563c09f3b854 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:28:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9157" for this suite.
Aug 20 02:28:33.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:28:33.805: INFO: namespace dns-9157 deletion completed in 6.110210405s

• [SLOW TEST:21.389 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:28:33.805: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8365
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 20 02:28:33.836: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 20 02:28:53.896: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.89.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8365 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:28:53.896: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:28:55.036: INFO: Found all expected endpoints: [netserver-0]
Aug 20 02:28:55.039: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.59.69 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8365 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:28:55.039: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:28:56.217: INFO: Found all expected endpoints: [netserver-1]
Aug 20 02:28:56.220: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.49.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8365 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:28:56.220: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:28:57.329: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:28:57.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8365" for this suite.
Aug 20 02:29:19.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:29:19.516: INFO: namespace pod-network-test-8365 deletion completed in 22.182874324s

• [SLOW TEST:45.711 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:29:19.517: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:29:19.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6705" for this suite.
Aug 20 02:29:25.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:29:25.685: INFO: namespace services-6705 deletion completed in 6.126682245s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.168 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:29:25.685: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:29:28.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6505" for this suite.
Aug 20 02:29:50.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:29:50.877: INFO: namespace replication-controller-6505 deletion completed in 22.126970337s

• [SLOW TEST:25.192 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:29:50.877: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-0966ccda-e611-4753-a8a6-4726bbdf1f99
STEP: Creating a pod to test consume configMaps
Aug 20 02:29:50.924: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0" in namespace "projected-529" to be "success or failure"
Aug 20 02:29:50.929: INFO: Pod "pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58398ms
Aug 20 02:29:52.934: INFO: Pod "pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00965197s
STEP: Saw pod success
Aug 20 02:29:52.934: INFO: Pod "pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0" satisfied condition "success or failure"
Aug 20 02:29:52.938: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:29:52.957: INFO: Waiting for pod pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0 to disappear
Aug 20 02:29:52.959: INFO: Pod pod-projected-configmaps-1ac85e6c-8462-4445-acd5-8c9382c2b4e0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:29:52.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-529" for this suite.
Aug 20 02:29:58.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:29:59.079: INFO: namespace projected-529 deletion completed in 6.115416295s

• [SLOW TEST:8.202 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:29:59.079: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:29:59.130: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 20 02:30:04.134: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 20 02:30:04.134: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 20 02:30:06.138: INFO: Creating deployment "test-rollover-deployment"
Aug 20 02:30:06.145: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 20 02:30:08.159: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 20 02:30:08.165: INFO: Ensure that both replica sets have 1 created replica
Aug 20 02:30:08.170: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 20 02:30:08.181: INFO: Updating deployment test-rollover-deployment
Aug 20 02:30:08.181: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 20 02:30:10.188: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 20 02:30:10.193: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 20 02:30:10.199: INFO: all replica sets need to contain the pod-template-hash label
Aug 20 02:30:10.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865010, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:30:12.205: INFO: all replica sets need to contain the pod-template-hash label
Aug 20 02:30:12.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865010, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:30:14.205: INFO: all replica sets need to contain the pod-template-hash label
Aug 20 02:30:14.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865010, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:30:16.206: INFO: all replica sets need to contain the pod-template-hash label
Aug 20 02:30:16.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865010, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:30:18.214: INFO: all replica sets need to contain the pod-template-hash label
Aug 20 02:30:18.214: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865010, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865006, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 20 02:30:20.205: INFO: 
Aug 20 02:30:20.205: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 20 02:30:20.213: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3600,SelfLink:/apis/apps/v1/namespaces/deployment-3600/deployments/test-rollover-deployment,UID:de9f9413-e8d3-4f76-88ed-591593925331,ResourceVersion:9020,Generation:2,CreationTimestamp:2019-08-20 02:30:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-20 02:30:06 +0000 UTC 2019-08-20 02:30:06 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-20 02:30:20 +0000 UTC 2019-08-20 02:30:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 20 02:30:20.215: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-3600,SelfLink:/apis/apps/v1/namespaces/deployment-3600/replicasets/test-rollover-deployment-854595fc44,UID:ecc3dea4-715f-4f75-985e-8aa788638708,ResourceVersion:9009,Generation:2,CreationTimestamp:2019-08-20 02:30:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de9f9413-e8d3-4f76-88ed-591593925331 0xc00275ef77 0xc00275ef78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 20 02:30:20.215: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 20 02:30:20.215: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3600,SelfLink:/apis/apps/v1/namespaces/deployment-3600/replicasets/test-rollover-controller,UID:117fbd63-42c2-4c45-9a89-b4c216efc18d,ResourceVersion:9019,Generation:2,CreationTimestamp:2019-08-20 02:29:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de9f9413-e8d3-4f76-88ed-591593925331 0xc00275ee9f 0xc00275eeb0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 02:30:20.215: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-3600,SelfLink:/apis/apps/v1/namespaces/deployment-3600/replicasets/test-rollover-deployment-9b8b997cf,UID:17819106-0021-42d6-aab2-23f226b53d17,ResourceVersion:8976,Generation:2,CreationTimestamp:2019-08-20 02:30:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de9f9413-e8d3-4f76-88ed-591593925331 0xc00275f030 0xc00275f031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 02:30:20.218: INFO: Pod "test-rollover-deployment-854595fc44-r5djh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-r5djh,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-3600,SelfLink:/api/v1/namespaces/deployment-3600/pods/test-rollover-deployment-854595fc44-r5djh,UID:5c399b27-8f11-4a28-8208-e2608d3d97b0,ResourceVersion:8989,Generation:0,CreationTimestamp:2019-08-20 02:30:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 ecc3dea4-715f-4f75-985e-8aa788638708 0xc00275fc07 0xc00275fc08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nv2lw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nv2lw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nv2lw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00275fc80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00275fca0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:30:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:30:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:30:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:30:08 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.75,StartTime:2019-08-20 02:30:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-20 02:30:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://b8c76edd34aa2ca3537db197a3db6f4617eb340f6cda6fa04f3ebd3c0ceb87b9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:30:20.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3600" for this suite.
Aug 20 02:30:26.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:30:26.359: INFO: namespace deployment-3600 deletion completed in 6.137635028s

• [SLOW TEST:27.280 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:30:26.360: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:30:26.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e" in namespace "downward-api-6554" to be "success or failure"
Aug 20 02:30:26.406: INFO: Pod "downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191483ms
Aug 20 02:30:28.409: INFO: Pod "downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005899604s
STEP: Saw pod success
Aug 20 02:30:28.409: INFO: Pod "downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e" satisfied condition "success or failure"
Aug 20 02:30:28.412: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e container client-container: <nil>
STEP: delete the pod
Aug 20 02:30:28.427: INFO: Waiting for pod downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e to disappear
Aug 20 02:30:28.429: INFO: Pod downwardapi-volume-73461f56-6eda-4262-a890-645d8cd1685e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:30:28.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6554" for this suite.
Aug 20 02:30:34.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:30:34.544: INFO: namespace downward-api-6554 deletion completed in 6.110540078s

• [SLOW TEST:8.184 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:30:34.544: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 20 02:30:37.102: INFO: Successfully updated pod "pod-update-69730dbf-17de-4c87-aa26-a485f8bf058a"
STEP: verifying the updated pod is in kubernetes
Aug 20 02:30:37.108: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:30:37.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6636" for this suite.
Aug 20 02:30:59.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:30:59.220: INFO: namespace pods-6636 deletion completed in 22.107684613s

• [SLOW TEST:24.676 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:30:59.220: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 20 02:30:59.259: INFO: Waiting up to 5m0s for pod "pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f" in namespace "emptydir-5682" to be "success or failure"
Aug 20 02:30:59.261: INFO: Pod "pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100277ms
Aug 20 02:31:01.265: INFO: Pod "pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.005626849s
Aug 20 02:31:03.268: INFO: Pod "pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008812977s
STEP: Saw pod success
Aug 20 02:31:03.268: INFO: Pod "pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f" satisfied condition "success or failure"
Aug 20 02:31:03.271: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f container test-container: <nil>
STEP: delete the pod
Aug 20 02:31:03.287: INFO: Waiting for pod pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f to disappear
Aug 20 02:31:03.289: INFO: Pod pod-39b4bfae-795f-4413-a309-eff9b8ba2d6f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:31:03.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5682" for this suite.
Aug 20 02:31:09.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:31:09.402: INFO: namespace emptydir-5682 deletion completed in 6.109387545s

• [SLOW TEST:10.182 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:31:09.402: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 02:31:09.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-0'
Aug 20 02:31:09.548: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 20 02:31:09.549: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug 20 02:31:11.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete deployment e2e-test-nginx-deployment --namespace=kubectl-0'
Aug 20 02:31:11.642: INFO: stderr: ""
Aug 20 02:31:11.642: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:31:11.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-0" for this suite.
Aug 20 02:31:33.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:31:33.754: INFO: namespace kubectl-0 deletion completed in 22.107345618s

• [SLOW TEST:24.351 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:31:33.754: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-d00fb4c1-8802-4eca-b14e-59f89a10916f
STEP: Creating a pod to test consume configMaps
Aug 20 02:31:33.799: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232" in namespace "configmap-7698" to be "success or failure"
Aug 20 02:31:33.810: INFO: Pod "pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232": Phase="Pending", Reason="", readiness=false. Elapsed: 11.185546ms
Aug 20 02:31:35.814: INFO: Pod "pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014694639s
STEP: Saw pod success
Aug 20 02:31:35.814: INFO: Pod "pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232" satisfied condition "success or failure"
Aug 20 02:31:35.816: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:31:35.831: INFO: Waiting for pod pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232 to disappear
Aug 20 02:31:35.833: INFO: Pod pod-configmaps-8ccbb888-442e-47b2-a951-20a8687af232 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:31:35.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7698" for this suite.
Aug 20 02:31:41.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:31:41.945: INFO: namespace configmap-7698 deletion completed in 6.108239997s

• [SLOW TEST:8.191 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:31:41.945: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 20 02:31:41.983: INFO: Waiting up to 5m0s for pod "pod-42e153a3-ef04-46ff-98e3-2bd719df9417" in namespace "emptydir-3712" to be "success or failure"
Aug 20 02:31:41.986: INFO: Pod "pod-42e153a3-ef04-46ff-98e3-2bd719df9417": Phase="Pending", Reason="", readiness=false. Elapsed: 2.511706ms
Aug 20 02:31:43.989: INFO: Pod "pod-42e153a3-ef04-46ff-98e3-2bd719df9417": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005855671s
STEP: Saw pod success
Aug 20 02:31:43.989: INFO: Pod "pod-42e153a3-ef04-46ff-98e3-2bd719df9417" satisfied condition "success or failure"
Aug 20 02:31:43.992: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-42e153a3-ef04-46ff-98e3-2bd719df9417 container test-container: <nil>
STEP: delete the pod
Aug 20 02:31:44.006: INFO: Waiting for pod pod-42e153a3-ef04-46ff-98e3-2bd719df9417 to disappear
Aug 20 02:31:44.009: INFO: Pod pod-42e153a3-ef04-46ff-98e3-2bd719df9417 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:31:44.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3712" for this suite.
Aug 20 02:31:50.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:31:50.139: INFO: namespace emptydir-3712 deletion completed in 6.126345838s

• [SLOW TEST:8.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:31:50.139: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 20 02:31:54.216: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:31:54.219: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:31:56.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:31:56.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:31:58.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:31:58.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:00.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:00.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:02.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:02.226: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:04.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:04.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:06.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:06.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:08.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:08.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:10.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:10.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:12.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:12.222: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 20 02:32:14.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 20 02:32:14.223: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:32:14.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6666" for this suite.
Aug 20 02:32:36.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:32:36.355: INFO: namespace container-lifecycle-hook-6666 deletion completed in 22.120212423s

• [SLOW TEST:46.216 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:32:36.355: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 20 02:32:36.394: INFO: Waiting up to 5m0s for pod "pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b" in namespace "emptydir-4096" to be "success or failure"
Aug 20 02:32:36.396: INFO: Pod "pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03713ms
Aug 20 02:32:38.400: INFO: Pod "pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005526416s
STEP: Saw pod success
Aug 20 02:32:38.400: INFO: Pod "pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b" satisfied condition "success or failure"
Aug 20 02:32:38.402: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b container test-container: <nil>
STEP: delete the pod
Aug 20 02:32:38.417: INFO: Waiting for pod pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b to disappear
Aug 20 02:32:38.419: INFO: Pod pod-cd6ea97f-fbb9-4fef-8f7d-f57e66a9a74b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:32:38.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4096" for this suite.
Aug 20 02:32:44.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:32:44.529: INFO: namespace emptydir-4096 deletion completed in 6.105400867s

• [SLOW TEST:8.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:32:44.529: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca in namespace container-probe-9024
Aug 20 02:32:48.575: INFO: Started pod liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca in namespace container-probe-9024
STEP: checking the pod's current state and verifying that restartCount is present
Aug 20 02:32:48.577: INFO: Initial restart count of pod liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is 0
Aug 20 02:33:06.614: INFO: Restart count of pod container-probe-9024/liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is now 1 (18.036366334s elapsed)
Aug 20 02:33:26.658: INFO: Restart count of pod container-probe-9024/liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is now 2 (38.080642596s elapsed)
Aug 20 02:33:44.692: INFO: Restart count of pod container-probe-9024/liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is now 3 (56.114109425s elapsed)
Aug 20 02:34:04.730: INFO: Restart count of pod container-probe-9024/liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is now 4 (1m16.152452635s elapsed)
Aug 20 02:35:08.848: INFO: Restart count of pod container-probe-9024/liveness-0bde48df-8031-4dd1-a4a3-4ceee019edca is now 5 (2m20.270705867s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:35:08.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9024" for this suite.
Aug 20 02:35:14.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:35:15.084: INFO: namespace container-probe-9024 deletion completed in 6.223101809s

• [SLOW TEST:150.555 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:35:15.084: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:35:15.114: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:35:17.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3691" for this suite.
Aug 20 02:35:57.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:35:57.271: INFO: namespace pods-3691 deletion completed in 40.103447384s

• [SLOW TEST:42.187 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:35:57.272: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:36:03.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7004" for this suite.
Aug 20 02:36:09.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:36:09.566: INFO: namespace namespaces-7004 deletion completed in 6.116306259s
STEP: Destroying namespace "nsdeletetest-8983" for this suite.
Aug 20 02:36:09.570: INFO: Namespace nsdeletetest-8983 was already deleted
STEP: Destroying namespace "nsdeletetest-7784" for this suite.
Aug 20 02:36:15.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:36:15.678: INFO: namespace nsdeletetest-7784 deletion completed in 6.107191423s

• [SLOW TEST:18.406 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:36:15.678: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 20 02:36:15.722: INFO: Waiting up to 5m0s for pod "pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926" in namespace "emptydir-4325" to be "success or failure"
Aug 20 02:36:15.724: INFO: Pod "pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130291ms
Aug 20 02:36:17.727: INFO: Pod "pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005408182s
Aug 20 02:36:19.731: INFO: Pod "pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008597751s
STEP: Saw pod success
Aug 20 02:36:19.731: INFO: Pod "pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926" satisfied condition "success or failure"
Aug 20 02:36:19.733: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926 container test-container: <nil>
STEP: delete the pod
Aug 20 02:36:19.749: INFO: Waiting for pod pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926 to disappear
Aug 20 02:36:19.751: INFO: Pod pod-4a1051f7-c29b-4efb-ba5a-1cddf1cf1926 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:36:19.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4325" for this suite.
Aug 20 02:36:25.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:36:25.874: INFO: namespace emptydir-4325 deletion completed in 6.119354751s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:36:25.876: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 20 02:36:25.933: INFO: Waiting up to 5m0s for pod "downward-api-19baef8c-84f0-4285-96aa-2e946568e4de" in namespace "downward-api-1741" to be "success or failure"
Aug 20 02:36:25.937: INFO: Pod "downward-api-19baef8c-84f0-4285-96aa-2e946568e4de": Phase="Pending", Reason="", readiness=false. Elapsed: 3.618919ms
Aug 20 02:36:27.940: INFO: Pod "downward-api-19baef8c-84f0-4285-96aa-2e946568e4de": Phase="Running", Reason="", readiness=true. Elapsed: 2.007088299s
Aug 20 02:36:29.943: INFO: Pod "downward-api-19baef8c-84f0-4285-96aa-2e946568e4de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009892222s
STEP: Saw pod success
Aug 20 02:36:29.943: INFO: Pod "downward-api-19baef8c-84f0-4285-96aa-2e946568e4de" satisfied condition "success or failure"
Aug 20 02:36:29.951: INFO: Trying to get logs from node ip-172-31-23-37 pod downward-api-19baef8c-84f0-4285-96aa-2e946568e4de container dapi-container: <nil>
STEP: delete the pod
Aug 20 02:36:29.968: INFO: Waiting for pod downward-api-19baef8c-84f0-4285-96aa-2e946568e4de to disappear
Aug 20 02:36:29.971: INFO: Pod downward-api-19baef8c-84f0-4285-96aa-2e946568e4de no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:36:29.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1741" for this suite.
Aug 20 02:36:35.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:36:36.081: INFO: namespace downward-api-1741 deletion completed in 6.106061743s

• [SLOW TEST:10.206 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:36:36.081: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 20 02:36:36.122: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-346,SelfLink:/api/v1/namespaces/watch-346/configmaps/e2e-watch-test-watch-closed,UID:d9e84e91-2b95-4fe0-bf28-971a37e007aa,ResourceVersion:10073,Generation:0,CreationTimestamp:2019-08-20 02:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 20 02:36:36.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-346,SelfLink:/api/v1/namespaces/watch-346/configmaps/e2e-watch-test-watch-closed,UID:d9e84e91-2b95-4fe0-bf28-971a37e007aa,ResourceVersion:10074,Generation:0,CreationTimestamp:2019-08-20 02:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 20 02:36:36.135: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-346,SelfLink:/api/v1/namespaces/watch-346/configmaps/e2e-watch-test-watch-closed,UID:d9e84e91-2b95-4fe0-bf28-971a37e007aa,ResourceVersion:10075,Generation:0,CreationTimestamp:2019-08-20 02:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 20 02:36:36.135: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-346,SelfLink:/api/v1/namespaces/watch-346/configmaps/e2e-watch-test-watch-closed,UID:d9e84e91-2b95-4fe0-bf28-971a37e007aa,ResourceVersion:10076,Generation:0,CreationTimestamp:2019-08-20 02:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:36:36.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-346" for this suite.
Aug 20 02:36:42.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:36:42.254: INFO: namespace watch-346 deletion completed in 6.10709469s

• [SLOW TEST:6.172 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:36:42.254: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3864
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 20 02:36:42.283: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 20 02:37:06.349: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.90:8080/dial?request=hostName&protocol=http&host=10.1.89.23&port=8080&tries=1'] Namespace:pod-network-test-3864 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:37:06.349: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:37:06.518: INFO: Waiting for endpoints: map[]
Aug 20 02:37:06.522: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.90:8080/dial?request=hostName&protocol=http&host=10.1.49.27&port=8080&tries=1'] Namespace:pod-network-test-3864 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:37:06.522: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:37:06.643: INFO: Waiting for endpoints: map[]
Aug 20 02:37:06.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.90:8080/dial?request=hostName&protocol=http&host=10.1.59.89&port=8080&tries=1'] Namespace:pod-network-test-3864 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:37:06.646: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:37:06.842: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:37:06.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3864" for this suite.
Aug 20 02:37:28.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:37:29.027: INFO: namespace pod-network-test-3864 deletion completed in 22.179616417s

• [SLOW TEST:46.773 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:37:29.027: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 20 02:37:29.365: INFO: Pod name wrapped-volume-race-cfc23bde-2e17-4420-9673-e5b3e2edc7cf: Found 0 pods out of 5
Aug 20 02:37:34.371: INFO: Pod name wrapped-volume-race-cfc23bde-2e17-4420-9673-e5b3e2edc7cf: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cfc23bde-2e17-4420-9673-e5b3e2edc7cf in namespace emptydir-wrapper-9404, will wait for the garbage collector to delete the pods
Aug 20 02:37:46.457: INFO: Deleting ReplicationController wrapped-volume-race-cfc23bde-2e17-4420-9673-e5b3e2edc7cf took: 8.526861ms
Aug 20 02:37:46.757: INFO: Terminating ReplicationController wrapped-volume-race-cfc23bde-2e17-4420-9673-e5b3e2edc7cf pods took: 300.227117ms
STEP: Creating RC which spawns configmap-volume pods
Aug 20 02:38:27.576: INFO: Pod name wrapped-volume-race-38c8d1ae-1371-4ca4-8d26-56a6aab617d6: Found 0 pods out of 5
Aug 20 02:38:32.582: INFO: Pod name wrapped-volume-race-38c8d1ae-1371-4ca4-8d26-56a6aab617d6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-38c8d1ae-1371-4ca4-8d26-56a6aab617d6 in namespace emptydir-wrapper-9404, will wait for the garbage collector to delete the pods
Aug 20 02:38:42.658: INFO: Deleting ReplicationController wrapped-volume-race-38c8d1ae-1371-4ca4-8d26-56a6aab617d6 took: 7.41808ms
Aug 20 02:38:42.958: INFO: Terminating ReplicationController wrapped-volume-race-38c8d1ae-1371-4ca4-8d26-56a6aab617d6 pods took: 300.22946ms
STEP: Creating RC which spawns configmap-volume pods
Aug 20 02:39:27.277: INFO: Pod name wrapped-volume-race-aaaf2a75-5124-4403-a543-9d2a728db83b: Found 0 pods out of 5
Aug 20 02:39:32.282: INFO: Pod name wrapped-volume-race-aaaf2a75-5124-4403-a543-9d2a728db83b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-aaaf2a75-5124-4403-a543-9d2a728db83b in namespace emptydir-wrapper-9404, will wait for the garbage collector to delete the pods
Aug 20 02:39:44.365: INFO: Deleting ReplicationController wrapped-volume-race-aaaf2a75-5124-4403-a543-9d2a728db83b took: 9.145738ms
Aug 20 02:39:44.668: INFO: Terminating ReplicationController wrapped-volume-race-aaaf2a75-5124-4403-a543-9d2a728db83b pods took: 302.889091ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:40:27.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9404" for this suite.
Aug 20 02:40:35.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:40:35.649: INFO: namespace emptydir-wrapper-9404 deletion completed in 8.113246296s

• [SLOW TEST:186.622 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:40:35.649: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 20 02:40:35.729: INFO: PodSpec: initContainers in spec.initContainers
Aug 20 02:41:17.941: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a39a6090-5121-4612-94e6-6b942ebf6954", GenerateName:"", Namespace:"init-container-2839", SelfLink:"/api/v1/namespaces/init-container-2839/pods/pod-init-a39a6090-5121-4612-94e6-6b942ebf6954", UID:"98f71f9b-c9a7-4df2-b2a8-26eadb1f7ef1", ResourceVersion:"11508", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701865635, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"729001598"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nnmrl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002148000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nnmrl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nnmrl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nnmrl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b8a098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-23-37", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003486000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b8a120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b8a140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002b8a148), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865635, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865635, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865635, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701865635, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.23.37", PodIP:"10.1.59.91", StartTime:(*v1.Time)(0xc0015780a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0015780e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0017d0150)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://5d9063d4dd34e790e2b754f0413113b3c6de5ee20fc29e00b9dc7b9cd4da638e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001578100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0015780c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:41:17.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2839" for this suite.
Aug 20 02:41:39.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:41:40.064: INFO: namespace init-container-2839 deletion completed in 22.118257511s

• [SLOW TEST:64.415 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:41:40.064: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:41:40.105: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841" in namespace "downward-api-2584" to be "success or failure"
Aug 20 02:41:40.110: INFO: Pod "downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841": Phase="Pending", Reason="", readiness=false. Elapsed: 4.526179ms
Aug 20 02:41:42.113: INFO: Pod "downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007952645s
STEP: Saw pod success
Aug 20 02:41:42.113: INFO: Pod "downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841" satisfied condition "success or failure"
Aug 20 02:41:42.116: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841 container client-container: <nil>
STEP: delete the pod
Aug 20 02:41:42.138: INFO: Waiting for pod downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841 to disappear
Aug 20 02:41:42.140: INFO: Pod downwardapi-volume-84a6ac5b-f788-437e-95f8-c0c36c2df841 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:41:42.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2584" for this suite.
Aug 20 02:41:48.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:41:48.252: INFO: namespace downward-api-2584 deletion completed in 6.106995477s

• [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:41:48.252: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 02:41:48.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7724'
Aug 20 02:41:48.550: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 20 02:41:48.550: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug 20 02:41:48.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7724'
Aug 20 02:41:48.630: INFO: stderr: ""
Aug 20 02:41:48.630: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:41:48.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7724" for this suite.
Aug 20 02:41:54.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:41:54.746: INFO: namespace kubectl-7724 deletion completed in 6.111642557s

• [SLOW TEST:6.494 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:41:54.746: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 20 02:41:54.786: INFO: Waiting up to 5m0s for pod "client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd" in namespace "containers-3718" to be "success or failure"
Aug 20 02:41:54.788: INFO: Pod "client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.476107ms
Aug 20 02:41:56.791: INFO: Pod "client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005689481s
Aug 20 02:41:58.795: INFO: Pod "client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009072255s
STEP: Saw pod success
Aug 20 02:41:58.795: INFO: Pod "client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd" satisfied condition "success or failure"
Aug 20 02:41:58.797: INFO: Trying to get logs from node ip-172-31-23-37 pod client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd container test-container: <nil>
STEP: delete the pod
Aug 20 02:41:58.813: INFO: Waiting for pod client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd to disappear
Aug 20 02:41:58.815: INFO: Pod client-containers-944198c5-3fb2-4690-99bb-46e615ea74bd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:41:58.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3718" for this suite.
Aug 20 02:42:04.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:42:04.951: INFO: namespace containers-3718 deletion completed in 6.131691332s

• [SLOW TEST:10.205 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:42:04.952: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-9fede19c-b3c3-41d0-b846-2abd74997836
STEP: Creating configMap with name cm-test-opt-upd-49627ce4-8aee-4027-9a4c-2bedf4d3f27c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9fede19c-b3c3-41d0-b846-2abd74997836
STEP: Updating configmap cm-test-opt-upd-49627ce4-8aee-4027-9a4c-2bedf4d3f27c
STEP: Creating configMap with name cm-test-opt-create-5b2b0c6a-eb82-4a7f-a968-4b6c2c4da6c3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:43:33.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9857" for this suite.
Aug 20 02:43:55.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:43:55.550: INFO: namespace projected-9857 deletion completed in 22.108635466s

• [SLOW TEST:110.599 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:43:55.550: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:43:57.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4837" for this suite.
Aug 20 02:44:49.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:44:49.754: INFO: namespace kubelet-test-4837 deletion completed in 52.147557326s

• [SLOW TEST:54.204 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:44:49.755: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 20 02:44:49.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 api-versions'
Aug 20 02:44:49.901: INFO: stderr: ""
Aug 20 02:44:49.901: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:44:49.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2354" for this suite.
Aug 20 02:44:55.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:44:56.037: INFO: namespace kubectl-2354 deletion completed in 6.128485658s

• [SLOW TEST:6.282 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:44:56.037: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 20 02:44:56.076: INFO: Waiting up to 5m0s for pod "var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347" in namespace "var-expansion-2979" to be "success or failure"
Aug 20 02:44:56.078: INFO: Pod "var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347": Phase="Pending", Reason="", readiness=false. Elapsed: 2.174443ms
Aug 20 02:44:58.085: INFO: Pod "var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009048079s
STEP: Saw pod success
Aug 20 02:44:58.085: INFO: Pod "var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347" satisfied condition "success or failure"
Aug 20 02:44:58.087: INFO: Trying to get logs from node ip-172-31-23-37 pod var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347 container dapi-container: <nil>
STEP: delete the pod
Aug 20 02:44:58.125: INFO: Waiting for pod var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347 to disappear
Aug 20 02:44:58.128: INFO: Pod var-expansion-bf5971d5-8481-419c-8590-4c07be6c7347 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:44:58.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2979" for this suite.
Aug 20 02:45:04.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:45:04.255: INFO: namespace var-expansion-2979 deletion completed in 6.122449738s

• [SLOW TEST:8.218 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:45:04.255: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 20 02:45:06.812: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8067 pod-service-account-5b15b54a-07be-4cd7-b601-b2574949ec5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 20 02:45:07.056: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8067 pod-service-account-5b15b54a-07be-4cd7-b601-b2574949ec5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 20 02:45:07.277: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8067 pod-service-account-5b15b54a-07be-4cd7-b601-b2574949ec5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:45:07.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8067" for this suite.
Aug 20 02:45:13.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:45:13.593: INFO: namespace svcaccounts-8067 deletion completed in 6.106612368s

• [SLOW TEST:9.338 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:45:13.593: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 20 02:45:13.632: INFO: Waiting up to 5m0s for pod "client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7" in namespace "containers-1454" to be "success or failure"
Aug 20 02:45:13.636: INFO: Pod "client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.711815ms
Aug 20 02:45:15.641: INFO: Pod "client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008982519s
STEP: Saw pod success
Aug 20 02:45:15.641: INFO: Pod "client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7" satisfied condition "success or failure"
Aug 20 02:45:15.643: INFO: Trying to get logs from node ip-172-31-23-37 pod client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7 container test-container: <nil>
STEP: delete the pod
Aug 20 02:45:15.657: INFO: Waiting for pod client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7 to disappear
Aug 20 02:45:15.659: INFO: Pod client-containers-9e195e99-db3c-4c5d-9b2b-280f0a8b5fb7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:45:15.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1454" for this suite.
Aug 20 02:45:21.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:45:21.772: INFO: namespace containers-1454 deletion completed in 6.109088456s

• [SLOW TEST:8.179 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:45:21.773: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7355
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 20 02:45:21.803: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 20 02:45:43.867: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.89.39:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7355 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:45:43.867: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:45:43.975: INFO: Found all expected endpoints: [netserver-0]
Aug 20 02:45:43.978: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.49.28:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7355 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:45:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:45:44.109: INFO: Found all expected endpoints: [netserver-1]
Aug 20 02:45:44.112: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.59.100:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7355 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 02:45:44.112: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 02:45:44.257: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:45:44.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7355" for this suite.
Aug 20 02:46:06.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:46:06.376: INFO: namespace pod-network-test-7355 deletion completed in 22.114406715s

• [SLOW TEST:44.603 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:46:06.376: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 20 02:46:08.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec pod-sharedvolume-c3ec436d-09b8-4689-a194-883f1ae4955f -c busybox-main-container --namespace=emptydir-9183 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 20 02:46:08.663: INFO: stderr: ""
Aug 20 02:46:08.663: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:46:08.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9183" for this suite.
Aug 20 02:46:14.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:46:14.779: INFO: namespace emptydir-9183 deletion completed in 6.106437123s

• [SLOW TEST:8.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:46:14.779: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 20 02:46:14.808: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:46:18.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3766" for this suite.
Aug 20 02:46:40.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:46:40.946: INFO: namespace init-container-3766 deletion completed in 22.102731195s

• [SLOW TEST:26.167 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:46:40.946: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:46:41.038: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2" in namespace "projected-8981" to be "success or failure"
Aug 20 02:46:41.040: INFO: Pod "downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080726ms
Aug 20 02:46:43.044: INFO: Pod "downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005744781s
STEP: Saw pod success
Aug 20 02:46:43.044: INFO: Pod "downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2" satisfied condition "success or failure"
Aug 20 02:46:43.047: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2 container client-container: <nil>
STEP: delete the pod
Aug 20 02:46:43.078: INFO: Waiting for pod downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2 to disappear
Aug 20 02:46:43.080: INFO: Pod downwardapi-volume-23079172-79dc-4bfc-a306-afe42cc57af2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:46:43.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8981" for this suite.
Aug 20 02:46:49.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:46:49.193: INFO: namespace projected-8981 deletion completed in 6.108709279s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:46:49.193: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:46:49.231: INFO: Waiting up to 5m0s for pod "downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a" in namespace "projected-987" to be "success or failure"
Aug 20 02:46:49.234: INFO: Pod "downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692119ms
Aug 20 02:46:51.238: INFO: Pod "downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006529831s
STEP: Saw pod success
Aug 20 02:46:51.238: INFO: Pod "downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a" satisfied condition "success or failure"
Aug 20 02:46:51.240: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a container client-container: <nil>
STEP: delete the pod
Aug 20 02:46:51.256: INFO: Waiting for pod downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a to disappear
Aug 20 02:46:51.258: INFO: Pod downwardapi-volume-870a566f-7bd0-46ed-8997-77bed2a2e03a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:46:51.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-987" for this suite.
Aug 20 02:46:57.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:46:57.366: INFO: namespace projected-987 deletion completed in 6.102498182s

• [SLOW TEST:8.173 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:46:57.366: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-4c643246-880a-464e-8134-9aa386e44958
STEP: Creating secret with name s-test-opt-upd-dff5bd5c-cb82-49ad-92a0-f90f23d548e0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4c643246-880a-464e-8134-9aa386e44958
STEP: Updating secret s-test-opt-upd-dff5bd5c-cb82-49ad-92a0-f90f23d548e0
STEP: Creating secret with name s-test-opt-create-b1f65045-0ea5-4848-a610-bbb0c56e22ca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:47:01.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3160" for this suite.
Aug 20 02:47:13.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:47:13.610: INFO: namespace projected-3160 deletion completed in 12.11239412s

• [SLOW TEST:16.244 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:47:13.610: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 02:47:17.675: INFO: DNS probes using dns-test-c0e90da2-af7a-4a90-a9e2-62f1cd5700dc succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 02:47:21.710: INFO: File wheezy_udp@dns-test-service-3.dns-380.svc.cluster.local from pod  dns-380/dns-test-5bf9bb1e-3942-4663-be7e-284853f69fbb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 20 02:47:21.714: INFO: File jessie_udp@dns-test-service-3.dns-380.svc.cluster.local from pod  dns-380/dns-test-5bf9bb1e-3942-4663-be7e-284853f69fbb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 20 02:47:21.714: INFO: Lookups using dns-380/dns-test-5bf9bb1e-3942-4663-be7e-284853f69fbb failed for: [wheezy_udp@dns-test-service-3.dns-380.svc.cluster.local jessie_udp@dns-test-service-3.dns-380.svc.cluster.local]

Aug 20 02:47:26.722: INFO: DNS probes using dns-test-5bf9bb1e-3942-4663-be7e-284853f69fbb succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-380.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-380.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 02:47:30.769: INFO: DNS probes using dns-test-f7d1415f-9bed-4656-9967-ec474cc99542 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:47:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-380" for this suite.
Aug 20 02:47:36.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:47:36.971: INFO: namespace dns-380 deletion completed in 6.176080834s

• [SLOW TEST:23.361 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:47:36.971: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-f2dk
STEP: Creating a pod to test atomic-volume-subpath
Aug 20 02:47:37.027: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f2dk" in namespace "subpath-7517" to be "success or failure"
Aug 20 02:47:37.033: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.355703ms
Aug 20 02:47:39.036: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 2.009095845s
Aug 20 02:47:41.040: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 4.012487271s
Aug 20 02:47:43.043: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 6.015676835s
Aug 20 02:47:45.046: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 8.019124648s
Aug 20 02:47:47.050: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 10.02286499s
Aug 20 02:47:49.054: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 12.02651161s
Aug 20 02:47:51.058: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 14.030164915s
Aug 20 02:47:53.061: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 16.033816142s
Aug 20 02:47:55.065: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 18.037754472s
Aug 20 02:47:57.069: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 20.041514847s
Aug 20 02:47:59.072: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Running", Reason="", readiness=true. Elapsed: 22.045110829s
Aug 20 02:48:01.076: INFO: Pod "pod-subpath-test-downwardapi-f2dk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048607207s
STEP: Saw pod success
Aug 20 02:48:01.076: INFO: Pod "pod-subpath-test-downwardapi-f2dk" satisfied condition "success or failure"
Aug 20 02:48:01.079: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-subpath-test-downwardapi-f2dk container test-container-subpath-downwardapi-f2dk: <nil>
STEP: delete the pod
Aug 20 02:48:01.110: INFO: Waiting for pod pod-subpath-test-downwardapi-f2dk to disappear
Aug 20 02:48:01.114: INFO: Pod pod-subpath-test-downwardapi-f2dk no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-f2dk
Aug 20 02:48:01.114: INFO: Deleting pod "pod-subpath-test-downwardapi-f2dk" in namespace "subpath-7517"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:48:01.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7517" for this suite.
Aug 20 02:48:07.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:48:07.270: INFO: namespace subpath-7517 deletion completed in 6.139694434s

• [SLOW TEST:30.299 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:48:07.270: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 02:48:07.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9039'
Aug 20 02:48:07.456: INFO: stderr: ""
Aug 20 02:48:07.456: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug 20 02:48:07.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete pods e2e-test-nginx-pod --namespace=kubectl-9039'
Aug 20 02:48:16.499: INFO: stderr: ""
Aug 20 02:48:16.499: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:48:16.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9039" for this suite.
Aug 20 02:48:22.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:48:22.668: INFO: namespace kubectl-9039 deletion completed in 6.164652752s

• [SLOW TEST:15.398 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:48:22.668: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 02:48:22.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3931'
Aug 20 02:48:22.800: INFO: stderr: ""
Aug 20 02:48:22.800: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 20 02:48:27.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pod e2e-test-nginx-pod --namespace=kubectl-3931 -o json'
Aug 20 02:48:27.920: INFO: stderr: ""
Aug 20 02:48:27.920: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-20T02:48:22Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3931\",\n        \"resourceVersion\": \"12889\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3931/pods/e2e-test-nginx-pod\",\n        \"uid\": \"199abc16-767e-4419-85b2-1c7522784ab4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-k4cnt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-23-37\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-k4cnt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-k4cnt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-20T02:48:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-20T02:48:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-20T02:48:24Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-20T02:48:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://756eea212399a9dabf930ec0024802a9fd06c03ba7f06879471d31832f67c7f0\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-20T02:48:23Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.23.37\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.59.112\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-20T02:48:22Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 20 02:48:27.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 replace -f - --namespace=kubectl-3931'
Aug 20 02:48:28.158: INFO: stderr: ""
Aug 20 02:48:28.158: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug 20 02:48:28.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete pods e2e-test-nginx-pod --namespace=kubectl-3931'
Aug 20 02:48:36.495: INFO: stderr: ""
Aug 20 02:48:36.495: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:48:36.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3931" for this suite.
Aug 20 02:48:42.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:48:42.684: INFO: namespace kubectl-3931 deletion completed in 6.185833648s

• [SLOW TEST:20.016 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:48:42.685: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 20 02:48:42.721: INFO: Waiting up to 5m0s for pod "pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca" in namespace "emptydir-6433" to be "success or failure"
Aug 20 02:48:42.723: INFO: Pod "pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 1.872113ms
Aug 20 02:48:44.726: INFO: Pod "pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00508883s
STEP: Saw pod success
Aug 20 02:48:44.726: INFO: Pod "pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca" satisfied condition "success or failure"
Aug 20 02:48:44.747: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca container test-container: <nil>
STEP: delete the pod
Aug 20 02:48:44.767: INFO: Waiting for pod pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca to disappear
Aug 20 02:48:44.771: INFO: Pod pod-ffa9cfe7-73cc-4a3a-afd1-b7ba5408a5ca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:48:44.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6433" for this suite.
Aug 20 02:48:50.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:48:50.891: INFO: namespace emptydir-6433 deletion completed in 6.11549296s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:48:50.892: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-4459b4d1-cfb3-4ed4-9b20-b2c3779a9966 in namespace container-probe-3553
Aug 20 02:48:52.942: INFO: Started pod busybox-4459b4d1-cfb3-4ed4-9b20-b2c3779a9966 in namespace container-probe-3553
STEP: checking the pod's current state and verifying that restartCount is present
Aug 20 02:48:52.944: INFO: Initial restart count of pod busybox-4459b4d1-cfb3-4ed4-9b20-b2c3779a9966 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:52:53.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3553" for this suite.
Aug 20 02:52:59.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:52:59.585: INFO: namespace container-probe-3553 deletion completed in 6.164023419s

• [SLOW TEST:248.693 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:52:59.585: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 20 02:52:59.635: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13426,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 20 02:52:59.635: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13427,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 20 02:52:59.635: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13428,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 20 02:53:09.660: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13447,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 20 02:53:09.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13448,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 20 02:53:09.660: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2576,SelfLink:/api/v1/namespaces/watch-2576/configmaps/e2e-watch-test-label-changed,UID:77e59627-b229-4d99-a379-257c1994cb90,ResourceVersion:13449,Generation:0,CreationTimestamp:2019-08-20 02:52:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:53:09.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2576" for this suite.
Aug 20 02:53:15.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:53:15.786: INFO: namespace watch-2576 deletion completed in 6.121772575s

• [SLOW TEST:16.200 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:53:15.786: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:53:15.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89" in namespace "projected-958" to be "success or failure"
Aug 20 02:53:15.830: INFO: Pod "downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.807517ms
Aug 20 02:53:17.833: INFO: Pod "downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006055419s
STEP: Saw pod success
Aug 20 02:53:17.833: INFO: Pod "downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89" satisfied condition "success or failure"
Aug 20 02:53:17.835: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89 container client-container: <nil>
STEP: delete the pod
Aug 20 02:53:17.857: INFO: Waiting for pod downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89 to disappear
Aug 20 02:53:17.859: INFO: Pod downwardapi-volume-91031112-a50e-4c79-8d0f-ba959105df89 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:53:17.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-958" for this suite.
Aug 20 02:53:23.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:53:23.967: INFO: namespace projected-958 deletion completed in 6.103529869s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:53:23.967: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:53:24.016: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321" in namespace "projected-7253" to be "success or failure"
Aug 20 02:53:24.018: INFO: Pod "downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197117ms
Aug 20 02:53:26.022: INFO: Pod "downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006517158s
STEP: Saw pod success
Aug 20 02:53:26.022: INFO: Pod "downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321" satisfied condition "success or failure"
Aug 20 02:53:26.025: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321 container client-container: <nil>
STEP: delete the pod
Aug 20 02:53:26.041: INFO: Waiting for pod downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321 to disappear
Aug 20 02:53:26.043: INFO: Pod downwardapi-volume-1d6c4f62-44e3-46f7-a1de-80772e534321 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:53:26.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7253" for this suite.
Aug 20 02:53:32.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:53:32.172: INFO: namespace projected-7253 deletion completed in 6.125534573s

• [SLOW TEST:8.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:53:32.172: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-52e1202b-14ba-4d0e-a937-039dee888801
STEP: Creating a pod to test consume configMaps
Aug 20 02:53:32.220: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871" in namespace "projected-1235" to be "success or failure"
Aug 20 02:53:32.223: INFO: Pod "pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.777117ms
Aug 20 02:53:34.226: INFO: Pod "pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005945768s
STEP: Saw pod success
Aug 20 02:53:34.226: INFO: Pod "pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871" satisfied condition "success or failure"
Aug 20 02:53:34.229: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:53:34.246: INFO: Waiting for pod pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871 to disappear
Aug 20 02:53:34.248: INFO: Pod pod-projected-configmaps-95291d9a-6f8a-4418-b110-678dd34f8871 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:53:34.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1235" for this suite.
Aug 20 02:53:40.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:53:40.367: INFO: namespace projected-1235 deletion completed in 6.115142494s

• [SLOW TEST:8.195 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:53:40.367: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:53:42.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1188" for this suite.
Aug 20 02:54:28.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:54:28.558: INFO: namespace kubelet-test-1188 deletion completed in 46.12744553s

• [SLOW TEST:48.191 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:54:28.558: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c90867be-2fc5-466b-b29c-1b7ff5ba9c7d
STEP: Creating a pod to test consume secrets
Aug 20 02:54:28.607: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba" in namespace "projected-108" to be "success or failure"
Aug 20 02:54:28.609: INFO: Pod "pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.743038ms
Aug 20 02:54:30.613: INFO: Pod "pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006232496s
STEP: Saw pod success
Aug 20 02:54:30.613: INFO: Pod "pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba" satisfied condition "success or failure"
Aug 20 02:54:30.616: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 20 02:54:30.633: INFO: Waiting for pod pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba to disappear
Aug 20 02:54:30.635: INFO: Pod pod-projected-secrets-de5acb55-8f68-46a3-a09b-89c4ce32b0ba no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:54:30.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-108" for this suite.
Aug 20 02:54:36.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:54:36.747: INFO: namespace projected-108 deletion completed in 6.107475937s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:54:36.747: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-47bq
STEP: Creating a pod to test atomic-volume-subpath
Aug 20 02:54:36.799: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-47bq" in namespace "subpath-1717" to be "success or failure"
Aug 20 02:54:36.801: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.519666ms
Aug 20 02:54:38.805: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 2.005811756s
Aug 20 02:54:40.808: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 4.00957775s
Aug 20 02:54:42.812: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 6.013093475s
Aug 20 02:54:44.816: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 8.016907916s
Aug 20 02:54:46.819: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 10.020452719s
Aug 20 02:54:48.824: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 12.025061527s
Aug 20 02:54:50.827: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 14.02816709s
Aug 20 02:54:52.831: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 16.031678885s
Aug 20 02:54:54.834: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 18.035025484s
Aug 20 02:54:56.837: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Running", Reason="", readiness=true. Elapsed: 20.038258688s
Aug 20 02:54:58.841: INFO: Pod "pod-subpath-test-configmap-47bq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.041747244s
STEP: Saw pod success
Aug 20 02:54:58.841: INFO: Pod "pod-subpath-test-configmap-47bq" satisfied condition "success or failure"
Aug 20 02:54:58.843: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-subpath-test-configmap-47bq container test-container-subpath-configmap-47bq: <nil>
STEP: delete the pod
Aug 20 02:54:58.860: INFO: Waiting for pod pod-subpath-test-configmap-47bq to disappear
Aug 20 02:54:58.862: INFO: Pod pod-subpath-test-configmap-47bq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-47bq
Aug 20 02:54:58.862: INFO: Deleting pod "pod-subpath-test-configmap-47bq" in namespace "subpath-1717"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:54:58.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1717" for this suite.
Aug 20 02:55:04.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:05.085: INFO: namespace subpath-1717 deletion completed in 6.216620521s

• [SLOW TEST:28.338 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:05.085: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 20 02:55:05.155: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9810,SelfLink:/api/v1/namespaces/watch-9810/configmaps/e2e-watch-test-resource-version,UID:7dafebc9-a196-4a11-8b89-d0eadc073eda,ResourceVersion:13800,Generation:0,CreationTimestamp:2019-08-20 02:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 20 02:55:05.156: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9810,SelfLink:/api/v1/namespaces/watch-9810/configmaps/e2e-watch-test-resource-version,UID:7dafebc9-a196-4a11-8b89-d0eadc073eda,ResourceVersion:13801,Generation:0,CreationTimestamp:2019-08-20 02:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:05.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9810" for this suite.
Aug 20 02:55:11.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:11.275: INFO: namespace watch-9810 deletion completed in 6.115021974s

• [SLOW TEST:6.189 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:11.275: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-eae8b872-7b48-4478-9c2b-875ac441f8bc
STEP: Creating a pod to test consume configMaps
Aug 20 02:55:11.334: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151" in namespace "configmap-2727" to be "success or failure"
Aug 20 02:55:11.336: INFO: Pod "pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151": Phase="Pending", Reason="", readiness=false. Elapsed: 2.382679ms
Aug 20 02:55:13.340: INFO: Pod "pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006275352s
STEP: Saw pod success
Aug 20 02:55:13.340: INFO: Pod "pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151" satisfied condition "success or failure"
Aug 20 02:55:13.343: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 02:55:13.360: INFO: Waiting for pod pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151 to disappear
Aug 20 02:55:13.363: INFO: Pod pod-configmaps-3ac4f04b-4716-46bb-9122-9ec224073151 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:13.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2727" for this suite.
Aug 20 02:55:19.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:19.601: INFO: namespace configmap-2727 deletion completed in 6.234375339s

• [SLOW TEST:8.326 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:19.601: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-b5a7db42-7d5d-4cce-a767-3e42330fddfd
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:19.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-342" for this suite.
Aug 20 02:55:25.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:25.737: INFO: namespace configmap-342 deletion completed in 6.100586807s

• [SLOW TEST:6.136 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:25.738: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:55:25.769: INFO: Creating deployment "nginx-deployment"
Aug 20 02:55:25.776: INFO: Waiting for observed generation 1
Aug 20 02:55:27.781: INFO: Waiting for all required pods to come up
Aug 20 02:55:27.784: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 20 02:55:29.791: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 20 02:55:29.796: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 20 02:55:29.802: INFO: Updating deployment nginx-deployment
Aug 20 02:55:29.802: INFO: Waiting for observed generation 2
Aug 20 02:55:31.809: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 20 02:55:31.813: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 20 02:55:31.815: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 20 02:55:31.821: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 20 02:55:31.821: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 20 02:55:31.824: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 20 02:55:31.828: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 20 02:55:31.828: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 20 02:55:31.834: INFO: Updating deployment nginx-deployment
Aug 20 02:55:31.834: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 20 02:55:31.839: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 20 02:55:31.841: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 20 02:55:33.849: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3776,SelfLink:/apis/apps/v1/namespaces/deployment-3776/deployments/nginx-deployment,UID:f0722170-f577-4734-a751-9dce875d5589,ResourceVersion:14210,Generation:3,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:11,UnavailableReplicas:22,Conditions:[{Available False 2019-08-20 02:55:31 +0000 UTC 2019-08-20 02:55:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-20 02:55:33 +0000 UTC 2019-08-20 02:55:25 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:11,CollisionCount:nil,},}

Aug 20 02:55:33.853: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-3776,SelfLink:/apis/apps/v1/namespaces/deployment-3776/replicasets/nginx-deployment-55fb7cb77f,UID:121d83fa-c85d-4f25-8f6e-a1eb4169b3a5,ResourceVersion:14140,Generation:3,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f0722170-f577-4734-a751-9dce875d5589 0xc001e7a6f7 0xc001e7a6f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 02:55:33.853: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 20 02:55:33.853: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-3776,SelfLink:/apis/apps/v1/namespaces/deployment-3776/replicasets/nginx-deployment-7b8c6f4498,UID:5489d894-9ec1-4656-aec4-efee07b82a8f,ResourceVersion:14209,Generation:3,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f0722170-f577-4734-a751-9dce875d5589 0xc001e7a7c7 0xc001e7a7c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:11,AvailableReplicas:11,Conditions:[],},}
Aug 20 02:55:33.857: INFO: Pod "nginx-deployment-55fb7cb77f-2mqmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2mqmc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-2mqmc,UID:91a30fe2-1f35-4875-9c06-7a027143caf6,ResourceVersion:14021,Generation:0,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b157 0xc001e7b158}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b1f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-599s5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-599s5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-599s5,UID:2e15f7cf-817f-445c-b095-dbaf5b22ecbd,ResourceVersion:14054,Generation:0,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b2b0 0xc001e7b2b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b350}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-6f4b5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6f4b5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-6f4b5,UID:68d6adb0-4544-435b-b5cc-09c9637b88a7,ResourceVersion:14136,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b410 0xc001e7b411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b4b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-6jtvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6jtvj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-6jtvj,UID:bbe477b8-8732-443a-b1e7-36c3643c9856,ResourceVersion:14172,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b570 0xc001e7b571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b610}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-6kclm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6kclm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-6kclm,UID:ca7fbaa6-cc17-4e51-b948-bb74b5d1aa78,ResourceVersion:14117,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b6d0 0xc001e7b6d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b770}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-6sm9t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6sm9t,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-6sm9t,UID:62f7dc46-9ddf-4a3f-b2ec-f4a4109659da,ResourceVersion:14145,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b830 0xc001e7b831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7b8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7b8d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-ccxwx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ccxwx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-ccxwx,UID:a7a3b097-5588-4aef-afab-2ac77c9201a7,ResourceVersion:14092,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7b990 0xc001e7b991}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7ba10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7ba30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:,StartTime:2019-08-20 02:55:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.858: INFO: Pod "nginx-deployment-55fb7cb77f-cw5rh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cw5rh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-cw5rh,UID:3dbf0b8e-861a-4f13-a8a7-77902d784e5d,ResourceVersion:14114,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7baf0 0xc001e7baf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7bb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7bb90}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-55fb7cb77f-ffrgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ffrgw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-ffrgw,UID:d278047c-b632-4c8f-be4c-e80224cf3ccf,ResourceVersion:14191,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7bc50 0xc001e7bc51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7bcd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7bcf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-55fb7cb77f-gdhzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gdhzh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-gdhzh,UID:3e63dd3a-8f62-42f2-8e5f-c8fb567f1850,ResourceVersion:14134,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7bdb0 0xc001e7bdb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7be30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7be50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-55fb7cb77f-jwv8q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jwv8q,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-jwv8q,UID:350f8fe3-091d-4a07-8dc6-6a442d1bf717,ResourceVersion:14033,Generation:0,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc001e7bf10 0xc001e7bf11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7bf90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7bfb0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-55fb7cb77f-q4zc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q4zc6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-q4zc6,UID:15f9920a-df74-4151-8cbe-5775b06769bf,ResourceVersion:14051,Generation:0,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc002db6070 0xc002db6071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db60f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6110}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-55fb7cb77f-rl4g2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rl4g2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-55fb7cb77f-rl4g2,UID:127c20b1-70a4-4f65-940f-c430b896fcfb,ResourceVersion:14038,Generation:0,CreationTimestamp:2019-08-20 02:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 121d83fa-c85d-4f25-8f6e-a1eb4169b3a5 0xc002db61d0 0xc002db61d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6270}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:29 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:,StartTime:2019-08-20 02:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.859: INFO: Pod "nginx-deployment-7b8c6f4498-5f6nk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5f6nk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-5f6nk,UID:33d55ea3-e097-45ba-bac2-a677864aa0bd,ResourceVersion:13973,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6330 0xc002db6331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db63a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db63c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:10.1.89.40,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://158e615265a0ea4e7c7eff555c5daab5fbdac72c1d53a32fc68b231379691b8a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.860: INFO: Pod "nginx-deployment-7b8c6f4498-5mtm6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5mtm6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-5mtm6,UID:89433a20-4041-4a6f-a027-8014718bccb8,ResourceVersion:14171,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6480 0xc002db6481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db64f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6510}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.860: INFO: Pod "nginx-deployment-7b8c6f4498-5nd6j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5nd6j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-5nd6j,UID:34fa5455-6b4b-4c63-a244-1b9a99e296e4,ResourceVersion:14123,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db65c7 0xc002db65c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6660}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.860: INFO: Pod "nginx-deployment-7b8c6f4498-5s6nr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5s6nr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-5s6nr,UID:67577b97-7728-4d89-a655-e12139e4abac,ResourceVersion:14109,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6717 0xc002db6718}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db67b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.860: INFO: Pod "nginx-deployment-7b8c6f4498-86kkm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-86kkm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-86kkm,UID:d42c1304-077c-447f-bfec-bea996eb7061,ResourceVersion:13976,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6867 0xc002db6868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db68e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6900}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:10.1.89.41,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://6c4042f59b07dd124abf8ac127a0234c82a2c9139b1bdd13341189bd54c9a362}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.863: INFO: Pod "nginx-deployment-7b8c6f4498-djtjs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-djtjs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-djtjs,UID:aca0a713-ea97-4758-90e5-6275c7c21ee6,ResourceVersion:14160,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db69c0 0xc002db69c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6a50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.863: INFO: Pod "nginx-deployment-7b8c6f4498-fzqxx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fzqxx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-fzqxx,UID:4e26c6fa-83a3-40b1-a069-6343d5eee6dc,ResourceVersion:14090,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6b07 0xc002db6b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6ba0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.864: INFO: Pod "nginx-deployment-7b8c6f4498-jldmv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jldmv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-jldmv,UID:d487229c-257a-4427-a963-b5a6a5c3ee7e,ResourceVersion:13966,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6c57 0xc002db6c58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6cf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.122,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:26 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://8be71647e462cca68230ccad1812d8b5a9bad50d2193f0dea2c7ae1a5027642b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.864: INFO: Pod "nginx-deployment-7b8c6f4498-jpr4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jpr4p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-jpr4p,UID:6986f152-0a80-4388-ab64-cd19114358a1,ResourceVersion:14152,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6db0 0xc002db6db1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6e40}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.864: INFO: Pod "nginx-deployment-7b8c6f4498-k8wpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k8wpt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-k8wpt,UID:0b90febe-10d7-438f-b71a-eff4483d3d16,ResourceVersion:14199,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db6ef7 0xc002db6ef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db6f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db6f90}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:10.1.89.50,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://de602b40a4bfe294c5e8b36f00c4ecc58257fa3e587a4dcfb0eb3c2ccdc634c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.864: INFO: Pod "nginx-deployment-7b8c6f4498-mpltn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mpltn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-mpltn,UID:1ec3315e-466d-4e0b-a07b-d98870539a86,ResourceVersion:14135,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7050 0xc002db7051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db70c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db70e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.864: INFO: Pod "nginx-deployment-7b8c6f4498-mv955" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mv955,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-mv955,UID:abf05e8a-f819-48d7-9afc-54a25f0d8fb8,ResourceVersion:13969,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7197 0xc002db7198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7230}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:10.1.89.42,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f198e1984080d3fbaeaead7ba08ec75bfb73ab7e28b995e3be39342647a9c089}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.865: INFO: Pod "nginx-deployment-7b8c6f4498-nclnn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nclnn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-nclnn,UID:ffd2e680-5e56-4c1f-b26b-8d83d1e19c24,ResourceVersion:14204,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db72f0 0xc002db72f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7380}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.131,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4cacb67837afea495f230569157a4990eb99c6a79baf89a8b48bf1514aba6572}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.865: INFO: Pod "nginx-deployment-7b8c6f4498-p2t7d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p2t7d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-p2t7d,UID:49806a19-27ce-40b0-934b-a9054205c476,ResourceVersion:13989,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7440 0xc002db7441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db74d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db74f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:10.1.49.31,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b2cab807ce14b4fa6c87cf2af6fd3459397107532a204b619f8b5c18f77d9444}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.865: INFO: Pod "nginx-deployment-7b8c6f4498-pcntp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pcntp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-pcntp,UID:f2e3f8a9-35e6-4221-aa31-d7221ac7ce72,ResourceVersion:14208,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db75b0 0xc002db75b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7640}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:10.1.49.38,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ade19afca48a1987fa42fc768a2c58c044b6a91bc6398a60a28c9610ec85411f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.865: INFO: Pod "nginx-deployment-7b8c6f4498-pv2vq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pv2vq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-pv2vq,UID:b1f3e8c1-8553-411f-abec-8115fc4130f5,ResourceVersion:13985,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7700 0xc002db7701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7790}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:10.1.49.32,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c5b9b7d0aaa8e13b91b43e548a2e1a6898efda9734d80335f1f7e91adccfa912}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.866: INFO: Pod "nginx-deployment-7b8c6f4498-rszqr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rszqr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-rszqr,UID:f08e57f1-0d97-4a20-877f-320cfa7bdc9b,ResourceVersion:13982,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7850 0xc002db7851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db78c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db78e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:10.1.49.30,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7323d8028a66370cfce779a50b7ece82c4f4c3ff8af3026bb7a17b63955ceee0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.866: INFO: Pod "nginx-deployment-7b8c6f4498-tmrfw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tmrfw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-tmrfw,UID:3f368c40-a08f-41f1-8cbc-e60e3f0488e9,ResourceVersion:14088,Generation:0,CreationTimestamp:2019-08-20 02:55:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db79a0 0xc002db79a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7a30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.866: INFO: Pod "nginx-deployment-7b8c6f4498-znr8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-znr8z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-znr8z,UID:b62259c0-5393-40a2-b1e0-0e3a02859eb1,ResourceVersion:14138,Generation:0,CreationTimestamp:2019-08-20 02:55:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7ae7 0xc002db7ae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-253,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7b80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.1.253,PodIP:,StartTime:2019-08-20 02:55:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 20 02:55:33.866: INFO: Pod "nginx-deployment-7b8c6f4498-zz9ct" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zz9ct,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3776,SelfLink:/api/v1/namespaces/deployment-3776/pods/nginx-deployment-7b8c6f4498-zz9ct,UID:baa16766-6a41-4644-bd98-47fd5c39e63e,ResourceVersion:13979,Generation:0,CreationTimestamp:2019-08-20 02:55:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 5489d894-9ec1-4656-aec4-efee07b82a8f 0xc002db7c37 0xc002db7c38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vf2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vf2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4vf2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-77-128,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002db7cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002db7cd0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 02:55:25 +0000 UTC  }],Message:,Reason:,HostIP:172.31.77.128,PodIP:10.1.49.29,StartTime:2019-08-20 02:55:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 02:55:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://d665d2fa1adfc1a6e4c29b07fa3c4393816a552382a60f9a2ff963f54010aa04}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:33.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3776" for this suite.
Aug 20 02:55:41.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:42.068: INFO: namespace deployment-3776 deletion completed in 8.196760686s

• [SLOW TEST:16.331 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:42.069: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:55:42.162: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346" in namespace "downward-api-4532" to be "success or failure"
Aug 20 02:55:42.164: INFO: Pod "downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238731ms
Aug 20 02:55:44.167: INFO: Pod "downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005851597s
STEP: Saw pod success
Aug 20 02:55:44.167: INFO: Pod "downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346" satisfied condition "success or failure"
Aug 20 02:55:44.170: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346 container client-container: <nil>
STEP: delete the pod
Aug 20 02:55:44.185: INFO: Waiting for pod downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346 to disappear
Aug 20 02:55:44.188: INFO: Pod downwardapi-volume-65c26eb7-1043-46e0-b410-fe7f58630346 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:44.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4532" for this suite.
Aug 20 02:55:50.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:50.300: INFO: namespace downward-api-4532 deletion completed in 6.107291338s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:50.300: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 20 02:55:53.356: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:55:53.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-128" for this suite.
Aug 20 02:55:59.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:55:59.523: INFO: namespace container-runtime-128 deletion completed in 6.152877137s

• [SLOW TEST:9.223 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:55:59.523: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-66bffad0-af09-4df4-9e50-9fb3e5359749
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:56:01.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2231" for this suite.
Aug 20 02:56:23.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:56:23.790: INFO: namespace configmap-2231 deletion completed in 22.172231671s

• [SLOW TEST:24.267 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:56:23.791: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 20 02:56:23.828: INFO: Waiting up to 5m0s for pod "client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685" in namespace "containers-4719" to be "success or failure"
Aug 20 02:56:23.830: INFO: Pod "client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685": Phase="Pending", Reason="", readiness=false. Elapsed: 2.267337ms
Aug 20 02:56:25.847: INFO: Pod "client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019443483s
STEP: Saw pod success
Aug 20 02:56:25.847: INFO: Pod "client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685" satisfied condition "success or failure"
Aug 20 02:56:25.850: INFO: Trying to get logs from node ip-172-31-23-37 pod client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685 container test-container: <nil>
STEP: delete the pod
Aug 20 02:56:25.864: INFO: Waiting for pod client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685 to disappear
Aug 20 02:56:25.867: INFO: Pod client-containers-9ccb3b7f-4aba-43c5-9302-53acfcb47685 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:56:25.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4719" for this suite.
Aug 20 02:56:31.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:56:31.986: INFO: namespace containers-4719 deletion completed in 6.115356719s

• [SLOW TEST:8.196 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:56:31.986: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3492, will wait for the garbage collector to delete the pods
Aug 20 02:56:34.093: INFO: Deleting Job.batch foo took: 12.882868ms
Aug 20 02:56:34.394: INFO: Terminating Job.batch foo pods took: 301.523978ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:57:16.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3492" for this suite.
Aug 20 02:57:22.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:57:22.717: INFO: namespace job-3492 deletion completed in 6.113830892s

• [SLOW TEST:50.730 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:57:22.717: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-92410285-c014-49c5-8b0c-bfc2a05c82d9
STEP: Creating a pod to test consume secrets
Aug 20 02:57:22.795: INFO: Waiting up to 5m0s for pod "pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c" in namespace "secrets-4591" to be "success or failure"
Aug 20 02:57:22.798: INFO: Pod "pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595004ms
Aug 20 02:57:24.802: INFO: Pod "pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.006534089s
Aug 20 02:57:26.805: INFO: Pod "pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010006409s
STEP: Saw pod success
Aug 20 02:57:26.805: INFO: Pod "pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c" satisfied condition "success or failure"
Aug 20 02:57:26.808: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 02:57:26.823: INFO: Waiting for pod pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c to disappear
Aug 20 02:57:26.825: INFO: Pod pod-secrets-11c6bb9b-f767-4d42-b162-04eb0e630d4c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:57:26.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4591" for this suite.
Aug 20 02:57:32.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:57:32.938: INFO: namespace secrets-4591 deletion completed in 6.109091012s
STEP: Destroying namespace "secret-namespace-6697" for this suite.
Aug 20 02:57:38.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:57:39.047: INFO: namespace secret-namespace-6697 deletion completed in 6.108450271s

• [SLOW TEST:16.330 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:57:39.047: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:57:39.093: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6" in namespace "projected-1457" to be "success or failure"
Aug 20 02:57:39.095: INFO: Pod "downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.292481ms
Aug 20 02:57:41.099: INFO: Pod "downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005581256s
STEP: Saw pod success
Aug 20 02:57:41.099: INFO: Pod "downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6" satisfied condition "success or failure"
Aug 20 02:57:41.101: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6 container client-container: <nil>
STEP: delete the pod
Aug 20 02:57:41.118: INFO: Waiting for pod downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6 to disappear
Aug 20 02:57:41.120: INFO: Pod downwardapi-volume-b1c09124-fb84-4c47-9ae7-3f3f747d89d6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:57:41.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1457" for this suite.
Aug 20 02:57:47.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:57:47.264: INFO: namespace projected-1457 deletion completed in 6.139790837s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:57:47.265: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[]
Aug 20 02:57:47.311: INFO: Get endpoints failed (4.196416ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 20 02:57:48.316: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[] (1.008395597s elapsed)
STEP: Creating pod pod1 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod1:[100]]
Aug 20 02:57:50.341: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod1:[100]] (2.019414236s elapsed)
STEP: Creating pod pod2 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 20 02:57:52.370: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod1:[100] pod2:[101]] (2.025496346s elapsed)
STEP: Deleting pod pod1 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod2:[101]]
Aug 20 02:57:53.388: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod2:[101]] (1.012560416s elapsed)
STEP: Deleting pod pod2 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[]
Aug 20 02:57:54.457: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[] (1.061843561s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:57:54.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1094" for this suite.
Aug 20 02:58:16.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:58:16.603: INFO: namespace services-1094 deletion completed in 22.118366455s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.338 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:58:16.603: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7641.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7641.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 02:58:20.683: INFO: DNS probes using dns-7641/dns-test-9b2d18ad-bf92-4d9b-b59a-96e099868a1b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:58:20.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7641" for this suite.
Aug 20 02:58:26.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:58:26.824: INFO: namespace dns-7641 deletion completed in 6.126888313s

• [SLOW TEST:10.220 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:58:26.824: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-942
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-942
STEP: Creating statefulset with conflicting port in namespace statefulset-942
STEP: Waiting until pod test-pod will start running in namespace statefulset-942
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-942
Aug 20 02:58:30.893: INFO: Observed stateful pod in namespace: statefulset-942, name: ss-0, uid: 021a34d4-cbab-41f2-9afe-84ae9d597f4b, status phase: Pending. Waiting for statefulset controller to delete.
Aug 20 02:58:31.082: INFO: Observed stateful pod in namespace: statefulset-942, name: ss-0, uid: 021a34d4-cbab-41f2-9afe-84ae9d597f4b, status phase: Failed. Waiting for statefulset controller to delete.
Aug 20 02:58:31.091: INFO: Observed stateful pod in namespace: statefulset-942, name: ss-0, uid: 021a34d4-cbab-41f2-9afe-84ae9d597f4b, status phase: Failed. Waiting for statefulset controller to delete.
Aug 20 02:58:31.099: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-942
STEP: Removing pod with conflicting port in namespace statefulset-942
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-942 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 20 02:58:35.118: INFO: Deleting all statefulset in ns statefulset-942
Aug 20 02:58:35.122: INFO: Scaling statefulset ss to 0
Aug 20 02:58:45.138: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 02:58:45.142: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:58:45.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-942" for this suite.
Aug 20 02:58:51.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:58:51.363: INFO: namespace statefulset-942 deletion completed in 6.198681496s

• [SLOW TEST:24.539 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:58:51.363: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:58:51.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1" in namespace "downward-api-2248" to be "success or failure"
Aug 20 02:58:51.415: INFO: Pod "downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.173818ms
Aug 20 02:58:53.418: INFO: Pod "downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005562836s
STEP: Saw pod success
Aug 20 02:58:53.418: INFO: Pod "downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1" satisfied condition "success or failure"
Aug 20 02:58:53.422: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1 container client-container: <nil>
STEP: delete the pod
Aug 20 02:58:53.444: INFO: Waiting for pod downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1 to disappear
Aug 20 02:58:53.446: INFO: Pod downwardapi-volume-04898e23-2a55-440f-a06f-285e3f777ba1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:58:53.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2248" for this suite.
Aug 20 02:58:59.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:58:59.565: INFO: namespace downward-api-2248 deletion completed in 6.114433408s

• [SLOW TEST:8.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:58:59.565: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 20 02:59:01.620: INFO: Pod pod-hostip-8a5afa97-0553-435c-9aab-42320bddb40f has hostIP: 172.31.23.37
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:59:01.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2430" for this suite.
Aug 20 02:59:23.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:59:23.745: INFO: namespace pods-2430 deletion completed in 22.120609551s

• [SLOW TEST:24.181 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:59:23.746: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 02:59:23.796: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 20 02:59:23.805: INFO: Number of nodes with available pods: 0
Aug 20 02:59:23.805: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 20 02:59:23.822: INFO: Number of nodes with available pods: 0
Aug 20 02:59:23.822: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:24.825: INFO: Number of nodes with available pods: 0
Aug 20 02:59:24.825: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:25.825: INFO: Number of nodes with available pods: 1
Aug 20 02:59:25.825: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 20 02:59:25.840: INFO: Number of nodes with available pods: 1
Aug 20 02:59:25.840: INFO: Number of running nodes: 0, number of available pods: 1
Aug 20 02:59:26.843: INFO: Number of nodes with available pods: 0
Aug 20 02:59:26.844: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 20 02:59:26.850: INFO: Number of nodes with available pods: 0
Aug 20 02:59:26.850: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:27.853: INFO: Number of nodes with available pods: 0
Aug 20 02:59:27.853: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:28.859: INFO: Number of nodes with available pods: 0
Aug 20 02:59:28.859: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:29.854: INFO: Number of nodes with available pods: 0
Aug 20 02:59:29.854: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:30.854: INFO: Number of nodes with available pods: 0
Aug 20 02:59:30.854: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:31.854: INFO: Number of nodes with available pods: 0
Aug 20 02:59:31.854: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 02:59:32.854: INFO: Number of nodes with available pods: 1
Aug 20 02:59:32.854: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9220, will wait for the garbage collector to delete the pods
Aug 20 02:59:32.924: INFO: Deleting DaemonSet.extensions daemon-set took: 10.088635ms
Aug 20 02:59:33.225: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.449293ms
Aug 20 02:59:35.928: INFO: Number of nodes with available pods: 0
Aug 20 02:59:35.928: INFO: Number of running nodes: 0, number of available pods: 0
Aug 20 02:59:35.931: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9220/daemonsets","resourceVersion":"15421"},"items":null}

Aug 20 02:59:35.933: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9220/pods","resourceVersion":"15421"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:59:35.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9220" for this suite.
Aug 20 02:59:41.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:59:42.147: INFO: namespace daemonsets-9220 deletion completed in 6.190729874s

• [SLOW TEST:18.401 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:59:42.148: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 20 02:59:42.181: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 20 02:59:42.191: INFO: Waiting for terminating namespaces to be deleted...
Aug 20 02:59:42.195: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-253 before test
Aug 20 02:59:42.205: INFO: heapster-v1.6.0-beta.1-969d875b-zfq5w from kube-system started at 2019-08-20 01:57:58 +0000 UTC (4 container statuses recorded)
Aug 20 02:59:42.205: INFO: 	Container eventer ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 	Container eventer-nanny ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 	Container heapster ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 	Container heapster-nanny ready: true, restart count 0
Aug 20 02:59:42.205: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-zk9kw from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 20 02:59:42.205: INFO: nginx-ingress-controller-kubernetes-worker-qb8kn from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.205: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 02:59:42.205: INFO: sonobuoy-e2e-job-ae4ab90fc45c47c3 from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.205: INFO: 	Container e2e ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 02:59:42.205: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-23-37 before test
Aug 20 02:59:42.220: INFO: default-http-backend-kubernetes-worker-ffcd96676-jps4h from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.220: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Aug 20 02:59:42.220: INFO: metrics-server-v0.3.3-cc578669-xl6k9 from kube-system started at 2019-08-20 01:58:00 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.220: INFO: 	Container metrics-server ready: true, restart count 0
Aug 20 02:59:42.220: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 20 02:59:42.220: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-20 02:03:49 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.220: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 20 02:59:42.220: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-gr2bt from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.220: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 02:59:42.220: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 20 02:59:42.220: INFO: nginx-ingress-controller-kubernetes-worker-vp4md from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:59 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.220: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 02:59:42.220: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-77-128 before test
Aug 20 02:59:42.258: INFO: nginx-ingress-controller-kubernetes-worker-mg2gl from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:58 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 02:59:42.258: INFO: coredns-75dc589b9b-2kf9z from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container coredns ready: true, restart count 0
Aug 20 02:59:42.258: INFO: coredns-75dc589b9b-v57jz from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container coredns ready: true, restart count 0
Aug 20 02:59:42.258: INFO: monitoring-influxdb-grafana-v4-77766b8fb9-6cwts from kube-system started at 2019-08-20 01:56:48 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container grafana ready: true, restart count 0
Aug 20 02:59:42.258: INFO: 	Container influxdb ready: true, restart count 0
Aug 20 02:59:42.258: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-sc7zl from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 02:59:42.258: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 20 02:59:42.258: INFO: kubernetes-dashboard-f9f9594f9-gxspl from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 02:59:42.258: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bc82401db149f5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:59:43.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3553" for this suite.
Aug 20 02:59:49.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:59:49.461: INFO: namespace sched-pred-3553 deletion completed in 6.15462643s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.314 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:59:49.462: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 02:59:49.511: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3" in namespace "downward-api-3574" to be "success or failure"
Aug 20 02:59:49.515: INFO: Pod "downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.478882ms
Aug 20 02:59:51.519: INFO: Pod "downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00801379s
STEP: Saw pod success
Aug 20 02:59:51.519: INFO: Pod "downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3" satisfied condition "success or failure"
Aug 20 02:59:51.521: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3 container client-container: <nil>
STEP: delete the pod
Aug 20 02:59:51.536: INFO: Waiting for pod downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3 to disappear
Aug 20 02:59:51.541: INFO: Pod downwardapi-volume-4658a54a-d10c-4d71-b26f-c90ea54914f3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 02:59:51.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3574" for this suite.
Aug 20 02:59:57.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 02:59:57.668: INFO: namespace downward-api-3574 deletion completed in 6.122915134s

• [SLOW TEST:8.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 02:59:57.668: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 20 02:59:57.700: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 20 03:00:04.737: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:00:04.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3660" for this suite.
Aug 20 03:00:10.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:00:10.855: INFO: namespace pods-3660 deletion completed in 6.111289036s

• [SLOW TEST:13.187 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:00:10.855: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 20 03:00:10.895: INFO: Waiting up to 5m0s for pod "var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1" in namespace "var-expansion-9632" to be "success or failure"
Aug 20 03:00:10.898: INFO: Pod "var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.411959ms
Aug 20 03:00:12.901: INFO: Pod "var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005998754s
STEP: Saw pod success
Aug 20 03:00:12.901: INFO: Pod "var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1" satisfied condition "success or failure"
Aug 20 03:00:12.904: INFO: Trying to get logs from node ip-172-31-23-37 pod var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1 container dapi-container: <nil>
STEP: delete the pod
Aug 20 03:00:12.919: INFO: Waiting for pod var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1 to disappear
Aug 20 03:00:12.922: INFO: Pod var-expansion-fd439d57-9e73-4ba1-a585-3f38931214d1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:00:12.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9632" for this suite.
Aug 20 03:00:18.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:00:19.056: INFO: namespace var-expansion-9632 deletion completed in 6.130649579s

• [SLOW TEST:8.201 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:00:19.057: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-76dae98f-838a-420b-848c-d485c7dc757c in namespace container-probe-9058
Aug 20 03:00:21.103: INFO: Started pod test-webserver-76dae98f-838a-420b-848c-d485c7dc757c in namespace container-probe-9058
STEP: checking the pod's current state and verifying that restartCount is present
Aug 20 03:00:21.106: INFO: Initial restart count of pod test-webserver-76dae98f-838a-420b-848c-d485c7dc757c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:04:21.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9058" for this suite.
Aug 20 03:04:27.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:04:27.678: INFO: namespace container-probe-9058 deletion completed in 6.117936955s

• [SLOW TEST:248.621 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:04:27.678: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 20 03:04:30.741: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:04:30.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3856" for this suite.
Aug 20 03:04:52.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:04:52.865: INFO: namespace replicaset-3856 deletion completed in 22.106649458s

• [SLOW TEST:25.187 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:04:52.865: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 20 03:04:52.903: INFO: Waiting up to 5m0s for pod "pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8" in namespace "emptydir-6929" to be "success or failure"
Aug 20 03:04:52.906: INFO: Pod "pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.15352ms
Aug 20 03:04:54.909: INFO: Pod "pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005568167s
STEP: Saw pod success
Aug 20 03:04:54.909: INFO: Pod "pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8" satisfied condition "success or failure"
Aug 20 03:04:54.911: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8 container test-container: <nil>
STEP: delete the pod
Aug 20 03:04:54.931: INFO: Waiting for pod pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8 to disappear
Aug 20 03:04:54.933: INFO: Pod pod-7e0e41a2-96b7-4c6e-9f6f-c82bf0c37da8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:04:54.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6929" for this suite.
Aug 20 03:05:00.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:05:01.094: INFO: namespace emptydir-6929 deletion completed in 6.156458354s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:05:01.095: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:05:01.130: INFO: Creating ReplicaSet my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc
Aug 20 03:05:01.144: INFO: Pod name my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc: Found 0 pods out of 1
Aug 20 03:05:06.148: INFO: Pod name my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc: Found 1 pods out of 1
Aug 20 03:05:06.148: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc" is running
Aug 20 03:05:06.150: INFO: Pod "my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc-blgwb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:05:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:05:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:05:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:05:01 +0000 UTC Reason: Message:}])
Aug 20 03:05:06.150: INFO: Trying to dial the pod
Aug 20 03:05:11.162: INFO: Controller my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc: Got expected result from replica 1 [my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc-blgwb]: "my-hostname-basic-38de4f9c-e27c-4d8a-ad4d-0c053c908bcc-blgwb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:05:11.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7840" for this suite.
Aug 20 03:05:17.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:05:17.279: INFO: namespace replicaset-7840 deletion completed in 6.11317897s

• [SLOW TEST:16.185 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:05:17.279: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 20 03:05:19.333: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:05:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2864" for this suite.
Aug 20 03:05:25.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:05:25.476: INFO: namespace container-runtime-2864 deletion completed in 6.124428441s

• [SLOW TEST:8.196 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:05:25.476: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 20 03:05:25.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-1941'
Aug 20 03:05:25.931: INFO: stderr: ""
Aug 20 03:05:25.931: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:05:25.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1941'
Aug 20 03:05:26.047: INFO: stderr: ""
Aug 20 03:05:26.047: INFO: stdout: "update-demo-nautilus-bdlj8 update-demo-nautilus-shpkd "
Aug 20 03:05:26.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bdlj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1941'
Aug 20 03:05:26.144: INFO: stderr: ""
Aug 20 03:05:26.144: INFO: stdout: ""
Aug 20 03:05:26.144: INFO: update-demo-nautilus-bdlj8 is created but not running
Aug 20 03:05:31.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1941'
Aug 20 03:05:31.258: INFO: stderr: ""
Aug 20 03:05:31.258: INFO: stdout: "update-demo-nautilus-bdlj8 update-demo-nautilus-shpkd "
Aug 20 03:05:31.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bdlj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1941'
Aug 20 03:05:31.356: INFO: stderr: ""
Aug 20 03:05:31.356: INFO: stdout: "true"
Aug 20 03:05:31.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bdlj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1941'
Aug 20 03:05:31.461: INFO: stderr: ""
Aug 20 03:05:31.461: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:05:31.461: INFO: validating pod update-demo-nautilus-bdlj8
Aug 20 03:05:31.466: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:05:31.466: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:05:31.466: INFO: update-demo-nautilus-bdlj8 is verified up and running
Aug 20 03:05:31.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-shpkd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1941'
Aug 20 03:05:31.565: INFO: stderr: ""
Aug 20 03:05:31.565: INFO: stdout: "true"
Aug 20 03:05:31.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-shpkd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1941'
Aug 20 03:05:31.636: INFO: stderr: ""
Aug 20 03:05:31.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:05:31.636: INFO: validating pod update-demo-nautilus-shpkd
Aug 20 03:05:31.642: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:05:31.642: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:05:31.642: INFO: update-demo-nautilus-shpkd is verified up and running
STEP: using delete to clean up resources
Aug 20 03:05:31.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-1941'
Aug 20 03:05:31.724: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 03:05:31.724: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 20 03:05:31.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1941'
Aug 20 03:05:31.802: INFO: stderr: "No resources found.\n"
Aug 20 03:05:31.802: INFO: stdout: ""
Aug 20 03:05:31.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=update-demo --namespace=kubectl-1941 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:05:31.872: INFO: stderr: ""
Aug 20 03:05:31.872: INFO: stdout: "update-demo-nautilus-bdlj8\nupdate-demo-nautilus-shpkd\n"
Aug 20 03:05:32.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1941'
Aug 20 03:05:32.457: INFO: stderr: "No resources found.\n"
Aug 20 03:05:32.457: INFO: stdout: ""
Aug 20 03:05:32.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=update-demo --namespace=kubectl-1941 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:05:32.545: INFO: stderr: ""
Aug 20 03:05:32.545: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:05:32.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1941" for this suite.
Aug 20 03:05:38.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:05:38.713: INFO: namespace kubectl-1941 deletion completed in 6.163712087s

• [SLOW TEST:13.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:05:38.713: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4401
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 20 03:05:38.752: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 20 03:06:00.823: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.158:8080/dial?request=hostName&protocol=udp&host=10.1.89.56&port=8081&tries=1'] Namespace:pod-network-test-4401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 03:06:00.823: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 03:06:00.979: INFO: Waiting for endpoints: map[]
Aug 20 03:06:00.982: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.158:8080/dial?request=hostName&protocol=udp&host=10.1.59.157&port=8081&tries=1'] Namespace:pod-network-test-4401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 03:06:00.982: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 03:06:01.099: INFO: Waiting for endpoints: map[]
Aug 20 03:06:01.105: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.59.158:8080/dial?request=hostName&protocol=udp&host=10.1.49.41&port=8081&tries=1'] Namespace:pod-network-test-4401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 20 03:06:01.105: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
Aug 20 03:06:01.226: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:06:01.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4401" for this suite.
Aug 20 03:06:23.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:06:23.379: INFO: namespace pod-network-test-4401 deletion completed in 22.14776242s

• [SLOW TEST:44.665 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:06:23.379: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 20 03:06:25.941: INFO: Successfully updated pod "labelsupdateca2b5763-3501-4254-93c3-7d50de9b4ebe"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:06:27.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7898" for this suite.
Aug 20 03:06:49.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:06:50.086: INFO: namespace downward-api-7898 deletion completed in 22.127241868s

• [SLOW TEST:26.707 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:06:50.086: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 03:06:50.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7573'
Aug 20 03:06:50.203: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 20 03:06:50.203: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 20 03:06:50.207: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 20 03:06:50.210: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 20 03:06:50.216: INFO: scanned /root for discovery docs: <nil>
Aug 20 03:06:50.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7573'
Aug 20 03:07:05.992: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 20 03:07:05.992: INFO: stdout: "Created e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f\nScaling up e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 20 03:07:05.992: INFO: stdout: "Created e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f\nScaling up e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 20 03:07:05.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7573'
Aug 20 03:07:06.090: INFO: stderr: ""
Aug 20 03:07:06.090: INFO: stdout: "e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f-5sg9c "
Aug 20 03:07:06.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f-5sg9c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7573'
Aug 20 03:07:06.182: INFO: stderr: ""
Aug 20 03:07:06.182: INFO: stdout: "true"
Aug 20 03:07:06.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f-5sg9c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7573'
Aug 20 03:07:06.286: INFO: stderr: ""
Aug 20 03:07:06.286: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 20 03:07:06.286: INFO: e2e-test-nginx-rc-6712c6b9542fad07e543ec4c5ee9ca4f-5sg9c is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug 20 03:07:06.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete rc e2e-test-nginx-rc --namespace=kubectl-7573'
Aug 20 03:07:06.398: INFO: stderr: ""
Aug 20 03:07:06.398: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:07:06.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7573" for this suite.
Aug 20 03:07:28.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:07:28.576: INFO: namespace kubectl-7573 deletion completed in 22.173708132s

• [SLOW TEST:38.490 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:07:28.577: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-3d0fd015-6b4a-4bac-824d-239550ed7232
STEP: Creating a pod to test consume secrets
Aug 20 03:07:28.674: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f" in namespace "projected-5281" to be "success or failure"
Aug 20 03:07:28.677: INFO: Pod "pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861167ms
Aug 20 03:07:30.680: INFO: Pod "pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006405066s
STEP: Saw pod success
Aug 20 03:07:30.680: INFO: Pod "pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f" satisfied condition "success or failure"
Aug 20 03:07:30.683: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:07:30.698: INFO: Waiting for pod pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f to disappear
Aug 20 03:07:30.700: INFO: Pod pod-projected-secrets-e7f7de5c-a97a-482f-9477-f8b11159cb2f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:07:30.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5281" for this suite.
Aug 20 03:07:36.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:07:36.838: INFO: namespace projected-5281 deletion completed in 6.133834937s

• [SLOW TEST:8.261 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:07:36.838: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug 20 03:07:36.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-9765'
Aug 20 03:07:37.172: INFO: stderr: ""
Aug 20 03:07:37.172: INFO: stdout: "pod/pause created\n"
Aug 20 03:07:37.172: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 20 03:07:37.172: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9765" to be "running and ready"
Aug 20 03:07:37.182: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.850507ms
Aug 20 03:07:39.185: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013114298s
Aug 20 03:07:41.188: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.016403686s
Aug 20 03:07:41.188: INFO: Pod "pause" satisfied condition "running and ready"
Aug 20 03:07:41.188: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 20 03:07:41.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 label pods pause testing-label=testing-label-value --namespace=kubectl-9765'
Aug 20 03:07:41.270: INFO: stderr: ""
Aug 20 03:07:41.270: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 20 03:07:41.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pod pause -L testing-label --namespace=kubectl-9765'
Aug 20 03:07:41.356: INFO: stderr: ""
Aug 20 03:07:41.356: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 20 03:07:41.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 label pods pause testing-label- --namespace=kubectl-9765'
Aug 20 03:07:41.454: INFO: stderr: ""
Aug 20 03:07:41.454: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 20 03:07:41.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pod pause -L testing-label --namespace=kubectl-9765'
Aug 20 03:07:41.546: INFO: stderr: ""
Aug 20 03:07:41.546: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug 20 03:07:41.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-9765'
Aug 20 03:07:41.644: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 03:07:41.644: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 20 03:07:41.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=pause --no-headers --namespace=kubectl-9765'
Aug 20 03:07:41.743: INFO: stderr: "No resources found.\n"
Aug 20 03:07:41.743: INFO: stdout: ""
Aug 20 03:07:41.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=pause --namespace=kubectl-9765 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:07:41.822: INFO: stderr: ""
Aug 20 03:07:41.822: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:07:41.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9765" for this suite.
Aug 20 03:07:47.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:07:47.928: INFO: namespace kubectl-9765 deletion completed in 6.101910574s

• [SLOW TEST:11.090 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:07:47.928: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 20 03:07:47.957: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:07:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6374" for this suite.
Aug 20 03:07:57.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:07:57.485: INFO: namespace init-container-6374 deletion completed in 6.152430933s

• [SLOW TEST:9.557 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:07:57.486: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-49b4cf67-f3a7-49d5-8250-b9a5b08c8ba4
STEP: Creating a pod to test consume configMaps
Aug 20 03:07:57.534: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b" in namespace "projected-9412" to be "success or failure"
Aug 20 03:07:57.536: INFO: Pod "pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.963244ms
Aug 20 03:07:59.539: INFO: Pod "pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005322208s
STEP: Saw pod success
Aug 20 03:07:59.539: INFO: Pod "pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b" satisfied condition "success or failure"
Aug 20 03:07:59.542: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:07:59.559: INFO: Waiting for pod pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b to disappear
Aug 20 03:07:59.562: INFO: Pod pod-projected-configmaps-ee5bc718-4231-46d2-a4f1-8848b65c577b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:07:59.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9412" for this suite.
Aug 20 03:08:05.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:08:05.784: INFO: namespace projected-9412 deletion completed in 6.216004809s

• [SLOW TEST:8.298 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:08:05.784: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde
Aug 20 03:08:05.828: INFO: Pod name my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde: Found 0 pods out of 1
Aug 20 03:08:10.832: INFO: Pod name my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde: Found 1 pods out of 1
Aug 20 03:08:10.832: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde" are running
Aug 20 03:08:10.835: INFO: Pod "my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde-xjbn5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:08:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:08:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:08:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-20 03:08:05 +0000 UTC Reason: Message:}])
Aug 20 03:08:10.835: INFO: Trying to dial the pod
Aug 20 03:08:15.845: INFO: Controller my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde: Got expected result from replica 1 [my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde-xjbn5]: "my-hostname-basic-705d28a7-fcba-4045-9294-58137029acde-xjbn5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:08:15.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2335" for this suite.
Aug 20 03:08:21.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:08:21.960: INFO: namespace replication-controller-2335 deletion completed in 6.110242864s

• [SLOW TEST:16.176 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:08:21.960: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:08:26.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7071" for this suite.
Aug 20 03:08:32.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:08:32.128: INFO: namespace kubelet-test-7071 deletion completed in 6.114719719s

• [SLOW TEST:10.168 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:08:32.129: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:08:32.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 version'
Aug 20 03:08:32.246: INFO: stderr: ""
Aug 20 03:08:32.246: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T17:06:39Z\", GoVersion:\"go1.12.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:08:32.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9657" for this suite.
Aug 20 03:08:38.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:08:38.361: INFO: namespace kubectl-9657 deletion completed in 6.109901883s

• [SLOW TEST:6.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:08:38.361: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 20 03:08:40.411: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0a794423-d8ca-462c-a6ac-bc0115496f0a,GenerateName:,Namespace:events-4370,SelfLink:/api/v1/namespaces/events-4370/pods/send-events-0a794423-d8ca-462c-a6ac-bc0115496f0a,UID:f726602a-1963-4444-a878-c38df5e6d0fd,ResourceVersion:17074,Generation:0,CreationTimestamp:2019-08-20 03:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 392849131,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-67vkl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-67vkl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-67vkl true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021a3f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021a3f20}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:08:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:08:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:08:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:08:38 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.169,StartTime:2019-08-20 03:08:38 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-20 03:08:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://ef4c84cadeb4b812f55202dafc9ce26d1cb1a1339584e305128ce05f010cac4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 20 03:08:42.424: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 20 03:08:44.428: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:08:44.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4370" for this suite.
Aug 20 03:09:22.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:09:22.549: INFO: namespace events-4370 deletion completed in 38.113186247s

• [SLOW TEST:44.188 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:09:22.549: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 20 03:09:22.587: INFO: Waiting up to 5m0s for pod "pod-dbadb0f2-d759-41b9-a758-03f40944996b" in namespace "emptydir-1524" to be "success or failure"
Aug 20 03:09:22.589: INFO: Pod "pod-dbadb0f2-d759-41b9-a758-03f40944996b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.383347ms
Aug 20 03:09:24.592: INFO: Pod "pod-dbadb0f2-d759-41b9-a758-03f40944996b": Phase="Running", Reason="", readiness=true. Elapsed: 2.005529459s
Aug 20 03:09:26.596: INFO: Pod "pod-dbadb0f2-d759-41b9-a758-03f40944996b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009592365s
STEP: Saw pod success
Aug 20 03:09:26.596: INFO: Pod "pod-dbadb0f2-d759-41b9-a758-03f40944996b" satisfied condition "success or failure"
Aug 20 03:09:26.599: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-dbadb0f2-d759-41b9-a758-03f40944996b container test-container: <nil>
STEP: delete the pod
Aug 20 03:09:26.613: INFO: Waiting for pod pod-dbadb0f2-d759-41b9-a758-03f40944996b to disappear
Aug 20 03:09:26.615: INFO: Pod pod-dbadb0f2-d759-41b9-a758-03f40944996b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:09:26.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1524" for this suite.
Aug 20 03:09:32.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:09:32.727: INFO: namespace emptydir-1524 deletion completed in 6.107849637s

• [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:09:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 20 03:09:32.764: INFO: Waiting up to 5m0s for pod "pod-9320380e-e921-4af8-afd3-5f3269514c07" in namespace "emptydir-5778" to be "success or failure"
Aug 20 03:09:32.766: INFO: Pod "pod-9320380e-e921-4af8-afd3-5f3269514c07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077526ms
Aug 20 03:09:34.770: INFO: Pod "pod-9320380e-e921-4af8-afd3-5f3269514c07": Phase="Running", Reason="", readiness=true. Elapsed: 2.005353835s
Aug 20 03:09:36.773: INFO: Pod "pod-9320380e-e921-4af8-afd3-5f3269514c07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008804388s
STEP: Saw pod success
Aug 20 03:09:36.773: INFO: Pod "pod-9320380e-e921-4af8-afd3-5f3269514c07" satisfied condition "success or failure"
Aug 20 03:09:36.776: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-9320380e-e921-4af8-afd3-5f3269514c07 container test-container: <nil>
STEP: delete the pod
Aug 20 03:09:36.790: INFO: Waiting for pod pod-9320380e-e921-4af8-afd3-5f3269514c07 to disappear
Aug 20 03:09:36.792: INFO: Pod pod-9320380e-e921-4af8-afd3-5f3269514c07 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:09:36.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5778" for this suite.
Aug 20 03:09:42.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:09:42.915: INFO: namespace emptydir-5778 deletion completed in 6.118650701s

• [SLOW TEST:10.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:09:42.916: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 20 03:09:48.987: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:48.989: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:09:50.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:50.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:09:52.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:52.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:09:54.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:54.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:09:56.990: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:56.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:09:58.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:09:59.004: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:00.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:00.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:02.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:02.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:04.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:04.994: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:06.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:06.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:08.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:08.992: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:10.990: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:10.998: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:12.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:12.992: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:14.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:14.993: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 20 03:10:16.989: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 20 03:10:16.993: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:10:16.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9936" for this suite.
Aug 20 03:10:39.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:10:39.103: INFO: namespace container-lifecycle-hook-9936 deletion completed in 22.104587145s

• [SLOW TEST:56.187 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:10:39.103: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-14ff2244-9186-4093-95f7-327283a1e3f1
STEP: Creating a pod to test consume configMaps
Aug 20 03:10:39.143: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c" in namespace "projected-7673" to be "success or failure"
Aug 20 03:10:39.145: INFO: Pod "pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044536ms
Aug 20 03:10:41.148: INFO: Pod "pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005195287s
Aug 20 03:10:43.152: INFO: Pod "pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008534493s
STEP: Saw pod success
Aug 20 03:10:43.152: INFO: Pod "pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c" satisfied condition "success or failure"
Aug 20 03:10:43.154: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:10:43.173: INFO: Waiting for pod pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c to disappear
Aug 20 03:10:43.175: INFO: Pod pod-projected-configmaps-2edd5301-61ab-4ede-9f84-8ef37838e57c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:10:43.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7673" for this suite.
Aug 20 03:10:49.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:10:49.285: INFO: namespace projected-7673 deletion completed in 6.105993445s

• [SLOW TEST:10.182 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:10:49.286: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 20 03:10:49.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 cluster-info'
Aug 20 03:10:49.419: INFO: stderr: ""
Aug 20 03:10:49.419: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mGrafana\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy\x1b[0m\n\x1b[0;32mInfluxDB\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:10:49.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-266" for this suite.
Aug 20 03:10:55.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:10:55.545: INFO: namespace kubectl-266 deletion completed in 6.121629934s

• [SLOW TEST:6.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:10:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:10:55.588: INFO: (0) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.348615ms)
Aug 20 03:10:55.592: INFO: (1) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.102552ms)
Aug 20 03:10:55.596: INFO: (2) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.401711ms)
Aug 20 03:10:55.600: INFO: (3) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.862787ms)
Aug 20 03:10:55.605: INFO: (4) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.493902ms)
Aug 20 03:10:55.609: INFO: (5) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.783172ms)
Aug 20 03:10:55.612: INFO: (6) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.737196ms)
Aug 20 03:10:55.616: INFO: (7) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.874674ms)
Aug 20 03:10:55.620: INFO: (8) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.831657ms)
Aug 20 03:10:55.624: INFO: (9) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.856534ms)
Aug 20 03:10:55.628: INFO: (10) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.744545ms)
Aug 20 03:10:55.632: INFO: (11) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.81093ms)
Aug 20 03:10:55.636: INFO: (12) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.218456ms)
Aug 20 03:10:55.640: INFO: (13) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.891452ms)
Aug 20 03:10:55.644: INFO: (14) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.201376ms)
Aug 20 03:10:55.648: INFO: (15) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.914186ms)
Aug 20 03:10:55.652: INFO: (16) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.878384ms)
Aug 20 03:10:55.656: INFO: (17) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.023911ms)
Aug 20 03:10:55.660: INFO: (18) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.82434ms)
Aug 20 03:10:55.664: INFO: (19) /api/v1/nodes/ip-172-31-1-253/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.920218ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:10:55.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3384" for this suite.
Aug 20 03:11:01.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:11:01.853: INFO: namespace proxy-3384 deletion completed in 6.185494148s

• [SLOW TEST:6.308 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:11:01.853: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 20 03:11:03.924: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:11:03.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9746" for this suite.
Aug 20 03:11:09.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:11:10.076: INFO: namespace container-runtime-9746 deletion completed in 6.136667968s

• [SLOW TEST:8.223 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:11:10.077: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-751f7062-6354-4283-8e3f-37fffd7cd409
STEP: Creating a pod to test consume secrets
Aug 20 03:11:10.126: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199" in namespace "projected-8925" to be "success or failure"
Aug 20 03:11:10.128: INFO: Pod "pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172036ms
Aug 20 03:11:12.131: INFO: Pod "pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199": Phase="Running", Reason="", readiness=true. Elapsed: 2.005346495s
Aug 20 03:11:14.134: INFO: Pod "pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008603824s
STEP: Saw pod success
Aug 20 03:11:14.134: INFO: Pod "pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199" satisfied condition "success or failure"
Aug 20 03:11:14.137: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:11:14.159: INFO: Waiting for pod pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199 to disappear
Aug 20 03:11:14.161: INFO: Pod pod-projected-secrets-aded7934-71e2-4598-958a-ee71828fa199 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:11:14.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8925" for this suite.
Aug 20 03:11:20.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:11:20.306: INFO: namespace projected-8925 deletion completed in 6.141007704s

• [SLOW TEST:10.230 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:11:20.307: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-ebb5943b-75b9-4fe3-9211-e4ff5fc35137 in namespace container-probe-5585
Aug 20 03:11:22.364: INFO: Started pod liveness-ebb5943b-75b9-4fe3-9211-e4ff5fc35137 in namespace container-probe-5585
STEP: checking the pod's current state and verifying that restartCount is present
Aug 20 03:11:22.366: INFO: Initial restart count of pod liveness-ebb5943b-75b9-4fe3-9211-e4ff5fc35137 is 0
Aug 20 03:11:44.413: INFO: Restart count of pod container-probe-5585/liveness-ebb5943b-75b9-4fe3-9211-e4ff5fc35137 is now 1 (22.047122147s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:11:44.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5585" for this suite.
Aug 20 03:11:50.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:11:50.574: INFO: namespace container-probe-5585 deletion completed in 6.141328431s

• [SLOW TEST:30.267 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:11:50.574: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 20 03:11:55.146: INFO: Successfully updated pod "pod-update-activedeadlineseconds-031f8331-c823-4311-8388-b4554fc3c72a"
Aug 20 03:11:55.146: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-031f8331-c823-4311-8388-b4554fc3c72a" in namespace "pods-5276" to be "terminated due to deadline exceeded"
Aug 20 03:11:55.148: INFO: Pod "pod-update-activedeadlineseconds-031f8331-c823-4311-8388-b4554fc3c72a": Phase="Running", Reason="", readiness=true. Elapsed: 2.500281ms
Aug 20 03:11:57.152: INFO: Pod "pod-update-activedeadlineseconds-031f8331-c823-4311-8388-b4554fc3c72a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006174563s
Aug 20 03:11:57.152: INFO: Pod "pod-update-activedeadlineseconds-031f8331-c823-4311-8388-b4554fc3c72a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:11:57.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5276" for this suite.
Aug 20 03:12:03.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:12:03.289: INFO: namespace pods-5276 deletion completed in 6.132652653s

• [SLOW TEST:12.715 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:12:03.289: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 03:12:03.333: INFO: Waiting up to 5m0s for pod "downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0" in namespace "projected-349" to be "success or failure"
Aug 20 03:12:03.337: INFO: Pod "downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.289485ms
Aug 20 03:12:05.340: INFO: Pod "downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007011042s
Aug 20 03:12:07.344: INFO: Pod "downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010690768s
STEP: Saw pod success
Aug 20 03:12:07.344: INFO: Pod "downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0" satisfied condition "success or failure"
Aug 20 03:12:07.347: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0 container client-container: <nil>
STEP: delete the pod
Aug 20 03:12:07.362: INFO: Waiting for pod downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0 to disappear
Aug 20 03:12:07.364: INFO: Pod downwardapi-volume-304eadc1-cfd4-44ef-8882-498a8ad98ee0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:12:07.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-349" for this suite.
Aug 20 03:12:13.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:12:13.474: INFO: namespace projected-349 deletion completed in 6.104877571s

• [SLOW TEST:10.185 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:12:13.474: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 20 03:12:13.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-1985'
Aug 20 03:12:13.708: INFO: stderr: ""
Aug 20 03:12:13.708: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:12:13.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1985'
Aug 20 03:12:13.825: INFO: stderr: ""
Aug 20 03:12:13.825: INFO: stdout: "update-demo-nautilus-bk69b update-demo-nautilus-m6wb6 "
Aug 20 03:12:13.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bk69b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:13.904: INFO: stderr: ""
Aug 20 03:12:13.904: INFO: stdout: ""
Aug 20 03:12:13.904: INFO: update-demo-nautilus-bk69b is created but not running
Aug 20 03:12:18.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1985'
Aug 20 03:12:18.992: INFO: stderr: ""
Aug 20 03:12:18.992: INFO: stdout: "update-demo-nautilus-bk69b update-demo-nautilus-m6wb6 "
Aug 20 03:12:18.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bk69b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:19.084: INFO: stderr: ""
Aug 20 03:12:19.084: INFO: stdout: "true"
Aug 20 03:12:19.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-bk69b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:19.184: INFO: stderr: ""
Aug 20 03:12:19.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:12:19.184: INFO: validating pod update-demo-nautilus-bk69b
Aug 20 03:12:19.190: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:12:19.190: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:12:19.190: INFO: update-demo-nautilus-bk69b is verified up and running
Aug 20 03:12:19.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-m6wb6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:19.279: INFO: stderr: ""
Aug 20 03:12:19.279: INFO: stdout: "true"
Aug 20 03:12:19.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-m6wb6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:19.371: INFO: stderr: ""
Aug 20 03:12:19.371: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:12:19.371: INFO: validating pod update-demo-nautilus-m6wb6
Aug 20 03:12:19.378: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:12:19.378: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:12:19.378: INFO: update-demo-nautilus-m6wb6 is verified up and running
STEP: rolling-update to new replication controller
Aug 20 03:12:19.380: INFO: scanned /root for discovery docs: <nil>
Aug 20 03:12:19.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1985'
Aug 20 03:12:41.727: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 20 03:12:41.727: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:12:41.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1985'
Aug 20 03:12:41.813: INFO: stderr: ""
Aug 20 03:12:41.813: INFO: stdout: "update-demo-kitten-4xflh update-demo-kitten-c987h "
Aug 20 03:12:41.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-kitten-4xflh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:41.906: INFO: stderr: ""
Aug 20 03:12:41.906: INFO: stdout: "true"
Aug 20 03:12:41.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-kitten-4xflh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:42.014: INFO: stderr: ""
Aug 20 03:12:42.014: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 20 03:12:42.014: INFO: validating pod update-demo-kitten-4xflh
Aug 20 03:12:42.019: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 20 03:12:42.019: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 20 03:12:42.019: INFO: update-demo-kitten-4xflh is verified up and running
Aug 20 03:12:42.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-kitten-c987h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:42.100: INFO: stderr: ""
Aug 20 03:12:42.100: INFO: stdout: "true"
Aug 20 03:12:42.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-kitten-c987h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1985'
Aug 20 03:12:42.182: INFO: stderr: ""
Aug 20 03:12:42.182: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 20 03:12:42.182: INFO: validating pod update-demo-kitten-c987h
Aug 20 03:12:42.187: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 20 03:12:42.187: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 20 03:12:42.187: INFO: update-demo-kitten-c987h is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:12:42.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1985" for this suite.
Aug 20 03:13:04.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:13:04.321: INFO: namespace kubectl-1985 deletion completed in 22.130771434s

• [SLOW TEST:50.847 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:13:04.322: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 20 03:13:04.363: INFO: Waiting up to 5m0s for pod "client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf" in namespace "containers-9917" to be "success or failure"
Aug 20 03:13:04.365: INFO: Pod "client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.448703ms
Aug 20 03:13:06.369: INFO: Pod "client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006193889s
STEP: Saw pod success
Aug 20 03:13:06.369: INFO: Pod "client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf" satisfied condition "success or failure"
Aug 20 03:13:06.371: INFO: Trying to get logs from node ip-172-31-23-37 pod client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf container test-container: <nil>
STEP: delete the pod
Aug 20 03:13:06.387: INFO: Waiting for pod client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf to disappear
Aug 20 03:13:06.389: INFO: Pod client-containers-47668683-9786-42b9-aed7-eedbc2ec8daf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:13:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9917" for this suite.
Aug 20 03:13:12.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:13:12.517: INFO: namespace containers-9917 deletion completed in 6.124362357s

• [SLOW TEST:8.196 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:13:12.517: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:13:12.570: INFO: Create a RollingUpdate DaemonSet
Aug 20 03:13:12.578: INFO: Check that daemon pods launch on every node of the cluster
Aug 20 03:13:12.585: INFO: Number of nodes with available pods: 0
Aug 20 03:13:12.585: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:13:13.592: INFO: Number of nodes with available pods: 0
Aug 20 03:13:13.592: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:13:14.592: INFO: Number of nodes with available pods: 3
Aug 20 03:13:14.592: INFO: Number of running nodes: 3, number of available pods: 3
Aug 20 03:13:14.592: INFO: Update the DaemonSet to trigger a rollout
Aug 20 03:13:14.599: INFO: Updating DaemonSet daemon-set
Aug 20 03:13:26.618: INFO: Roll back the DaemonSet before rollout is complete
Aug 20 03:13:26.625: INFO: Updating DaemonSet daemon-set
Aug 20 03:13:26.625: INFO: Make sure DaemonSet rollback is complete
Aug 20 03:13:26.628: INFO: Wrong image for pod: daemon-set-c4795. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 20 03:13:26.628: INFO: Pod daemon-set-c4795 is not available
Aug 20 03:13:27.635: INFO: Wrong image for pod: daemon-set-c4795. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 20 03:13:27.635: INFO: Pod daemon-set-c4795 is not available
Aug 20 03:13:28.636: INFO: Wrong image for pod: daemon-set-c4795. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 20 03:13:28.636: INFO: Pod daemon-set-c4795 is not available
Aug 20 03:13:29.636: INFO: Wrong image for pod: daemon-set-c4795. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 20 03:13:29.636: INFO: Pod daemon-set-c4795 is not available
Aug 20 03:13:30.636: INFO: Wrong image for pod: daemon-set-c4795. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 20 03:13:30.636: INFO: Pod daemon-set-c4795 is not available
Aug 20 03:13:31.636: INFO: Pod daemon-set-xkgb2 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3346, will wait for the garbage collector to delete the pods
Aug 20 03:13:31.705: INFO: Deleting DaemonSet.extensions daemon-set took: 7.142387ms
Aug 20 03:13:32.005: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.286709ms
Aug 20 03:14:56.509: INFO: Number of nodes with available pods: 0
Aug 20 03:14:56.509: INFO: Number of running nodes: 0, number of available pods: 0
Aug 20 03:14:56.511: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3346/daemonsets","resourceVersion":"18246"},"items":null}

Aug 20 03:14:56.513: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3346/pods","resourceVersion":"18246"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:14:56.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3346" for this suite.
Aug 20 03:15:02.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:15:02.666: INFO: namespace daemonsets-3346 deletion completed in 6.135155258s

• [SLOW TEST:110.148 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:15:02.666: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:15:02.704: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 20 03:15:02.714: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 20 03:15:07.717: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 20 03:15:07.717: INFO: Creating deployment "test-rolling-update-deployment"
Aug 20 03:15:07.722: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 20 03:15:07.727: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 20 03:15:09.732: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 20 03:15:09.735: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 20 03:15:09.741: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-2175,SelfLink:/apis/apps/v1/namespaces/deployment-2175/deployments/test-rolling-update-deployment,UID:0168f756-47bd-4a9b-9cda-620f766bb60a,ResourceVersion:18349,Generation:1,CreationTimestamp:2019-08-20 03:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-20 03:15:07 +0000 UTC 2019-08-20 03:15:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-20 03:15:09 +0000 UTC 2019-08-20 03:15:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 20 03:15:09.744: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-2175,SelfLink:/apis/apps/v1/namespaces/deployment-2175/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:c2ea6f10-07a2-41ec-9714-ba4009cc11e8,ResourceVersion:18338,Generation:1,CreationTimestamp:2019-08-20 03:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0168f756-47bd-4a9b-9cda-620f766bb60a 0xc000e44837 0xc000e44838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 20 03:15:09.744: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 20 03:15:09.744: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-2175,SelfLink:/apis/apps/v1/namespaces/deployment-2175/replicasets/test-rolling-update-controller,UID:aad5e83c-1fff-4e4e-87e5-2dbcb46344a7,ResourceVersion:18348,Generation:2,CreationTimestamp:2019-08-20 03:15:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0168f756-47bd-4a9b-9cda-620f766bb60a 0xc000e44767 0xc000e44768}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 03:15:09.746: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-j2j4g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-j2j4g,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-2175,SelfLink:/api/v1/namespaces/deployment-2175/pods/test-rolling-update-deployment-79f6b9d75c-j2j4g,UID:1fd03c2d-4fc9-4729-a35e-ee4baf70a54d,ResourceVersion:18337,Generation:0,CreationTimestamp:2019-08-20 03:15:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c c2ea6f10-07a2-41ec-9714-ba4009cc11e8 0xc000e45147 0xc000e45148}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lhpd4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lhpd4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lhpd4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e451d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e451f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:15:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:15:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:15:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:15:07 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.188,StartTime:2019-08-20 03:15:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-20 03:15:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://295654e2db0b16eb1b279f7d91fa77dcc9c2df44da71a550b5d7f1293fa7874e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:15:09.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2175" for this suite.
Aug 20 03:15:15.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:15:15.872: INFO: namespace deployment-2175 deletion completed in 6.122154022s

• [SLOW TEST:13.206 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:15:15.873: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-63b5e598-3c76-468e-a85e-dcf8be2977a4
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:15:15.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7221" for this suite.
Aug 20 03:15:21.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:15:22.022: INFO: namespace secrets-7221 deletion completed in 6.106496483s

• [SLOW TEST:6.149 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:15:22.022: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-5d4b7dd1-964b-466a-9e33-8c4d960586a4
STEP: Creating a pod to test consume configMaps
Aug 20 03:15:22.078: INFO: Waiting up to 5m0s for pod "pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171" in namespace "configmap-7820" to be "success or failure"
Aug 20 03:15:22.081: INFO: Pod "pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171": Phase="Pending", Reason="", readiness=false. Elapsed: 1.990223ms
Aug 20 03:15:24.084: INFO: Pod "pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171": Phase="Running", Reason="", readiness=true. Elapsed: 2.005380557s
Aug 20 03:15:26.087: INFO: Pod "pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008708215s
STEP: Saw pod success
Aug 20 03:15:26.087: INFO: Pod "pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171" satisfied condition "success or failure"
Aug 20 03:15:26.090: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:15:26.105: INFO: Waiting for pod pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171 to disappear
Aug 20 03:15:26.107: INFO: Pod pod-configmaps-59af24fc-d364-4f87-bd05-455a2f248171 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:15:26.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7820" for this suite.
Aug 20 03:15:32.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:15:32.273: INFO: namespace configmap-7820 deletion completed in 6.163031658s

• [SLOW TEST:10.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:15:32.274: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug 20 03:16:02.848: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0820 03:16:02.848899      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:16:02.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1936" for this suite.
Aug 20 03:16:08.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:16:08.963: INFO: namespace gc-1936 deletion completed in 6.11045073s

• [SLOW TEST:36.689 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:16:08.963: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:16:09.003: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 20 03:16:14.008: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 20 03:16:14.008: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 20 03:16:14.025: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2042,SelfLink:/apis/apps/v1/namespaces/deployment-2042/deployments/test-cleanup-deployment,UID:9f564d7d-d57c-4a74-a6ac-abce93214985,ResourceVersion:18594,Generation:1,CreationTimestamp:2019-08-20 03:16:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Aug 20 03:16:14.029: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-2042,SelfLink:/apis/apps/v1/namespaces/deployment-2042/replicasets/test-cleanup-deployment-55bbcbc84c,UID:fe384298-ef7b-4609-97a6-6e3bad0203e4,ResourceVersion:18596,Generation:1,CreationTimestamp:2019-08-20 03:16:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9f564d7d-d57c-4a74-a6ac-abce93214985 0xc0020daad7 0xc0020daad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 03:16:14.029: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 20 03:16:14.030: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2042,SelfLink:/apis/apps/v1/namespaces/deployment-2042/replicasets/test-cleanup-controller,UID:c0313dca-f97c-479b-b1de-2cc669bea83c,ResourceVersion:18595,Generation:1,CreationTimestamp:2019-08-20 03:16:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9f564d7d-d57c-4a74-a6ac-abce93214985 0xc0020daa07 0xc0020daa08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 20 03:16:14.032: INFO: Pod "test-cleanup-controller-td759" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-td759,GenerateName:test-cleanup-controller-,Namespace:deployment-2042,SelfLink:/api/v1/namespaces/deployment-2042/pods/test-cleanup-controller-td759,UID:f5766f57-c790-48a0-952d-7d01355f80e5,ResourceVersion:18585,Generation:0,CreationTimestamp:2019-08-20 03:16:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c0313dca-f97c-479b-b1de-2cc669bea83c 0xc0020db3e7 0xc0020db3e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hb45s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hb45s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hb45s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020db460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020db480}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:16:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:16:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:16:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:16:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:10.1.59.191,StartTime:2019-08-20 03:16:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-20 03:16:10 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4613d4ea0ba14ac113a37dafdf91b68410ee1d6223aadd2ffbcb1681069d663f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:16:14.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2042" for this suite.
Aug 20 03:16:20.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:16:20.161: INFO: namespace deployment-2042 deletion completed in 6.117551675s

• [SLOW TEST:11.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:16:20.161: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 20 03:16:20.239: INFO: Number of nodes with available pods: 0
Aug 20 03:16:20.239: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:16:21.247: INFO: Number of nodes with available pods: 0
Aug 20 03:16:21.247: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:16:22.247: INFO: Number of nodes with available pods: 3
Aug 20 03:16:22.247: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 20 03:16:22.262: INFO: Number of nodes with available pods: 2
Aug 20 03:16:22.262: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:23.271: INFO: Number of nodes with available pods: 2
Aug 20 03:16:23.271: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:24.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:24.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:25.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:25.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:26.271: INFO: Number of nodes with available pods: 2
Aug 20 03:16:26.271: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:27.271: INFO: Number of nodes with available pods: 2
Aug 20 03:16:27.271: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:28.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:28.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:29.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:29.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:30.272: INFO: Number of nodes with available pods: 2
Aug 20 03:16:30.272: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:31.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:31.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:32.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:32.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:33.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:33.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:34.271: INFO: Number of nodes with available pods: 2
Aug 20 03:16:34.271: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:35.279: INFO: Number of nodes with available pods: 2
Aug 20 03:16:35.279: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:36.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:36.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:37.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:37.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:38.270: INFO: Number of nodes with available pods: 2
Aug 20 03:16:38.270: INFO: Node ip-172-31-23-37 is running more than one daemon pod
Aug 20 03:16:39.270: INFO: Number of nodes with available pods: 3
Aug 20 03:16:39.270: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1743, will wait for the garbage collector to delete the pods
Aug 20 03:16:39.332: INFO: Deleting DaemonSet.extensions daemon-set took: 7.2305ms
Aug 20 03:16:39.433: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.302524ms
Aug 20 03:16:51.836: INFO: Number of nodes with available pods: 0
Aug 20 03:16:51.836: INFO: Number of running nodes: 0, number of available pods: 0
Aug 20 03:16:51.838: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1743/daemonsets","resourceVersion":"18771"},"items":null}

Aug 20 03:16:51.841: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1743/pods","resourceVersion":"18771"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:16:51.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1743" for this suite.
Aug 20 03:16:57.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:16:57.962: INFO: namespace daemonsets-1743 deletion completed in 6.103527091s

• [SLOW TEST:37.801 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:16:57.963: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-txdcf in namespace proxy-9138
I0820 03:16:58.009226      18 runners.go:180] Created replication controller with name: proxy-service-txdcf, namespace: proxy-9138, replica count: 1
I0820 03:16:59.059668      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0820 03:17:00.060923      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0820 03:17:01.061161      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0820 03:17:02.061360      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0820 03:17:03.061598      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0820 03:17:04.061804      18 runners.go:180] proxy-service-txdcf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 20 03:17:04.066: INFO: setup took 6.076313996s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 20 03:17:04.073: INFO: (0) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 6.643101ms)
Aug 20 03:17:04.074: INFO: (0) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.65448ms)
Aug 20 03:17:04.074: INFO: (0) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 8.029319ms)
Aug 20 03:17:04.075: INFO: (0) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 8.951992ms)
Aug 20 03:17:04.075: INFO: (0) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 9.395957ms)
Aug 20 03:17:04.075: INFO: (0) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 9.474666ms)
Aug 20 03:17:04.076: INFO: (0) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 9.556295ms)
Aug 20 03:17:04.079: INFO: (0) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 13.077181ms)
Aug 20 03:17:04.080: INFO: (0) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 13.986205ms)
Aug 20 03:17:04.081: INFO: (0) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 14.553258ms)
Aug 20 03:17:04.081: INFO: (0) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 14.527534ms)
Aug 20 03:17:04.082: INFO: (0) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 15.605979ms)
Aug 20 03:17:04.082: INFO: (0) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 16.422576ms)
Aug 20 03:17:04.082: INFO: (0) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 16.258807ms)
Aug 20 03:17:04.083: INFO: (0) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 17.103151ms)
Aug 20 03:17:04.087: INFO: (0) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 20.705927ms)
Aug 20 03:17:04.091: INFO: (1) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 4.705486ms)
Aug 20 03:17:04.097: INFO: (1) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 10.501126ms)
Aug 20 03:17:04.097: INFO: (1) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 10.662741ms)
Aug 20 03:17:04.097: INFO: (1) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 10.568486ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 10.595472ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 10.685272ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 10.821162ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.758947ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 10.879406ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 10.867804ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 10.698926ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 10.773592ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 10.749881ms)
Aug 20 03:17:04.098: INFO: (1) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 10.7346ms)
Aug 20 03:17:04.099: INFO: (1) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 11.736558ms)
Aug 20 03:17:04.099: INFO: (1) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 12.034326ms)
Aug 20 03:17:04.110: INFO: (2) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 11.378934ms)
Aug 20 03:17:04.114: INFO: (2) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 14.330375ms)
Aug 20 03:17:04.115: INFO: (2) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 16.325969ms)
Aug 20 03:17:04.115: INFO: (2) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 16.372335ms)
Aug 20 03:17:04.115: INFO: (2) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 16.151739ms)
Aug 20 03:17:04.115: INFO: (2) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 16.034722ms)
Aug 20 03:17:04.115: INFO: (2) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 16.348264ms)
Aug 20 03:17:04.116: INFO: (2) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 16.616454ms)
Aug 20 03:17:04.116: INFO: (2) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 16.926894ms)
Aug 20 03:17:04.116: INFO: (2) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 16.552298ms)
Aug 20 03:17:04.116: INFO: (2) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 17.284376ms)
Aug 20 03:17:04.118: INFO: (2) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 19.10588ms)
Aug 20 03:17:04.119: INFO: (2) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 20.047633ms)
Aug 20 03:17:04.120: INFO: (2) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 20.036174ms)
Aug 20 03:17:04.120: INFO: (2) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 20.44319ms)
Aug 20 03:17:04.120: INFO: (2) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 20.892977ms)
Aug 20 03:17:04.125: INFO: (3) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 4.84147ms)
Aug 20 03:17:04.128: INFO: (3) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.523969ms)
Aug 20 03:17:04.128: INFO: (3) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.414737ms)
Aug 20 03:17:04.128: INFO: (3) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.505501ms)
Aug 20 03:17:04.128: INFO: (3) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 7.697371ms)
Aug 20 03:17:04.128: INFO: (3) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 7.586392ms)
Aug 20 03:17:04.129: INFO: (3) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 8.155099ms)
Aug 20 03:17:04.129: INFO: (3) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 8.617268ms)
Aug 20 03:17:04.129: INFO: (3) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 8.455959ms)
Aug 20 03:17:04.129: INFO: (3) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 8.963222ms)
Aug 20 03:17:04.130: INFO: (3) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 9.778603ms)
Aug 20 03:17:04.131: INFO: (3) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 10.133398ms)
Aug 20 03:17:04.131: INFO: (3) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 10.558986ms)
Aug 20 03:17:04.131: INFO: (3) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 10.701066ms)
Aug 20 03:17:04.132: INFO: (3) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 11.774621ms)
Aug 20 03:17:04.133: INFO: (3) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 12.244011ms)
Aug 20 03:17:04.137: INFO: (4) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 4.031318ms)
Aug 20 03:17:04.137: INFO: (4) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 4.128606ms)
Aug 20 03:17:04.138: INFO: (4) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 4.713274ms)
Aug 20 03:17:04.138: INFO: (4) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 5.180867ms)
Aug 20 03:17:04.138: INFO: (4) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 5.15493ms)
Aug 20 03:17:04.141: INFO: (4) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 8.035102ms)
Aug 20 03:17:04.141: INFO: (4) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 7.78922ms)
Aug 20 03:17:04.141: INFO: (4) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.865825ms)
Aug 20 03:17:04.141: INFO: (4) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.882308ms)
Aug 20 03:17:04.141: INFO: (4) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 8.381031ms)
Aug 20 03:17:04.143: INFO: (4) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 10.1253ms)
Aug 20 03:17:04.143: INFO: (4) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.144737ms)
Aug 20 03:17:04.143: INFO: (4) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 10.196753ms)
Aug 20 03:17:04.144: INFO: (4) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 10.622537ms)
Aug 20 03:17:04.144: INFO: (4) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 10.991981ms)
Aug 20 03:17:04.144: INFO: (4) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 11.132404ms)
Aug 20 03:17:04.152: INFO: (5) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.70934ms)
Aug 20 03:17:04.153: INFO: (5) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 9.204673ms)
Aug 20 03:17:04.154: INFO: (5) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 9.905872ms)
Aug 20 03:17:04.155: INFO: (5) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 10.856694ms)
Aug 20 03:17:04.157: INFO: (5) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 12.59128ms)
Aug 20 03:17:04.157: INFO: (5) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 12.94761ms)
Aug 20 03:17:04.158: INFO: (5) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 13.766257ms)
Aug 20 03:17:04.158: INFO: (5) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 13.821379ms)
Aug 20 03:17:04.158: INFO: (5) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 14.001487ms)
Aug 20 03:17:04.158: INFO: (5) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 13.961429ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 14.196275ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 14.726479ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 14.690345ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 14.758984ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 14.838148ms)
Aug 20 03:17:04.159: INFO: (5) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 15.073616ms)
Aug 20 03:17:04.164: INFO: (6) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 4.828325ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.228152ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.249015ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 7.680045ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 7.637219ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 7.96754ms)
Aug 20 03:17:04.167: INFO: (6) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 7.93543ms)
Aug 20 03:17:04.169: INFO: (6) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 9.126324ms)
Aug 20 03:17:04.169: INFO: (6) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 9.336475ms)
Aug 20 03:17:04.169: INFO: (6) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 9.329409ms)
Aug 20 03:17:04.169: INFO: (6) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 9.621599ms)
Aug 20 03:17:04.169: INFO: (6) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 9.76365ms)
Aug 20 03:17:04.171: INFO: (6) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 11.229626ms)
Aug 20 03:17:04.172: INFO: (6) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 12.474042ms)
Aug 20 03:17:04.172: INFO: (6) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 12.499306ms)
Aug 20 03:17:04.172: INFO: (6) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 12.706447ms)
Aug 20 03:17:04.177: INFO: (7) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 4.105765ms)
Aug 20 03:17:04.178: INFO: (7) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 5.753727ms)
Aug 20 03:17:04.179: INFO: (7) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.16022ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 7.751536ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 7.796554ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 8.02959ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.723517ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 7.844522ms)
Aug 20 03:17:04.180: INFO: (7) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.798896ms)
Aug 20 03:17:04.181: INFO: (7) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 8.373372ms)
Aug 20 03:17:04.181: INFO: (7) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 8.395148ms)
Aug 20 03:17:04.182: INFO: (7) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 9.40812ms)
Aug 20 03:17:04.182: INFO: (7) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 9.673182ms)
Aug 20 03:17:04.184: INFO: (7) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 11.198517ms)
Aug 20 03:17:04.184: INFO: (7) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 12.049491ms)
Aug 20 03:17:04.185: INFO: (7) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 12.262443ms)
Aug 20 03:17:04.188: INFO: (8) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 3.743197ms)
Aug 20 03:17:04.189: INFO: (8) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 4.510968ms)
Aug 20 03:17:04.190: INFO: (8) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 5.241091ms)
Aug 20 03:17:04.191: INFO: (8) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.113791ms)
Aug 20 03:17:04.191: INFO: (8) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 6.445317ms)
Aug 20 03:17:04.191: INFO: (8) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 6.546215ms)
Aug 20 03:17:04.191: INFO: (8) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 6.587873ms)
Aug 20 03:17:04.192: INFO: (8) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.18153ms)
Aug 20 03:17:04.193: INFO: (8) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 7.834728ms)
Aug 20 03:17:04.193: INFO: (8) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 8.056338ms)
Aug 20 03:17:04.193: INFO: (8) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 8.319284ms)
Aug 20 03:17:04.195: INFO: (8) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 9.75806ms)
Aug 20 03:17:04.209: INFO: (8) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 23.979948ms)
Aug 20 03:17:04.209: INFO: (8) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 23.963305ms)
Aug 20 03:17:04.209: INFO: (8) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 23.988534ms)
Aug 20 03:17:04.209: INFO: (8) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 24.258155ms)
Aug 20 03:17:04.223: INFO: (9) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 13.801685ms)
Aug 20 03:17:04.224: INFO: (9) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 14.51839ms)
Aug 20 03:17:04.224: INFO: (9) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 15.072182ms)
Aug 20 03:17:04.224: INFO: (9) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 15.10388ms)
Aug 20 03:17:04.225: INFO: (9) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 15.599404ms)
Aug 20 03:17:04.225: INFO: (9) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 15.537004ms)
Aug 20 03:17:04.225: INFO: (9) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 15.942715ms)
Aug 20 03:17:04.227: INFO: (9) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 17.694766ms)
Aug 20 03:17:04.227: INFO: (9) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 17.589079ms)
Aug 20 03:17:04.227: INFO: (9) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 17.637059ms)
Aug 20 03:17:04.227: INFO: (9) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 18.094131ms)
Aug 20 03:17:04.228: INFO: (9) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 18.870417ms)
Aug 20 03:17:04.228: INFO: (9) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 19.030213ms)
Aug 20 03:17:04.228: INFO: (9) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 19.036815ms)
Aug 20 03:17:04.228: INFO: (9) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 19.217178ms)
Aug 20 03:17:04.229: INFO: (9) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 19.309138ms)
Aug 20 03:17:04.233: INFO: (10) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 3.890762ms)
Aug 20 03:17:04.234: INFO: (10) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 5.271721ms)
Aug 20 03:17:04.235: INFO: (10) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 5.781621ms)
Aug 20 03:17:04.235: INFO: (10) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.193508ms)
Aug 20 03:17:04.236: INFO: (10) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.86958ms)
Aug 20 03:17:04.236: INFO: (10) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 6.860557ms)
Aug 20 03:17:04.236: INFO: (10) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 7.656246ms)
Aug 20 03:17:04.238: INFO: (10) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 8.774563ms)
Aug 20 03:17:04.238: INFO: (10) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 9.436692ms)
Aug 20 03:17:04.239: INFO: (10) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 10.197782ms)
Aug 20 03:17:04.239: INFO: (10) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 10.247831ms)
Aug 20 03:17:04.239: INFO: (10) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 10.075917ms)
Aug 20 03:17:04.240: INFO: (10) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 11.195677ms)
Aug 20 03:17:04.240: INFO: (10) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 11.311806ms)
Aug 20 03:17:04.240: INFO: (10) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 11.583649ms)
Aug 20 03:17:04.241: INFO: (10) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 11.791233ms)
Aug 20 03:17:04.245: INFO: (11) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 4.621219ms)
Aug 20 03:17:04.249: INFO: (11) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 7.99205ms)
Aug 20 03:17:04.249: INFO: (11) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 7.912514ms)
Aug 20 03:17:04.254: INFO: (11) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 13.030483ms)
Aug 20 03:17:04.254: INFO: (11) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 13.187428ms)
Aug 20 03:17:04.255: INFO: (11) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 13.892326ms)
Aug 20 03:17:04.255: INFO: (11) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 13.79ms)
Aug 20 03:17:04.255: INFO: (11) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 14.10622ms)
Aug 20 03:17:04.256: INFO: (11) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 15.356862ms)
Aug 20 03:17:04.256: INFO: (11) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 15.373814ms)
Aug 20 03:17:04.256: INFO: (11) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 15.416549ms)
Aug 20 03:17:04.257: INFO: (11) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 16.026002ms)
Aug 20 03:17:04.257: INFO: (11) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 16.131889ms)
Aug 20 03:17:04.259: INFO: (11) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 17.582242ms)
Aug 20 03:17:04.259: INFO: (11) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 17.837897ms)
Aug 20 03:17:04.259: INFO: (11) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 18.031958ms)
Aug 20 03:17:04.263: INFO: (12) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 3.473066ms)
Aug 20 03:17:04.264: INFO: (12) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 4.554186ms)
Aug 20 03:17:04.265: INFO: (12) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 5.306665ms)
Aug 20 03:17:04.265: INFO: (12) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 5.746149ms)
Aug 20 03:17:04.266: INFO: (12) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.866642ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 7.736032ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.715108ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 7.767158ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.867803ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 7.704421ms)
Aug 20 03:17:04.267: INFO: (12) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 7.895709ms)
Aug 20 03:17:04.269: INFO: (12) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 9.603445ms)
Aug 20 03:17:04.269: INFO: (12) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 9.995172ms)
Aug 20 03:17:04.270: INFO: (12) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.76345ms)
Aug 20 03:17:04.270: INFO: (12) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 10.956074ms)
Aug 20 03:17:04.270: INFO: (12) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 11.032078ms)
Aug 20 03:17:04.275: INFO: (13) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 4.766436ms)
Aug 20 03:17:04.278: INFO: (13) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 7.669897ms)
Aug 20 03:17:04.279: INFO: (13) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 8.859917ms)
Aug 20 03:17:04.280: INFO: (13) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 9.125339ms)
Aug 20 03:17:04.281: INFO: (13) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 10.209459ms)
Aug 20 03:17:04.281: INFO: (13) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 10.099398ms)
Aug 20 03:17:04.281: INFO: (13) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 10.220752ms)
Aug 20 03:17:04.282: INFO: (13) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 11.089121ms)
Aug 20 03:17:04.282: INFO: (13) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 11.141947ms)
Aug 20 03:17:04.282: INFO: (13) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 11.597099ms)
Aug 20 03:17:04.282: INFO: (13) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 11.430788ms)
Aug 20 03:17:04.282: INFO: (13) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 11.797134ms)
Aug 20 03:17:04.283: INFO: (13) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 12.168641ms)
Aug 20 03:17:04.283: INFO: (13) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 12.631599ms)
Aug 20 03:17:04.284: INFO: (13) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 13.835014ms)
Aug 20 03:17:04.285: INFO: (13) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 13.942722ms)
Aug 20 03:17:04.288: INFO: (14) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 3.910319ms)
Aug 20 03:17:04.289: INFO: (14) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 4.309318ms)
Aug 20 03:17:04.289: INFO: (14) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 4.642654ms)
Aug 20 03:17:04.291: INFO: (14) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.246998ms)
Aug 20 03:17:04.291: INFO: (14) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 6.214563ms)
Aug 20 03:17:04.293: INFO: (14) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 8.307258ms)
Aug 20 03:17:04.293: INFO: (14) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 8.646336ms)
Aug 20 03:17:04.293: INFO: (14) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 8.250723ms)
Aug 20 03:17:04.294: INFO: (14) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 9.046347ms)
Aug 20 03:17:04.294: INFO: (14) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 9.258195ms)
Aug 20 03:17:04.294: INFO: (14) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 9.607768ms)
Aug 20 03:17:04.295: INFO: (14) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 9.984663ms)
Aug 20 03:17:04.295: INFO: (14) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 10.550595ms)
Aug 20 03:17:04.295: INFO: (14) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 10.677887ms)
Aug 20 03:17:04.295: INFO: (14) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 10.470803ms)
Aug 20 03:17:04.296: INFO: (14) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 11.11242ms)
Aug 20 03:17:04.301: INFO: (15) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 4.621211ms)
Aug 20 03:17:04.301: INFO: (15) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 4.727907ms)
Aug 20 03:17:04.301: INFO: (15) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 4.882662ms)
Aug 20 03:17:04.301: INFO: (15) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 4.931257ms)
Aug 20 03:17:04.305: INFO: (15) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 8.545125ms)
Aug 20 03:17:04.305: INFO: (15) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 8.560667ms)
Aug 20 03:17:04.305: INFO: (15) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 8.64619ms)
Aug 20 03:17:04.305: INFO: (15) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 8.712971ms)
Aug 20 03:17:04.305: INFO: (15) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 9.002186ms)
Aug 20 03:17:04.306: INFO: (15) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 10.040143ms)
Aug 20 03:17:04.306: INFO: (15) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 10.113749ms)
Aug 20 03:17:04.306: INFO: (15) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 10.396179ms)
Aug 20 03:17:04.307: INFO: (15) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 10.708925ms)
Aug 20 03:17:04.308: INFO: (15) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 12.365302ms)
Aug 20 03:17:04.309: INFO: (15) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 13.093845ms)
Aug 20 03:17:04.309: INFO: (15) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 13.327862ms)
Aug 20 03:17:04.313: INFO: (16) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 3.409372ms)
Aug 20 03:17:04.314: INFO: (16) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 4.385179ms)
Aug 20 03:17:04.315: INFO: (16) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 5.311669ms)
Aug 20 03:17:04.316: INFO: (16) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 5.914303ms)
Aug 20 03:17:04.316: INFO: (16) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 5.868637ms)
Aug 20 03:17:04.317: INFO: (16) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 7.30198ms)
Aug 20 03:17:04.317: INFO: (16) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 7.197633ms)
Aug 20 03:17:04.318: INFO: (16) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 8.078136ms)
Aug 20 03:17:04.318: INFO: (16) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 8.195492ms)
Aug 20 03:17:04.318: INFO: (16) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 8.351123ms)
Aug 20 03:17:04.320: INFO: (16) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.58791ms)
Aug 20 03:17:04.321: INFO: (16) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 11.104253ms)
Aug 20 03:17:04.321: INFO: (16) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 11.200583ms)
Aug 20 03:17:04.321: INFO: (16) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 11.184509ms)
Aug 20 03:17:04.321: INFO: (16) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 11.771914ms)
Aug 20 03:17:04.321: INFO: (16) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 11.575637ms)
Aug 20 03:17:04.328: INFO: (17) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.857768ms)
Aug 20 03:17:04.330: INFO: (17) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 8.639119ms)
Aug 20 03:17:04.331: INFO: (17) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 9.55659ms)
Aug 20 03:17:04.332: INFO: (17) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 10.66874ms)
Aug 20 03:17:04.333: INFO: (17) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 11.433914ms)
Aug 20 03:17:04.333: INFO: (17) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 11.226601ms)
Aug 20 03:17:04.333: INFO: (17) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 12.05706ms)
Aug 20 03:17:04.334: INFO: (17) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 12.810388ms)
Aug 20 03:17:04.335: INFO: (17) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 13.361755ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 14.36282ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 14.384318ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 14.578978ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 14.503668ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 14.689882ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 14.915216ms)
Aug 20 03:17:04.336: INFO: (17) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 14.974288ms)
Aug 20 03:17:04.340: INFO: (18) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 3.757172ms)
Aug 20 03:17:04.341: INFO: (18) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 4.385144ms)
Aug 20 03:17:04.342: INFO: (18) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 4.685291ms)
Aug 20 03:17:04.342: INFO: (18) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 4.889442ms)
Aug 20 03:17:04.343: INFO: (18) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 6.04734ms)
Aug 20 03:17:04.344: INFO: (18) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 6.846148ms)
Aug 20 03:17:04.344: INFO: (18) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 6.662327ms)
Aug 20 03:17:04.345: INFO: (18) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.338706ms)
Aug 20 03:17:04.345: INFO: (18) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.502982ms)
Aug 20 03:17:04.345: INFO: (18) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.509894ms)
Aug 20 03:17:04.346: INFO: (18) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 9.076214ms)
Aug 20 03:17:04.346: INFO: (18) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 9.230065ms)
Aug 20 03:17:04.346: INFO: (18) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 9.601593ms)
Aug 20 03:17:04.347: INFO: (18) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.08034ms)
Aug 20 03:17:04.348: INFO: (18) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 10.487149ms)
Aug 20 03:17:04.348: INFO: (18) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 10.596676ms)
Aug 20 03:17:04.351: INFO: (19) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">... (200; 3.693602ms)
Aug 20 03:17:04.352: INFO: (19) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:460/proxy/: tls baz (200; 4.094544ms)
Aug 20 03:17:04.355: INFO: (19) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 6.990851ms)
Aug 20 03:17:04.355: INFO: (19) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 7.007182ms)
Aug 20 03:17:04.355: INFO: (19) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:462/proxy/: tls qux (200; 7.121945ms)
Aug 20 03:17:04.355: INFO: (19) /api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/https:proxy-service-txdcf-rxn2z:443/proxy/tlsrewritem... (200; 7.626781ms)
Aug 20 03:17:04.356: INFO: (19) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:162/proxy/: bar (200; 8.101936ms)
Aug 20 03:17:04.356: INFO: (19) /api/v1/namespaces/proxy-9138/pods/http:proxy-service-txdcf-rxn2z:160/proxy/: foo (200; 7.966101ms)
Aug 20 03:17:04.356: INFO: (19) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z/proxy/rewriteme">test</a> (200; 8.554341ms)
Aug 20 03:17:04.357: INFO: (19) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname1/proxy/: tls baz (200; 9.22719ms)
Aug 20 03:17:04.357: INFO: (19) /api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/: <a href="/api/v1/namespaces/proxy-9138/pods/proxy-service-txdcf-rxn2z:1080/proxy/rewriteme">test<... (200; 8.971366ms)
Aug 20 03:17:04.358: INFO: (19) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname1/proxy/: foo (200; 9.916112ms)
Aug 20 03:17:04.358: INFO: (19) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname1/proxy/: foo (200; 10.736227ms)
Aug 20 03:17:04.359: INFO: (19) /api/v1/namespaces/proxy-9138/services/http:proxy-service-txdcf:portname2/proxy/: bar (200; 10.745329ms)
Aug 20 03:17:04.359: INFO: (19) /api/v1/namespaces/proxy-9138/services/https:proxy-service-txdcf:tlsportname2/proxy/: tls qux (200; 10.861905ms)
Aug 20 03:17:04.359: INFO: (19) /api/v1/namespaces/proxy-9138/services/proxy-service-txdcf:portname2/proxy/: bar (200; 11.042037ms)
STEP: deleting ReplicationController proxy-service-txdcf in namespace proxy-9138, will wait for the garbage collector to delete the pods
Aug 20 03:17:04.418: INFO: Deleting ReplicationController proxy-service-txdcf took: 6.847205ms
Aug 20 03:17:04.718: INFO: Terminating ReplicationController proxy-service-txdcf pods took: 300.191185ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:17:16.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9138" for this suite.
Aug 20 03:17:22.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:17:22.631: INFO: namespace proxy-9138 deletion completed in 6.107511891s

• [SLOW TEST:24.669 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:17:22.631: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 20 03:17:24.684: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-136865096 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 20 03:17:29.785: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:17:29.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7207" for this suite.
Aug 20 03:17:35.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:17:35.898: INFO: namespace pods-7207 deletion completed in 6.106749432s

• [SLOW TEST:13.267 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:17:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3331.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3331.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3331.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3331.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3331.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3331.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 20 03:17:37.982: INFO: DNS probes using dns-3331/dns-test-1e9fba4f-20dc-459c-a8c3-bce0e3fade54 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:17:37.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3331" for this suite.
Aug 20 03:17:44.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:17:44.137: INFO: namespace dns-3331 deletion completed in 6.138485648s

• [SLOW TEST:8.239 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:17:44.138: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-2636
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2636
STEP: Deleting pre-stop pod
Aug 20 03:17:55.210: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:17:55.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2636" for this suite.
Aug 20 03:18:33.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:18:33.356: INFO: namespace prestop-2636 deletion completed in 38.136737361s

• [SLOW TEST:49.218 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:18:33.356: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 20 03:18:35.409: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:18:35.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1078" for this suite.
Aug 20 03:18:41.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:18:41.530: INFO: namespace container-runtime-1078 deletion completed in 6.10688513s

• [SLOW TEST:8.174 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:18:41.531: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-ecbb1f61-1c9c-403b-999a-06b84997d12d
STEP: Creating a pod to test consume secrets
Aug 20 03:18:41.573: INFO: Waiting up to 5m0s for pod "pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978" in namespace "secrets-3767" to be "success or failure"
Aug 20 03:18:41.575: INFO: Pod "pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075649ms
Aug 20 03:18:43.579: INFO: Pod "pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978": Phase="Running", Reason="", readiness=true. Elapsed: 2.006013107s
Aug 20 03:18:45.582: INFO: Pod "pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009468319s
STEP: Saw pod success
Aug 20 03:18:45.582: INFO: Pod "pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978" satisfied condition "success or failure"
Aug 20 03:18:45.585: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:18:45.604: INFO: Waiting for pod pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978 to disappear
Aug 20 03:18:45.606: INFO: Pod pod-secrets-f33b20ac-abe5-43e4-be81-78b03d6d0978 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:18:45.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3767" for this suite.
Aug 20 03:18:51.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:18:51.757: INFO: namespace secrets-3767 deletion completed in 6.146899685s

• [SLOW TEST:10.226 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:18:51.757: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 20 03:18:52.366: INFO: created pod pod-service-account-defaultsa
Aug 20 03:18:52.366: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 20 03:18:52.370: INFO: created pod pod-service-account-mountsa
Aug 20 03:18:52.370: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 20 03:18:52.379: INFO: created pod pod-service-account-nomountsa
Aug 20 03:18:52.379: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 20 03:18:52.382: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 20 03:18:52.383: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 20 03:18:52.386: INFO: created pod pod-service-account-mountsa-mountspec
Aug 20 03:18:52.386: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 20 03:18:52.391: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 20 03:18:52.391: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 20 03:18:52.395: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 20 03:18:52.395: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 20 03:18:52.399: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 20 03:18:52.399: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 20 03:18:52.403: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 20 03:18:52.403: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:18:52.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-95" for this suite.
Aug 20 03:18:58.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:18:58.562: INFO: namespace svcaccounts-95 deletion completed in 6.152715373s

• [SLOW TEST:6.805 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:18:58.563: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 03:18:58.599: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5" in namespace "downward-api-7638" to be "success or failure"
Aug 20 03:18:58.602: INFO: Pod "downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304384ms
Aug 20 03:19:00.605: INFO: Pod "downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005856706s
Aug 20 03:19:02.609: INFO: Pod "downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009545514s
STEP: Saw pod success
Aug 20 03:19:02.609: INFO: Pod "downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5" satisfied condition "success or failure"
Aug 20 03:19:02.611: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5 container client-container: <nil>
STEP: delete the pod
Aug 20 03:19:02.628: INFO: Waiting for pod downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5 to disappear
Aug 20 03:19:02.630: INFO: Pod downwardapi-volume-65545376-4b85-4143-a28c-e19cc0f020b5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:19:02.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7638" for this suite.
Aug 20 03:19:08.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:19:08.738: INFO: namespace downward-api-7638 deletion completed in 6.104174097s

• [SLOW TEST:10.176 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:19:08.738: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-6625f6a3-ba22-47ed-ab20-6ab5e535434d
STEP: Creating a pod to test consume secrets
Aug 20 03:19:08.780: INFO: Waiting up to 5m0s for pod "pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91" in namespace "secrets-825" to be "success or failure"
Aug 20 03:19:08.782: INFO: Pod "pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91": Phase="Pending", Reason="", readiness=false. Elapsed: 1.977625ms
Aug 20 03:19:10.786: INFO: Pod "pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91": Phase="Running", Reason="", readiness=true. Elapsed: 2.006708195s
Aug 20 03:19:12.790: INFO: Pod "pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010675057s
STEP: Saw pod success
Aug 20 03:19:12.790: INFO: Pod "pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91" satisfied condition "success or failure"
Aug 20 03:19:12.793: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:19:12.809: INFO: Waiting for pod pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91 to disappear
Aug 20 03:19:12.812: INFO: Pod pod-secrets-227f029c-2a77-45ba-94f0-16637d432b91 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:19:12.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-825" for this suite.
Aug 20 03:19:18.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:19:18.917: INFO: namespace secrets-825 deletion completed in 6.101661592s

• [SLOW TEST:10.179 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:19:18.917: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-5951/secret-test-88f37137-76e9-48c3-8fb7-a4d3f90ed122
STEP: Creating a pod to test consume secrets
Aug 20 03:19:18.967: INFO: Waiting up to 5m0s for pod "pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f" in namespace "secrets-5951" to be "success or failure"
Aug 20 03:19:18.970: INFO: Pod "pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.201499ms
Aug 20 03:19:20.974: INFO: Pod "pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f": Phase="Running", Reason="", readiness=true. Elapsed: 2.006611777s
Aug 20 03:19:22.977: INFO: Pod "pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010015548s
STEP: Saw pod success
Aug 20 03:19:22.977: INFO: Pod "pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f" satisfied condition "success or failure"
Aug 20 03:19:22.980: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f container env-test: <nil>
STEP: delete the pod
Aug 20 03:19:23.000: INFO: Waiting for pod pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f to disappear
Aug 20 03:19:23.002: INFO: Pod pod-configmaps-34a7a79c-2832-4cdc-ab34-c5bd9547ca0f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:19:23.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5951" for this suite.
Aug 20 03:19:29.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:19:29.117: INFO: namespace secrets-5951 deletion completed in 6.109811578s

• [SLOW TEST:10.200 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:19:29.117: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 20 03:19:29.146: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 20 03:19:29.153: INFO: Waiting for terminating namespaces to be deleted...
Aug 20 03:19:29.157: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-253 before test
Aug 20 03:19:29.167: INFO: sonobuoy-e2e-job-ae4ab90fc45c47c3 from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.167: INFO: 	Container e2e ready: true, restart count 0
Aug 20 03:19:29.167: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 03:19:29.167: INFO: heapster-v1.6.0-beta.1-969d875b-zfq5w from kube-system started at 2019-08-20 01:57:58 +0000 UTC (4 container statuses recorded)
Aug 20 03:19:29.167: INFO: 	Container eventer ready: true, restart count 0
Aug 20 03:19:29.167: INFO: 	Container eventer-nanny ready: true, restart count 0
Aug 20 03:19:29.167: INFO: 	Container heapster ready: true, restart count 0
Aug 20 03:19:29.167: INFO: 	Container heapster-nanny ready: true, restart count 0
Aug 20 03:19:29.167: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-zk9kw from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.167: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:19:29.167: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 20 03:19:29.167: INFO: nginx-ingress-controller-kubernetes-worker-qb8kn from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.167: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:19:29.167: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-23-37 before test
Aug 20 03:19:29.173: INFO: nginx-ingress-controller-kubernetes-worker-vp4md from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:59 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.173: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:19:29.173: INFO: default-http-backend-kubernetes-worker-ffcd96676-jps4h from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.173: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Aug 20 03:19:29.173: INFO: metrics-server-v0.3.3-cc578669-xl6k9 from kube-system started at 2019-08-20 01:58:00 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.173: INFO: 	Container metrics-server ready: true, restart count 0
Aug 20 03:19:29.173: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 20 03:19:29.173: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-20 02:03:49 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.173: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 20 03:19:29.173: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-gr2bt from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.173: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:19:29.173: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 20 03:19:29.173: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-77-128 before test
Aug 20 03:19:29.184: INFO: kubernetes-dashboard-f9f9594f9-gxspl from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 20 03:19:29.184: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-sc7zl from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:19:29.184: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 20 03:19:29.184: INFO: coredns-75dc589b9b-2kf9z from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container coredns ready: true, restart count 0
Aug 20 03:19:29.184: INFO: nginx-ingress-controller-kubernetes-worker-mg2gl from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:58 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:19:29.184: INFO: monitoring-influxdb-grafana-v4-77766b8fb9-6cwts from kube-system started at 2019-08-20 01:56:48 +0000 UTC (2 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container grafana ready: true, restart count 0
Aug 20 03:19:29.184: INFO: 	Container influxdb ready: true, restart count 0
Aug 20 03:19:29.184: INFO: coredns-75dc589b9b-v57jz from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:19:29.184: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b5488105-a528-48ee-965a-c4ba77ce2631 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b5488105-a528-48ee-965a-c4ba77ce2631 off the node ip-172-31-23-37
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b5488105-a528-48ee-965a-c4ba77ce2631
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:19:33.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1506" for this suite.
Aug 20 03:19:51.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:19:51.370: INFO: namespace sched-pred-1506 deletion completed in 18.111538044s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:22.253 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:19:51.370: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:20:15.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2700" for this suite.
Aug 20 03:20:21.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:20:21.659: INFO: namespace namespaces-2700 deletion completed in 6.15432796s
STEP: Destroying namespace "nsdeletetest-946" for this suite.
Aug 20 03:20:21.663: INFO: Namespace nsdeletetest-946 was already deleted
STEP: Destroying namespace "nsdeletetest-6536" for this suite.
Aug 20 03:20:27.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:20:27.794: INFO: namespace nsdeletetest-6536 deletion completed in 6.131074314s

• [SLOW TEST:36.424 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:20:27.794: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:20:27.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4877" for this suite.
Aug 20 03:20:33.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:20:33.958: INFO: namespace kubelet-test-4877 deletion completed in 6.107181597s

• [SLOW TEST:6.164 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:20:33.958: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 20 03:20:38.025: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:38.028: INFO: Pod pod-with-prestop-http-hook still exists
Aug 20 03:20:40.028: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:40.031: INFO: Pod pod-with-prestop-http-hook still exists
Aug 20 03:20:42.028: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:42.031: INFO: Pod pod-with-prestop-http-hook still exists
Aug 20 03:20:44.028: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:44.031: INFO: Pod pod-with-prestop-http-hook still exists
Aug 20 03:20:46.028: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:46.031: INFO: Pod pod-with-prestop-http-hook still exists
Aug 20 03:20:48.028: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 20 03:20:48.031: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:20:48.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7793" for this suite.
Aug 20 03:21:10.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:21:10.164: INFO: namespace container-lifecycle-hook-7793 deletion completed in 22.121784332s

• [SLOW TEST:36.206 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:21:10.164: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-002c7534-c109-42f9-8862-1d11f32af979
STEP: Creating a pod to test consume configMaps
Aug 20 03:21:10.216: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524" in namespace "projected-4926" to be "success or failure"
Aug 20 03:21:10.218: INFO: Pod "pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273665ms
Aug 20 03:21:12.222: INFO: Pod "pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006052296s
STEP: Saw pod success
Aug 20 03:21:12.222: INFO: Pod "pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524" satisfied condition "success or failure"
Aug 20 03:21:12.224: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:21:12.239: INFO: Waiting for pod pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524 to disappear
Aug 20 03:21:12.241: INFO: Pod pod-projected-configmaps-0ba4752d-6927-4e8d-a043-d2edbd118524 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:21:12.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4926" for this suite.
Aug 20 03:21:18.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:21:18.352: INFO: namespace projected-4926 deletion completed in 6.10739502s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:21:18.353: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-b0c1dacf-ab19-444d-849d-30fd53d15cd9 in namespace container-probe-4591
Aug 20 03:21:22.403: INFO: Started pod busybox-b0c1dacf-ab19-444d-849d-30fd53d15cd9 in namespace container-probe-4591
STEP: checking the pod's current state and verifying that restartCount is present
Aug 20 03:21:22.406: INFO: Initial restart count of pod busybox-b0c1dacf-ab19-444d-849d-30fd53d15cd9 is 0
Aug 20 03:22:08.495: INFO: Restart count of pod container-probe-4591/busybox-b0c1dacf-ab19-444d-849d-30fd53d15cd9 is now 1 (46.089001234s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:22:08.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4591" for this suite.
Aug 20 03:22:14.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:22:14.635: INFO: namespace container-probe-4591 deletion completed in 6.119905189s

• [SLOW TEST:56.282 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:22:14.635: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:22:14.664: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:22:16.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9518" for this suite.
Aug 20 03:22:58.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:22:58.966: INFO: namespace pods-9518 deletion completed in 42.164797327s

• [SLOW TEST:44.331 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:22:58.967: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 20 03:22:59.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-8744'
Aug 20 03:22:59.488: INFO: stderr: ""
Aug 20 03:22:59.488: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 20 03:23:00.492: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:23:00.492: INFO: Found 0 / 1
Aug 20 03:23:01.493: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:23:01.493: INFO: Found 1 / 1
Aug 20 03:23:01.493: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 20 03:23:01.497: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:23:01.497: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 20 03:23:01.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 patch pod redis-master-2qd78 --namespace=kubectl-8744 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 20 03:23:01.586: INFO: stderr: ""
Aug 20 03:23:01.587: INFO: stdout: "pod/redis-master-2qd78 patched\n"
STEP: checking annotations
Aug 20 03:23:01.593: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:23:01.593: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:23:01.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8744" for this suite.
Aug 20 03:23:23.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:23:23.725: INFO: namespace kubectl-8744 deletion completed in 22.124020614s

• [SLOW TEST:24.758 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:23:23.725: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-270e6d78-6bdb-4236-8a3b-fdbc1a1e2f92
STEP: Creating a pod to test consume configMaps
Aug 20 03:23:23.767: INFO: Waiting up to 5m0s for pod "pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4" in namespace "configmap-6108" to be "success or failure"
Aug 20 03:23:23.769: INFO: Pod "pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.337005ms
Aug 20 03:23:25.773: INFO: Pod "pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006344306s
STEP: Saw pod success
Aug 20 03:23:25.773: INFO: Pod "pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4" satisfied condition "success or failure"
Aug 20 03:23:25.776: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:23:25.811: INFO: Waiting for pod pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4 to disappear
Aug 20 03:23:25.814: INFO: Pod pod-configmaps-35c884bc-531b-43f3-bfd1-e55ad9d879a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:23:25.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6108" for this suite.
Aug 20 03:23:31.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:23:31.928: INFO: namespace configmap-6108 deletion completed in 6.110868028s

• [SLOW TEST:8.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:23:31.928: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8514
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8514
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8514
Aug 20 03:23:31.979: INFO: Found 0 stateful pods, waiting for 1
Aug 20 03:23:41.982: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 20 03:23:41.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 03:23:42.227: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 03:23:42.227: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 03:23:42.227: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 03:23:42.230: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 20 03:23:52.234: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 03:23:52.234: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 03:23:52.249: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:23:52.249: INFO: ss-0  ip-172-31-23-37  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:23:52.250: INFO: 
Aug 20 03:23:52.250: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 20 03:23:53.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997263757s
Aug 20 03:23:54.257: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993364653s
Aug 20 03:23:55.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989758312s
Aug 20 03:23:56.264: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986067802s
Aug 20 03:23:57.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982461876s
Aug 20 03:23:58.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978839134s
Aug 20 03:23:59.275: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975621432s
Aug 20 03:24:00.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971793957s
Aug 20 03:24:01.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.471338ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8514
Aug 20 03:24:02.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:02.514: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 20 03:24:02.514: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 03:24:02.514: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 03:24:02.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:02.821: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 20 03:24:02.821: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 03:24:02.821: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 03:24:02.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:03.143: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 20 03:24:03.143: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 20 03:24:03.143: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 20 03:24:03.147: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 20 03:24:13.151: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 03:24:13.151: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 20 03:24:13.151: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 20 03:24:13.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 03:24:13.347: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 03:24:13.347: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 03:24:13.347: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 03:24:13.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 03:24:13.570: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 03:24:13.570: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 03:24:13.570: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 03:24:13.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 20 03:24:13.787: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 20 03:24:13.787: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 20 03:24:13.787: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 20 03:24:13.787: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 03:24:13.791: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 20 03:24:23.800: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 03:24:23.800: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 03:24:23.800: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 20 03:24:23.824: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Aug 20 03:24:23.824: INFO: ss-0  ip-172-31-23-37   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:23.824: INFO: ss-1  ip-172-31-77-128  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  }]
Aug 20 03:24:23.824: INFO: ss-2  ip-172-31-1-253   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  }]
Aug 20 03:24:23.824: INFO: 
Aug 20 03:24:23.824: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 20 03:24:24.828: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Aug 20 03:24:24.828: INFO: ss-0  ip-172-31-23-37   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:24.828: INFO: ss-1  ip-172-31-77-128  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  }]
Aug 20 03:24:24.828: INFO: ss-2  ip-172-31-1-253   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  }]
Aug 20 03:24:24.828: INFO: 
Aug 20 03:24:24.828: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 20 03:24:25.832: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Aug 20 03:24:25.832: INFO: ss-0  ip-172-31-23-37   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:25.832: INFO: ss-1  ip-172-31-77-128  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:52 +0000 UTC  }]
Aug 20 03:24:25.832: INFO: 
Aug 20 03:24:25.832: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 20 03:24:26.835: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:26.835: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:26.835: INFO: 
Aug 20 03:24:26.835: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:27.843: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:27.843: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:27.843: INFO: 
Aug 20 03:24:27.843: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:28.848: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:28.848: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:28.848: INFO: 
Aug 20 03:24:28.848: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:29.851: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:29.851: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:29.851: INFO: 
Aug 20 03:24:29.851: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:30.855: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:30.855: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:30.855: INFO: 
Aug 20 03:24:30.855: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:31.859: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:31.859: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:31.859: INFO: 
Aug 20 03:24:31.859: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 20 03:24:32.863: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Aug 20 03:24:32.863: INFO: ss-0  ip-172-31-23-37  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:23:32 +0000 UTC  }]
Aug 20 03:24:32.863: INFO: 
Aug 20 03:24:32.863: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8514
Aug 20 03:24:33.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:33.967: INFO: rc: 1
Aug 20 03:24:33.968: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001440870 exit status 1 <nil> <nil> true [0xc001409880 0xc001409898 0xc0014098b0] [0xc001409880 0xc001409898 0xc0014098b0] [0xc001409890 0xc0014098a8] [0x9d17b0 0x9d17b0] 0xc0028d4660 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Aug 20 03:24:43.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:44.055: INFO: rc: 1
Aug 20 03:24:44.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fb8c0 exit status 1 <nil> <nil> true [0xc003064918 0xc003064930 0xc003064948] [0xc003064918 0xc003064930 0xc003064948] [0xc003064928 0xc003064940] [0x9d17b0 0x9d17b0] 0xc002da8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:24:54.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:24:54.130: INFO: rc: 1
Aug 20 03:24:54.130: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fbbf0 exit status 1 <nil> <nil> true [0xc003064950 0xc003064968 0xc003064980] [0xc003064950 0xc003064968 0xc003064980] [0xc003064960 0xc003064978] [0x9d17b0 0x9d17b0] 0xc002da85a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:04.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:04.222: INFO: rc: 1
Aug 20 03:25:04.222: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ec00f0 exit status 1 <nil> <nil> true [0xc003064988 0xc0030649a0 0xc0030649b8] [0xc003064988 0xc0030649a0 0xc0030649b8] [0xc003064998 0xc0030649b0] [0x9d17b0 0x9d17b0] 0xc002da89c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:14.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:14.303: INFO: rc: 1
Aug 20 03:25:14.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ec0450 exit status 1 <nil> <nil> true [0xc0030649c0 0xc0030649d8 0xc0030649f0] [0xc0030649c0 0xc0030649d8 0xc0030649f0] [0xc0030649d0 0xc0030649e8] [0x9d17b0 0x9d17b0] 0xc002da8ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:24.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:24.398: INFO: rc: 1
Aug 20 03:25:24.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fa360 exit status 1 <nil> <nil> true [0xc002b8c018 0xc002b8c058 0xc002b8c070] [0xc002b8c018 0xc002b8c058 0xc002b8c070] [0xc002b8c050 0xc002b8c068] [0x9d17b0 0x9d17b0] 0xc00326c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:34.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:34.487: INFO: rc: 1
Aug 20 03:25:34.488: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fa6c0 exit status 1 <nil> <nil> true [0xc002b8c078 0xc002b8c090 0xc002b8c0b0] [0xc002b8c078 0xc002b8c090 0xc002b8c0b0] [0xc002b8c088 0xc002b8c0a8] [0x9d17b0 0x9d17b0] 0xc00326c600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:44.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:44.592: INFO: rc: 1
Aug 20 03:25:44.592: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000bc2360 exit status 1 <nil> <nil> true [0xc001408000 0xc001408028 0xc001408068] [0xc001408000 0xc001408028 0xc001408068] [0xc001408020 0xc001408050] [0x9d17b0 0x9d17b0] 0xc002b546c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:25:54.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:25:54.673: INFO: rc: 1
Aug 20 03:25:54.673: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033faa20 exit status 1 <nil> <nil> true [0xc002b8c0b8 0xc002b8c0d0 0xc002b8c0e8] [0xc002b8c0b8 0xc002b8c0d0 0xc002b8c0e8] [0xc002b8c0c8 0xc002b8c0e0] [0x9d17b0 0x9d17b0] 0xc00326c960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:04.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:04.749: INFO: rc: 1
Aug 20 03:26:04.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002772330 exit status 1 <nil> <nil> true [0xc003064000 0xc003064018 0xc003064030] [0xc003064000 0xc003064018 0xc003064030] [0xc003064010 0xc003064028] [0x9d17b0 0x9d17b0] 0xc00202e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:14.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:14.825: INFO: rc: 1
Aug 20 03:26:14.826: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000bc2720 exit status 1 <nil> <nil> true [0xc001408070 0xc001408088 0xc0014080d0] [0xc001408070 0xc001408088 0xc0014080d0] [0xc001408080 0xc0014080b8] [0x9d17b0 0x9d17b0] 0xc002b54f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:24.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:24.940: INFO: rc: 1
Aug 20 03:26:24.940: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0027726f0 exit status 1 <nil> <nil> true [0xc003064038 0xc003064050 0xc003064068] [0xc003064038 0xc003064050 0xc003064068] [0xc003064048 0xc003064060] [0x9d17b0 0x9d17b0] 0xc00202ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:34.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:35.039: INFO: rc: 1
Aug 20 03:26:35.039: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002772a50 exit status 1 <nil> <nil> true [0xc003064070 0xc003064088 0xc0030640a0] [0xc003064070 0xc003064088 0xc0030640a0] [0xc003064080 0xc003064098] [0x9d17b0 0x9d17b0] 0xc00202f380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:45.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:45.146: INFO: rc: 1
Aug 20 03:26:45.146: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002772db0 exit status 1 <nil> <nil> true [0xc0030640a8 0xc0030640c0 0xc0030640d8] [0xc0030640a8 0xc0030640c0 0xc0030640d8] [0xc0030640b8 0xc0030640d0] [0x9d17b0 0x9d17b0] 0xc00202fa40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:26:55.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:26:55.237: INFO: rc: 1
Aug 20 03:26:55.237: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fad80 exit status 1 <nil> <nil> true [0xc002b8c0f0 0xc002b8c108 0xc002b8c120] [0xc002b8c0f0 0xc002b8c108 0xc002b8c120] [0xc002b8c100 0xc002b8c118] [0x9d17b0 0x9d17b0] 0xc00326ccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:05.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:05.313: INFO: rc: 1
Aug 20 03:27:05.313: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002773110 exit status 1 <nil> <nil> true [0xc0030640e0 0xc0030640f8 0xc003064110] [0xc0030640e0 0xc0030640f8 0xc003064110] [0xc0030640f0 0xc003064108] [0x9d17b0 0x9d17b0] 0xc0023c4000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:15.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:15.401: INFO: rc: 1
Aug 20 03:27:15.401: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c103f0 exit status 1 <nil> <nil> true [0xc0033f8000 0xc0033f8018 0xc0033f8030] [0xc0033f8000 0xc0033f8018 0xc0033f8030] [0xc0033f8010 0xc0033f8028] [0x9d17b0 0x9d17b0] 0xc002fb0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:25.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:25.509: INFO: rc: 1
Aug 20 03:27:25.509: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c10750 exit status 1 <nil> <nil> true [0xc0033f8040 0xc0033f8058 0xc0033f8070] [0xc0033f8040 0xc0033f8058 0xc0033f8070] [0xc0033f8050 0xc0033f8068] [0x9d17b0 0x9d17b0] 0xc002fb0d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:35.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:35.590: INFO: rc: 1
Aug 20 03:27:35.590: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fa390 exit status 1 <nil> <nil> true [0xc003064000 0xc003064018 0xc003064030] [0xc003064000 0xc003064018 0xc003064030] [0xc003064010 0xc003064028] [0x9d17b0 0x9d17b0] 0xc00202e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:45.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:45.666: INFO: rc: 1
Aug 20 03:27:45.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fa6f0 exit status 1 <nil> <nil> true [0xc003064038 0xc003064050 0xc003064068] [0xc003064038 0xc003064050 0xc003064068] [0xc003064048 0xc003064060] [0x9d17b0 0x9d17b0] 0xc00202ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:27:55.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:27:55.766: INFO: rc: 1
Aug 20 03:27:55.766: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c103c0 exit status 1 <nil> <nil> true [0xc002b8c010 0xc002b8c050 0xc002b8c068] [0xc002b8c010 0xc002b8c050 0xc002b8c068] [0xc002b8c038 0xc002b8c060] [0x9d17b0 0x9d17b0] 0xc0023c4360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:05.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:05.839: INFO: rc: 1
Aug 20 03:28:05.839: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c10ae0 exit status 1 <nil> <nil> true [0xc002b8c070 0xc002b8c088 0xc002b8c0a8] [0xc002b8c070 0xc002b8c088 0xc002b8c0a8] [0xc002b8c080 0xc002b8c0a0] [0x9d17b0 0x9d17b0] 0xc0023c46c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:15.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:15.912: INFO: rc: 1
Aug 20 03:28:15.912: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033faae0 exit status 1 <nil> <nil> true [0xc003064070 0xc003064088 0xc0030640a0] [0xc003064070 0xc003064088 0xc0030640a0] [0xc003064080 0xc003064098] [0x9d17b0 0x9d17b0] 0xc00202f380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:25.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:26.023: INFO: rc: 1
Aug 20 03:28:26.023: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fae40 exit status 1 <nil> <nil> true [0xc0030640a8 0xc0030640c0 0xc0030640d8] [0xc0030640a8 0xc0030640c0 0xc0030640d8] [0xc0030640b8 0xc0030640d0] [0x9d17b0 0x9d17b0] 0xc00202fa40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:36.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:36.138: INFO: rc: 1
Aug 20 03:28:36.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c10e70 exit status 1 <nil> <nil> true [0xc002b8c0b0 0xc002b8c0c8 0xc002b8c0e0] [0xc002b8c0b0 0xc002b8c0c8 0xc002b8c0e0] [0xc002b8c0c0 0xc002b8c0d8] [0x9d17b0 0x9d17b0] 0xc0023c4a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:46.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:46.220: INFO: rc: 1
Aug 20 03:28:46.220: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fb1d0 exit status 1 <nil> <nil> true [0xc0030640e0 0xc0030640f8 0xc003064110] [0xc0030640e0 0xc0030640f8 0xc003064110] [0xc0030640f0 0xc003064108] [0x9d17b0 0x9d17b0] 0xc00326c000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:28:56.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:28:56.305: INFO: rc: 1
Aug 20 03:28:56.306: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c111a0 exit status 1 <nil> <nil> true [0xc002b8c0e8 0xc002b8c100 0xc002b8c118] [0xc002b8c0e8 0xc002b8c100 0xc002b8c118] [0xc002b8c0f8 0xc002b8c110] [0x9d17b0 0x9d17b0] 0xc0023c4de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:29:06.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:29:06.388: INFO: rc: 1
Aug 20 03:29:06.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033fb560 exit status 1 <nil> <nil> true [0xc003064118 0xc003064130 0xc003064148] [0xc003064118 0xc003064130 0xc003064148] [0xc003064128 0xc003064140] [0x9d17b0 0x9d17b0] 0xc00326c360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:29:16.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:29:16.477: INFO: rc: 1
Aug 20 03:29:16.477: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c11530 exit status 1 <nil> <nil> true [0xc002b8c120 0xc002b8c138 0xc002b8c150] [0xc002b8c120 0xc002b8c138 0xc002b8c150] [0xc002b8c130 0xc002b8c148] [0x9d17b0 0x9d17b0] 0xc0023c5380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:29:26.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:29:26.557: INFO: rc: 1
Aug 20 03:29:26.557: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002c103f0 exit status 1 <nil> <nil> true [0xc002b8c018 0xc002b8c058 0xc002b8c070] [0xc002b8c018 0xc002b8c058 0xc002b8c070] [0xc002b8c050 0xc002b8c068] [0x9d17b0 0x9d17b0] 0xc00202e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Aug 20 03:29:36.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 exec --namespace=statefulset-8514 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 20 03:29:36.631: INFO: rc: 1
Aug 20 03:29:36.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Aug 20 03:29:36.631: INFO: Scaling statefulset ss to 0
Aug 20 03:29:36.656: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 20 03:29:36.662: INFO: Deleting all statefulset in ns statefulset-8514
Aug 20 03:29:36.672: INFO: Scaling statefulset ss to 0
Aug 20 03:29:36.696: INFO: Waiting for statefulset status.replicas updated to 0
Aug 20 03:29:36.703: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:29:36.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8514" for this suite.
Aug 20 03:29:42.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:29:42.862: INFO: namespace statefulset-8514 deletion completed in 6.115388706s

• [SLOW TEST:370.934 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:29:42.862: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-a5c7357d-ba10-4675-a765-ae1d91094e13
STEP: Creating a pod to test consume configMaps
Aug 20 03:29:42.903: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa" in namespace "projected-3801" to be "success or failure"
Aug 20 03:29:42.905: INFO: Pod "pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046252ms
Aug 20 03:29:44.908: INFO: Pod "pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005501129s
STEP: Saw pod success
Aug 20 03:29:44.908: INFO: Pod "pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa" satisfied condition "success or failure"
Aug 20 03:29:44.911: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:29:44.970: INFO: Waiting for pod pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa to disappear
Aug 20 03:29:44.974: INFO: Pod pod-projected-configmaps-257f8f88-43a5-4066-a8d1-1710346d95fa no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:29:44.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3801" for this suite.
Aug 20 03:29:51.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:29:51.121: INFO: namespace projected-3801 deletion completed in 6.137975739s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:29:51.122: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-4d4c6577-1ff2-44ea-9348-e3c9545025d4
STEP: Creating a pod to test consume configMaps
Aug 20 03:29:51.168: INFO: Waiting up to 5m0s for pod "pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650" in namespace "configmap-7815" to be "success or failure"
Aug 20 03:29:51.170: INFO: Pod "pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650": Phase="Pending", Reason="", readiness=false. Elapsed: 2.395295ms
Aug 20 03:29:53.174: INFO: Pod "pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006444762s
STEP: Saw pod success
Aug 20 03:29:53.174: INFO: Pod "pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650" satisfied condition "success or failure"
Aug 20 03:29:53.177: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:29:53.192: INFO: Waiting for pod pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650 to disappear
Aug 20 03:29:53.195: INFO: Pod pod-configmaps-79bde71c-d280-4997-b840-c99d4ae0d650 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:29:53.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7815" for this suite.
Aug 20 03:29:59.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:29:59.333: INFO: namespace configmap-7815 deletion completed in 6.13440088s

• [SLOW TEST:8.212 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:29:59.333: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8hmg
STEP: Creating a pod to test atomic-volume-subpath
Aug 20 03:29:59.382: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8hmg" in namespace "subpath-9437" to be "success or failure"
Aug 20 03:29:59.384: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234538ms
Aug 20 03:30:01.395: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012572787s
Aug 20 03:30:03.398: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 4.016059098s
Aug 20 03:30:05.402: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 6.019691714s
Aug 20 03:30:07.406: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 8.023802063s
Aug 20 03:30:09.409: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 10.02721591s
Aug 20 03:30:11.413: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 12.030795915s
Aug 20 03:30:13.416: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 14.034257858s
Aug 20 03:30:15.420: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 16.037859905s
Aug 20 03:30:17.423: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 18.041437989s
Aug 20 03:30:19.427: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 20.044623716s
Aug 20 03:30:21.430: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Running", Reason="", readiness=true. Elapsed: 22.047848314s
Aug 20 03:30:23.433: INFO: Pod "pod-subpath-test-configmap-8hmg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051136167s
STEP: Saw pod success
Aug 20 03:30:23.433: INFO: Pod "pod-subpath-test-configmap-8hmg" satisfied condition "success or failure"
Aug 20 03:30:23.435: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-subpath-test-configmap-8hmg container test-container-subpath-configmap-8hmg: <nil>
STEP: delete the pod
Aug 20 03:30:23.459: INFO: Waiting for pod pod-subpath-test-configmap-8hmg to disappear
Aug 20 03:30:23.462: INFO: Pod pod-subpath-test-configmap-8hmg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8hmg
Aug 20 03:30:23.462: INFO: Deleting pod "pod-subpath-test-configmap-8hmg" in namespace "subpath-9437"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:30:23.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9437" for this suite.
Aug 20 03:30:29.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:30:29.590: INFO: namespace subpath-9437 deletion completed in 6.121538836s

• [SLOW TEST:30.257 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:30:29.590: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:30:31.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7156" for this suite.
Aug 20 03:30:37.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:30:37.766: INFO: namespace emptydir-wrapper-7156 deletion completed in 6.102675259s

• [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:30:37.766: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 20 03:30:37.804: INFO: Waiting up to 5m0s for pod "pod-59437a60-0747-4def-b470-11c81a83d9a5" in namespace "emptydir-7838" to be "success or failure"
Aug 20 03:30:37.806: INFO: Pod "pod-59437a60-0747-4def-b470-11c81a83d9a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083401ms
Aug 20 03:30:39.810: INFO: Pod "pod-59437a60-0747-4def-b470-11c81a83d9a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005911273s
STEP: Saw pod success
Aug 20 03:30:39.810: INFO: Pod "pod-59437a60-0747-4def-b470-11c81a83d9a5" satisfied condition "success or failure"
Aug 20 03:30:39.813: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-59437a60-0747-4def-b470-11c81a83d9a5 container test-container: <nil>
STEP: delete the pod
Aug 20 03:30:39.828: INFO: Waiting for pod pod-59437a60-0747-4def-b470-11c81a83d9a5 to disappear
Aug 20 03:30:39.831: INFO: Pod pod-59437a60-0747-4def-b470-11c81a83d9a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:30:39.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7838" for this suite.
Aug 20 03:30:45.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:30:45.966: INFO: namespace emptydir-7838 deletion completed in 6.131292917s

• [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:30:45.966: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-7f20293d-3908-4bba-bb5f-2bd85b4e85fa
STEP: Creating a pod to test consume secrets
Aug 20 03:30:46.012: INFO: Waiting up to 5m0s for pod "pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86" in namespace "secrets-7894" to be "success or failure"
Aug 20 03:30:46.014: INFO: Pod "pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86": Phase="Pending", Reason="", readiness=false. Elapsed: 1.998618ms
Aug 20 03:30:48.017: INFO: Pod "pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00558265s
STEP: Saw pod success
Aug 20 03:30:48.017: INFO: Pod "pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86" satisfied condition "success or failure"
Aug 20 03:30:48.020: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:30:48.037: INFO: Waiting for pod pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86 to disappear
Aug 20 03:30:48.039: INFO: Pod pod-secrets-3b523020-8ea4-47ec-b2fd-3df330e95e86 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:30:48.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7894" for this suite.
Aug 20 03:30:54.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:30:54.171: INFO: namespace secrets-7894 deletion completed in 6.126973177s

• [SLOW TEST:8.205 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:30:54.172: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 03:30:54.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288" in namespace "projected-6807" to be "success or failure"
Aug 20 03:30:54.215: INFO: Pod "downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121918ms
Aug 20 03:30:56.219: INFO: Pod "downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005768395s
STEP: Saw pod success
Aug 20 03:30:56.219: INFO: Pod "downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288" satisfied condition "success or failure"
Aug 20 03:30:56.221: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288 container client-container: <nil>
STEP: delete the pod
Aug 20 03:30:56.236: INFO: Waiting for pod downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288 to disappear
Aug 20 03:30:56.238: INFO: Pod downwardapi-volume-3bcc0c46-9f67-4b07-869d-2c583397d288 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:30:56.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6807" for this suite.
Aug 20 03:31:02.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:02.353: INFO: namespace projected-6807 deletion completed in 6.111041108s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:02.354: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:02.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2928" for this suite.
Aug 20 03:31:24.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:24.538: INFO: namespace pods-2928 deletion completed in 22.137454099s

• [SLOW TEST:22.185 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:24.539: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 03:31:24.579: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92" in namespace "downward-api-4495" to be "success or failure"
Aug 20 03:31:24.582: INFO: Pod "downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085857ms
Aug 20 03:31:26.592: INFO: Pod "downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012935907s
STEP: Saw pod success
Aug 20 03:31:26.592: INFO: Pod "downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92" satisfied condition "success or failure"
Aug 20 03:31:26.595: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92 container client-container: <nil>
STEP: delete the pod
Aug 20 03:31:26.613: INFO: Waiting for pod downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92 to disappear
Aug 20 03:31:26.616: INFO: Pod downwardapi-volume-4f7513e4-7c86-4606-9d6b-dfbdca061e92 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:26.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4495" for this suite.
Aug 20 03:31:32.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:32.726: INFO: namespace downward-api-4495 deletion completed in 6.104232474s

• [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 20 03:31:32.766: INFO: Waiting up to 5m0s for pod "pod-07e11e29-9345-4b0f-9760-0265637b5aed" in namespace "emptydir-8003" to be "success or failure"
Aug 20 03:31:32.769: INFO: Pod "pod-07e11e29-9345-4b0f-9760-0265637b5aed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.574872ms
Aug 20 03:31:34.772: INFO: Pod "pod-07e11e29-9345-4b0f-9760-0265637b5aed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006040737s
STEP: Saw pod success
Aug 20 03:31:34.772: INFO: Pod "pod-07e11e29-9345-4b0f-9760-0265637b5aed" satisfied condition "success or failure"
Aug 20 03:31:34.774: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-07e11e29-9345-4b0f-9760-0265637b5aed container test-container: <nil>
STEP: delete the pod
Aug 20 03:31:34.789: INFO: Waiting for pod pod-07e11e29-9345-4b0f-9760-0265637b5aed to disappear
Aug 20 03:31:34.791: INFO: Pod pod-07e11e29-9345-4b0f-9760-0265637b5aed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:34.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8003" for this suite.
Aug 20 03:31:40.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:40.894: INFO: namespace emptydir-8003 deletion completed in 6.098627704s

• [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:40.895: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 20 03:31:40.931: INFO: Waiting up to 5m0s for pod "pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691" in namespace "emptydir-5615" to be "success or failure"
Aug 20 03:31:40.933: INFO: Pod "pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691": Phase="Pending", Reason="", readiness=false. Elapsed: 2.001236ms
Aug 20 03:31:42.937: INFO: Pod "pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005425084s
STEP: Saw pod success
Aug 20 03:31:42.937: INFO: Pod "pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691" satisfied condition "success or failure"
Aug 20 03:31:42.940: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691 container test-container: <nil>
STEP: delete the pod
Aug 20 03:31:42.955: INFO: Waiting for pod pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691 to disappear
Aug 20 03:31:42.957: INFO: Pod pod-5cbc4b9c-0b34-44e1-8fa8-1b724c548691 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:42.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5615" for this suite.
Aug 20 03:31:48.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:49.073: INFO: namespace emptydir-5615 deletion completed in 6.111387877s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:49.073: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2991/configmap-test-32455ba4-8945-46d5-a6d4-b4b547aeb6fd
STEP: Creating a pod to test consume configMaps
Aug 20 03:31:49.128: INFO: Waiting up to 5m0s for pod "pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258" in namespace "configmap-2991" to be "success or failure"
Aug 20 03:31:49.130: INFO: Pod "pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258": Phase="Pending", Reason="", readiness=false. Elapsed: 2.133241ms
Aug 20 03:31:51.134: INFO: Pod "pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005487937s
STEP: Saw pod success
Aug 20 03:31:51.134: INFO: Pod "pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258" satisfied condition "success or failure"
Aug 20 03:31:51.136: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258 container env-test: <nil>
STEP: delete the pod
Aug 20 03:31:51.165: INFO: Waiting for pod pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258 to disappear
Aug 20 03:31:51.168: INFO: Pod pod-configmaps-45036ae0-ca57-4461-9a1e-fb69e04d7258 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:51.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2991" for this suite.
Aug 20 03:31:57.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:31:57.279: INFO: namespace configmap-2991 deletion completed in 6.106261246s

• [SLOW TEST:8.206 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:31:57.279: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-3a1dae6a-58e9-40cc-bb7a-e031bdf46e86
STEP: Creating a pod to test consume secrets
Aug 20 03:31:57.324: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73" in namespace "projected-1705" to be "success or failure"
Aug 20 03:31:57.326: INFO: Pod "pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73": Phase="Pending", Reason="", readiness=false. Elapsed: 1.990771ms
Aug 20 03:31:59.329: INFO: Pod "pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005047304s
STEP: Saw pod success
Aug 20 03:31:59.329: INFO: Pod "pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73" satisfied condition "success or failure"
Aug 20 03:31:59.331: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:31:59.348: INFO: Waiting for pod pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73 to disappear
Aug 20 03:31:59.351: INFO: Pod pod-projected-secrets-9d182125-db57-477f-bf7d-c53884002d73 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:31:59.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1705" for this suite.
Aug 20 03:32:05.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:32:05.491: INFO: namespace projected-1705 deletion completed in 6.135651382s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:32:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7c3fef50-4b0d-434a-bcef-0c7aa7df3368
STEP: Creating a pod to test consume secrets
Aug 20 03:32:05.535: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555" in namespace "projected-2502" to be "success or failure"
Aug 20 03:32:05.537: INFO: Pod "pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110931ms
Aug 20 03:32:07.541: INFO: Pod "pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005687056s
STEP: Saw pod success
Aug 20 03:32:07.541: INFO: Pod "pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555" satisfied condition "success or failure"
Aug 20 03:32:07.544: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:32:07.559: INFO: Waiting for pod pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555 to disappear
Aug 20 03:32:07.561: INFO: Pod pod-projected-secrets-c6318fc8-8349-44ff-94ae-b3cfb2f96555 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:32:07.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2502" for this suite.
Aug 20 03:32:13.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:32:13.760: INFO: namespace projected-2502 deletion completed in 6.194613024s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:32:13.760: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:32:15.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7974" for this suite.
Aug 20 03:32:53.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:32:54.070: INFO: namespace kubelet-test-7974 deletion completed in 38.240978168s

• [SLOW TEST:40.310 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:32:54.071: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 20 03:32:54.113: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 20 03:32:59.117: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8222" for this suite.
Aug 20 03:33:06.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:06.234: INFO: namespace replication-controller-8222 deletion completed in 6.102012814s

• [SLOW TEST:12.163 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:06.234: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:33:06.266: INFO: Creating deployment "test-recreate-deployment"
Aug 20 03:33:06.274: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 20 03:33:06.279: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 20 03:33:08.286: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 20 03:33:08.302: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 20 03:33:08.309: INFO: Updating deployment test-recreate-deployment
Aug 20 03:33:08.309: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 20 03:33:08.436: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/deployments/test-recreate-deployment,UID:6a43090b-6f15-4a32-8886-fbe364cb99ff,ResourceVersion:21712,Generation:2,CreationTimestamp:2019-08-20 03:33:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-20 03:33:08 +0000 UTC 2019-08-20 03:33:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-20 03:33:08 +0000 UTC 2019-08-20 03:33:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 20 03:33:08.439: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/replicasets/test-recreate-deployment-5c8c9cc69d,UID:b6cea03e-2eb8-48d7-b107-0ca051a5edf2,ResourceVersion:21711,Generation:1,CreationTimestamp:2019-08-20 03:33:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6a43090b-6f15-4a32-8886-fbe364cb99ff 0xc002e48767 0xc002e48768}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 03:33:08.439: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 20 03:33:08.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/replicasets/test-recreate-deployment-6df85df6b9,UID:069dc9d7-e0db-47d7-b9a4-ada097adf227,ResourceVersion:21701,Generation:2,CreationTimestamp:2019-08-20 03:33:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6a43090b-6f15-4a32-8886-fbe364cb99ff 0xc002e48837 0xc002e48838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 20 03:33:08.442: INFO: Pod "test-recreate-deployment-5c8c9cc69d-5bglv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-5bglv,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1401,SelfLink:/api/v1/namespaces/deployment-1401/pods/test-recreate-deployment-5c8c9cc69d-5bglv,UID:94f954cc-446c-4d2c-9aaf-9c31b3effde3,ResourceVersion:21713,Generation:0,CreationTimestamp:2019-08-20 03:33:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d b6cea03e-2eb8-48d7-b107-0ca051a5edf2 0xc002e49127 0xc002e49128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rsxb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rsxb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rsxb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-23-37,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e491a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e491c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:33:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:33:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:33:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-20 03:33:08 +0000 UTC  }],Message:,Reason:,HostIP:172.31.23.37,PodIP:,StartTime:2019-08-20 03:33:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:08.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1401" for this suite.
Aug 20 03:33:14.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:14.586: INFO: namespace deployment-1401 deletion completed in 6.139433103s

• [SLOW TEST:8.351 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:14.586: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 20 03:33:14.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081" in namespace "projected-488" to be "success or failure"
Aug 20 03:33:14.631: INFO: Pod "downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081": Phase="Pending", Reason="", readiness=false. Elapsed: 2.859933ms
Aug 20 03:33:16.634: INFO: Pod "downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005957195s
STEP: Saw pod success
Aug 20 03:33:16.634: INFO: Pod "downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081" satisfied condition "success or failure"
Aug 20 03:33:16.636: INFO: Trying to get logs from node ip-172-31-23-37 pod downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081 container client-container: <nil>
STEP: delete the pod
Aug 20 03:33:16.653: INFO: Waiting for pod downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081 to disappear
Aug 20 03:33:16.655: INFO: Pod downwardapi-volume-f1f31f57-6bb1-4a11-b780-c116c68e6081 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:16.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-488" for this suite.
Aug 20 03:33:22.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:22.766: INFO: namespace projected-488 deletion completed in 6.107571912s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:22.767: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 20 03:33:22.795: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 20 03:33:22.803: INFO: Waiting for terminating namespaces to be deleted...
Aug 20 03:33:22.806: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-253 before test
Aug 20 03:33:22.816: INFO: sonobuoy-e2e-job-ae4ab90fc45c47c3 from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.816: INFO: 	Container e2e ready: true, restart count 0
Aug 20 03:33:22.816: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 20 03:33:22.816: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-zk9kw from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.816: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:33:22.816: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 20 03:33:22.816: INFO: heapster-v1.6.0-beta.1-969d875b-zfq5w from kube-system started at 2019-08-20 01:57:58 +0000 UTC (4 container statuses recorded)
Aug 20 03:33:22.816: INFO: 	Container eventer ready: true, restart count 0
Aug 20 03:33:22.816: INFO: 	Container eventer-nanny ready: true, restart count 0
Aug 20 03:33:22.816: INFO: 	Container heapster ready: true, restart count 0
Aug 20 03:33:22.816: INFO: 	Container heapster-nanny ready: true, restart count 0
Aug 20 03:33:22.816: INFO: nginx-ingress-controller-kubernetes-worker-qb8kn from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.816: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:33:22.816: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-23-37 before test
Aug 20 03:33:22.822: INFO: default-http-backend-kubernetes-worker-ffcd96676-jps4h from ingress-nginx-kubernetes-worker started at 2019-08-20 01:57:00 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.822: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Aug 20 03:33:22.822: INFO: metrics-server-v0.3.3-cc578669-xl6k9 from kube-system started at 2019-08-20 01:58:00 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.822: INFO: 	Container metrics-server ready: true, restart count 0
Aug 20 03:33:22.822: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 20 03:33:22.822: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-20 02:03:49 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.822: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 20 03:33:22.822: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-gr2bt from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.822: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:33:22.822: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 20 03:33:22.822: INFO: nginx-ingress-controller-kubernetes-worker-vp4md from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:59 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.822: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:33:22.822: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-77-128 before test
Aug 20 03:33:22.832: INFO: coredns-75dc589b9b-2kf9z from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container coredns ready: true, restart count 0
Aug 20 03:33:22.832: INFO: nginx-ingress-controller-kubernetes-worker-mg2gl from ingress-nginx-kubernetes-worker started at 2019-08-20 01:56:58 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Aug 20 03:33:22.832: INFO: monitoring-influxdb-grafana-v4-77766b8fb9-6cwts from kube-system started at 2019-08-20 01:56:48 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container grafana ready: true, restart count 0
Aug 20 03:33:22.832: INFO: 	Container influxdb ready: true, restart count 0
Aug 20 03:33:22.832: INFO: coredns-75dc589b9b-v57jz from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container coredns ready: true, restart count 0
Aug 20 03:33:22.832: INFO: kubernetes-dashboard-f9f9594f9-gxspl from kube-system started at 2019-08-20 01:56:48 +0000 UTC (1 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 20 03:33:22.832: INFO: sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-sc7zl from heptio-sonobuoy started at 2019-08-20 02:03:54 +0000 UTC (2 container statuses recorded)
Aug 20 03:33:22.832: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 20 03:33:22.832: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node ip-172-31-1-253
STEP: verifying the node has the label node ip-172-31-23-37
STEP: verifying the node has the label node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-23-37
Aug 20 03:33:22.872: INFO: Pod sonobuoy-e2e-job-ae4ab90fc45c47c3 requesting resource cpu=0m on Node ip-172-31-1-253
Aug 20 03:33:22.872: INFO: Pod sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-gr2bt requesting resource cpu=0m on Node ip-172-31-23-37
Aug 20 03:33:22.872: INFO: Pod sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-sc7zl requesting resource cpu=0m on Node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-zk9kw requesting resource cpu=0m on Node ip-172-31-1-253
Aug 20 03:33:22.872: INFO: Pod default-http-backend-kubernetes-worker-ffcd96676-jps4h requesting resource cpu=10m on Node ip-172-31-23-37
Aug 20 03:33:22.872: INFO: Pod nginx-ingress-controller-kubernetes-worker-mg2gl requesting resource cpu=0m on Node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod nginx-ingress-controller-kubernetes-worker-qb8kn requesting resource cpu=0m on Node ip-172-31-1-253
Aug 20 03:33:22.872: INFO: Pod nginx-ingress-controller-kubernetes-worker-vp4md requesting resource cpu=0m on Node ip-172-31-23-37
Aug 20 03:33:22.872: INFO: Pod coredns-75dc589b9b-2kf9z requesting resource cpu=100m on Node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod coredns-75dc589b9b-v57jz requesting resource cpu=100m on Node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod heapster-v1.6.0-beta.1-969d875b-zfq5w requesting resource cpu=288m on Node ip-172-31-1-253
Aug 20 03:33:22.872: INFO: Pod kubernetes-dashboard-f9f9594f9-gxspl requesting resource cpu=0m on Node ip-172-31-77-128
Aug 20 03:33:22.872: INFO: Pod metrics-server-v0.3.3-cc578669-xl6k9 requesting resource cpu=53m on Node ip-172-31-23-37
Aug 20 03:33:22.872: INFO: Pod monitoring-influxdb-grafana-v4-77766b8fb9-6cwts requesting resource cpu=200m on Node ip-172-31-77-128
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89.15bc8416935df93b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8327/filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89 to ip-172-31-23-37]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89.15bc8416c7b24edc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89.15bc8416cdd3ad68], Reason = [Created], Message = [Created container filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89.15bc8416d744dbfd], Reason = [Started], Message = [Started container filler-pod-2883ca28-a3a4-4eab-bc32-48a0e75feb89]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a.15bc84169370d63b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8327/filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a to ip-172-31-77-128]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a.15bc8416c91a9d2c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a.15bc8416cff5103e], Reason = [Created], Message = [Created container filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a.15bc8416dd218011], Reason = [Started], Message = [Started container filler-pod-7bf674aa-51b2-4576-8e40-c4624cb1014a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084.15bc8416937a79d2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8327/filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084 to ip-172-31-1-253]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084.15bc8416c3617b1b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084.15bc8416c942e37f], Reason = [Created], Message = [Created container filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084.15bc8416d5d80959], Reason = [Started], Message = [Started container filler-pod-ae536b6c-eee7-43f8-b3d6-91177c4c2084]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bc84170a944915], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-77-128
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-1-253
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-23-37
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:25.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8327" for this suite.
Aug 20 03:33:31.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:32.099: INFO: namespace sched-pred-8327 deletion completed in 6.142222613s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.332 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:32.099: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-edc6c3c0-39c4-427d-9947-f7aa9181e151
STEP: Creating a pod to test consume secrets
Aug 20 03:33:32.150: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9" in namespace "projected-7092" to be "success or failure"
Aug 20 03:33:32.155: INFO: Pod "pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.825549ms
Aug 20 03:33:34.158: INFO: Pod "pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008353301s
STEP: Saw pod success
Aug 20 03:33:34.158: INFO: Pod "pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9" satisfied condition "success or failure"
Aug 20 03:33:34.161: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:33:34.179: INFO: Waiting for pod pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9 to disappear
Aug 20 03:33:34.181: INFO: Pod pod-projected-secrets-8c33c276-cb11-48e5-a927-82c0c2a2a4a9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:34.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7092" for this suite.
Aug 20 03:33:40.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:40.355: INFO: namespace projected-7092 deletion completed in 6.169982713s

• [SLOW TEST:8.256 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:40.356: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 20 03:33:40.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7835'
Aug 20 03:33:40.623: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 20 03:33:40.623: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 20 03:33:40.630: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-q6pnr]
Aug 20 03:33:40.630: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-q6pnr" in namespace "kubectl-7835" to be "running and ready"
Aug 20 03:33:40.635: INFO: Pod "e2e-test-nginx-rc-q6pnr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.848862ms
Aug 20 03:33:42.638: INFO: Pod "e2e-test-nginx-rc-q6pnr": Phase="Running", Reason="", readiness=true. Elapsed: 2.008287025s
Aug 20 03:33:42.638: INFO: Pod "e2e-test-nginx-rc-q6pnr" satisfied condition "running and ready"
Aug 20 03:33:42.638: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-q6pnr]
Aug 20 03:33:42.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 logs rc/e2e-test-nginx-rc --namespace=kubectl-7835'
Aug 20 03:33:42.734: INFO: stderr: ""
Aug 20 03:33:42.734: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug 20 03:33:42.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete rc e2e-test-nginx-rc --namespace=kubectl-7835'
Aug 20 03:33:42.835: INFO: stderr: ""
Aug 20 03:33:42.835: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:42.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7835" for this suite.
Aug 20 03:33:48.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:33:48.969: INFO: namespace kubectl-7835 deletion completed in 6.129938495s

• [SLOW TEST:8.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:33:48.969: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 20 03:33:53.050: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 20 03:33:53.052: INFO: Pod pod-with-poststart-http-hook still exists
Aug 20 03:33:55.052: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 20 03:33:55.056: INFO: Pod pod-with-poststart-http-hook still exists
Aug 20 03:33:57.052: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 20 03:33:57.056: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:33:57.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-228" for this suite.
Aug 20 03:34:09.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:34:09.181: INFO: namespace container-lifecycle-hook-228 deletion completed in 12.121193913s

• [SLOW TEST:20.212 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:34:09.181: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-bc3823b2-43af-452a-8fc3-e12a8f69cde6
STEP: Creating a pod to test consume secrets
Aug 20 03:34:09.228: INFO: Waiting up to 5m0s for pod "pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4" in namespace "secrets-2185" to be "success or failure"
Aug 20 03:34:09.230: INFO: Pod "pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.889575ms
Aug 20 03:34:11.234: INFO: Pod "pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00526909s
STEP: Saw pod success
Aug 20 03:34:11.234: INFO: Pod "pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4" satisfied condition "success or failure"
Aug 20 03:34:11.236: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4 container secret-volume-test: <nil>
STEP: delete the pod
Aug 20 03:34:11.253: INFO: Waiting for pod pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4 to disappear
Aug 20 03:34:11.255: INFO: Pod pod-secrets-9914d170-eeda-4bb6-a2d5-f56b674c7fe4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:34:11.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2185" for this suite.
Aug 20 03:34:17.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:34:17.371: INFO: namespace secrets-2185 deletion completed in 6.112400763s

• [SLOW TEST:8.190 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:34:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 20 03:34:17.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-5071'
Aug 20 03:34:17.750: INFO: stderr: ""
Aug 20 03:34:17.750: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 20 03:34:17.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-5071'
Aug 20 03:34:17.972: INFO: stderr: ""
Aug 20 03:34:17.972: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 20 03:34:18.976: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:34:18.976: INFO: Found 0 / 1
Aug 20 03:34:19.976: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:34:19.976: INFO: Found 1 / 1
Aug 20 03:34:19.976: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 20 03:34:19.978: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:34:19.978: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 20 03:34:19.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 describe pod redis-master-g5vl7 --namespace=kubectl-5071'
Aug 20 03:34:20.063: INFO: stderr: ""
Aug 20 03:34:20.063: INFO: stdout: "Name:           redis-master-g5vl7\nNamespace:      kubectl-5071\nNode:           ip-172-31-23-37/172.31.23.37\nStart Time:     Tue, 20 Aug 2019 03:34:17 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.1.59.249\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a5a2472a3fd9837b42a6bb75a081fc4d6f51229f32e8fdd74370fc14fe67e1cd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 20 Aug 2019 03:34:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7jlrz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7jlrz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7jlrz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                      Message\n  ----    ------     ----  ----                      -------\n  Normal  Scheduled  3s    default-scheduler         Successfully assigned kubectl-5071/redis-master-g5vl7 to ip-172-31-23-37\n  Normal  Pulled     2s    kubelet, ip-172-31-23-37  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-172-31-23-37  Created container redis-master\n  Normal  Started    2s    kubelet, ip-172-31-23-37  Started container redis-master\n"
Aug 20 03:34:20.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 describe rc redis-master --namespace=kubectl-5071'
Aug 20 03:34:20.174: INFO: stderr: ""
Aug 20 03:34:20.174: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5071\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-g5vl7\n"
Aug 20 03:34:20.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 describe service redis-master --namespace=kubectl-5071'
Aug 20 03:34:20.275: INFO: stderr: ""
Aug 20 03:34:20.275: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5071\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.152.183.192\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.59.249:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 20 03:34:20.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 describe node ip-172-31-1-253'
Aug 20 03:34:20.402: INFO: stderr: ""
Aug 20 03:34:20.402: INFO: stdout: "Name:               ip-172-31-1-253\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-1-253\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 20 Aug 2019 01:56:50 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 20 Aug 2019 03:34:01 +0000   Tue, 20 Aug 2019 01:56:50 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 20 Aug 2019 03:34:01 +0000   Tue, 20 Aug 2019 01:56:50 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 20 Aug 2019 03:34:01 +0000   Tue, 20 Aug 2019 01:56:50 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 20 Aug 2019 03:34:01 +0000   Tue, 20 Aug 2019 02:06:37 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.1.253\n  Hostname:    ip-172-31-1-253\nCapacity:\n cpu:                4\n ephemeral-storage:  16197480Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16235508Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  14927597544\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16133108Ki\n pods:               110\nSystem Info:\n Machine ID:                       ec2e0ce9ed373e3f2886a824e938a5b8\n System UUID:                      EC2E0CE9-ED37-3E3F-2886-A824E938A5B8\n Boot ID:                          9e39e0b7-aa1c-4da4-9cce-1cfc75c80622\n Kernel Version:                   4.15.0-1045-aws\n OS Image:                         Ubuntu 18.04.3 LTS\n Operating System:                 linux\n Architecture:                     amd64\n Container Runtime Version:        containerd://1.2.6\n Kubelet Version:                  v1.15.2\n Kube-Proxy Version:               v1.15.2\nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy                  sonobuoy-e2e-job-ae4ab90fc45c47c3                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         90m\n  heptio-sonobuoy                  sonobuoy-systemd-logs-daemon-set-953ecdae223f4d92-zk9kw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         90m\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-qb8kn           0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                      heapster-v1.6.0-beta.1-969d875b-zfq5w                      288m (7%)     288m (7%)   394416Ki (2%)    394416Ki (2%)  96m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                288m (7%)      288m (7%)\n  memory             394416Ki (2%)  394416Ki (2%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug 20 03:34:20.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 describe namespace kubectl-5071'
Aug 20 03:34:20.491: INFO: stderr: ""
Aug 20 03:34:20.491: INFO: stdout: "Name:         kubectl-5071\nLabels:       e2e-framework=kubectl\n              e2e-run=bccfc2c9-d1f3-449d-8062-79288d9fb431\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:34:20.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5071" for this suite.
Aug 20 03:34:42.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:34:42.600: INFO: namespace kubectl-5071 deletion completed in 22.103940347s

• [SLOW TEST:25.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:34:42.601: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 20 03:34:42.660: INFO: Number of nodes with available pods: 0
Aug 20 03:34:42.660: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:34:43.667: INFO: Number of nodes with available pods: 0
Aug 20 03:34:43.667: INFO: Node ip-172-31-1-253 is running more than one daemon pod
Aug 20 03:34:44.671: INFO: Number of nodes with available pods: 3
Aug 20 03:34:44.671: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 20 03:34:44.690: INFO: Number of nodes with available pods: 3
Aug 20 03:34:44.690: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1513, will wait for the garbage collector to delete the pods
Aug 20 03:34:45.757: INFO: Deleting DaemonSet.extensions daemon-set took: 6.487964ms
Aug 20 03:34:46.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.247796ms
Aug 20 03:35:49.762: INFO: Number of nodes with available pods: 0
Aug 20 03:35:49.762: INFO: Number of running nodes: 0, number of available pods: 0
Aug 20 03:35:49.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1513/daemonsets","resourceVersion":"22336"},"items":null}

Aug 20 03:35:49.767: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1513/pods","resourceVersion":"22336"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:35:49.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1513" for this suite.
Aug 20 03:35:55.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:35:55.917: INFO: namespace daemonsets-1513 deletion completed in 6.132676359s

• [SLOW TEST:73.316 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:35:55.917: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-2714
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2714 to expose endpoints map[]
Aug 20 03:35:55.969: INFO: Get endpoints failed (3.531854ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Aug 20 03:35:56.974: INFO: successfully validated that service endpoint-test2 in namespace services-2714 exposes endpoints map[] (1.008131666s elapsed)
STEP: Creating pod pod1 in namespace services-2714
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2714 to expose endpoints map[pod1:[80]]
Aug 20 03:35:59.003: INFO: successfully validated that service endpoint-test2 in namespace services-2714 exposes endpoints map[pod1:[80]] (2.022324209s elapsed)
STEP: Creating pod pod2 in namespace services-2714
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2714 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 20 03:36:01.053: INFO: successfully validated that service endpoint-test2 in namespace services-2714 exposes endpoints map[pod1:[80] pod2:[80]] (2.045634001s elapsed)
STEP: Deleting pod pod1 in namespace services-2714
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2714 to expose endpoints map[pod2:[80]]
Aug 20 03:36:02.083: INFO: successfully validated that service endpoint-test2 in namespace services-2714 exposes endpoints map[pod2:[80]] (1.024408505s elapsed)
STEP: Deleting pod pod2 in namespace services-2714
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2714 to expose endpoints map[]
Aug 20 03:36:03.105: INFO: successfully validated that service endpoint-test2 in namespace services-2714 exposes endpoints map[] (1.015966903s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:03.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2714" for this suite.
Aug 20 03:36:09.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:36:09.266: INFO: namespace services-2714 deletion completed in 6.137000147s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:13.349 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:36:09.267: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 20 03:36:09.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 --namespace=kubectl-5688 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 20 03:36:11.005: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 20 03:36:11.005: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:13.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5688" for this suite.
Aug 20 03:36:19.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:36:19.125: INFO: namespace kubectl-5688 deletion completed in 6.107969065s

• [SLOW TEST:9.858 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:36:19.125: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 20 03:36:19.185: INFO: Waiting up to 5m0s for pod "var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf" in namespace "var-expansion-2736" to be "success or failure"
Aug 20 03:36:19.187: INFO: Pod "var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.303855ms
Aug 20 03:36:21.191: INFO: Pod "var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005763141s
STEP: Saw pod success
Aug 20 03:36:21.191: INFO: Pod "var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf" satisfied condition "success or failure"
Aug 20 03:36:21.193: INFO: Trying to get logs from node ip-172-31-23-37 pod var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf container dapi-container: <nil>
STEP: delete the pod
Aug 20 03:36:21.214: INFO: Waiting for pod var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf to disappear
Aug 20 03:36:21.216: INFO: Pod var-expansion-81525c1c-6515-47ae-bad3-1afca72e0ccf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:21.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2736" for this suite.
Aug 20 03:36:27.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:36:27.361: INFO: namespace var-expansion-2736 deletion completed in 6.141284483s

• [SLOW TEST:8.236 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:36:27.362: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug 20 03:36:27.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-4065'
Aug 20 03:36:27.568: INFO: stderr: ""
Aug 20 03:36:27.568: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 20 03:36:28.572: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:28.572: INFO: Found 0 / 1
Aug 20 03:36:29.572: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:29.572: INFO: Found 1 / 1
Aug 20 03:36:29.572: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 20 03:36:29.574: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:29.574: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 20 03:36:29.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 logs redis-master-bwnk2 redis-master --namespace=kubectl-4065'
Aug 20 03:36:29.657: INFO: stderr: ""
Aug 20 03:36:29.657: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Aug 03:36:28.681 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Aug 03:36:28.681 # Server started, Redis version 3.2.12\n1:M 20 Aug 03:36:28.681 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Aug 03:36:28.681 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 20 03:36:29.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 log redis-master-bwnk2 redis-master --namespace=kubectl-4065 --tail=1'
Aug 20 03:36:29.747: INFO: stderr: ""
Aug 20 03:36:29.747: INFO: stdout: "1:M 20 Aug 03:36:28.681 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 20 03:36:29.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 log redis-master-bwnk2 redis-master --namespace=kubectl-4065 --limit-bytes=1'
Aug 20 03:36:29.846: INFO: stderr: ""
Aug 20 03:36:29.846: INFO: stdout: " "
STEP: exposing timestamps
Aug 20 03:36:29.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 log redis-master-bwnk2 redis-master --namespace=kubectl-4065 --tail=1 --timestamps'
Aug 20 03:36:29.948: INFO: stderr: ""
Aug 20 03:36:29.948: INFO: stdout: "2019-08-20T03:36:28.682024711Z 1:M 20 Aug 03:36:28.681 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 20 03:36:32.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 log redis-master-bwnk2 redis-master --namespace=kubectl-4065 --since=1s'
Aug 20 03:36:32.549: INFO: stderr: ""
Aug 20 03:36:32.549: INFO: stdout: ""
Aug 20 03:36:32.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 log redis-master-bwnk2 redis-master --namespace=kubectl-4065 --since=24h'
Aug 20 03:36:32.645: INFO: stderr: ""
Aug 20 03:36:32.645: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Aug 03:36:28.681 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Aug 03:36:28.681 # Server started, Redis version 3.2.12\n1:M 20 Aug 03:36:28.681 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Aug 03:36:28.681 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug 20 03:36:32.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-4065'
Aug 20 03:36:32.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 03:36:32.733: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 20 03:36:32.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4065'
Aug 20 03:36:32.839: INFO: stderr: "No resources found.\n"
Aug 20 03:36:32.839: INFO: stdout: ""
Aug 20 03:36:32.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=nginx --namespace=kubectl-4065 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:36:32.951: INFO: stderr: ""
Aug 20 03:36:32.951: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:32.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4065" for this suite.
Aug 20 03:36:38.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:36:39.066: INFO: namespace kubectl-4065 deletion completed in 6.11097138s

• [SLOW TEST:11.704 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:36:39.066: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-22b4e2d1-03e9-48ce-b280-a93ce5065ccd
STEP: Creating a pod to test consume configMaps
Aug 20 03:36:39.111: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4" in namespace "projected-2036" to be "success or failure"
Aug 20 03:36:39.113: INFO: Pod "pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083232ms
Aug 20 03:36:41.116: INFO: Pod "pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005288264s
STEP: Saw pod success
Aug 20 03:36:41.116: INFO: Pod "pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4" satisfied condition "success or failure"
Aug 20 03:36:41.119: INFO: Trying to get logs from node ip-172-31-23-37 pod pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 20 03:36:41.143: INFO: Waiting for pod pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4 to disappear
Aug 20 03:36:41.148: INFO: Pod pod-projected-configmaps-e77a108c-73ce-4f4e-8023-3726976c76e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:41.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2036" for this suite.
Aug 20 03:36:47.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:36:47.261: INFO: namespace projected-2036 deletion completed in 6.108776107s

• [SLOW TEST:8.195 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:36:47.261: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 20 03:36:47.295: INFO: namespace kubectl-7010
Aug 20 03:36:47.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-7010'
Aug 20 03:36:47.516: INFO: stderr: ""
Aug 20 03:36:47.516: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 20 03:36:48.519: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:48.519: INFO: Found 0 / 1
Aug 20 03:36:49.519: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:49.520: INFO: Found 1 / 1
Aug 20 03:36:49.520: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 20 03:36:49.522: INFO: Selector matched 1 pods for map[app:redis]
Aug 20 03:36:49.522: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 20 03:36:49.522: INFO: wait on redis-master startup in kubectl-7010 
Aug 20 03:36:49.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 logs redis-master-4n65d redis-master --namespace=kubectl-7010'
Aug 20 03:36:49.617: INFO: stderr: ""
Aug 20 03:36:49.617: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Aug 03:36:48.621 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Aug 03:36:48.622 # Server started, Redis version 3.2.12\n1:M 20 Aug 03:36:48.622 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Aug 03:36:48.622 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 20 03:36:49.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7010'
Aug 20 03:36:49.716: INFO: stderr: ""
Aug 20 03:36:49.716: INFO: stdout: "service/rm2 exposed\n"
Aug 20 03:36:49.720: INFO: Service rm2 in namespace kubectl-7010 found.
STEP: exposing service
Aug 20 03:36:51.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7010'
Aug 20 03:36:51.807: INFO: stderr: ""
Aug 20 03:36:51.807: INFO: stdout: "service/rm3 exposed\n"
Aug 20 03:36:51.812: INFO: Service rm3 in namespace kubectl-7010 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:36:53.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7010" for this suite.
Aug 20 03:37:15.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:37:15.932: INFO: namespace kubectl-7010 deletion completed in 22.107905242s

• [SLOW TEST:28.671 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:37:15.932: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 20 03:37:25.988: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0820 03:37:25.988429      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:37:25.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4056" for this suite.
Aug 20 03:37:32.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:37:32.117: INFO: namespace gc-4056 deletion completed in 6.125729821s

• [SLOW TEST:16.185 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:37:32.117: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 20 03:37:32.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 create -f - --namespace=kubectl-9429'
Aug 20 03:37:32.405: INFO: stderr: ""
Aug 20 03:37:32.405: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:37:32.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:32.545: INFO: stderr: ""
Aug 20 03:37:32.545: INFO: stdout: "update-demo-nautilus-7rlvx update-demo-nautilus-zsncr "
Aug 20 03:37:32.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-7rlvx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:32.638: INFO: stderr: ""
Aug 20 03:37:32.638: INFO: stdout: ""
Aug 20 03:37:32.638: INFO: update-demo-nautilus-7rlvx is created but not running
Aug 20 03:37:37.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:37.712: INFO: stderr: ""
Aug 20 03:37:37.712: INFO: stdout: "update-demo-nautilus-7rlvx update-demo-nautilus-zsncr "
Aug 20 03:37:37.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-7rlvx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:37.780: INFO: stderr: ""
Aug 20 03:37:37.780: INFO: stdout: "true"
Aug 20 03:37:37.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-7rlvx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:37.849: INFO: stderr: ""
Aug 20 03:37:37.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:37:37.849: INFO: validating pod update-demo-nautilus-7rlvx
Aug 20 03:37:37.853: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:37:37.853: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:37:37.853: INFO: update-demo-nautilus-7rlvx is verified up and running
Aug 20 03:37:37.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:37.937: INFO: stderr: ""
Aug 20 03:37:37.937: INFO: stdout: "true"
Aug 20 03:37:37.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:38.004: INFO: stderr: ""
Aug 20 03:37:38.004: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:37:38.004: INFO: validating pod update-demo-nautilus-zsncr
Aug 20 03:37:38.008: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:37:38.008: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:37:38.008: INFO: update-demo-nautilus-zsncr is verified up and running
STEP: scaling down the replication controller
Aug 20 03:37:38.010: INFO: scanned /root for discovery docs: <nil>
Aug 20 03:37:38.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9429'
Aug 20 03:37:39.132: INFO: stderr: ""
Aug 20 03:37:39.132: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:37:39.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:39.201: INFO: stderr: ""
Aug 20 03:37:39.201: INFO: stdout: "update-demo-nautilus-7rlvx update-demo-nautilus-zsncr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 20 03:37:44.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:44.292: INFO: stderr: ""
Aug 20 03:37:44.292: INFO: stdout: "update-demo-nautilus-7rlvx update-demo-nautilus-zsncr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 20 03:37:49.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:49.376: INFO: stderr: ""
Aug 20 03:37:49.376: INFO: stdout: "update-demo-nautilus-zsncr "
Aug 20 03:37:49.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:49.452: INFO: stderr: ""
Aug 20 03:37:49.452: INFO: stdout: "true"
Aug 20 03:37:49.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:49.525: INFO: stderr: ""
Aug 20 03:37:49.525: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:37:49.525: INFO: validating pod update-demo-nautilus-zsncr
Aug 20 03:37:49.529: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:37:49.529: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:37:49.529: INFO: update-demo-nautilus-zsncr is verified up and running
STEP: scaling up the replication controller
Aug 20 03:37:49.530: INFO: scanned /root for discovery docs: <nil>
Aug 20 03:37:49.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9429'
Aug 20 03:37:50.633: INFO: stderr: ""
Aug 20 03:37:50.633: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 20 03:37:50.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:50.736: INFO: stderr: ""
Aug 20 03:37:50.736: INFO: stdout: "update-demo-nautilus-9ppn8 update-demo-nautilus-zsncr "
Aug 20 03:37:50.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-9ppn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:50.837: INFO: stderr: ""
Aug 20 03:37:50.837: INFO: stdout: ""
Aug 20 03:37:50.837: INFO: update-demo-nautilus-9ppn8 is created but not running
Aug 20 03:37:55.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9429'
Aug 20 03:37:55.966: INFO: stderr: ""
Aug 20 03:37:55.966: INFO: stdout: "update-demo-nautilus-9ppn8 update-demo-nautilus-zsncr "
Aug 20 03:37:55.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-9ppn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:56.081: INFO: stderr: ""
Aug 20 03:37:56.081: INFO: stdout: "true"
Aug 20 03:37:56.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-9ppn8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:56.162: INFO: stderr: ""
Aug 20 03:37:56.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:37:56.162: INFO: validating pod update-demo-nautilus-9ppn8
Aug 20 03:37:56.168: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:37:56.168: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:37:56.168: INFO: update-demo-nautilus-9ppn8 is verified up and running
Aug 20 03:37:56.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:56.246: INFO: stderr: ""
Aug 20 03:37:56.246: INFO: stdout: "true"
Aug 20 03:37:56.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods update-demo-nautilus-zsncr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9429'
Aug 20 03:37:56.335: INFO: stderr: ""
Aug 20 03:37:56.335: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 20 03:37:56.335: INFO: validating pod update-demo-nautilus-zsncr
Aug 20 03:37:56.340: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 20 03:37:56.340: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 20 03:37:56.340: INFO: update-demo-nautilus-zsncr is verified up and running
STEP: using delete to clean up resources
Aug 20 03:37:56.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 delete --grace-period=0 --force -f - --namespace=kubectl-9429'
Aug 20 03:37:56.427: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 20 03:37:56.427: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 20 03:37:56.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9429'
Aug 20 03:37:56.507: INFO: stderr: "No resources found.\n"
Aug 20 03:37:56.507: INFO: stdout: ""
Aug 20 03:37:56.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=update-demo --namespace=kubectl-9429 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:37:56.596: INFO: stderr: ""
Aug 20 03:37:56.596: INFO: stdout: "update-demo-nautilus-9ppn8\nupdate-demo-nautilus-zsncr\n"
Aug 20 03:37:57.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9429'
Aug 20 03:37:57.169: INFO: stderr: "No resources found.\n"
Aug 20 03:37:57.169: INFO: stdout: ""
Aug 20 03:37:57.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-136865096 get pods -l name=update-demo --namespace=kubectl-9429 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 20 03:37:57.242: INFO: stderr: ""
Aug 20 03:37:57.242: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:37:57.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9429" for this suite.
Aug 20 03:38:19.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:38:19.381: INFO: namespace kubectl-9429 deletion completed in 22.134376944s

• [SLOW TEST:47.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:38:19.381: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 20 03:38:29.475: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0820 03:38:29.475052      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 20 03:38:29.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5112" for this suite.
Aug 20 03:38:35.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:38:35.596: INFO: namespace gc-5112 deletion completed in 6.11703542s

• [SLOW TEST:16.215 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 20 03:38:35.596: INFO: >>> kubeConfig: /tmp/kubeconfig-136865096
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 20 03:38:35.635: INFO: Waiting up to 5m0s for pod "downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed" in namespace "downward-api-7261" to be "success or failure"
Aug 20 03:38:35.638: INFO: Pod "downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.458564ms
Aug 20 03:38:37.641: INFO: Pod "downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006075446s
STEP: Saw pod success
Aug 20 03:38:37.641: INFO: Pod "downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed" satisfied condition "success or failure"
Aug 20 03:38:37.644: INFO: Trying to get logs from node ip-172-31-23-37 pod downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed container dapi-container: <nil>
STEP: delete the pod
Aug 20 03:38:37.659: INFO: Waiting for pod downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed to disappear
Aug 20 03:38:37.661: INFO: Pod downward-api-ec0e58eb-95ba-4a13-9712-ab892e5b15ed no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 20 03:38:37.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7261" for this suite.
Aug 20 03:38:43.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 20 03:38:43.777: INFO: namespace downward-api-7261 deletion completed in 6.112162453s

• [SLOW TEST:8.180 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
Aug 20 03:38:43.777: INFO: Running AfterSuite actions on all nodes
Aug 20 03:38:43.777: INFO: Running AfterSuite actions on node 1
Aug 20 03:38:43.777: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5663.153 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h34m24.601252759s
Test Suite Passed
