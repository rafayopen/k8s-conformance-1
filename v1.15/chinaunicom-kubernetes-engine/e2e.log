I0904 15:05:30.668213      17 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-227760248
I0904 15:05:30.668336      17 e2e.go:241] Starting e2e run "2d63d4af-55df-4c9a-9542-39f8d7bdf3f7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567609528 - Will randomize all specs
Will run 215 of 4411 specs

Sep  4 15:05:31.079: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:05:31.084: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  4 15:05:31.103: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 15:05:31.125: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 15:05:31.125: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep  4 15:05:31.125: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  4 15:05:31.131: INFO: e2e test version: v1.15.0
Sep  4 15:05:31.131: INFO: kube-apiserver version: v1.15.0
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:05:31.132: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
Sep  4 15:05:31.171: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:05:51.181: INFO: Container started at 2019-09-04 15:05:32 +0000 UTC, pod became ready at 2019-09-04 15:05:50 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:05:51.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5321" for this suite.
Sep  4 15:06:13.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:06:13.231: INFO: namespace container-probe-5321 deletion completed in 22.047833861s

• [SLOW TEST:42.099 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:06:13.231: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 15:06:13.275: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:06:16.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-451" for this suite.
Sep  4 15:06:38.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:06:38.819: INFO: namespace init-container-451 deletion completed in 22.067559495s

• [SLOW TEST:25.588 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:06:38.819: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8235
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8235
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8235
Sep  4 15:06:38.892: INFO: Found 0 stateful pods, waiting for 1
Sep  4 15:06:48.894: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  4 15:06:48.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 15:06:49.090: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 15:06:49.090: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 15:06:49.090: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 15:06:49.092: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 15:06:59.095: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 15:06:59.095: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 15:06:59.110: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999793s
Sep  4 15:07:00.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990524532s
Sep  4 15:07:01.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988316742s
Sep  4 15:07:02.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986002139s
Sep  4 15:07:03.119: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983608078s
Sep  4 15:07:04.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981229794s
Sep  4 15:07:05.124: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.978985886s
Sep  4 15:07:06.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.976441956s
Sep  4 15:07:07.129: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.973445334s
Sep  4 15:07:08.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 971.032108ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8235
Sep  4 15:07:09.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 15:07:09.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 15:07:09.311: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 15:07:09.311: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 15:07:09.314: INFO: Found 1 stateful pods, waiting for 3
Sep  4 15:07:19.316: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:07:19.316: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:07:19.316: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  4 15:07:19.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 15:07:19.528: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 15:07:19.528: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 15:07:19.528: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 15:07:19.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 15:07:19.725: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 15:07:19.725: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 15:07:19.725: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 15:07:19.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 15:07:19.876: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 15:07:19.876: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 15:07:19.876: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 15:07:19.876: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 15:07:19.878: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  4 15:07:29.882: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 15:07:29.882: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 15:07:29.882: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 15:07:29.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999811s
Sep  4 15:07:30.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.981557108s
Sep  4 15:07:31.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979712785s
Sep  4 15:07:32.911: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.976089762s
Sep  4 15:07:33.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97385484s
Sep  4 15:07:34.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971489259s
Sep  4 15:07:35.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969065553s
Sep  4 15:07:36.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963076936s
Sep  4 15:07:37.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944742809s
Sep  4 15:07:38.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.458725ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8235
Sep  4 15:07:39.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 15:07:40.150: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 15:07:40.150: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 15:07:40.150: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 15:07:40.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 15:07:40.444: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 15:07:40.444: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 15:07:40.444: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 15:07:40.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-8235 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 15:07:40.602: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 15:07:40.603: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 15:07:40.603: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 15:07:40.603: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 15:08:00.612: INFO: Deleting all statefulset in ns statefulset-8235
Sep  4 15:08:00.613: INFO: Scaling statefulset ss to 0
Sep  4 15:08:00.617: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 15:08:00.619: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:08:00.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8235" for this suite.
Sep  4 15:08:06.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:08:06.684: INFO: namespace statefulset-8235 deletion completed in 6.056080501s

• [SLOW TEST:87.864 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:08:06.684: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-7582db10-ea7a-41f4-9b0e-05867db88656
STEP: Creating configMap with name cm-test-opt-upd-1443d6a0-a2ed-4d92-ac63-865a0b42865c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7582db10-ea7a-41f4-9b0e-05867db88656
STEP: Updating configmap cm-test-opt-upd-1443d6a0-a2ed-4d92-ac63-865a0b42865c
STEP: Creating configMap with name cm-test-opt-create-d0695daa-36bf-44dd-a994-1d1af85da874
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:08:10.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8924" for this suite.
Sep  4 15:08:32.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:08:32.915: INFO: namespace projected-8924 deletion completed in 22.06516421s

• [SLOW TEST:26.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:08:32.915: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-5db24346-665a-446d-ac6d-ec6405fe7a24
STEP: Creating a pod to test consume secrets
Sep  4 15:08:32.992: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83" in namespace "projected-9714" to be "success or failure"
Sep  4 15:08:32.997: INFO: Pod "pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83": Phase="Pending", Reason="", readiness=false. Elapsed: 4.371943ms
Sep  4 15:08:34.998: INFO: Pod "pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006130716s
STEP: Saw pod success
Sep  4 15:08:34.998: INFO: Pod "pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83" satisfied condition "success or failure"
Sep  4 15:08:35.000: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:08:35.037: INFO: Waiting for pod pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83 to disappear
Sep  4 15:08:35.042: INFO: Pod pod-projected-secrets-c7f95952-6055-4e66-8096-839828dc1e83 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:08:35.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9714" for this suite.
Sep  4 15:08:41.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:08:41.092: INFO: namespace projected-9714 deletion completed in 6.047199399s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:08:41.092: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:08:43.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2650" for this suite.
Sep  4 15:09:25.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:09:25.298: INFO: namespace kubelet-test-2650 deletion completed in 42.056626479s

• [SLOW TEST:44.206 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:09:25.299: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:09:25.370: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3" in namespace "projected-9486" to be "success or failure"
Sep  4 15:09:25.384: INFO: Pod "downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.799021ms
Sep  4 15:09:27.402: INFO: Pod "downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032395027s
STEP: Saw pod success
Sep  4 15:09:27.402: INFO: Pod "downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3" satisfied condition "success or failure"
Sep  4 15:09:27.404: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3 container client-container: <nil>
STEP: delete the pod
Sep  4 15:09:27.421: INFO: Waiting for pod downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3 to disappear
Sep  4 15:09:27.426: INFO: Pod downwardapi-volume-3b881537-9c37-46de-b1dc-edd131dfdcc3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:09:27.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9486" for this suite.
Sep  4 15:09:33.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:09:33.475: INFO: namespace projected-9486 deletion completed in 6.04712029s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:09:33.475: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-d99c69dc-99da-4897-add6-0eedaf7fdda1
STEP: Creating a pod to test consume configMaps
Sep  4 15:09:33.536: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c" in namespace "projected-5588" to be "success or failure"
Sep  4 15:09:33.579: INFO: Pod "pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c": Phase="Pending", Reason="", readiness=false. Elapsed: 43.649397ms
Sep  4 15:09:35.582: INFO: Pod "pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04585293s
STEP: Saw pod success
Sep  4 15:09:35.582: INFO: Pod "pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c" satisfied condition "success or failure"
Sep  4 15:09:35.583: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:09:35.598: INFO: Waiting for pod pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c to disappear
Sep  4 15:09:35.603: INFO: Pod pod-projected-configmaps-d1a1f367-20e4-4267-9bcb-f0677c5f4a4c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:09:35.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5588" for this suite.
Sep  4 15:09:41.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:09:41.690: INFO: namespace projected-5588 deletion completed in 6.084875924s

• [SLOW TEST:8.215 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:09:41.690: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:09:41.756: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 15:09:41.810: INFO: Number of nodes with available pods: 0
Sep  4 15:09:41.810: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:09:42.815: INFO: Number of nodes with available pods: 0
Sep  4 15:09:42.815: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:09:43.814: INFO: Number of nodes with available pods: 1
Sep  4 15:09:43.814: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:09:44.815: INFO: Number of nodes with available pods: 2
Sep  4 15:09:44.815: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  4 15:09:44.871: INFO: Wrong image for pod: daemon-set-j75m5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:44.871: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:45.881: INFO: Wrong image for pod: daemon-set-j75m5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:45.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:46.881: INFO: Wrong image for pod: daemon-set-j75m5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:46.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:47.881: INFO: Wrong image for pod: daemon-set-j75m5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:47.881: INFO: Pod daemon-set-j75m5 is not available
Sep  4 15:09:47.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:48.881: INFO: Pod daemon-set-h5bnw is not available
Sep  4 15:09:48.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:49.881: INFO: Pod daemon-set-h5bnw is not available
Sep  4 15:09:49.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:50.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:51.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:51.881: INFO: Pod daemon-set-xrr8g is not available
Sep  4 15:09:52.881: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:52.881: INFO: Pod daemon-set-xrr8g is not available
Sep  4 15:09:53.880: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:53.880: INFO: Pod daemon-set-xrr8g is not available
Sep  4 15:09:54.880: INFO: Wrong image for pod: daemon-set-xrr8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 15:09:54.880: INFO: Pod daemon-set-xrr8g is not available
Sep  4 15:09:55.881: INFO: Pod daemon-set-9m5pg is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  4 15:09:55.886: INFO: Number of nodes with available pods: 1
Sep  4 15:09:55.886: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:09:56.890: INFO: Number of nodes with available pods: 2
Sep  4 15:09:56.890: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4808, will wait for the garbage collector to delete the pods
Sep  4 15:09:56.952: INFO: Deleting DaemonSet.extensions daemon-set took: 3.180704ms
Sep  4 15:09:58.952: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.000216661s
Sep  4 15:10:05.368: INFO: Number of nodes with available pods: 0
Sep  4 15:10:05.368: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 15:10:05.369: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4808/daemonsets","resourceVersion":"3526"},"items":null}

Sep  4 15:10:05.370: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4808/pods","resourceVersion":"3526"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:10:05.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4808" for this suite.
Sep  4 15:10:11.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:10:11.434: INFO: namespace daemonsets-4808 deletion completed in 6.056950362s

• [SLOW TEST:29.744 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:10:11.434: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 15:10:11.504: INFO: Waiting up to 5m0s for pod "downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8" in namespace "downward-api-1287" to be "success or failure"
Sep  4 15:10:11.513: INFO: Pod "downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.189488ms
Sep  4 15:10:13.515: INFO: Pod "downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01162378s
STEP: Saw pod success
Sep  4 15:10:13.515: INFO: Pod "downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8" satisfied condition "success or failure"
Sep  4 15:10:13.517: INFO: Trying to get logs from node 192.168.0.166 pod downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8 container dapi-container: <nil>
STEP: delete the pod
Sep  4 15:10:13.554: INFO: Waiting for pod downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8 to disappear
Sep  4 15:10:13.558: INFO: Pod downward-api-41249bbc-d38d-4504-b77f-2a22e6d4bac8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:10:13.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1287" for this suite.
Sep  4 15:10:19.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:10:19.638: INFO: namespace downward-api-1287 deletion completed in 6.077385324s

• [SLOW TEST:8.203 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:10:19.638: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 15:10:19.751: INFO: Number of nodes with available pods: 0
Sep  4 15:10:19.751: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:10:20.755: INFO: Number of nodes with available pods: 0
Sep  4 15:10:20.755: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:10:21.765: INFO: Number of nodes with available pods: 2
Sep  4 15:10:21.765: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  4 15:10:21.778: INFO: Number of nodes with available pods: 1
Sep  4 15:10:21.778: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:22.785: INFO: Number of nodes with available pods: 1
Sep  4 15:10:22.785: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:23.782: INFO: Number of nodes with available pods: 1
Sep  4 15:10:23.782: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:24.828: INFO: Number of nodes with available pods: 1
Sep  4 15:10:24.828: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:25.829: INFO: Number of nodes with available pods: 1
Sep  4 15:10:25.829: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:26.782: INFO: Number of nodes with available pods: 1
Sep  4 15:10:26.782: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:27.782: INFO: Number of nodes with available pods: 1
Sep  4 15:10:27.782: INFO: Node 192.168.0.166 is running more than one daemon pod
Sep  4 15:10:28.782: INFO: Number of nodes with available pods: 2
Sep  4 15:10:28.782: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1031, will wait for the garbage collector to delete the pods
Sep  4 15:10:28.839: INFO: Deleting DaemonSet.extensions daemon-set took: 3.391622ms
Sep  4 15:10:29.139: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.165619ms
Sep  4 15:10:31.943: INFO: Number of nodes with available pods: 0
Sep  4 15:10:31.943: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 15:10:31.945: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1031/daemonsets","resourceVersion":"3706"},"items":null}

Sep  4 15:10:31.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1031/pods","resourceVersion":"3706"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:10:31.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1031" for this suite.
Sep  4 15:10:37.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:10:38.008: INFO: namespace daemonsets-1031 deletion completed in 6.056110605s

• [SLOW TEST:18.370 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:10:38.008: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6192
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6192
STEP: Creating statefulset with conflicting port in namespace statefulset-6192
STEP: Waiting until pod test-pod will start running in namespace statefulset-6192
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6192
Sep  4 15:10:40.151: INFO: Observed stateful pod in namespace: statefulset-6192, name: ss-0, uid: 6e818cdc-941a-47a9-8a92-e83e4cf9c8c0, status phase: Pending. Waiting for statefulset controller to delete.
Sep  4 15:10:47.968: INFO: Observed stateful pod in namespace: statefulset-6192, name: ss-0, uid: 6e818cdc-941a-47a9-8a92-e83e4cf9c8c0, status phase: Failed. Waiting for statefulset controller to delete.
Sep  4 15:10:47.989: INFO: Observed stateful pod in namespace: statefulset-6192, name: ss-0, uid: 6e818cdc-941a-47a9-8a92-e83e4cf9c8c0, status phase: Failed. Waiting for statefulset controller to delete.
Sep  4 15:10:47.999: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6192
STEP: Removing pod with conflicting port in namespace statefulset-6192
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6192 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 15:11:00.153: INFO: Deleting all statefulset in ns statefulset-6192
Sep  4 15:11:00.154: INFO: Scaling statefulset ss to 0
Sep  4 15:11:10.171: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 15:11:10.172: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:11:10.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6192" for this suite.
Sep  4 15:11:16.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:11:16.239: INFO: namespace statefulset-6192 deletion completed in 6.052538576s

• [SLOW TEST:38.230 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:11:16.239: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:11:16.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185" in namespace "projected-6859" to be "success or failure"
Sep  4 15:11:16.360: INFO: Pod "downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185": Phase="Pending", Reason="", readiness=false. Elapsed: 34.34318ms
Sep  4 15:11:18.362: INFO: Pod "downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036458485s
STEP: Saw pod success
Sep  4 15:11:18.362: INFO: Pod "downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185" satisfied condition "success or failure"
Sep  4 15:11:18.364: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185 container client-container: <nil>
STEP: delete the pod
Sep  4 15:11:18.389: INFO: Waiting for pod downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185 to disappear
Sep  4 15:11:18.400: INFO: Pod downwardapi-volume-0f9a925b-5c79-48fe-be0e-daf538e1f185 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:11:18.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6859" for this suite.
Sep  4 15:11:24.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:11:24.447: INFO: namespace projected-6859 deletion completed in 6.045468444s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:11:24.448: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:11:24.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475" in namespace "projected-5663" to be "success or failure"
Sep  4 15:11:24.509: INFO: Pod "downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475": Phase="Pending", Reason="", readiness=false. Elapsed: 4.590819ms
Sep  4 15:11:26.511: INFO: Pod "downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00674798s
STEP: Saw pod success
Sep  4 15:11:26.511: INFO: Pod "downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475" satisfied condition "success or failure"
Sep  4 15:11:26.512: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475 container client-container: <nil>
STEP: delete the pod
Sep  4 15:11:26.527: INFO: Waiting for pod downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475 to disappear
Sep  4 15:11:26.544: INFO: Pod downwardapi-volume-58de7dff-0e13-4c73-9182-3dd5ada97475 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:11:26.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5663" for this suite.
Sep  4 15:11:32.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:11:32.601: INFO: namespace projected-5663 deletion completed in 6.05567443s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:11:32.602: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:11:32.645: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep  4 15:11:34.726: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:11:35.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4517" for this suite.
Sep  4 15:11:41.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:11:41.836: INFO: namespace replication-controller-4517 deletion completed in 6.100189761s

• [SLOW TEST:9.235 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:11:41.836: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-174
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 15:11:41.923: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 15:11:58.043: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.135.141:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:11:58.043: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:11:58.187: INFO: Found all expected endpoints: [netserver-0]
Sep  4 15:11:58.189: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.166.148:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:11:58.189: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:11:58.320: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:11:58.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-174" for this suite.
Sep  4 15:12:20.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:12:20.382: INFO: namespace pod-network-test-174 deletion completed in 22.058590859s

• [SLOW TEST:38.545 seconds]
[sig-network] Networking
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:12:20.382: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 15:12:20.512: INFO: Waiting up to 5m0s for pod "downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e" in namespace "downward-api-1401" to be "success or failure"
Sep  4 15:12:20.521: INFO: Pod "downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.306144ms
Sep  4 15:12:22.523: INFO: Pod "downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01143776s
STEP: Saw pod success
Sep  4 15:12:22.523: INFO: Pod "downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e" satisfied condition "success or failure"
Sep  4 15:12:22.525: INFO: Trying to get logs from node 192.168.0.166 pod downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e container dapi-container: <nil>
STEP: delete the pod
Sep  4 15:12:22.560: INFO: Waiting for pod downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e to disappear
Sep  4 15:12:22.567: INFO: Pod downward-api-d261f58c-0b1c-4aaa-94b1-d70eb521965e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:12:22.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1401" for this suite.
Sep  4 15:12:28.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:12:28.614: INFO: namespace downward-api-1401 deletion completed in 6.04492378s

• [SLOW TEST:8.232 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:12:28.614: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 15:12:28.688: INFO: Waiting up to 5m0s for pod "pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f" in namespace "emptydir-8464" to be "success or failure"
Sep  4 15:12:28.703: INFO: Pod "pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.185812ms
Sep  4 15:12:30.705: INFO: Pod "pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016924474s
STEP: Saw pod success
Sep  4 15:12:30.705: INFO: Pod "pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f" satisfied condition "success or failure"
Sep  4 15:12:30.748: INFO: Trying to get logs from node 192.168.0.166 pod pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f container test-container: <nil>
STEP: delete the pod
Sep  4 15:12:30.780: INFO: Waiting for pod pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f to disappear
Sep  4 15:12:30.790: INFO: Pod pod-c77d6950-d383-4ba5-bea4-7f2d16f9738f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:12:30.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8464" for this suite.
Sep  4 15:12:36.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:12:36.858: INFO: namespace emptydir-8464 deletion completed in 6.066219548s

• [SLOW TEST:8.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:12:36.858: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  4 15:12:38.921: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-4609bf78-4c44-4ef9-a021-bdc456907f31,GenerateName:,Namespace:events-1380,SelfLink:/api/v1/namespaces/events-1380/pods/send-events-4609bf78-4c44-4ef9-a021-bdc456907f31,UID:3d45f534-18b2-4c53-82c2-0a51216bed45,ResourceVersion:4356,Generation:0,CreationTimestamp:2019-09-04 15:12:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 905038417,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-v9qhb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v9qhb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-v9qhb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035ea250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035ea270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:12:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:12:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:12:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:12:36 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.152,StartTime:2019-09-04 15:12:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-04 15:12:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/k8s-authenticated-test/serve-hostname:1.1 docker-pullable://reg.mg.hcbss/devcke/serve-hostname@sha256:5792caa151fd823f01e765c535bcdb0386e0e9c9a2b5687e4a613cecadfa3505 docker://1cd03527cdf299616c6da4bebf7190922c073864233156f9f6f752de79cc8b8c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  4 15:12:40.923: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  4 15:12:42.925: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:12:42.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1380" for this suite.
Sep  4 15:13:26.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:13:27.003: INFO: namespace events-1380 deletion completed in 44.058607348s

• [SLOW TEST:50.145 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:13:27.003: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-89zs
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 15:13:27.095: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-89zs" in namespace "subpath-1536" to be "success or failure"
Sep  4 15:13:27.110: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Pending", Reason="", readiness=false. Elapsed: 15.363376ms
Sep  4 15:13:29.112: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.017257717s
Sep  4 15:13:31.114: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 4.019254084s
Sep  4 15:13:33.116: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 6.021378373s
Sep  4 15:13:35.118: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 8.023325467s
Sep  4 15:13:37.120: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 10.025115619s
Sep  4 15:13:39.122: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 12.027137286s
Sep  4 15:13:41.124: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 14.028966252s
Sep  4 15:13:43.126: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 16.030987913s
Sep  4 15:13:45.128: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 18.033127176s
Sep  4 15:13:47.130: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Running", Reason="", readiness=true. Elapsed: 20.035089904s
Sep  4 15:13:49.132: INFO: Pod "pod-subpath-test-configmap-89zs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037331094s
STEP: Saw pod success
Sep  4 15:13:49.132: INFO: Pod "pod-subpath-test-configmap-89zs" satisfied condition "success or failure"
Sep  4 15:13:49.133: INFO: Trying to get logs from node 192.168.0.166 pod pod-subpath-test-configmap-89zs container test-container-subpath-configmap-89zs: <nil>
STEP: delete the pod
Sep  4 15:13:49.197: INFO: Waiting for pod pod-subpath-test-configmap-89zs to disappear
Sep  4 15:13:49.208: INFO: Pod pod-subpath-test-configmap-89zs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-89zs
Sep  4 15:13:49.208: INFO: Deleting pod "pod-subpath-test-configmap-89zs" in namespace "subpath-1536"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:13:49.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1536" for this suite.
Sep  4 15:13:55.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:13:55.262: INFO: namespace subpath-1536 deletion completed in 6.046868465s

• [SLOW TEST:28.259 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:13:55.263: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-448f29ba-363b-4f5a-977b-e723cea9bf0d
STEP: Creating secret with name s-test-opt-upd-40347d45-aeee-4801-b666-f53d52ade373
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-448f29ba-363b-4f5a-977b-e723cea9bf0d
STEP: Updating secret s-test-opt-upd-40347d45-aeee-4801-b666-f53d52ade373
STEP: Creating secret with name s-test-opt-create-f2856dde-7f84-4a06-b962-52623e002a87
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:13:59.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1537" for this suite.
Sep  4 15:14:13.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:14:13.519: INFO: namespace projected-1537 deletion completed in 14.053250724s

• [SLOW TEST:18.257 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:14:13.520: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-17c59218-1641-4ba4-a606-82674d13abaa
STEP: Creating a pod to test consume configMaps
Sep  4 15:14:13.616: INFO: Waiting up to 5m0s for pod "pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c" in namespace "configmap-4070" to be "success or failure"
Sep  4 15:14:13.620: INFO: Pod "pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.474384ms
Sep  4 15:14:15.622: INFO: Pod "pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006615775s
STEP: Saw pod success
Sep  4 15:14:15.622: INFO: Pod "pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c" satisfied condition "success or failure"
Sep  4 15:14:15.624: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:14:15.672: INFO: Waiting for pod pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c to disappear
Sep  4 15:14:15.677: INFO: Pod pod-configmaps-2be72f5a-dec0-4e4b-a5d5-5020651b7e9c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:14:15.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4070" for this suite.
Sep  4 15:14:21.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:14:21.743: INFO: namespace configmap-4070 deletion completed in 6.063840912s

• [SLOW TEST:8.224 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:14:21.743: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 15:14:23.831: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:14:23.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3910" for this suite.
Sep  4 15:14:29.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:14:29.927: INFO: namespace container-runtime-3910 deletion completed in 6.075707963s

• [SLOW TEST:8.183 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:14:29.927: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:14:29.979: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  4 15:14:30.107: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  4 15:14:35.109: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 15:14:35.109: INFO: Creating deployment "test-rolling-update-deployment"
Sep  4 15:14:35.111: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  4 15:14:35.130: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  4 15:14:37.134: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  4 15:14:37.135: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep  4 15:14:37.139: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6152,SelfLink:/apis/apps/v1/namespaces/deployment-6152/deployments/test-rolling-update-deployment,UID:52d6fe10-0bdd-4a47-a490-d40b98d65ceb,ResourceVersion:4766,Generation:1,CreationTimestamp:2019-09-04 15:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-04 15:14:35 +0000 UTC 2019-09-04 15:14:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-04 15:14:36 +0000 UTC 2019-09-04 15:14:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  4 15:14:37.141: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6152,SelfLink:/apis/apps/v1/namespaces/deployment-6152/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:7d258b7c-5fff-4aef-b617-7707be4b7acc,ResourceVersion:4755,Generation:1,CreationTimestamp:2019-09-04 15:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 52d6fe10-0bdd-4a47-a490-d40b98d65ceb 0xc002f163c7 0xc002f163c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 15:14:37.141: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  4 15:14:37.141: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6152,SelfLink:/apis/apps/v1/namespaces/deployment-6152/replicasets/test-rolling-update-controller,UID:dcebab4a-96ba-43d6-aff9-787327836d35,ResourceVersion:4764,Generation:2,CreationTimestamp:2019-09-04 15:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 52d6fe10-0bdd-4a47-a490-d40b98d65ceb 0xc002f162ef 0xc002f16300}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:14:37.143: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-w7tnj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-w7tnj,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6152,SelfLink:/api/v1/namespaces/deployment-6152/pods/test-rolling-update-deployment-79f6b9d75c-w7tnj,UID:201baede-f627-409b-bb49-7a815e048801,ResourceVersion:4754,Generation:0,CreationTimestamp:2019-09-04 15:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 7d258b7c-5fff-4aef-b617-7707be4b7acc 0xc002f16c87 0xc002f16c88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9nrjj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9nrjj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9nrjj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:14:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:14:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:14:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.158,StartTime:2019-09-04 15:14:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-04 15:14:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://a4ff34f92fe5a98a6a2bae6ad688a6617b6d4f267a482049860966bf71027718}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:14:37.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6152" for this suite.
Sep  4 15:14:43.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:14:43.192: INFO: namespace deployment-6152 deletion completed in 6.047647172s

• [SLOW TEST:13.265 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:14:43.192: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0904 15:15:23.298027      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 15:15:23.298: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:15:23.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8339" for this suite.
Sep  4 15:15:31.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:15:31.350: INFO: namespace gc-8339 deletion completed in 8.05047661s

• [SLOW TEST:48.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:15:31.350: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-e81e4a64-967b-47e7-9fb8-8360eeb55624
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:15:31.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-197" for this suite.
Sep  4 15:15:37.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:15:37.482: INFO: namespace configmap-197 deletion completed in 6.047441633s

• [SLOW TEST:6.132 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:15:37.482: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:15:37.707: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  4 15:15:42.710: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 15:15:42.710: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep  4 15:15:42.735: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7532,SelfLink:/apis/apps/v1/namespaces/deployment-7532/deployments/test-cleanup-deployment,UID:dc57b17b-81f0-45ff-9088-b96bf80cfdf7,ResourceVersion:5202,Generation:1,CreationTimestamp:2019-09-04 15:15:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  4 15:15:42.758: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-7532,SelfLink:/apis/apps/v1/namespaces/deployment-7532/replicasets/test-cleanup-deployment-55bbcbc84c,UID:76366cf5-5a3b-44ae-88e5-626d8a90119d,ResourceVersion:5204,Generation:1,CreationTimestamp:2019-09-04 15:15:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment dc57b17b-81f0-45ff-9088-b96bf80cfdf7 0xc002c3a467 0xc002c3a468}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:15:42.758: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep  4 15:15:42.758: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-7532,SelfLink:/apis/apps/v1/namespaces/deployment-7532/replicasets/test-cleanup-controller,UID:52eec9d8-4b34-4cff-b1c1-1edb016f1ba0,ResourceVersion:5203,Generation:1,CreationTimestamp:2019-09-04 15:15:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment dc57b17b-81f0-45ff-9088-b96bf80cfdf7 0xc002c3a167 0xc002c3a168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 15:15:42.787: INFO: Pod "test-cleanup-controller-fxl5s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-fxl5s,GenerateName:test-cleanup-controller-,Namespace:deployment-7532,SelfLink:/api/v1/namespaces/deployment-7532/pods/test-cleanup-controller-fxl5s,UID:7d48ea0f-ada8-4e81-90e2-b8952e4c6439,ResourceVersion:5197,Generation:0,CreationTimestamp:2019-09-04 15:15:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 52eec9d8-4b34-4cff-b1c1-1edb016f1ba0 0xc002876297 0xc002876298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nf2hk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nf2hk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nf2hk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002876310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002876330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:15:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:15:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:15:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:15:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.164,StartTime:2019-09-04 15:15:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:15:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://0cee75030caa47eb5ed378dc58924791160b965eaa87c07e1a00b988c64d426e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:15:42.787: INFO: Pod "test-cleanup-deployment-55bbcbc84c-xtp6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-xtp6x,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-7532,SelfLink:/api/v1/namespaces/deployment-7532/pods/test-cleanup-deployment-55bbcbc84c-xtp6x,UID:78d599a9-6582-4294-b170-f7f728957de4,ResourceVersion:5210,Generation:0,CreationTimestamp:2019-09-04 15:15:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 76366cf5-5a3b-44ae-88e5-626d8a90119d 0xc0028763df 0xc002876410}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nf2hk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nf2hk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nf2hk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002876480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028764a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:15:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:15:42.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7532" for this suite.
Sep  4 15:15:48.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:15:48.843: INFO: namespace deployment-7532 deletion completed in 6.048315407s

• [SLOW TEST:11.361 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:15:48.843: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8841/configmap-test-ce24e40d-901d-4373-9b8f-0bd9816cb4d5
STEP: Creating a pod to test consume configMaps
Sep  4 15:15:48.904: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9" in namespace "configmap-8841" to be "success or failure"
Sep  4 15:15:48.918: INFO: Pod "pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.332832ms
Sep  4 15:15:50.933: INFO: Pod "pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029477884s
STEP: Saw pod success
Sep  4 15:15:50.933: INFO: Pod "pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9" satisfied condition "success or failure"
Sep  4 15:15:50.943: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9 container env-test: <nil>
STEP: delete the pod
Sep  4 15:15:50.955: INFO: Waiting for pod pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9 to disappear
Sep  4 15:15:50.960: INFO: Pod pod-configmaps-2b45dc3d-4411-474f-a8eb-8e69adccd5b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:15:50.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8841" for this suite.
Sep  4 15:15:56.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:15:57.009: INFO: namespace configmap-8841 deletion completed in 6.04690305s

• [SLOW TEST:8.166 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:15:57.010: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0904 15:16:03.087351      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 15:16:03.087: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:16:03.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2763" for this suite.
Sep  4 15:16:09.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:16:09.142: INFO: namespace gc-2763 deletion completed in 6.052920594s

• [SLOW TEST:12.132 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:16:09.142: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep  4 15:16:09.216: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep  4 15:16:10.053: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep  4 15:16:12.282: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:16:14.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:16:16.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703206970, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:16:19.103: INFO: Waited 815.124009ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:16:19.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8501" for this suite.
Sep  4 15:16:25.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:16:25.691: INFO: namespace aggregator-8501 deletion completed in 6.1482072s

• [SLOW TEST:16.549 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:16:25.692: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:16:27.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-441" for this suite.
Sep  4 15:17:17.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:17:17.984: INFO: namespace kubelet-test-441 deletion completed in 50.063659442s

• [SLOW TEST:52.292 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:17:17.984: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  4 15:17:20.580: INFO: Successfully updated pod "pod-update-fb399d38-fd06-4853-ab0b-43e62747e930"
STEP: verifying the updated pod is in kubernetes
Sep  4 15:17:20.594: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:17:20.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9597" for this suite.
Sep  4 15:17:42.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:17:42.645: INFO: namespace pods-9597 deletion completed in 22.048039626s

• [SLOW TEST:24.661 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:17:42.645: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep  4 15:18:13.231: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0904 15:18:13.231706      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:13.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5170" for this suite.
Sep  4 15:18:19.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:19.355: INFO: namespace gc-5170 deletion completed in 6.122009851s

• [SLOW TEST:36.710 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 15:18:19.522: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 15:18:19.531: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 15:18:19.533: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.165 before test
Sep  4 15:18:19.538: INFO: kubernetes-dashboard-5cd5576947-pplbs from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  4 15:18:19.538: INFO: ckecsi-provisioner-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 15:18:19.538: INFO: nginx-ingress-controller-slhvq from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  4 15:18:19.538: INFO: ckecsi-8lpfb from default started at 2019-09-04 14:44:58 +0000 UTC (2 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 15:18:19.538: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 15:18:19.538: INFO: sonobuoy-e2e-job-57060aab3bac4fe0 from heptio-sonobuoy started at 2019-09-04 15:05:14 +0000 UTC (2 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container e2e ready: true, restart count 0
Sep  4 15:18:19.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 15:18:19.538: INFO: ckecsi-attacher-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep  4 15:18:19.538: INFO: calico-kube-controllers-568647f5b9-n6xm7 from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 15:18:19.538: INFO: coredns-55d8c6f4f-h7pxd from kube-system started at 2019-09-04 14:44:59 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container coredns ready: true, restart count 0
Sep  4 15:18:19.538: INFO: default-http-backend-7f744bb697-nkz9c from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.538: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  4 15:18:19.538: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.166 before test
Sep  4 15:18:19.542: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 15:05:11 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.542: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  4 15:18:19.542: INFO: ckecsi-ks4dd from default started at 2019-09-04 14:45:05 +0000 UTC (2 container statuses recorded)
Sep  4 15:18:19.542: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 15:18:19.542: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 15:18:19.543: INFO: ckecsi-provisioner-1 from default started at 2019-09-04 14:46:43 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.543: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 15:18:19.543: INFO: ckecsi-attacher-1 from default started at 2019-09-04 14:46:48 +0000 UTC (1 container statuses recorded)
Sep  4 15:18:19.543: INFO: 	Container ckecsi-attacher ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c145430b180756], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:20.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-932" for this suite.
Sep  4 15:18:26.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:26.613: INFO: namespace sched-pred-932 deletion completed in 6.056817451s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.258 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:26.614: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  4 15:18:26.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2556,SelfLink:/api/v1/namespaces/watch-2556/configmaps/e2e-watch-test-watch-closed,UID:c878fc33-14dd-44a1-aa59-08c3a7e169df,ResourceVersion:6075,Generation:0,CreationTimestamp:2019-09-04 15:18:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 15:18:26.720: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2556,SelfLink:/api/v1/namespaces/watch-2556/configmaps/e2e-watch-test-watch-closed,UID:c878fc33-14dd-44a1-aa59-08c3a7e169df,ResourceVersion:6076,Generation:0,CreationTimestamp:2019-09-04 15:18:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  4 15:18:26.736: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2556,SelfLink:/api/v1/namespaces/watch-2556/configmaps/e2e-watch-test-watch-closed,UID:c878fc33-14dd-44a1-aa59-08c3a7e169df,ResourceVersion:6077,Generation:0,CreationTimestamp:2019-09-04 15:18:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 15:18:26.736: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2556,SelfLink:/api/v1/namespaces/watch-2556/configmaps/e2e-watch-test-watch-closed,UID:c878fc33-14dd-44a1-aa59-08c3a7e169df,ResourceVersion:6078,Generation:0,CreationTimestamp:2019-09-04 15:18:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:26.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2556" for this suite.
Sep  4 15:18:32.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:32.801: INFO: namespace watch-2556 deletion completed in 6.059999116s

• [SLOW TEST:6.187 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:32.801: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep  4 15:18:32.885: INFO: Waiting up to 5m0s for pod "client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579" in namespace "containers-5877" to be "success or failure"
Sep  4 15:18:32.915: INFO: Pod "client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579": Phase="Pending", Reason="", readiness=false. Elapsed: 30.644892ms
Sep  4 15:18:34.917: INFO: Pod "client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032759627s
STEP: Saw pod success
Sep  4 15:18:34.917: INFO: Pod "client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579" satisfied condition "success or failure"
Sep  4 15:18:34.919: INFO: Trying to get logs from node 192.168.0.166 pod client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579 container test-container: <nil>
STEP: delete the pod
Sep  4 15:18:34.986: INFO: Waiting for pod client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579 to disappear
Sep  4 15:18:34.992: INFO: Pod client-containers-60bcdef9-012f-46da-b0a2-989eb7c89579 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:34.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5877" for this suite.
Sep  4 15:18:41.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:41.038: INFO: namespace containers-5877 deletion completed in 6.044057606s

• [SLOW TEST:8.237 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:41.038: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:18:41.091: INFO: Waiting up to 5m0s for pod "downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019" in namespace "projected-7374" to be "success or failure"
Sep  4 15:18:41.105: INFO: Pod "downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019": Phase="Pending", Reason="", readiness=false. Elapsed: 13.971475ms
Sep  4 15:18:43.107: INFO: Pod "downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016208875s
STEP: Saw pod success
Sep  4 15:18:43.107: INFO: Pod "downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019" satisfied condition "success or failure"
Sep  4 15:18:43.108: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019 container client-container: <nil>
STEP: delete the pod
Sep  4 15:18:43.157: INFO: Waiting for pod downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019 to disappear
Sep  4 15:18:43.164: INFO: Pod downwardapi-volume-579058f0-add5-49d4-b66c-30a5a23b8019 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:43.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7374" for this suite.
Sep  4 15:18:49.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:49.218: INFO: namespace projected-7374 deletion completed in 6.052719288s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:49.219: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep  4 15:18:51.794: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8110 pod-service-account-b78d0d15-e3e0-4e88-9f58-827ae0356c2e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep  4 15:18:51.987: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8110 pod-service-account-b78d0d15-e3e0-4e88-9f58-827ae0356c2e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep  4 15:18:52.155: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8110 pod-service-account-b78d0d15-e3e0-4e88-9f58-827ae0356c2e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:18:52.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8110" for this suite.
Sep  4 15:18:58.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:18:58.405: INFO: namespace svcaccounts-8110 deletion completed in 6.103180634s

• [SLOW TEST:9.187 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:18:58.406: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f
Sep  4 15:18:58.484: INFO: Pod name my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f: Found 0 pods out of 1
Sep  4 15:19:03.486: INFO: Pod name my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f: Found 1 pods out of 1
Sep  4 15:19:03.486: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f" are running
Sep  4 15:19:03.488: INFO: Pod "my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f-tf7j8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 15:18:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 15:18:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 15:18:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 15:18:58 +0000 UTC Reason: Message:}])
Sep  4 15:19:03.488: INFO: Trying to dial the pod
Sep  4 15:19:08.493: INFO: Controller my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f: Got expected result from replica 1 [my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f-tf7j8]: "my-hostname-basic-7572d990-c3a4-40d4-9d29-25967a34255f-tf7j8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:19:08.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6078" for this suite.
Sep  4 15:19:14.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:14.542: INFO: namespace replication-controller-6078 deletion completed in 6.047142938s

• [SLOW TEST:16.137 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:19:14.543: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:19:20.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8123" for this suite.
Sep  4 15:19:26.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:26.853: INFO: namespace namespaces-8123 deletion completed in 6.062150665s
STEP: Destroying namespace "nsdeletetest-7163" for this suite.
Sep  4 15:19:26.854: INFO: Namespace nsdeletetest-7163 was already deleted
STEP: Destroying namespace "nsdeletetest-470" for this suite.
Sep  4 15:19:32.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:32.904: INFO: namespace nsdeletetest-470 deletion completed in 6.049771803s

• [SLOW TEST:18.361 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:19:32.904: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:19:32.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9" in namespace "downward-api-5408" to be "success or failure"
Sep  4 15:19:32.970: INFO: Pod "downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.537733ms
Sep  4 15:19:34.973: INFO: Pod "downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006707149s
STEP: Saw pod success
Sep  4 15:19:34.973: INFO: Pod "downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9" satisfied condition "success or failure"
Sep  4 15:19:34.974: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9 container client-container: <nil>
STEP: delete the pod
Sep  4 15:19:35.018: INFO: Waiting for pod downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9 to disappear
Sep  4 15:19:35.028: INFO: Pod downwardapi-volume-3fc41b6c-ea8f-4959-8672-7f64898867f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:19:35.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5408" for this suite.
Sep  4 15:19:41.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:41.075: INFO: namespace downward-api-5408 deletion completed in 6.04573678s

• [SLOW TEST:8.172 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:19:41.076: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep  4 15:19:41.131: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-227760248 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:19:41.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7255" for this suite.
Sep  4 15:19:47.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:47.269: INFO: namespace kubectl-7255 deletion completed in 6.064323767s

• [SLOW TEST:6.194 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:19:47.269: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  4 15:19:47.326: INFO: Waiting up to 5m0s for pod "pod-d6ed7b41-f11d-4063-a088-0f96aab0986c" in namespace "emptydir-6419" to be "success or failure"
Sep  4 15:19:47.362: INFO: Pod "pod-d6ed7b41-f11d-4063-a088-0f96aab0986c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.953453ms
Sep  4 15:19:49.374: INFO: Pod "pod-d6ed7b41-f11d-4063-a088-0f96aab0986c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047498681s
STEP: Saw pod success
Sep  4 15:19:49.374: INFO: Pod "pod-d6ed7b41-f11d-4063-a088-0f96aab0986c" satisfied condition "success or failure"
Sep  4 15:19:49.376: INFO: Trying to get logs from node 192.168.0.166 pod pod-d6ed7b41-f11d-4063-a088-0f96aab0986c container test-container: <nil>
STEP: delete the pod
Sep  4 15:19:49.421: INFO: Waiting for pod pod-d6ed7b41-f11d-4063-a088-0f96aab0986c to disappear
Sep  4 15:19:49.438: INFO: Pod pod-d6ed7b41-f11d-4063-a088-0f96aab0986c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:19:49.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6419" for this suite.
Sep  4 15:19:55.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:19:55.512: INFO: namespace emptydir-6419 deletion completed in 6.071704967s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:19:55.512: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:19:55.574: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  4 15:19:55.582: INFO: Number of nodes with available pods: 0
Sep  4 15:19:55.582: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  4 15:19:55.644: INFO: Number of nodes with available pods: 0
Sep  4 15:19:55.644: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:19:56.646: INFO: Number of nodes with available pods: 0
Sep  4 15:19:56.646: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:19:57.646: INFO: Number of nodes with available pods: 0
Sep  4 15:19:57.646: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:19:58.646: INFO: Number of nodes with available pods: 1
Sep  4 15:19:58.646: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  4 15:19:58.671: INFO: Number of nodes with available pods: 1
Sep  4 15:19:58.671: INFO: Number of running nodes: 0, number of available pods: 1
Sep  4 15:19:59.673: INFO: Number of nodes with available pods: 0
Sep  4 15:19:59.673: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  4 15:19:59.710: INFO: Number of nodes with available pods: 0
Sep  4 15:19:59.711: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:20:00.713: INFO: Number of nodes with available pods: 0
Sep  4 15:20:00.713: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:20:01.713: INFO: Number of nodes with available pods: 0
Sep  4 15:20:01.713: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:20:02.726: INFO: Number of nodes with available pods: 0
Sep  4 15:20:02.726: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:20:03.713: INFO: Number of nodes with available pods: 0
Sep  4 15:20:03.713: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:20:04.713: INFO: Number of nodes with available pods: 1
Sep  4 15:20:04.713: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1114, will wait for the garbage collector to delete the pods
Sep  4 15:20:04.769: INFO: Deleting DaemonSet.extensions daemon-set took: 2.635357ms
Sep  4 15:20:05.069: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.127847ms
Sep  4 15:20:08.171: INFO: Number of nodes with available pods: 0
Sep  4 15:20:08.171: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 15:20:08.173: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1114/daemonsets","resourceVersion":"6570"},"items":null}

Sep  4 15:20:08.174: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1114/pods","resourceVersion":"6570"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:08.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1114" for this suite.
Sep  4 15:20:14.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:14.287: INFO: namespace daemonsets-1114 deletion completed in 6.064797786s

• [SLOW TEST:18.775 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:14.287: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-ad0416dd-462a-44b8-8c86-16c4a5ec30b6
STEP: Creating a pod to test consume configMaps
Sep  4 15:20:14.344: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441" in namespace "projected-4533" to be "success or failure"
Sep  4 15:20:14.385: INFO: Pod "pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441": Phase="Pending", Reason="", readiness=false. Elapsed: 40.803554ms
Sep  4 15:20:16.387: INFO: Pod "pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042924901s
STEP: Saw pod success
Sep  4 15:20:16.387: INFO: Pod "pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441" satisfied condition "success or failure"
Sep  4 15:20:16.388: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:20:16.431: INFO: Waiting for pod pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441 to disappear
Sep  4 15:20:16.440: INFO: Pod pod-projected-configmaps-7ff85dcc-3ffb-4552-a01c-d9d836752441 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:16.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4533" for this suite.
Sep  4 15:20:22.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:22.512: INFO: namespace projected-4533 deletion completed in 6.070012805s

• [SLOW TEST:8.225 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:22.512: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-70b63ba3-3171-4451-a96b-2e7206b55b96
STEP: Creating a pod to test consume secrets
Sep  4 15:20:22.584: INFO: Waiting up to 5m0s for pod "pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594" in namespace "secrets-6474" to be "success or failure"
Sep  4 15:20:22.589: INFO: Pod "pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594": Phase="Pending", Reason="", readiness=false. Elapsed: 4.655345ms
Sep  4 15:20:24.591: INFO: Pod "pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006481151s
STEP: Saw pod success
Sep  4 15:20:24.591: INFO: Pod "pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594" satisfied condition "success or failure"
Sep  4 15:20:24.592: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:20:24.607: INFO: Waiting for pod pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594 to disappear
Sep  4 15:20:24.612: INFO: Pod pod-secrets-2e1d4d28-1cab-4e89-a334-fb9e452da594 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:24.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6474" for this suite.
Sep  4 15:20:30.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:30.661: INFO: namespace secrets-6474 deletion completed in 6.047801774s

• [SLOW TEST:8.149 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:30.662: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  4 15:20:30.779: INFO: Waiting up to 5m0s for pod "pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18" in namespace "emptydir-4184" to be "success or failure"
Sep  4 15:20:30.783: INFO: Pod "pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18": Phase="Pending", Reason="", readiness=false. Elapsed: 4.684659ms
Sep  4 15:20:32.786: INFO: Pod "pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006848489s
STEP: Saw pod success
Sep  4 15:20:32.786: INFO: Pod "pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18" satisfied condition "success or failure"
Sep  4 15:20:32.787: INFO: Trying to get logs from node 192.168.0.166 pod pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18 container test-container: <nil>
STEP: delete the pod
Sep  4 15:20:32.818: INFO: Waiting for pod pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18 to disappear
Sep  4 15:20:32.836: INFO: Pod pod-5bf54677-2a89-4c14-bbdf-8ddc077cea18 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:32.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4184" for this suite.
Sep  4 15:20:38.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:38.887: INFO: namespace emptydir-4184 deletion completed in 6.048396965s

• [SLOW TEST:8.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:38.887: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:41.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9029" for this suite.
Sep  4 15:20:47.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:47.104: INFO: namespace emptydir-wrapper-9029 deletion completed in 6.045227506s

• [SLOW TEST:8.217 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:47.104: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep  4 15:20:47.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 cluster-info'
Sep  4 15:20:47.241: INFO: stderr: ""
Sep  4 15:20:47.241: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:47.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-792" for this suite.
Sep  4 15:20:53.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:20:53.294: INFO: namespace kubectl-792 deletion completed in 6.050709317s

• [SLOW TEST:6.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:20:53.294: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:20:53.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5" in namespace "projected-6234" to be "success or failure"
Sep  4 15:20:53.355: INFO: Pod "downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.147686ms
Sep  4 15:20:55.357: INFO: Pod "downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006287396s
STEP: Saw pod success
Sep  4 15:20:55.357: INFO: Pod "downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5" satisfied condition "success or failure"
Sep  4 15:20:55.359: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5 container client-container: <nil>
STEP: delete the pod
Sep  4 15:20:55.403: INFO: Waiting for pod downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5 to disappear
Sep  4 15:20:55.412: INFO: Pod downwardapi-volume-982e9299-2be7-43d0-a455-21b924d70cf5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:20:55.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6234" for this suite.
Sep  4 15:21:01.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:01.459: INFO: namespace projected-6234 deletion completed in 6.044888055s

• [SLOW TEST:8.165 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:01.459: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-6086452b-6667-4df7-8935-a2d2207246ff
STEP: Creating a pod to test consume configMaps
Sep  4 15:21:01.540: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d" in namespace "projected-8657" to be "success or failure"
Sep  4 15:21:01.559: INFO: Pod "pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.53839ms
Sep  4 15:21:03.561: INFO: Pod "pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020678785s
STEP: Saw pod success
Sep  4 15:21:03.561: INFO: Pod "pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d" satisfied condition "success or failure"
Sep  4 15:21:03.563: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:21:03.587: INFO: Waiting for pod pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d to disappear
Sep  4 15:21:03.619: INFO: Pod pod-projected-configmaps-a3c81ee3-06d6-4379-8c0c-d6d81a0db15d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:21:03.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8657" for this suite.
Sep  4 15:21:09.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:09.700: INFO: namespace projected-8657 deletion completed in 6.078930944s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:09.700: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:21:09.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9" in namespace "downward-api-8980" to be "success or failure"
Sep  4 15:21:09.813: INFO: Pod "downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.120868ms
Sep  4 15:21:11.815: INFO: Pod "downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008959542s
STEP: Saw pod success
Sep  4 15:21:11.815: INFO: Pod "downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9" satisfied condition "success or failure"
Sep  4 15:21:11.816: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9 container client-container: <nil>
STEP: delete the pod
Sep  4 15:21:11.883: INFO: Waiting for pod downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9 to disappear
Sep  4 15:21:11.887: INFO: Pod downwardapi-volume-3b9e6af7-03e0-4f41-8d00-6de0edbe0bb9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:21:11.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8980" for this suite.
Sep  4 15:21:17.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:17.951: INFO: namespace downward-api-8980 deletion completed in 6.061639988s

• [SLOW TEST:8.251 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:17.951: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 15:21:18.036: INFO: Waiting up to 5m0s for pod "downward-api-e4068c50-a969-4a76-b223-157672b266f1" in namespace "downward-api-229" to be "success or failure"
Sep  4 15:21:18.041: INFO: Pod "downward-api-e4068c50-a969-4a76-b223-157672b266f1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.586971ms
Sep  4 15:21:20.049: INFO: Pod "downward-api-e4068c50-a969-4a76-b223-157672b266f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013070528s
STEP: Saw pod success
Sep  4 15:21:20.049: INFO: Pod "downward-api-e4068c50-a969-4a76-b223-157672b266f1" satisfied condition "success or failure"
Sep  4 15:21:20.059: INFO: Trying to get logs from node 192.168.0.166 pod downward-api-e4068c50-a969-4a76-b223-157672b266f1 container dapi-container: <nil>
STEP: delete the pod
Sep  4 15:21:20.094: INFO: Waiting for pod downward-api-e4068c50-a969-4a76-b223-157672b266f1 to disappear
Sep  4 15:21:20.111: INFO: Pod downward-api-e4068c50-a969-4a76-b223-157672b266f1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:21:20.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-229" for this suite.
Sep  4 15:21:26.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:26.169: INFO: namespace downward-api-229 deletion completed in 6.055516605s

• [SLOW TEST:8.218 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:26.170: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep  4 15:21:28.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec pod-sharedvolume-e7386ce4-3398-4e7a-9f6f-6db0910e7eb6 -c busybox-main-container --namespace=emptydir-4706 -- cat /usr/share/volumeshare/shareddata.txt'
Sep  4 15:21:28.407: INFO: stderr: ""
Sep  4 15:21:28.407: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:21:28.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4706" for this suite.
Sep  4 15:21:34.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:34.466: INFO: namespace emptydir-4706 deletion completed in 6.057222563s

• [SLOW TEST:8.297 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:34.466: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:21:37.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1867" for this suite.
Sep  4 15:21:59.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:21:59.643: INFO: namespace replication-controller-1867 deletion completed in 22.094108907s

• [SLOW TEST:25.177 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:21:59.643: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-165a0bf4-6f82-4fef-8ff9-e046ab7338c1 in namespace container-probe-2424
Sep  4 15:22:01.724: INFO: Started pod test-webserver-165a0bf4-6f82-4fef-8ff9-e046ab7338c1 in namespace container-probe-2424
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 15:22:01.725: INFO: Initial restart count of pod test-webserver-165a0bf4-6f82-4fef-8ff9-e046ab7338c1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:26:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2424" for this suite.
Sep  4 15:26:08.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:26:08.144: INFO: namespace container-probe-2424 deletion completed in 6.059902075s

• [SLOW TEST:248.501 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:26:08.144: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep  4 15:26:08.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-5338'
Sep  4 15:26:08.413: INFO: stderr: ""
Sep  4 15:26:08.413: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 15:26:09.416: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:26:09.416: INFO: Found 0 / 1
Sep  4 15:26:10.416: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:26:10.416: INFO: Found 1 / 1
Sep  4 15:26:10.416: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  4 15:26:10.417: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:26:10.417: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 15:26:10.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 patch pod redis-master-lk6sk --namespace=kubectl-5338 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  4 15:26:10.490: INFO: stderr: ""
Sep  4 15:26:10.490: INFO: stdout: "pod/redis-master-lk6sk patched\n"
STEP: checking annotations
Sep  4 15:26:10.495: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:26:10.495: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:26:10.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5338" for this suite.
Sep  4 15:26:32.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:26:32.558: INFO: namespace kubectl-5338 deletion completed in 22.061099121s

• [SLOW TEST:24.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:26:32.559: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-998
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep  4 15:26:32.656: INFO: Found 0 stateful pods, waiting for 3
Sep  4 15:26:42.659: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:26:42.659: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:26:42.659: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  4 15:26:42.677: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  4 15:26:52.708: INFO: Updating stateful set ss2
Sep  4 15:26:52.719: INFO: Waiting for Pod statefulset-998/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  4 15:27:02.723: INFO: Waiting for Pod statefulset-998/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep  4 15:27:12.917: INFO: Found 2 stateful pods, waiting for 3
Sep  4 15:27:22.920: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:27:22.920: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 15:27:22.920: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  4 15:27:22.937: INFO: Updating stateful set ss2
Sep  4 15:27:22.948: INFO: Waiting for Pod statefulset-998/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  4 15:27:32.966: INFO: Updating stateful set ss2
Sep  4 15:27:32.977: INFO: Waiting for StatefulSet statefulset-998/ss2 to complete update
Sep  4 15:27:32.977: INFO: Waiting for Pod statefulset-998/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  4 15:27:42.981: INFO: Waiting for StatefulSet statefulset-998/ss2 to complete update
Sep  4 15:27:42.981: INFO: Waiting for Pod statefulset-998/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 15:27:52.981: INFO: Deleting all statefulset in ns statefulset-998
Sep  4 15:27:52.982: INFO: Scaling statefulset ss2 to 0
Sep  4 15:28:22.990: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 15:28:22.992: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:28:23.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-998" for this suite.
Sep  4 15:28:29.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:28:29.065: INFO: namespace statefulset-998 deletion completed in 6.060985783s

• [SLOW TEST:116.506 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:28:29.066: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5267
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 15:28:29.145: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 15:28:49.223: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.166.141:8080/dial?request=hostName&protocol=udp&host=172.30.166.140&port=8081&tries=1'] Namespace:pod-network-test-5267 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:28:49.223: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:28:50.339: INFO: Waiting for endpoints: map[]
Sep  4 15:28:50.341: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.166.141:8080/dial?request=hostName&protocol=udp&host=172.30.135.156&port=8081&tries=1'] Namespace:pod-network-test-5267 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:28:50.341: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:28:50.425: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:28:50.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5267" for this suite.
Sep  4 15:29:12.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:29:12.530: INFO: namespace pod-network-test-5267 deletion completed in 22.102307912s

• [SLOW TEST:43.465 seconds]
[sig-network] Networking
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:29:12.530: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:29:12.598: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:29:14.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6129" for this suite.
Sep  4 15:29:52.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:29:52.696: INFO: namespace pods-6129 deletion completed in 38.057568727s

• [SLOW TEST:40.165 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:29:52.696: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:29:52.768: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0" in namespace "downward-api-1144" to be "success or failure"
Sep  4 15:29:52.773: INFO: Pod "downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.44363ms
Sep  4 15:29:54.775: INFO: Pod "downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006502666s
STEP: Saw pod success
Sep  4 15:29:54.775: INFO: Pod "downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0" satisfied condition "success or failure"
Sep  4 15:29:54.776: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0 container client-container: <nil>
STEP: delete the pod
Sep  4 15:29:54.819: INFO: Waiting for pod downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0 to disappear
Sep  4 15:29:54.824: INFO: Pod downwardapi-volume-efcb471e-f1a3-4e1c-8109-30f7da3760f0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:29:54.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1144" for this suite.
Sep  4 15:30:00.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:30:00.871: INFO: namespace downward-api-1144 deletion completed in 6.045008659s

• [SLOW TEST:8.175 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:30:00.872: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:30:00.922: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:30:03.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3639" for this suite.
Sep  4 15:30:41.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:30:41.088: INFO: namespace pods-3639 deletion completed in 38.049993894s

• [SLOW TEST:40.216 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:30:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:30:41.163: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e" in namespace "downward-api-4293" to be "success or failure"
Sep  4 15:30:41.178: INFO: Pod "downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.897965ms
Sep  4 15:30:43.181: INFO: Pod "downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017237425s
STEP: Saw pod success
Sep  4 15:30:43.181: INFO: Pod "downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e" satisfied condition "success or failure"
Sep  4 15:30:43.182: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e container client-container: <nil>
STEP: delete the pod
Sep  4 15:30:43.197: INFO: Waiting for pod downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e to disappear
Sep  4 15:30:43.202: INFO: Pod downwardapi-volume-d28f1628-f304-4a14-aca4-0d9bccf26a0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:30:43.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4293" for this suite.
Sep  4 15:30:49.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:30:49.248: INFO: namespace downward-api-4293 deletion completed in 6.044079574s

• [SLOW TEST:8.161 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:30:49.249: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 15:30:51.872: INFO: Successfully updated pod "labelsupdate1af6c272-c36a-4ad8-ba12-be59ddf0ea2e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:30:53.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8274" for this suite.
Sep  4 15:31:15.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:31:15.935: INFO: namespace projected-8274 deletion completed in 22.048041638s

• [SLOW TEST:26.686 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:31:15.935: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep  4 15:31:15.999: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-227760248 proxy --unix-socket=/tmp/kubectl-proxy-unix610909339/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:31:16.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7309" for this suite.
Sep  4 15:31:22.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:31:22.104: INFO: namespace kubectl-7309 deletion completed in 6.048686013s

• [SLOW TEST:6.169 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:31:22.104: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-6310b4cd-cae2-4a8a-ad2c-2c04af15600a
STEP: Creating a pod to test consume secrets
Sep  4 15:31:22.187: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78" in namespace "projected-7596" to be "success or failure"
Sep  4 15:31:22.262: INFO: Pod "pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78": Phase="Pending", Reason="", readiness=false. Elapsed: 75.118229ms
Sep  4 15:31:24.265: INFO: Pod "pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.077608921s
STEP: Saw pod success
Sep  4 15:31:24.265: INFO: Pod "pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78" satisfied condition "success or failure"
Sep  4 15:31:24.266: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:31:24.294: INFO: Waiting for pod pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78 to disappear
Sep  4 15:31:24.300: INFO: Pod pod-projected-secrets-d44aba57-8fbb-40e7-b654-2d7d9e75fe78 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:31:24.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7596" for this suite.
Sep  4 15:31:30.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:31:30.347: INFO: namespace projected-7596 deletion completed in 6.044741358s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:31:30.347: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep  4 15:31:31.064: INFO: created pod pod-service-account-defaultsa
Sep  4 15:31:31.064: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  4 15:31:31.072: INFO: created pod pod-service-account-mountsa
Sep  4 15:31:31.072: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  4 15:31:31.078: INFO: created pod pod-service-account-nomountsa
Sep  4 15:31:31.078: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  4 15:31:31.124: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  4 15:31:31.124: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  4 15:31:31.142: INFO: created pod pod-service-account-mountsa-mountspec
Sep  4 15:31:31.142: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  4 15:31:31.223: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  4 15:31:31.223: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  4 15:31:31.251: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  4 15:31:31.251: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  4 15:31:31.275: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  4 15:31:31.275: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  4 15:31:31.310: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  4 15:31:31.310: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:31:31.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8359" for this suite.
Sep  4 15:31:37.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:31:37.614: INFO: namespace svcaccounts-8359 deletion completed in 6.205557253s

• [SLOW TEST:7.267 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:31:37.614: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep  4 15:31:37.711: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  4 15:31:37.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:37.889: INFO: stderr: ""
Sep  4 15:31:37.889: INFO: stdout: "service/redis-slave created\n"
Sep  4 15:31:37.889: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  4 15:31:37.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:38.048: INFO: stderr: ""
Sep  4 15:31:38.048: INFO: stdout: "service/redis-master created\n"
Sep  4 15:31:38.049: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  4 15:31:38.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:38.227: INFO: stderr: ""
Sep  4 15:31:38.227: INFO: stdout: "service/frontend created\n"
Sep  4 15:31:38.227: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  4 15:31:38.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:38.366: INFO: stderr: ""
Sep  4 15:31:38.366: INFO: stdout: "deployment.apps/frontend created\n"
Sep  4 15:31:38.366: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  4 15:31:38.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:38.525: INFO: stderr: ""
Sep  4 15:31:38.525: INFO: stdout: "deployment.apps/redis-master created\n"
Sep  4 15:31:38.525: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  4 15:31:38.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-4633'
Sep  4 15:31:38.664: INFO: stderr: ""
Sep  4 15:31:38.664: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep  4 15:31:38.664: INFO: Waiting for all frontend pods to be Running.
Sep  4 15:32:14.063: INFO: Waiting for frontend to serve content.
Sep  4 15:32:14.533: INFO: Trying to add a new entry to the guestbook.
Sep  4 15:32:14.567: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  4 15:32:14.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:14.896: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:14.896: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 15:32:14.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:15.046: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:15.046: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 15:32:15.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:15.153: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:15.153: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 15:32:15.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:15.268: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:15.268: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 15:32:15.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:15.338: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:15.338: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 15:32:15.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-4633'
Sep  4 15:32:15.419: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:32:15.419: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:32:15.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4633" for this suite.
Sep  4 15:32:59.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:32:59.470: INFO: namespace kubectl-4633 deletion completed in 44.049173405s

• [SLOW TEST:81.856 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:32:59.470: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  4 15:33:05.582: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:05.636: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:07.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:07.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:09.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:09.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:11.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:11.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:13.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:13.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:15.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:15.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:17.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:17.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:19.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:19.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:21.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:21.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:23.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:23.638: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 15:33:25.636: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 15:33:25.664: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:33:25.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5028" for this suite.
Sep  4 15:33:47.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:33:47.715: INFO: namespace container-lifecycle-hook-5028 deletion completed in 22.048740788s

• [SLOW TEST:48.245 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:33:47.716: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-890c15c3-5ee6-4b13-b035-26db679da7f5
STEP: Creating secret with name secret-projected-all-test-volume-1c6ee4d8-0ca7-430f-a17c-b8643a722d48
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  4 15:33:47.825: INFO: Waiting up to 5m0s for pod "projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db" in namespace "projected-7414" to be "success or failure"
Sep  4 15:33:47.829: INFO: Pod "projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.938876ms
Sep  4 15:33:49.831: INFO: Pod "projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005924301s
STEP: Saw pod success
Sep  4 15:33:49.831: INFO: Pod "projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db" satisfied condition "success or failure"
Sep  4 15:33:49.832: INFO: Trying to get logs from node 192.168.0.166 pod projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  4 15:33:49.847: INFO: Waiting for pod projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db to disappear
Sep  4 15:33:49.867: INFO: Pod projected-volume-07a19fd4-91c3-485e-8fe2-3eb7eaaff5db no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:33:49.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7414" for this suite.
Sep  4 15:33:55.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:33:55.920: INFO: namespace projected-7414 deletion completed in 6.050985569s

• [SLOW TEST:8.204 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:33:55.920: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0904 15:33:57.019371      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 15:33:57.019: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:33:57.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8116" for this suite.
Sep  4 15:34:03.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:34:03.114: INFO: namespace gc-8116 deletion completed in 6.092850551s

• [SLOW TEST:7.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:34:03.114: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 15:34:05.686: INFO: Successfully updated pod "labelsupdate05786411-aacc-424a-8fb7-40bff0f00244"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:34:07.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2572" for this suite.
Sep  4 15:34:29.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:34:29.771: INFO: namespace downward-api-2572 deletion completed in 22.067201395s

• [SLOW TEST:26.657 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:34:29.772: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep  4 15:34:29.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-2211'
Sep  4 15:34:30.096: INFO: stderr: ""
Sep  4 15:34:30.096: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 15:34:30.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2211'
Sep  4 15:34:30.193: INFO: stderr: ""
Sep  4 15:34:30.193: INFO: stdout: "update-demo-nautilus-d4jbm update-demo-nautilus-zbb5q "
Sep  4 15:34:30.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-d4jbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2211'
Sep  4 15:34:30.260: INFO: stderr: ""
Sep  4 15:34:30.260: INFO: stdout: ""
Sep  4 15:34:30.260: INFO: update-demo-nautilus-d4jbm is created but not running
Sep  4 15:34:35.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2211'
Sep  4 15:34:35.337: INFO: stderr: ""
Sep  4 15:34:35.337: INFO: stdout: "update-demo-nautilus-d4jbm update-demo-nautilus-zbb5q "
Sep  4 15:34:35.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-d4jbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2211'
Sep  4 15:34:35.413: INFO: stderr: ""
Sep  4 15:34:35.413: INFO: stdout: "true"
Sep  4 15:34:35.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-d4jbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2211'
Sep  4 15:34:35.483: INFO: stderr: ""
Sep  4 15:34:35.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 15:34:35.483: INFO: validating pod update-demo-nautilus-d4jbm
Sep  4 15:34:35.485: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 15:34:35.485: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 15:34:35.485: INFO: update-demo-nautilus-d4jbm is verified up and running
Sep  4 15:34:35.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-zbb5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2211'
Sep  4 15:34:35.558: INFO: stderr: ""
Sep  4 15:34:35.558: INFO: stdout: "true"
Sep  4 15:34:35.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-zbb5q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2211'
Sep  4 15:34:35.636: INFO: stderr: ""
Sep  4 15:34:35.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 15:34:35.636: INFO: validating pod update-demo-nautilus-zbb5q
Sep  4 15:34:35.638: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 15:34:35.638: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 15:34:35.638: INFO: update-demo-nautilus-zbb5q is verified up and running
STEP: using delete to clean up resources
Sep  4 15:34:35.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-2211'
Sep  4 15:34:35.712: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:34:35.712: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 15:34:35.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2211'
Sep  4 15:34:35.785: INFO: stderr: "No resources found.\n"
Sep  4 15:34:35.785: INFO: stdout: ""
Sep  4 15:34:35.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=update-demo --namespace=kubectl-2211 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 15:34:35.857: INFO: stderr: ""
Sep  4 15:34:35.857: INFO: stdout: "update-demo-nautilus-d4jbm\nupdate-demo-nautilus-zbb5q\n"
Sep  4 15:34:36.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2211'
Sep  4 15:34:36.427: INFO: stderr: "No resources found.\n"
Sep  4 15:34:36.427: INFO: stdout: ""
Sep  4 15:34:36.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=update-demo --namespace=kubectl-2211 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 15:34:36.496: INFO: stderr: ""
Sep  4 15:34:36.496: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:34:36.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2211" for this suite.
Sep  4 15:34:58.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:34:58.551: INFO: namespace kubectl-2211 deletion completed in 22.052969138s

• [SLOW TEST:28.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:34:58.552: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 15:35:04.669: INFO: File wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local from pod  dns-756/dns-test-d1262deb-ef3c-47dc-ab55-398de4ce3053 contains '' instead of 'foo.example.com.'
Sep  4 15:35:04.671: INFO: Lookups using dns-756/dns-test-d1262deb-ef3c-47dc-ab55-398de4ce3053 failed for: [wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local]

Sep  4 15:35:09.675: INFO: DNS probes using dns-test-d1262deb-ef3c-47dc-ab55-398de4ce3053 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 15:35:13.761: INFO: File wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local from pod  dns-756/dns-test-40e6cc0c-c86f-451b-9610-d7c3a0311633 contains '' instead of 'bar.example.com.'
Sep  4 15:35:13.763: INFO: Lookups using dns-756/dns-test-40e6cc0c-c86f-451b-9610-d7c3a0311633 failed for: [wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local]

Sep  4 15:35:18.767: INFO: DNS probes using dns-test-40e6cc0c-c86f-451b-9610-d7c3a0311633 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-756.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-756.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 15:35:22.924: INFO: DNS probes using dns-test-f05fb1d6-3cdb-42f2-b713-62e2fec25275 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:35:23.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-756" for this suite.
Sep  4 15:35:29.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:35:29.077: INFO: namespace dns-756 deletion completed in 6.052199558s

• [SLOW TEST:30.526 seconds]
[sig-network] DNS
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:35:29.078: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 15:35:31.689: INFO: Successfully updated pod "annotationupdate0e643d20-6fa5-48e8-bd06-cd121609c41e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:35:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7879" for this suite.
Sep  4 15:35:55.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:35:55.771: INFO: namespace downward-api-7879 deletion completed in 22.050888514s

• [SLOW TEST:26.694 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:35:55.771: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 15:35:55.856: INFO: Waiting up to 5m0s for pod "pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65" in namespace "emptydir-9554" to be "success or failure"
Sep  4 15:35:55.874: INFO: Pod "pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65": Phase="Pending", Reason="", readiness=false. Elapsed: 18.690016ms
Sep  4 15:35:57.877: INFO: Pod "pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02105794s
STEP: Saw pod success
Sep  4 15:35:57.877: INFO: Pod "pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65" satisfied condition "success or failure"
Sep  4 15:35:57.878: INFO: Trying to get logs from node 192.168.0.166 pod pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65 container test-container: <nil>
STEP: delete the pod
Sep  4 15:35:57.907: INFO: Waiting for pod pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65 to disappear
Sep  4 15:35:57.911: INFO: Pod pod-38bc9df3-784b-4127-80c3-3bbbabfd8a65 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:35:57.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9554" for this suite.
Sep  4 15:36:03.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:36:03.980: INFO: namespace emptydir-9554 deletion completed in 6.066619913s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:36:03.980: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:36:04.059: INFO: Creating deployment "nginx-deployment"
Sep  4 15:36:04.061: INFO: Waiting for observed generation 1
Sep  4 15:36:06.077: INFO: Waiting for all required pods to come up
Sep  4 15:36:06.137: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  4 15:36:08.172: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  4 15:36:08.176: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  4 15:36:08.218: INFO: Updating deployment nginx-deployment
Sep  4 15:36:08.218: INFO: Waiting for observed generation 2
Sep  4 15:36:10.230: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  4 15:36:10.231: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  4 15:36:10.233: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  4 15:36:10.236: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  4 15:36:10.236: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  4 15:36:10.237: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  4 15:36:10.240: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  4 15:36:10.240: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  4 15:36:10.243: INFO: Updating deployment nginx-deployment
Sep  4 15:36:10.243: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  4 15:36:10.256: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  4 15:36:10.276: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep  4 15:36:10.468: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7841,SelfLink:/apis/apps/v1/namespaces/deployment-7841/deployments/nginx-deployment,UID:eb04a697-bad6-4c10-80d9-98b73372db1f,ResourceVersion:10167,Generation:3,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-09-04 15:36:08 +0000 UTC 2019-09-04 15:36:04 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-09-04 15:36:10 +0000 UTC 2019-09-04 15:36:10 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  4 15:36:10.578: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-7841,SelfLink:/apis/apps/v1/namespaces/deployment-7841/replicasets/nginx-deployment-55fb7cb77f,UID:a57a8d5e-be86-46b7-8236-65875b3b5af4,ResourceVersion:10204,Generation:3,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment eb04a697-bad6-4c10-80d9-98b73372db1f 0xc002a27b37 0xc002a27b38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:36:10.578: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  4 15:36:10.578: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-7841,SelfLink:/apis/apps/v1/namespaces/deployment-7841/replicasets/nginx-deployment-7b8c6f4498,UID:4e30e370-5c1f-43c0-812d-1a789049b4dc,ResourceVersion:10202,Generation:3,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment eb04a697-bad6-4c10-80d9-98b73372db1f 0xc002a27c07 0xc002a27c08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  4 15:36:10.651: INFO: Pod "nginx-deployment-55fb7cb77f-2c2vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2c2vw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-2c2vw,UID:126edf5e-ad95-49a5-98ff-6d76564a7d70,ResourceVersion:10180,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365e577 0xc00365e578}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365e5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365e610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.651: INFO: Pod "nginx-deployment-55fb7cb77f-447dt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-447dt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-447dt,UID:512fd64d-0800-44f2-8dbd-8b59cc0f2d13,ResourceVersion:10187,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365e690 0xc00365e691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365e710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365e730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.665: INFO: Pod "nginx-deployment-55fb7cb77f-7rmd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7rmd8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-7rmd8,UID:87bbadca-3239-4bb0-90db-ea4f0e183765,ResourceVersion:10173,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365e7b0 0xc00365e7b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365e830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365e850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-hh2bq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hh2bq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-hh2bq,UID:7bd7cafc-9ce4-4c3c-ac51-0fdb46576415,ResourceVersion:10193,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365e8d0 0xc00365e8d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365e950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365e970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-j8vs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-j8vs9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-j8vs9,UID:6b0778af-da69-4abd-9986-ac90c03e378c,ResourceVersion:10108,Generation:0,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365e9f0 0xc00365e9f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365ea70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365ea90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:36:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-njgp6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-njgp6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-njgp6,UID:3d12795d-71e6-4ef9-a5b2-61f87f81dea0,ResourceVersion:10189,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365eb60 0xc00365eb61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365ebe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365ec00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-p2pcm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-p2pcm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-p2pcm,UID:7d658b30-1709-4b0d-b0de-c08ed5c1f677,ResourceVersion:10206,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365ec80 0xc00365ec81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365ed00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365ed20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:,StartTime:2019-09-04 15:36:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-pzgnr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pzgnr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-pzgnr,UID:9ce17302-cd03-483c-8071-aaefebc85239,ResourceVersion:10199,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365edf0 0xc00365edf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365ee80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365eea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-q2679" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q2679,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-q2679,UID:c08a377f-1405-4e6a-886c-f6dbcfefcec8,ResourceVersion:10115,Generation:0,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365ef20 0xc00365ef21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365efa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365efc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:36:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-sgptk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sgptk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-sgptk,UID:5d37084a-84c7-434f-b69c-958adafece98,ResourceVersion:10097,Generation:0,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365f090 0xc00365f091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:,StartTime:2019-09-04 15:36:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.666: INFO: Pod "nginx-deployment-55fb7cb77f-t9p48" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t9p48,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-t9p48,UID:7e61763a-dfd1-4ce8-a9b0-0b4c847070a4,ResourceVersion:10114,Generation:0,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365f270 0xc00365f271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:,StartTime:2019-09-04 15:36:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-55fb7cb77f-tl2f6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tl2f6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-tl2f6,UID:360d387b-142e-4fea-91dc-21dcc4f145a8,ResourceVersion:10192,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365f3f0 0xc00365f3f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-55fb7cb77f-twrrk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-twrrk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-55fb7cb77f-twrrk,UID:7f27a9fe-c8ca-4065-b681-00472ea2da79,ResourceVersion:10092,Generation:0,CreationTimestamp:2019-09-04 15:36:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f a57a8d5e-be86-46b7-8236-65875b3b5af4 0xc00365f520 0xc00365f521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:36:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-2gqmd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2gqmd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-2gqmd,UID:b97c73bf-6dec-44a1-943c-9e57168f08b4,ResourceVersion:10211,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365f6a0 0xc00365f6a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:36:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-2kp8l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2kp8l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-2kp8l,UID:57832fc3-9a4c-4d46-85a3-2fa80650daeb,ResourceVersion:10194,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365f817 0xc00365f818}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-4swhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4swhc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-4swhc,UID:369c7e27-c206-4292-acaa-454feb1cb870,ResourceVersion:10197,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365f930 0xc00365f931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365f9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365f9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-5gv7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5gv7n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-5gv7n,UID:c6b7a1eb-7ea6-4285-8dd7-147e7b701be0,ResourceVersion:10196,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365fa40 0xc00365fa41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365fab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365fae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-68x6f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-68x6f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-68x6f,UID:d881b6da-2309-4f66-8e4e-009af4037eec,ResourceVersion:10184,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365fb60 0xc00365fb61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365fbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365fbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-78kq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-78kq9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-78kq9,UID:442b0f59-d03c-4e0b-94e9-fb08bae0894f,ResourceVersion:10165,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365fc70 0xc00365fc71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365fce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365fd00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.667: INFO: Pod "nginx-deployment-7b8c6f4498-86bcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-86bcs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-86bcs,UID:154d7517-7b3e-4358-b143-ff708b3b977a,ResourceVersion:10195,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365fd90 0xc00365fd91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365fe00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365fe20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-926jw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-926jw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-926jw,UID:73ef8b69-9b95-4a15-ae74-97a9d8301b30,ResourceVersion:10036,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc00365fea0 0xc00365fea1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365ff20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365ff40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.172,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://808b8206c4b15eeae58646fdde0f2ec7bf7dcf69b9eab1edefae559749255e52}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-b84jk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-b84jk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-b84jk,UID:8d888ca0-601f-4dc1-8450-de4e60dc1629,ResourceVersion:10049,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0017 0xc0024d0018}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d00b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:172.30.135.164,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://c331e2d2effb5b9a72e08859a53e9ed52b3ab1f1b58ba3214b5a41ab07446f26}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-bb6gt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bb6gt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-bb6gt,UID:655e7d23-beeb-41eb-b984-08502b4a0463,ResourceVersion:10033,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0187 0xc0024d0188}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.173,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://8be2e742149bff5f40f82c0fd160d525c69cbefa0afe19bf5225ad16cef828a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-cbg4k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cbg4k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-cbg4k,UID:2cd26bd7-a022-41a4-83bc-f7d1cf89ed7b,ResourceVersion:10029,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d02f7 0xc0024d02f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.167,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://def2819412b58c44eda2fdc2f9f3f53c6abb042a703afe0b8d526f9a8d03cc92}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-d5crg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d5crg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-d5crg,UID:03cfa0d8-527f-4bf7-ad81-7dc11656de93,ResourceVersion:10060,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0467 0xc0024d0468}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d04e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:172.30.135.165,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://d7d7161cec4b5c3c763a73346eb64e741b52a42d2ab0631e56d713c9a1b61562}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.688: INFO: Pod "nginx-deployment-7b8c6f4498-fvfpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fvfpn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-fvfpn,UID:4f737021-a373-4da3-99d1-395b871596d8,ResourceVersion:10182,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d05d7 0xc0024d05d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-j7n8l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j7n8l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-j7n8l,UID:3c642456-9b8b-436f-aaa0-966cb9548d6f,ResourceVersion:10025,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0700 0xc0024d0701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.174,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://2b9802c2ca1f7e68251e3e42e698b61cfb8c72d21eff28ddd88ccf0a10864d76}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-kzwq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kzwq9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-kzwq9,UID:bcb9423e-74f3-4da7-9a5d-2b0477721fce,ResourceVersion:10181,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0867 0xc0024d0868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d08f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-lzwkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lzwkr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-lzwkr,UID:f9f8708d-5fff-4243-a013-edca3d70878b,ResourceVersion:10183,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0990 0xc0024d0991}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-nlshc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nlshc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-nlshc,UID:b3409148-3286-4576-9e63-49ee849dd6ff,ResourceVersion:10190,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0aa0 0xc0024d0aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-tlp2s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tlp2s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-tlp2s,UID:a4026914-bf59-4b60-9583-b2e844eda930,ResourceVersion:10041,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0bb0 0xc0024d0bb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:172.30.135.163,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://4e0651e87c59e06f0ae0ae98ffdb06220e4b8123ec2cbac6bf9d44a23d551075}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-tnd6c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tnd6c,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-tnd6c,UID:b32f99da-b75e-4e3a-8a18-6ecf760b072d,ResourceVersion:10045,Generation:0,CreationTimestamp:2019-09-04 15:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0d17 0xc0024d0d18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.165,PodIP:172.30.135.162,StartTime:2019-09-04 15:36:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 15:36:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://49e8394652b4c786e6d53b16370c7a519258885c8b876a18f9ecf098f8649102}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 15:36:10.689: INFO: Pod "nginx-deployment-7b8c6f4498-xbld6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xbld6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7841,SelfLink:/api/v1/namespaces/deployment-7841/pods/nginx-deployment-7b8c6f4498-xbld6,UID:5ca9750c-b3c9-4292-99e1-ec00c1a79fc5,ResourceVersion:10200,Generation:0,CreationTimestamp:2019-09-04 15:36:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4e30e370-5c1f-43c0-812d-1a789049b4dc 0xc0024d0e87 0xc0024d0e88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4htxv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4htxv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4htxv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024d0f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024d0f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:36:10 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:36:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:36:10.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7841" for this suite.
Sep  4 15:36:18.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:36:19.048: INFO: namespace deployment-7841 deletion completed in 8.278446657s

• [SLOW TEST:15.067 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:36:19.048: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 15:36:19.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5606'
Sep  4 15:36:19.191: INFO: stderr: ""
Sep  4 15:36:19.191: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  4 15:36:24.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pod e2e-test-nginx-pod --namespace=kubectl-5606 -o json'
Sep  4 15:36:24.322: INFO: stderr: ""
Sep  4 15:36:24.322: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-04T15:36:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5606\",\n        \"resourceVersion\": \"10747\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5606/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3bbd9296-b907-4c55-83b8-1efd6acc82f8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hfq8c\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.0.166\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hfq8c\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hfq8c\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T15:36:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T15:36:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T15:36:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T15:36:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://eb2fe797100e06e351f5da5857778490ffec09294c7fa005e101ecbbe05ac83e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-04T15:36:20Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.166\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.166.191\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-04T15:36:19Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  4 15:36:24.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 replace -f - --namespace=kubectl-5606'
Sep  4 15:36:24.462: INFO: stderr: ""
Sep  4 15:36:24.462: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep  4 15:36:24.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete pods e2e-test-nginx-pod --namespace=kubectl-5606'
Sep  4 15:36:35.264: INFO: stderr: ""
Sep  4 15:36:35.264: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:36:35.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5606" for this suite.
Sep  4 15:36:41.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:36:41.327: INFO: namespace kubectl-5606 deletion completed in 6.060066509s

• [SLOW TEST:22.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:36:41.327: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 15:36:43.399: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:36:43.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5262" for this suite.
Sep  4 15:36:49.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:36:49.490: INFO: namespace container-runtime-5262 deletion completed in 6.050471862s

• [SLOW TEST:8.163 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:36:49.491: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 15:36:51.587: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:36:51.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8107" for this suite.
Sep  4 15:36:57.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:36:57.668: INFO: namespace container-runtime-8107 deletion completed in 6.045268092s

• [SLOW TEST:8.178 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:36:57.668: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:36:57.774: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  4 15:37:02.776: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 15:37:02.776: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  4 15:37:04.778: INFO: Creating deployment "test-rollover-deployment"
Sep  4 15:37:04.801: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  4 15:37:06.805: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  4 15:37:06.825: INFO: Ensure that both replica sets have 1 created replica
Sep  4 15:37:06.827: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  4 15:37:06.830: INFO: Updating deployment test-rollover-deployment
Sep  4 15:37:06.830: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  4 15:37:08.877: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  4 15:37:08.880: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  4 15:37:08.883: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 15:37:08.883: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208228, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:37:10.888: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 15:37:10.888: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208228, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:37:12.887: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 15:37:12.887: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208228, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:37:14.887: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 15:37:14.887: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208228, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:37:16.887: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 15:37:16.887: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208228, loc:(*time.Location)(0x80bb5c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208224, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 15:37:18.887: INFO: 
Sep  4 15:37:18.887: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep  4 15:37:18.891: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-6876,SelfLink:/apis/apps/v1/namespaces/deployment-6876/deployments/test-rollover-deployment,UID:c97c3138-2639-4c5e-bb1d-1576054de36c,ResourceVersion:11011,Generation:2,CreationTimestamp:2019-09-04 15:37:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-04 15:37:04 +0000 UTC 2019-09-04 15:37:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-04 15:37:18 +0000 UTC 2019-09-04 15:37:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  4 15:37:18.892: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-6876,SelfLink:/apis/apps/v1/namespaces/deployment-6876/replicasets/test-rollover-deployment-854595fc44,UID:0271214a-198a-4617-b398-04b6c8ed33a7,ResourceVersion:11000,Generation:2,CreationTimestamp:2019-09-04 15:37:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c97c3138-2639-4c5e-bb1d-1576054de36c 0xc0034cd497 0xc0034cd498}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 15:37:18.892: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  4 15:37:18.893: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-6876,SelfLink:/apis/apps/v1/namespaces/deployment-6876/replicasets/test-rollover-controller,UID:03cac217-aa5c-4427-afbd-01a3e624de6f,ResourceVersion:11009,Generation:2,CreationTimestamp:2019-09-04 15:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c97c3138-2639-4c5e-bb1d-1576054de36c 0xc0034cd3c7 0xc0034cd3c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:37:18.893: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-6876,SelfLink:/apis/apps/v1/namespaces/deployment-6876/replicasets/test-rollover-deployment-9b8b997cf,UID:33c4bfde-ed6d-4f91-a06b-c48f0c483cad,ResourceVersion:10968,Generation:2,CreationTimestamp:2019-09-04 15:37:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c97c3138-2639-4c5e-bb1d-1576054de36c 0xc0034cd560 0xc0034cd561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:37:18.894: INFO: Pod "test-rollover-deployment-854595fc44-wt95s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-wt95s,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-6876,SelfLink:/api/v1/namespaces/deployment-6876/pods/test-rollover-deployment-854595fc44-wt95s,UID:3e57f72d-36b3-42ac-9b5c-9c0590186832,ResourceVersion:10982,Generation:0,CreationTimestamp:2019-09-04 15:37:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 0271214a-198a-4617-b398-04b6c8ed33a7 0xc002f2e117 0xc002f2e118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ghszf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ghszf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ghszf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2e190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2e1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:37:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:37:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:37:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:37:06 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:172.30.166.133,StartTime:2019-09-04 15:37:06 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-04 15:37:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://56412c838e4b7f6b9dd9b72c8a25e42b681aba21f676f1abce5a509e353e536a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:37:18.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6876" for this suite.
Sep  4 15:37:24.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:37:24.945: INFO: namespace deployment-6876 deletion completed in 6.048725725s

• [SLOW TEST:27.277 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:37:24.945: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 15:37:25.006: INFO: PodSpec: initContainers in spec.initContainers
Sep  4 15:38:13.784: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-62f1b85c-6579-4c54-a6c5-86eca35de7ce", GenerateName:"", Namespace:"init-container-7074", SelfLink:"/api/v1/namespaces/init-container-7074/pods/pod-init-62f1b85c-6579-4c54-a6c5-86eca35de7ce", UID:"eea1c0ca-1335-4c4f-831f-da96753f9354", ResourceVersion:"11171", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703208245, loc:(*time.Location)(0x80bb5c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"6083367"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8vd57", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003140000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8vd57", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8vd57", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8vd57", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00168e088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.0.166", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e520c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00168e110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00168e130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00168e138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00168e13c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208245, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208245, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208245, loc:(*time.Location)(0x80bb5c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703208245, loc:(*time.Location)(0x80bb5c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.166", PodIP:"172.30.166.136", StartTime:(*v1.Time)(0xc00178c120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002438070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0024380e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://reg.mg.hcbss/devcke/busybox@sha256:cbcde3595079b1f7a6b046e96e7547fe786d5c2c8eba678bc260161bc01b8dbe", ContainerID:"docker://a061a0fb8277e79bbf82982dbb1ba50b575b3450afe5b4a360b4afa8a79a9274"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00178c160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00178c140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:38:13.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7074" for this suite.
Sep  4 15:38:35.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:38:35.880: INFO: namespace init-container-7074 deletion completed in 22.07862132s

• [SLOW TEST:70.935 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:38:35.880: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1c369330-e95b-486c-b49d-189f6587c4ee
STEP: Creating a pod to test consume secrets
Sep  4 15:38:35.938: INFO: Waiting up to 5m0s for pod "pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d" in namespace "secrets-6817" to be "success or failure"
Sep  4 15:38:35.956: INFO: Pod "pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.872412ms
Sep  4 15:38:37.958: INFO: Pod "pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020051111s
STEP: Saw pod success
Sep  4 15:38:37.958: INFO: Pod "pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d" satisfied condition "success or failure"
Sep  4 15:38:37.959: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:38:37.990: INFO: Waiting for pod pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d to disappear
Sep  4 15:38:37.994: INFO: Pod pod-secrets-c3da36fc-fac0-4504-9abd-c3fb171e367d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:38:37.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6817" for this suite.
Sep  4 15:38:44.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:38:44.042: INFO: namespace secrets-6817 deletion completed in 6.046256637s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:38:44.042: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 15:38:44.092: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:38:48.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6896" for this suite.
Sep  4 15:38:54.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:38:54.236: INFO: namespace init-container-6896 deletion completed in 6.06237136s

• [SLOW TEST:10.193 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:38:54.236: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:38:54.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-6569'
Sep  4 15:38:54.456: INFO: stderr: ""
Sep  4 15:38:54.456: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  4 15:38:54.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-6569'
Sep  4 15:38:54.616: INFO: stderr: ""
Sep  4 15:38:54.616: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 15:38:55.623: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:38:55.624: INFO: Found 0 / 1
Sep  4 15:38:56.618: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:38:56.618: INFO: Found 1 / 1
Sep  4 15:38:56.618: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 15:38:56.620: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:38:56.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 15:38:56.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 describe pod redis-master-qvd9k --namespace=kubectl-6569'
Sep  4 15:38:56.701: INFO: stderr: ""
Sep  4 15:38:56.701: INFO: stdout: "Name:           redis-master-qvd9k\nNamespace:      kubectl-6569\nPriority:       0\nNode:           192.168.0.166/192.168.0.166\nStart Time:     Wed, 04 Sep 2019 15:38:54 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             172.30.166.139\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://dcd92ae4c98261776b0202d5ff33735eb40e06ac5e77580d4f32c518afd87330\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 04 Sep 2019 15:38:55 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-c5sbj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-c5sbj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-c5sbj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned kubectl-6569/redis-master-qvd9k to 192.168.0.166\n  Normal  Pulled     1s    kubelet, 192.168.0.166  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 192.168.0.166  Created container redis-master\n  Normal  Started    1s    kubelet, 192.168.0.166  Started container redis-master\n"
Sep  4 15:38:56.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 describe rc redis-master --namespace=kubectl-6569'
Sep  4 15:38:56.787: INFO: stderr: ""
Sep  4 15:38:56.787: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6569\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-qvd9k\n"
Sep  4 15:38:56.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 describe service redis-master --namespace=kubectl-6569'
Sep  4 15:38:56.866: INFO: stderr: ""
Sep  4 15:38:56.866: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6569\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                11.254.142.179\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.166.139:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  4 15:38:56.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 describe node 192.168.0.165'
Sep  4 15:38:56.963: INFO: stderr: ""
Sep  4 15:38:56.963: INFO: stdout: "Name:               192.168.0.165\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    ingress_igr1=1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.0.165\n                    kubernetes.io/os=linux\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"ckecsi\":\"192.168.0.165\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 04 Sep 2019 14:44:48 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 04 Sep 2019 15:38:02 +0000   Wed, 04 Sep 2019 14:44:48 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 04 Sep 2019 15:38:02 +0000   Wed, 04 Sep 2019 14:44:48 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 04 Sep 2019 15:38:02 +0000   Wed, 04 Sep 2019 14:44:48 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 04 Sep 2019 15:38:02 +0000   Wed, 04 Sep 2019 14:44:58 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.0.165\n  Hostname:    192.168.0.165\nCapacity:\n cpu:                24\n ephemeral-storage:  865158628Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             131619316Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  865158628Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             11297149137\n pods:               110\nSystem Info:\n Machine ID:                 \n System UUID:                ee4b32b6-d6c8-11e6-9fbe-18ded76a6cca\n Boot ID:                    a42b4ffa-2c21-4ad2-86d0-e867b50a9a5e\n Kernel Version:             4.19.8-1.el7.elrepo.x86_64\n OS Image:                   Alpine Linux v3.7\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.12.1-ce\n Kubelet Version:            v1.15.0\n Kube-Proxy Version:         v1.15.0\nPodCIDR:                     172.30.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                        ------------  ----------  ---------------  -------------  ---\n  default                    ckecsi-8lpfb                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         53m\n  default                    ckecsi-attacher-0                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\n  default                    ckecsi-provisioner-0                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\n  heptio-sonobuoy            sonobuoy-e2e-job-57060aab3bac4fe0           0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  ingress-igr1               default-http-backend-7f744bb697-nkz9c       10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      54m\n  ingress-igr1               nginx-ingress-controller-slhvq              0 (0%)        0 (0%)      0 (0%)           0 (0%)         53m\n  kube-system                calico-kube-controllers-568647f5b9-n6xm7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\n  kube-system                coredns-55d8c6f4f-h7pxd                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     54m\n  kube-system                kubernetes-dashboard-5cd5576947-pplbs       0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                110m (2%)  10m (0%)\n  memory             90Mi (0%)  190Mi (1%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type    Reason                   Age                From                       Message\n  ----    ------                   ----               ----                       -------\n  Normal  Starting                 54m                kubelet, 192.168.0.165     Starting kubelet.\n  Normal  NodeHasSufficientMemory  54m (x2 over 54m)  kubelet, 192.168.0.165     Node 192.168.0.165 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    54m (x2 over 54m)  kubelet, 192.168.0.165     Node 192.168.0.165 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     54m (x2 over 54m)  kubelet, 192.168.0.165     Node 192.168.0.165 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  54m                kubelet, 192.168.0.165     Updated Node Allocatable limit across pods\n  Normal  Starting                 54m                kube-proxy, 192.168.0.165  Starting kube-proxy.\n  Normal  NodeReady                53m                kubelet, 192.168.0.165     Node 192.168.0.165 status is now: NodeReady\n"
Sep  4 15:38:56.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 describe namespace kubectl-6569'
Sep  4 15:38:57.040: INFO: stderr: ""
Sep  4 15:38:57.040: INFO: stdout: "Name:         kubectl-6569\nLabels:       e2e-framework=kubectl\n              e2e-run=2d63d4af-55df-4c9a-9542-39f8d7bdf3f7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:38:57.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6569" for this suite.
Sep  4 15:39:31.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:39:31.135: INFO: namespace kubectl-6569 deletion completed in 34.093494752s

• [SLOW TEST:36.900 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:39:31.136: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep  4 15:39:33.204: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-227760248 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep  4 15:39:48.270: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:39:48.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1963" for this suite.
Sep  4 15:39:54.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:39:54.323: INFO: namespace pods-1963 deletion completed in 6.049828729s

• [SLOW TEST:23.188 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:39:54.324: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  4 15:39:58.428: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 15:39:58.435: INFO: Pod pod-with-poststart-http-hook still exists
Sep  4 15:40:00.435: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 15:40:00.437: INFO: Pod pod-with-poststart-http-hook still exists
Sep  4 15:40:02.435: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 15:40:02.437: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:40:02.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-107" for this suite.
Sep  4 15:40:24.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:40:24.491: INFO: namespace container-lifecycle-hook-107 deletion completed in 22.051605941s

• [SLOW TEST:30.167 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:40:24.491: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep  4 15:40:24.551: INFO: namespace kubectl-7445
Sep  4 15:40:24.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-7445'
Sep  4 15:40:24.693: INFO: stderr: ""
Sep  4 15:40:24.694: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 15:40:25.695: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:40:25.695: INFO: Found 0 / 1
Sep  4 15:40:26.696: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:40:26.696: INFO: Found 1 / 1
Sep  4 15:40:26.696: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 15:40:26.697: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 15:40:26.697: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 15:40:26.697: INFO: wait on redis-master startup in kubectl-7445 
Sep  4 15:40:26.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 logs redis-master-7qvv9 redis-master --namespace=kubectl-7445'
Sep  4 15:40:26.774: INFO: stderr: ""
Sep  4 15:40:26.774: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 15:40:25.670 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 15:40:25.670 # Server started, Redis version 3.2.12\n1:M 04 Sep 15:40:25.670 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  4 15:40:26.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7445'
Sep  4 15:40:26.883: INFO: stderr: ""
Sep  4 15:40:26.883: INFO: stdout: "service/rm2 exposed\n"
Sep  4 15:40:26.893: INFO: Service rm2 in namespace kubectl-7445 found.
STEP: exposing service
Sep  4 15:40:28.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7445'
Sep  4 15:40:29.008: INFO: stderr: ""
Sep  4 15:40:29.008: INFO: stdout: "service/rm3 exposed\n"
Sep  4 15:40:29.013: INFO: Service rm3 in namespace kubectl-7445 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:40:31.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7445" for this suite.
Sep  4 15:40:53.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:40:53.069: INFO: namespace kubectl-7445 deletion completed in 22.051817718s

• [SLOW TEST:28.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:40:53.070: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:40:53.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1243" for this suite.
Sep  4 15:40:59.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:40:59.278: INFO: namespace kubelet-test-1243 deletion completed in 6.049902499s

• [SLOW TEST:6.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:40:59.278: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:40:59.334: INFO: Waiting up to 5m0s for pod "downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d" in namespace "projected-5013" to be "success or failure"
Sep  4 15:40:59.345: INFO: Pod "downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.092977ms
Sep  4 15:41:01.347: INFO: Pod "downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01243772s
STEP: Saw pod success
Sep  4 15:41:01.347: INFO: Pod "downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d" satisfied condition "success or failure"
Sep  4 15:41:01.348: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d container client-container: <nil>
STEP: delete the pod
Sep  4 15:41:01.392: INFO: Waiting for pod downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d to disappear
Sep  4 15:41:01.402: INFO: Pod downwardapi-volume-368b5aa2-f02f-45d7-a005-70de6fae416d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:01.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5013" for this suite.
Sep  4 15:41:07.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:07.454: INFO: namespace projected-5013 deletion completed in 6.049070352s

• [SLOW TEST:8.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:07.454: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 15:41:07.517: INFO: Waiting up to 5m0s for pod "pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d" in namespace "emptydir-3146" to be "success or failure"
Sep  4 15:41:07.522: INFO: Pod "pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.505388ms
Sep  4 15:41:09.524: INFO: Pod "pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006771428s
STEP: Saw pod success
Sep  4 15:41:09.524: INFO: Pod "pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d" satisfied condition "success or failure"
Sep  4 15:41:09.526: INFO: Trying to get logs from node 192.168.0.166 pod pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d container test-container: <nil>
STEP: delete the pod
Sep  4 15:41:09.540: INFO: Waiting for pod pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d to disappear
Sep  4 15:41:09.567: INFO: Pod pod-c69af3df-dafc-449c-9f6f-32f55c1c2e8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:09.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3146" for this suite.
Sep  4 15:41:15.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:15.637: INFO: namespace emptydir-3146 deletion completed in 6.068218905s

• [SLOW TEST:8.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:15.637: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 15:41:15.716: INFO: Waiting up to 5m0s for pod "pod-b07e870f-ea64-4b68-905a-785c9a3e6962" in namespace "emptydir-8982" to be "success or failure"
Sep  4 15:41:15.722: INFO: Pod "pod-b07e870f-ea64-4b68-905a-785c9a3e6962": Phase="Pending", Reason="", readiness=false. Elapsed: 5.986533ms
Sep  4 15:41:17.724: INFO: Pod "pod-b07e870f-ea64-4b68-905a-785c9a3e6962": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007686318s
STEP: Saw pod success
Sep  4 15:41:17.724: INFO: Pod "pod-b07e870f-ea64-4b68-905a-785c9a3e6962" satisfied condition "success or failure"
Sep  4 15:41:17.725: INFO: Trying to get logs from node 192.168.0.166 pod pod-b07e870f-ea64-4b68-905a-785c9a3e6962 container test-container: <nil>
STEP: delete the pod
Sep  4 15:41:17.740: INFO: Waiting for pod pod-b07e870f-ea64-4b68-905a-785c9a3e6962 to disappear
Sep  4 15:41:17.745: INFO: Pod pod-b07e870f-ea64-4b68-905a-785c9a3e6962 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:17.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8982" for this suite.
Sep  4 15:41:23.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:23.793: INFO: namespace emptydir-8982 deletion completed in 6.04558146s

• [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:23.793: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-e80a865a-8670-40d0-9379-8e0de48c42d8
STEP: Creating a pod to test consume configMaps
Sep  4 15:41:23.861: INFO: Waiting up to 5m0s for pod "pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061" in namespace "configmap-3375" to be "success or failure"
Sep  4 15:41:23.865: INFO: Pod "pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061": Phase="Pending", Reason="", readiness=false. Elapsed: 4.695975ms
Sep  4 15:41:25.867: INFO: Pod "pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006665389s
STEP: Saw pod success
Sep  4 15:41:25.867: INFO: Pod "pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061" satisfied condition "success or failure"
Sep  4 15:41:25.869: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:41:25.883: INFO: Waiting for pod pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061 to disappear
Sep  4 15:41:25.900: INFO: Pod pod-configmaps-b05b9b7f-adba-4970-a5df-c0e490ab6061 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:25.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3375" for this suite.
Sep  4 15:41:31.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:31.951: INFO: namespace configmap-3375 deletion completed in 6.049851161s

• [SLOW TEST:8.159 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:31.952: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1874488c-eab2-4c1d-8146-2bb59973f4ba
STEP: Creating a pod to test consume secrets
Sep  4 15:41:32.009: INFO: Waiting up to 5m0s for pod "pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765" in namespace "secrets-3520" to be "success or failure"
Sep  4 15:41:32.014: INFO: Pod "pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765": Phase="Pending", Reason="", readiness=false. Elapsed: 4.564043ms
Sep  4 15:41:34.016: INFO: Pod "pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006695556s
STEP: Saw pod success
Sep  4 15:41:34.016: INFO: Pod "pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765" satisfied condition "success or failure"
Sep  4 15:41:34.018: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:41:34.043: INFO: Waiting for pod pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765 to disappear
Sep  4 15:41:34.048: INFO: Pod pod-secrets-ee494d15-cf36-4b0b-8b12-754284964765 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:34.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3520" for this suite.
Sep  4 15:41:40.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:40.094: INFO: namespace secrets-3520 deletion completed in 6.043889384s

• [SLOW TEST:8.142 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:40.094: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-410ca95b-10be-49d5-9c4a-160fe06f35dd
STEP: Creating a pod to test consume secrets
Sep  4 15:41:40.170: INFO: Waiting up to 5m0s for pod "pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555" in namespace "secrets-8751" to be "success or failure"
Sep  4 15:41:40.186: INFO: Pod "pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555": Phase="Pending", Reason="", readiness=false. Elapsed: 16.410016ms
Sep  4 15:41:42.188: INFO: Pod "pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018421525s
STEP: Saw pod success
Sep  4 15:41:42.188: INFO: Pod "pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555" satisfied condition "success or failure"
Sep  4 15:41:42.189: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:41:42.231: INFO: Waiting for pod pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555 to disappear
Sep  4 15:41:42.237: INFO: Pod pod-secrets-46b83de9-69e3-4640-b0fb-b135050bd555 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:42.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8751" for this suite.
Sep  4 15:41:48.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:48.286: INFO: namespace secrets-8751 deletion completed in 6.046864003s

• [SLOW TEST:8.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:48.287: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 15:41:50.362: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:50.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4046" for this suite.
Sep  4 15:41:56.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:41:56.445: INFO: namespace container-runtime-4046 deletion completed in 6.046143331s

• [SLOW TEST:8.159 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:41:56.446: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-751e3c74-e628-401c-a16c-e01ea33c4840
STEP: Creating a pod to test consume secrets
Sep  4 15:41:56.535: INFO: Waiting up to 5m0s for pod "pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08" in namespace "secrets-7771" to be "success or failure"
Sep  4 15:41:56.540: INFO: Pod "pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08": Phase="Pending", Reason="", readiness=false. Elapsed: 4.944767ms
Sep  4 15:41:58.542: INFO: Pod "pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006842665s
STEP: Saw pod success
Sep  4 15:41:58.542: INFO: Pod "pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08" satisfied condition "success or failure"
Sep  4 15:41:58.543: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:41:58.553: INFO: Waiting for pod pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08 to disappear
Sep  4 15:41:58.558: INFO: Pod pod-secrets-0f354bcd-7583-4b27-9be1-971f261f5a08 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:41:58.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7771" for this suite.
Sep  4 15:42:04.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:42:04.606: INFO: namespace secrets-7771 deletion completed in 6.046156137s

• [SLOW TEST:8.160 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:42:04.606: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-69756d66-dfbc-4e47-83cb-f7f265715d9a
STEP: Creating a pod to test consume configMaps
Sep  4 15:42:04.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d" in namespace "configmap-26" to be "success or failure"
Sep  4 15:42:04.700: INFO: Pod "pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.434509ms
Sep  4 15:42:06.702: INFO: Pod "pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003719463s
STEP: Saw pod success
Sep  4 15:42:06.702: INFO: Pod "pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d" satisfied condition "success or failure"
Sep  4 15:42:06.704: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:42:06.719: INFO: Waiting for pod pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d to disappear
Sep  4 15:42:06.723: INFO: Pod pod-configmaps-e4dedd1a-eae4-4543-9b2b-b1ef1432be1d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:42:06.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-26" for this suite.
Sep  4 15:42:12.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:42:12.770: INFO: namespace configmap-26 deletion completed in 6.045067149s

• [SLOW TEST:8.164 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:42:12.771: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3249.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3249.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3249.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3249.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3249.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3249.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 15:42:16.867: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3249/dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7: the server could not find the requested resource (get pods dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7)
Sep  4 15:42:16.868: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3249/dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7: the server could not find the requested resource (get pods dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7)
Sep  4 15:42:16.874: INFO: Lookups using dns-3249/dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord]

Sep  4 15:42:21.887: INFO: DNS probes using dns-3249/dns-test-5990b053-71bd-4b3f-aa35-170b079edaa7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:42:21.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3249" for this suite.
Sep  4 15:42:27.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:42:27.982: INFO: namespace dns-3249 deletion completed in 6.05147673s

• [SLOW TEST:15.211 seconds]
[sig-network] DNS
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:42:27.982: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 15:42:28.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-2641'
Sep  4 15:42:28.132: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 15:42:28.132: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep  4 15:42:30.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2641'
Sep  4 15:42:30.288: INFO: stderr: ""
Sep  4 15:42:30.288: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:42:30.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2641" for this suite.
Sep  4 15:42:36.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:42:36.352: INFO: namespace kubectl-2641 deletion completed in 6.061316768s

• [SLOW TEST:8.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:42:36.352: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:42:38.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2886" for this suite.
Sep  4 15:43:16.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:43:16.475: INFO: namespace kubelet-test-2886 deletion completed in 38.048709993s

• [SLOW TEST:40.122 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:43:16.475: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 15:43:19.084: INFO: Successfully updated pod "annotationupdate5eaeba28-8a4e-4bf1-a488-66fcc1f3d156"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:43:23.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4396" for this suite.
Sep  4 15:43:45.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:43:45.153: INFO: namespace projected-4396 deletion completed in 22.04780445s

• [SLOW TEST:28.678 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:43:45.154: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep  4 15:43:45.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-2707'
Sep  4 15:43:45.373: INFO: stderr: ""
Sep  4 15:43:45.373: INFO: stdout: "pod/pause created\n"
Sep  4 15:43:45.373: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  4 15:43:45.373: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2707" to be "running and ready"
Sep  4 15:43:45.377: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129987ms
Sep  4 15:43:47.378: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.00488621s
Sep  4 15:43:47.378: INFO: Pod "pause" satisfied condition "running and ready"
Sep  4 15:43:47.378: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  4 15:43:47.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 label pods pause testing-label=testing-label-value --namespace=kubectl-2707'
Sep  4 15:43:47.449: INFO: stderr: ""
Sep  4 15:43:47.449: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  4 15:43:47.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pod pause -L testing-label --namespace=kubectl-2707'
Sep  4 15:43:47.529: INFO: stderr: ""
Sep  4 15:43:47.529: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  4 15:43:47.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 label pods pause testing-label- --namespace=kubectl-2707'
Sep  4 15:43:47.601: INFO: stderr: ""
Sep  4 15:43:47.601: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  4 15:43:47.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pod pause -L testing-label --namespace=kubectl-2707'
Sep  4 15:43:47.668: INFO: stderr: ""
Sep  4 15:43:47.668: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep  4 15:43:47.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-2707'
Sep  4 15:43:47.769: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 15:43:47.769: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  4 15:43:47.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=pause --no-headers --namespace=kubectl-2707'
Sep  4 15:43:47.900: INFO: stderr: "No resources found.\n"
Sep  4 15:43:47.900: INFO: stdout: ""
Sep  4 15:43:47.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=pause --namespace=kubectl-2707 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 15:43:47.985: INFO: stderr: ""
Sep  4 15:43:47.986: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:43:47.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2707" for this suite.
Sep  4 15:43:54.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:43:54.052: INFO: namespace kubectl-2707 deletion completed in 6.049875054s

• [SLOW TEST:8.898 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:43:54.052: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  4 15:43:54.137: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12512,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 15:43:54.137: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12512,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  4 15:44:04.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12528,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 15:44:04.141: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12528,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  4 15:44:14.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12543,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 15:44:14.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12543,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  4 15:44:24.148: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12559,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 15:44:24.148: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-a,UID:b336a0ce-8d99-43aa-8155-b036b7ca8354,ResourceVersion:12559,Generation:0,CreationTimestamp:2019-09-04 15:43:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  4 15:44:34.151: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-b,UID:f340a354-bbfa-43b6-a662-850e1560e716,ResourceVersion:12575,Generation:0,CreationTimestamp:2019-09-04 15:44:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 15:44:34.151: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-b,UID:f340a354-bbfa-43b6-a662-850e1560e716,ResourceVersion:12575,Generation:0,CreationTimestamp:2019-09-04 15:44:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  4 15:44:44.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-b,UID:f340a354-bbfa-43b6-a662-850e1560e716,ResourceVersion:12590,Generation:0,CreationTimestamp:2019-09-04 15:44:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 15:44:44.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2005,SelfLink:/api/v1/namespaces/watch-2005/configmaps/e2e-watch-test-configmap-b,UID:f340a354-bbfa-43b6-a662-850e1560e716,ResourceVersion:12590,Generation:0,CreationTimestamp:2019-09-04 15:44:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:44:54.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2005" for this suite.
Sep  4 15:45:00.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:00.235: INFO: namespace watch-2005 deletion completed in 6.076915547s

• [SLOW TEST:66.183 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:00.235: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:45:00.301: INFO: Waiting up to 5m0s for pod "downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f" in namespace "downward-api-8991" to be "success or failure"
Sep  4 15:45:00.308: INFO: Pod "downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.22508ms
Sep  4 15:45:02.311: INFO: Pod "downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009385575s
STEP: Saw pod success
Sep  4 15:45:02.311: INFO: Pod "downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f" satisfied condition "success or failure"
Sep  4 15:45:02.312: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f container client-container: <nil>
STEP: delete the pod
Sep  4 15:45:02.350: INFO: Waiting for pod downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f to disappear
Sep  4 15:45:02.365: INFO: Pod downwardapi-volume-407181a9-6299-4e84-9e2d-b2a0db03112f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:45:02.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8991" for this suite.
Sep  4 15:45:08.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:08.413: INFO: namespace downward-api-8991 deletion completed in 6.045868019s

• [SLOW TEST:8.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:08.414: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-b0bfc2a4-56e4-4c4e-b6e0-aafb4dcca963
STEP: Creating a pod to test consume secrets
Sep  4 15:45:08.493: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d" in namespace "projected-1466" to be "success or failure"
Sep  4 15:45:08.509: INFO: Pod "pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.857623ms
Sep  4 15:45:10.511: INFO: Pod "pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017961349s
STEP: Saw pod success
Sep  4 15:45:10.511: INFO: Pod "pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d" satisfied condition "success or failure"
Sep  4 15:45:10.512: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:45:10.556: INFO: Waiting for pod pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d to disappear
Sep  4 15:45:10.570: INFO: Pod pod-projected-secrets-7a1063fb-722d-4f0f-804b-0377d8d6844d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:45:10.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1466" for this suite.
Sep  4 15:45:16.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:16.625: INFO: namespace projected-1466 deletion completed in 6.052571619s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:16.625: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep  4 15:45:16.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 --namespace=kubectl-1648 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  4 15:45:18.258: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  4 15:45:18.258: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:45:20.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1648" for this suite.
Sep  4 15:45:26.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:26.333: INFO: namespace kubectl-1648 deletion completed in 6.070434603s

• [SLOW TEST:9.707 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:26.333: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep  4 15:45:28.420: INFO: Pod pod-hostip-bf494d6c-6a02-45b6-a46f-3220f59f7a91 has hostIP: 192.168.0.166
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:45:28.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9681" for this suite.
Sep  4 15:45:50.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:50.469: INFO: namespace pods-9681 deletion completed in 22.04654826s

• [SLOW TEST:24.136 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:50.469: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b7095a86-28ef-43ee-92fb-ab8e8ca54871
STEP: Creating a pod to test consume secrets
Sep  4 15:45:50.590: INFO: Waiting up to 5m0s for pod "pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c" in namespace "secrets-923" to be "success or failure"
Sep  4 15:45:50.601: INFO: Pod "pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.255977ms
Sep  4 15:45:52.610: INFO: Pod "pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019313121s
STEP: Saw pod success
Sep  4 15:45:52.610: INFO: Pod "pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c" satisfied condition "success or failure"
Sep  4 15:45:52.618: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:45:52.647: INFO: Waiting for pod pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c to disappear
Sep  4 15:45:52.652: INFO: Pod pod-secrets-a6096b86-68f2-49cb-87a5-f09cc5fbfe9c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:45:52.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-923" for this suite.
Sep  4 15:45:58.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:45:58.700: INFO: namespace secrets-923 deletion completed in 6.045554092s

• [SLOW TEST:8.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:45:58.700: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-4dnx
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 15:45:58.801: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4dnx" in namespace "subpath-4439" to be "success or failure"
Sep  4 15:45:58.807: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Pending", Reason="", readiness=false. Elapsed: 5.594053ms
Sep  4 15:46:00.808: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.007275476s
Sep  4 15:46:02.810: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 4.009366158s
Sep  4 15:46:04.813: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 6.011583625s
Sep  4 15:46:06.815: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 8.013754226s
Sep  4 15:46:08.817: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 10.015667827s
Sep  4 15:46:10.819: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 12.017727728s
Sep  4 15:46:12.821: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 14.019923621s
Sep  4 15:46:14.823: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 16.021918008s
Sep  4 15:46:16.825: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 18.023916092s
Sep  4 15:46:18.827: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Running", Reason="", readiness=true. Elapsed: 20.026120841s
Sep  4 15:46:20.829: INFO: Pod "pod-subpath-test-configmap-4dnx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.028464176s
STEP: Saw pod success
Sep  4 15:46:20.829: INFO: Pod "pod-subpath-test-configmap-4dnx" satisfied condition "success or failure"
Sep  4 15:46:20.831: INFO: Trying to get logs from node 192.168.0.166 pod pod-subpath-test-configmap-4dnx container test-container-subpath-configmap-4dnx: <nil>
STEP: delete the pod
Sep  4 15:46:20.842: INFO: Waiting for pod pod-subpath-test-configmap-4dnx to disappear
Sep  4 15:46:20.848: INFO: Pod pod-subpath-test-configmap-4dnx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4dnx
Sep  4 15:46:20.848: INFO: Deleting pod "pod-subpath-test-configmap-4dnx" in namespace "subpath-4439"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:46:20.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4439" for this suite.
Sep  4 15:46:26.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:46:26.900: INFO: namespace subpath-4439 deletion completed in 6.049020423s

• [SLOW TEST:28.200 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:46:26.900: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 15:46:27.018: INFO: Number of nodes with available pods: 0
Sep  4 15:46:27.018: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:46:28.022: INFO: Number of nodes with available pods: 0
Sep  4 15:46:28.022: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 15:46:29.022: INFO: Number of nodes with available pods: 2
Sep  4 15:46:29.022: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  4 15:46:29.053: INFO: Number of nodes with available pods: 2
Sep  4 15:46:29.053: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9288, will wait for the garbage collector to delete the pods
Sep  4 15:46:30.118: INFO: Deleting DaemonSet.extensions daemon-set took: 4.511073ms
Sep  4 15:46:30.419: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.15404ms
Sep  4 15:46:45.320: INFO: Number of nodes with available pods: 0
Sep  4 15:46:45.320: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 15:46:45.322: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9288/daemonsets","resourceVersion":"13072"},"items":null}

Sep  4 15:46:45.323: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9288/pods","resourceVersion":"13072"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:46:45.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9288" for this suite.
Sep  4 15:46:51.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:46:51.381: INFO: namespace daemonsets-9288 deletion completed in 6.048344274s

• [SLOW TEST:24.481 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:46:51.381: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-0f941a41-039a-4b9e-9d98-9eac35789343
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:46:51.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1644" for this suite.
Sep  4 15:46:57.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:46:57.495: INFO: namespace secrets-1644 deletion completed in 6.047170378s

• [SLOW TEST:6.114 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:46:57.496: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 15:46:57.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374" in namespace "downward-api-6745" to be "success or failure"
Sep  4 15:46:57.568: INFO: Pod "downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374": Phase="Pending", Reason="", readiness=false. Elapsed: 4.527029ms
Sep  4 15:46:59.569: INFO: Pod "downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006227441s
STEP: Saw pod success
Sep  4 15:46:59.569: INFO: Pod "downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374" satisfied condition "success or failure"
Sep  4 15:46:59.571: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374 container client-container: <nil>
STEP: delete the pod
Sep  4 15:46:59.590: INFO: Waiting for pod downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374 to disappear
Sep  4 15:46:59.596: INFO: Pod downwardapi-volume-9e6fbfae-1f1c-41da-a3ee-1bfce8ca6374 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:46:59.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6745" for this suite.
Sep  4 15:47:05.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:47:05.646: INFO: namespace downward-api-6745 deletion completed in 6.047954252s

• [SLOW TEST:8.151 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:47:05.646: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  4 15:47:05.700: INFO: Waiting up to 5m0s for pod "pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5" in namespace "emptydir-2711" to be "success or failure"
Sep  4 15:47:05.746: INFO: Pod "pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5": Phase="Pending", Reason="", readiness=false. Elapsed: 45.271081ms
Sep  4 15:47:07.748: INFO: Pod "pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047390513s
STEP: Saw pod success
Sep  4 15:47:07.748: INFO: Pod "pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5" satisfied condition "success or failure"
Sep  4 15:47:07.749: INFO: Trying to get logs from node 192.168.0.166 pod pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5 container test-container: <nil>
STEP: delete the pod
Sep  4 15:47:07.764: INFO: Waiting for pod pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5 to disappear
Sep  4 15:47:07.768: INFO: Pod pod-7a8c5e76-17e7-4f50-b9d0-83ded725a1a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:47:07.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2711" for this suite.
Sep  4 15:47:13.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:47:13.816: INFO: namespace emptydir-2711 deletion completed in 6.045726189s

• [SLOW TEST:8.169 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:47:13.816: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 15:47:13.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3481'
Sep  4 15:47:13.957: INFO: stderr: ""
Sep  4 15:47:13.957: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep  4 15:47:13.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete pods e2e-test-nginx-pod --namespace=kubectl-3481'
Sep  4 15:47:25.263: INFO: stderr: ""
Sep  4 15:47:25.263: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:47:25.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3481" for this suite.
Sep  4 15:47:31.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:47:31.321: INFO: namespace kubectl-3481 deletion completed in 6.055102744s

• [SLOW TEST:17.505 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:47:31.321: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-ea03c188-43a3-4e05-9f6e-53cb57076db1
STEP: Creating secret with name s-test-opt-upd-92192780-6a79-4c9b-816c-06135c2f5317
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ea03c188-43a3-4e05-9f6e-53cb57076db1
STEP: Updating secret s-test-opt-upd-92192780-6a79-4c9b-816c-06135c2f5317
STEP: Creating secret with name s-test-opt-create-8485899e-cf7a-441c-b87f-7b001979dfc7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:47:35.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3882" for this suite.
Sep  4 15:47:57.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:47:57.536: INFO: namespace secrets-3882 deletion completed in 22.053550455s

• [SLOW TEST:26.214 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:47:57.536: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:47:57.659: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5a0a93e7-d96a-42c0-b9ad-804798243e01", Controller:(*bool)(0xc002de3c16), BlockOwnerDeletion:(*bool)(0xc002de3c17)}}
Sep  4 15:47:57.682: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6e312571-a6dd-42f3-a848-aab2ce3a563a", Controller:(*bool)(0xc0039d8976), BlockOwnerDeletion:(*bool)(0xc0039d8977)}}
Sep  4 15:47:57.689: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"042ef679-bc8b-4c35-ba2c-6279b3d0cf16", Controller:(*bool)(0xc0024d0ff6), BlockOwnerDeletion:(*bool)(0xc0024d0ff7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:02.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7584" for this suite.
Sep  4 15:48:08.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:08.783: INFO: namespace gc-7584 deletion completed in 6.051833553s

• [SLOW TEST:11.248 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:08.783: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-9558/secret-test-d2a73222-9faf-407f-ac95-94c4f4a09531
STEP: Creating a pod to test consume secrets
Sep  4 15:48:08.845: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47" in namespace "secrets-9558" to be "success or failure"
Sep  4 15:48:08.849: INFO: Pod "pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.357902ms
Sep  4 15:48:10.851: INFO: Pod "pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006207561s
STEP: Saw pod success
Sep  4 15:48:10.851: INFO: Pod "pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47" satisfied condition "success or failure"
Sep  4 15:48:10.852: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47 container env-test: <nil>
STEP: delete the pod
Sep  4 15:48:10.882: INFO: Waiting for pod pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47 to disappear
Sep  4 15:48:10.889: INFO: Pod pod-configmaps-9f6d61ad-f14b-4aa2-9613-eb12878a7a47 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:10.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9558" for this suite.
Sep  4 15:48:16.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:16.938: INFO: namespace secrets-9558 deletion completed in 6.046966098s

• [SLOW TEST:8.155 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:16.939: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep  4 15:48:17.016: INFO: Waiting up to 5m0s for pod "var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e" in namespace "var-expansion-4873" to be "success or failure"
Sep  4 15:48:17.048: INFO: Pod "var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e": Phase="Pending", Reason="", readiness=false. Elapsed: 31.074016ms
Sep  4 15:48:19.050: INFO: Pod "var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03345329s
STEP: Saw pod success
Sep  4 15:48:19.050: INFO: Pod "var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e" satisfied condition "success or failure"
Sep  4 15:48:19.052: INFO: Trying to get logs from node 192.168.0.166 pod var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e container dapi-container: <nil>
STEP: delete the pod
Sep  4 15:48:19.091: INFO: Waiting for pod var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e to disappear
Sep  4 15:48:19.101: INFO: Pod var-expansion-ff41915a-805d-4862-8332-8e9ca9c5511e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:19.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4873" for this suite.
Sep  4 15:48:25.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:25.148: INFO: namespace var-expansion-4873 deletion completed in 6.045854607s

• [SLOW TEST:8.210 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:25.149: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:48:25.201: INFO: Creating deployment "test-recreate-deployment"
Sep  4 15:48:25.209: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  4 15:48:25.221: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep  4 15:48:27.225: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  4 15:48:27.226: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  4 15:48:27.229: INFO: Updating deployment test-recreate-deployment
Sep  4 15:48:27.229: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep  4 15:48:27.394: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1424,SelfLink:/apis/apps/v1/namespaces/deployment-1424/deployments/test-recreate-deployment,UID:dbca8b7e-be1a-42f0-bf3f-123bef8f80a1,ResourceVersion:13580,Generation:2,CreationTimestamp:2019-09-04 15:48:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-04 15:48:27 +0000 UTC 2019-09-04 15:48:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-04 15:48:27 +0000 UTC 2019-09-04 15:48:25 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  4 15:48:27.396: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1424,SelfLink:/apis/apps/v1/namespaces/deployment-1424/replicasets/test-recreate-deployment-5c8c9cc69d,UID:44639d48-e152-4c4f-a385-b4bb79127fe8,ResourceVersion:13578,Generation:1,CreationTimestamp:2019-09-04 15:48:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dbca8b7e-be1a-42f0-bf3f-123bef8f80a1 0xc00319dff7 0xc00319dff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:48:27.396: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  4 15:48:27.396: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1424,SelfLink:/apis/apps/v1/namespaces/deployment-1424/replicasets/test-recreate-deployment-6df85df6b9,UID:50e0ddf9-e362-42e4-9d6a-d1f9c41ca830,ResourceVersion:13569,Generation:2,CreationTimestamp:2019-09-04 15:48:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dbca8b7e-be1a-42f0-bf3f-123bef8f80a1 0xc00052c267 0xc00052c268}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 15:48:27.404: INFO: Pod "test-recreate-deployment-5c8c9cc69d-s27s6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-s27s6,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1424,SelfLink:/api/v1/namespaces/deployment-1424/pods/test-recreate-deployment-5c8c9cc69d-s27s6,UID:ef2bc1da-b20b-48bb-b4d2-c5ffaf7b2a42,ResourceVersion:13581,Generation:0,CreationTimestamp:2019-09-04 15:48:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 44639d48-e152-4c4f-a385-b4bb79127fe8 0xc00285c207 0xc00285c208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-246sn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-246sn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-246sn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00285c280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00285c2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:48:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:48:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:48:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 15:48:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.166,PodIP:,StartTime:2019-09-04 15:48:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:27.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1424" for this suite.
Sep  4 15:48:33.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:33.452: INFO: namespace deployment-1424 deletion completed in 6.045662507s

• [SLOW TEST:8.303 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:33.452: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep  4 15:48:33.513: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:45.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4541" for this suite.
Sep  4 15:48:51.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:51.309: INFO: namespace pods-4541 deletion completed in 6.045166495s

• [SLOW TEST:17.856 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:51.309: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 15:48:51.354: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:48:52.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7362" for this suite.
Sep  4 15:48:58.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:48:58.570: INFO: namespace custom-resource-definition-7362 deletion completed in 6.07991583s

• [SLOW TEST:7.261 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:48:58.570: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-543d351e-90cd-476a-8633-82cf52f50062
STEP: Creating a pod to test consume configMaps
Sep  4 15:48:58.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0" in namespace "configmap-6466" to be "success or failure"
Sep  4 15:48:58.667: INFO: Pod "pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.677801ms
Sep  4 15:49:00.669: INFO: Pod "pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006619242s
STEP: Saw pod success
Sep  4 15:49:00.669: INFO: Pod "pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0" satisfied condition "success or failure"
Sep  4 15:49:00.670: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:49:00.685: INFO: Waiting for pod pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0 to disappear
Sep  4 15:49:00.702: INFO: Pod pod-configmaps-3d2c37a4-522a-4edd-be00-4796778101a0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:49:00.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6466" for this suite.
Sep  4 15:49:06.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:49:06.753: INFO: namespace configmap-6466 deletion completed in 6.04971552s

• [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:49:06.754: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d43f35d7-8e26-469d-bb3c-20cf837631e1
STEP: Creating a pod to test consume secrets
Sep  4 15:49:06.840: INFO: Waiting up to 5m0s for pod "pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff" in namespace "secrets-2412" to be "success or failure"
Sep  4 15:49:06.845: INFO: Pod "pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.791986ms
Sep  4 15:49:08.846: INFO: Pod "pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006463516s
STEP: Saw pod success
Sep  4 15:49:08.846: INFO: Pod "pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff" satisfied condition "success or failure"
Sep  4 15:49:08.848: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff container secret-env-test: <nil>
STEP: delete the pod
Sep  4 15:49:08.863: INFO: Waiting for pod pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff to disappear
Sep  4 15:49:08.867: INFO: Pod pod-secrets-fbf9b172-29ac-47cf-97fb-0986e350b3ff no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:49:08.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2412" for this suite.
Sep  4 15:49:14.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:49:14.924: INFO: namespace secrets-2412 deletion completed in 6.054272482s

• [SLOW TEST:8.170 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:49:14.924: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  4 15:49:15.458: INFO: Pod name wrapped-volume-race-80321a8d-c109-4b9f-a222-10af84f82097: Found 0 pods out of 5
Sep  4 15:49:20.472: INFO: Pod name wrapped-volume-race-80321a8d-c109-4b9f-a222-10af84f82097: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-80321a8d-c109-4b9f-a222-10af84f82097 in namespace emptydir-wrapper-1624, will wait for the garbage collector to delete the pods
Sep  4 15:49:30.557: INFO: Deleting ReplicationController wrapped-volume-race-80321a8d-c109-4b9f-a222-10af84f82097 took: 3.31077ms
Sep  4 15:49:30.857: INFO: Terminating ReplicationController wrapped-volume-race-80321a8d-c109-4b9f-a222-10af84f82097 pods took: 300.156302ms
STEP: Creating RC which spawns configmap-volume pods
Sep  4 15:50:08.179: INFO: Pod name wrapped-volume-race-c43ba184-aa07-4a08-832f-683002ff6a61: Found 0 pods out of 5
Sep  4 15:50:13.182: INFO: Pod name wrapped-volume-race-c43ba184-aa07-4a08-832f-683002ff6a61: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c43ba184-aa07-4a08-832f-683002ff6a61 in namespace emptydir-wrapper-1624, will wait for the garbage collector to delete the pods
Sep  4 15:50:23.248: INFO: Deleting ReplicationController wrapped-volume-race-c43ba184-aa07-4a08-832f-683002ff6a61 took: 3.356347ms
Sep  4 15:50:23.548: INFO: Terminating ReplicationController wrapped-volume-race-c43ba184-aa07-4a08-832f-683002ff6a61 pods took: 300.179406ms
STEP: Creating RC which spawns configmap-volume pods
Sep  4 15:50:58.812: INFO: Pod name wrapped-volume-race-6b687a88-673c-4b8d-a892-178c9d60174b: Found 0 pods out of 5
Sep  4 15:51:03.817: INFO: Pod name wrapped-volume-race-6b687a88-673c-4b8d-a892-178c9d60174b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6b687a88-673c-4b8d-a892-178c9d60174b in namespace emptydir-wrapper-1624, will wait for the garbage collector to delete the pods
Sep  4 15:51:15.889: INFO: Deleting ReplicationController wrapped-volume-race-6b687a88-673c-4b8d-a892-178c9d60174b took: 7.357106ms
Sep  4 15:51:16.189: INFO: Terminating ReplicationController wrapped-volume-race-6b687a88-673c-4b8d-a892-178c9d60174b pods took: 300.18486ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:51:50.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1624" for this suite.
Sep  4 15:51:58.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:51:58.786: INFO: namespace emptydir-wrapper-1624 deletion completed in 8.068697794s

• [SLOW TEST:163.862 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:51:58.786: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  4 15:52:01.364: INFO: Successfully updated pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132"
Sep  4 15:52:01.364: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132" in namespace "pods-2826" to be "terminated due to deadline exceeded"
Sep  4 15:52:01.389: INFO: Pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132": Phase="Running", Reason="", readiness=true. Elapsed: 25.497021ms
Sep  4 15:52:03.391: INFO: Pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132": Phase="Running", Reason="", readiness=true. Elapsed: 2.027732561s
Sep  4 15:52:05.393: INFO: Pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.029832182s
Sep  4 15:52:05.393: INFO: Pod "pod-update-activedeadlineseconds-988cc026-5a89-4cab-ae6d-14733c364132" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:52:05.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2826" for this suite.
Sep  4 15:52:11.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:52:11.446: INFO: namespace pods-2826 deletion completed in 6.049811595s

• [SLOW TEST:12.659 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:52:11.446: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  4 15:52:11.524: INFO: Waiting up to 5m0s for pod "pod-f4aa6d65-073f-46e6-b152-aa876d71b99b" in namespace "emptydir-6249" to be "success or failure"
Sep  4 15:52:11.566: INFO: Pod "pod-f4aa6d65-073f-46e6-b152-aa876d71b99b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.674006ms
Sep  4 15:52:13.568: INFO: Pod "pod-f4aa6d65-073f-46e6-b152-aa876d71b99b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043840852s
STEP: Saw pod success
Sep  4 15:52:13.568: INFO: Pod "pod-f4aa6d65-073f-46e6-b152-aa876d71b99b" satisfied condition "success or failure"
Sep  4 15:52:13.570: INFO: Trying to get logs from node 192.168.0.166 pod pod-f4aa6d65-073f-46e6-b152-aa876d71b99b container test-container: <nil>
STEP: delete the pod
Sep  4 15:52:13.582: INFO: Waiting for pod pod-f4aa6d65-073f-46e6-b152-aa876d71b99b to disappear
Sep  4 15:52:13.623: INFO: Pod pod-f4aa6d65-073f-46e6-b152-aa876d71b99b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:52:13.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6249" for this suite.
Sep  4 15:52:19.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:52:19.682: INFO: namespace emptydir-6249 deletion completed in 6.057223246s

• [SLOW TEST:8.237 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:52:19.682: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-6672/configmap-test-e7cb9ed4-5309-4a57-be46-556dad054edd
STEP: Creating a pod to test consume configMaps
Sep  4 15:52:19.759: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2b14415-7297-4702-a468-f293df0df883" in namespace "configmap-6672" to be "success or failure"
Sep  4 15:52:19.764: INFO: Pod "pod-configmaps-a2b14415-7297-4702-a468-f293df0df883": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54871ms
Sep  4 15:52:21.766: INFO: Pod "pod-configmaps-a2b14415-7297-4702-a468-f293df0df883": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007255476s
STEP: Saw pod success
Sep  4 15:52:21.766: INFO: Pod "pod-configmaps-a2b14415-7297-4702-a468-f293df0df883" satisfied condition "success or failure"
Sep  4 15:52:21.775: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-a2b14415-7297-4702-a468-f293df0df883 container env-test: <nil>
STEP: delete the pod
Sep  4 15:52:21.788: INFO: Waiting for pod pod-configmaps-a2b14415-7297-4702-a468-f293df0df883 to disappear
Sep  4 15:52:21.792: INFO: Pod pod-configmaps-a2b14415-7297-4702-a468-f293df0df883 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:52:21.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6672" for this suite.
Sep  4 15:52:27.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:52:27.857: INFO: namespace configmap-6672 deletion completed in 6.062162864s

• [SLOW TEST:8.174 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:52:27.857: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a0b1c464-d6a2-46a8-bca9-6d31838d6dc0
STEP: Creating a pod to test consume configMaps
Sep  4 15:52:27.914: INFO: Waiting up to 5m0s for pod "pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c" in namespace "configmap-7251" to be "success or failure"
Sep  4 15:52:27.957: INFO: Pod "pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c": Phase="Pending", Reason="", readiness=false. Elapsed: 43.010307ms
Sep  4 15:52:29.961: INFO: Pod "pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046926276s
STEP: Saw pod success
Sep  4 15:52:29.961: INFO: Pod "pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c" satisfied condition "success or failure"
Sep  4 15:52:29.962: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 15:52:29.976: INFO: Waiting for pod pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c to disappear
Sep  4 15:52:29.994: INFO: Pod pod-configmaps-86525ba2-a9e8-45ea-984f-f30f7cf0c86c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:52:29.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7251" for this suite.
Sep  4 15:52:36.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:52:36.045: INFO: namespace configmap-7251 deletion completed in 6.048388505s

• [SLOW TEST:8.188 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:52:36.045: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-wjth
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 15:52:36.128: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wjth" in namespace "subpath-6041" to be "success or failure"
Sep  4 15:52:36.130: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Pending", Reason="", readiness=false. Elapsed: 1.956642ms
Sep  4 15:52:38.132: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 2.003888758s
Sep  4 15:52:40.134: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 4.006217718s
Sep  4 15:52:42.136: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 6.008478683s
Sep  4 15:52:44.138: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 8.010539912s
Sep  4 15:52:46.141: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 10.012703029s
Sep  4 15:52:48.143: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 12.014719564s
Sep  4 15:52:50.145: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 14.016744613s
Sep  4 15:52:52.147: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 16.01875132s
Sep  4 15:52:54.148: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 18.020487243s
Sep  4 15:52:56.150: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Running", Reason="", readiness=true. Elapsed: 20.022348165s
Sep  4 15:52:58.152: INFO: Pod "pod-subpath-test-secret-wjth": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.024215838s
STEP: Saw pod success
Sep  4 15:52:58.152: INFO: Pod "pod-subpath-test-secret-wjth" satisfied condition "success or failure"
Sep  4 15:52:58.153: INFO: Trying to get logs from node 192.168.0.166 pod pod-subpath-test-secret-wjth container test-container-subpath-secret-wjth: <nil>
STEP: delete the pod
Sep  4 15:52:58.171: INFO: Waiting for pod pod-subpath-test-secret-wjth to disappear
Sep  4 15:52:58.176: INFO: Pod pod-subpath-test-secret-wjth no longer exists
STEP: Deleting pod pod-subpath-test-secret-wjth
Sep  4 15:52:58.176: INFO: Deleting pod "pod-subpath-test-secret-wjth" in namespace "subpath-6041"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:52:58.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6041" for this suite.
Sep  4 15:53:04.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:53:04.226: INFO: namespace subpath-6041 deletion completed in 6.047845885s

• [SLOW TEST:28.181 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:53:04.226: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-92312ede-47ae-4300-a29f-de5fe5f1c84c
STEP: Creating a pod to test consume secrets
Sep  4 15:53:04.297: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98" in namespace "projected-1624" to be "success or failure"
Sep  4 15:53:04.302: INFO: Pod "pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.47251ms
Sep  4 15:53:06.304: INFO: Pod "pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006659163s
STEP: Saw pod success
Sep  4 15:53:06.304: INFO: Pod "pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98" satisfied condition "success or failure"
Sep  4 15:53:06.305: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 15:53:06.319: INFO: Waiting for pod pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98 to disappear
Sep  4 15:53:06.324: INFO: Pod pod-projected-secrets-ec56f784-bd60-499b-aa75-d9b54d485e98 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:53:06.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1624" for this suite.
Sep  4 15:53:12.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:53:12.389: INFO: namespace projected-1624 deletion completed in 6.062489789s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:53:12.389: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-26e04def-0ad0-49f7-acfa-d92d5ccca4ba
STEP: Creating configMap with name cm-test-opt-upd-0af817fb-739d-4840-9fb6-e1676cdb0f75
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-26e04def-0ad0-49f7-acfa-d92d5ccca4ba
STEP: Updating configmap cm-test-opt-upd-0af817fb-739d-4840-9fb6-e1676cdb0f75
STEP: Creating configMap with name cm-test-opt-create-8005e5bc-072b-4a8b-ba80-bca4c4e4a051
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:53:16.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7597" for this suite.
Sep  4 15:53:38.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:53:38.724: INFO: namespace configmap-7597 deletion completed in 22.055861993s

• [SLOW TEST:26.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:53:38.724: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  4 15:53:42.865: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:42.865: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:42.947: INFO: Exec stderr: ""
Sep  4 15:53:42.947: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:42.947: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.021: INFO: Exec stderr: ""
Sep  4 15:53:43.021: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.021: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.095: INFO: Exec stderr: ""
Sep  4 15:53:43.095: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.095: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.165: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  4 15:53:43.165: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.165: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.239: INFO: Exec stderr: ""
Sep  4 15:53:43.239: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.239: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.314: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  4 15:53:43.314: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.314: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.389: INFO: Exec stderr: ""
Sep  4 15:53:43.389: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.389: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.458: INFO: Exec stderr: ""
Sep  4 15:53:43.458: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.458: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.532: INFO: Exec stderr: ""
Sep  4 15:53:43.532: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9784 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 15:53:43.532: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 15:53:43.612: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:53:43.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9784" for this suite.
Sep  4 15:54:35.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:54:35.664: INFO: namespace e2e-kubelet-etc-hosts-9784 deletion completed in 52.048679227s

• [SLOW TEST:56.939 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:54:35.665: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-5918e56c-fb08-4665-a2da-c5196ebfaf38 in namespace container-probe-9234
Sep  4 15:54:37.728: INFO: Started pod busybox-5918e56c-fb08-4665-a2da-c5196ebfaf38 in namespace container-probe-9234
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 15:54:37.729: INFO: Initial restart count of pod busybox-5918e56c-fb08-4665-a2da-c5196ebfaf38 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:58:37.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9234" for this suite.
Sep  4 15:58:44.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:58:44.051: INFO: namespace container-probe-9234 deletion completed in 6.054791s

• [SLOW TEST:248.386 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:58:44.053: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep  4 15:58:44.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-3942'
Sep  4 15:58:44.332: INFO: stderr: ""
Sep  4 15:58:44.332: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 15:58:44.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3942'
Sep  4 15:58:44.411: INFO: stderr: ""
Sep  4 15:58:44.411: INFO: stdout: "update-demo-nautilus-jjtjc update-demo-nautilus-phmml "
Sep  4 15:58:44.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-jjtjc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:58:44.512: INFO: stderr: ""
Sep  4 15:58:44.512: INFO: stdout: ""
Sep  4 15:58:44.512: INFO: update-demo-nautilus-jjtjc is created but not running
Sep  4 15:58:49.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3942'
Sep  4 15:58:49.585: INFO: stderr: ""
Sep  4 15:58:49.585: INFO: stdout: "update-demo-nautilus-jjtjc update-demo-nautilus-phmml "
Sep  4 15:58:49.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-jjtjc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:58:49.661: INFO: stderr: ""
Sep  4 15:58:49.661: INFO: stdout: "true"
Sep  4 15:58:49.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-jjtjc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:58:49.730: INFO: stderr: ""
Sep  4 15:58:49.730: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 15:58:49.730: INFO: validating pod update-demo-nautilus-jjtjc
Sep  4 15:58:49.732: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 15:58:49.732: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 15:58:49.732: INFO: update-demo-nautilus-jjtjc is verified up and running
Sep  4 15:58:49.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-phmml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:58:49.805: INFO: stderr: ""
Sep  4 15:58:49.805: INFO: stdout: "true"
Sep  4 15:58:49.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-phmml -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:58:49.875: INFO: stderr: ""
Sep  4 15:58:49.875: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 15:58:49.875: INFO: validating pod update-demo-nautilus-phmml
Sep  4 15:58:49.878: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 15:58:49.878: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 15:58:49.878: INFO: update-demo-nautilus-phmml is verified up and running
STEP: rolling-update to new replication controller
Sep  4 15:58:49.879: INFO: scanned /root for discovery docs: <nil>
Sep  4 15:58:49.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3942'
Sep  4 15:59:12.245: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 15:59:12.245: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 15:59:12.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3942'
Sep  4 15:59:12.333: INFO: stderr: ""
Sep  4 15:59:12.333: INFO: stdout: "update-demo-kitten-klc6q update-demo-kitten-pp57q "
Sep  4 15:59:12.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-kitten-klc6q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:59:12.402: INFO: stderr: ""
Sep  4 15:59:12.402: INFO: stdout: "true"
Sep  4 15:59:12.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-kitten-klc6q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:59:12.471: INFO: stderr: ""
Sep  4 15:59:12.471: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  4 15:59:12.471: INFO: validating pod update-demo-kitten-klc6q
Sep  4 15:59:12.473: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 15:59:12.473: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 15:59:12.473: INFO: update-demo-kitten-klc6q is verified up and running
Sep  4 15:59:12.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-kitten-pp57q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:59:12.552: INFO: stderr: ""
Sep  4 15:59:12.552: INFO: stdout: "true"
Sep  4 15:59:12.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-kitten-pp57q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3942'
Sep  4 15:59:12.621: INFO: stderr: ""
Sep  4 15:59:12.621: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  4 15:59:12.621: INFO: validating pod update-demo-kitten-pp57q
Sep  4 15:59:12.624: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 15:59:12.624: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 15:59:12.624: INFO: update-demo-kitten-pp57q is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:59:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3942" for this suite.
Sep  4 15:59:34.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:59:34.677: INFO: namespace kubectl-3942 deletion completed in 22.051784017s

• [SLOW TEST:50.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:59:34.678: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  4 15:59:34.771: INFO: Waiting up to 5m0s for pod "pod-33217144-daea-419b-86c2-05030ba65116" in namespace "emptydir-6753" to be "success or failure"
Sep  4 15:59:34.774: INFO: Pod "pod-33217144-daea-419b-86c2-05030ba65116": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889566ms
Sep  4 15:59:36.777: INFO: Pod "pod-33217144-daea-419b-86c2-05030ba65116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006013131s
STEP: Saw pod success
Sep  4 15:59:36.777: INFO: Pod "pod-33217144-daea-419b-86c2-05030ba65116" satisfied condition "success or failure"
Sep  4 15:59:36.778: INFO: Trying to get logs from node 192.168.0.166 pod pod-33217144-daea-419b-86c2-05030ba65116 container test-container: <nil>
STEP: delete the pod
Sep  4 15:59:36.830: INFO: Waiting for pod pod-33217144-daea-419b-86c2-05030ba65116 to disappear
Sep  4 15:59:36.837: INFO: Pod pod-33217144-daea-419b-86c2-05030ba65116 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:59:36.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6753" for this suite.
Sep  4 15:59:42.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:59:42.884: INFO: namespace emptydir-6753 deletion completed in 6.045106242s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:59:42.884: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep  4 15:59:42.971: INFO: Waiting up to 5m0s for pod "var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f" in namespace "var-expansion-5123" to be "success or failure"
Sep  4 15:59:42.980: INFO: Pod "var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.193714ms
Sep  4 15:59:44.982: INFO: Pod "var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011438527s
STEP: Saw pod success
Sep  4 15:59:44.982: INFO: Pod "var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f" satisfied condition "success or failure"
Sep  4 15:59:44.984: INFO: Trying to get logs from node 192.168.0.166 pod var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f container dapi-container: <nil>
STEP: delete the pod
Sep  4 15:59:45.058: INFO: Waiting for pod var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f to disappear
Sep  4 15:59:45.066: INFO: Pod var-expansion-9755be73-beec-42a1-8c0a-3e795c68a97f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:59:45.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5123" for this suite.
Sep  4 15:59:51.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:59:51.113: INFO: namespace var-expansion-5123 deletion completed in 6.045214864s

• [SLOW TEST:8.229 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:59:51.113: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 15:59:51.181: INFO: Waiting up to 5m0s for pod "pod-d38550b8-e710-4677-ba3b-436a13456ab2" in namespace "emptydir-7263" to be "success or failure"
Sep  4 15:59:51.198: INFO: Pod "pod-d38550b8-e710-4677-ba3b-436a13456ab2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.903824ms
Sep  4 15:59:53.201: INFO: Pod "pod-d38550b8-e710-4677-ba3b-436a13456ab2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019271405s
STEP: Saw pod success
Sep  4 15:59:53.201: INFO: Pod "pod-d38550b8-e710-4677-ba3b-436a13456ab2" satisfied condition "success or failure"
Sep  4 15:59:53.202: INFO: Trying to get logs from node 192.168.0.166 pod pod-d38550b8-e710-4677-ba3b-436a13456ab2 container test-container: <nil>
STEP: delete the pod
Sep  4 15:59:53.243: INFO: Waiting for pod pod-d38550b8-e710-4677-ba3b-436a13456ab2 to disappear
Sep  4 15:59:53.249: INFO: Pod pod-d38550b8-e710-4677-ba3b-436a13456ab2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 15:59:53.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7263" for this suite.
Sep  4 15:59:59.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 15:59:59.298: INFO: namespace emptydir-7263 deletion completed in 6.046973621s

• [SLOW TEST:8.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 15:59:59.298: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 15:59:59.382: INFO: Waiting up to 5m0s for pod "downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b" in namespace "downward-api-454" to be "success or failure"
Sep  4 15:59:59.398: INFO: Pod "downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.139847ms
Sep  4 16:00:01.400: INFO: Pod "downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018552833s
STEP: Saw pod success
Sep  4 16:00:01.400: INFO: Pod "downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b" satisfied condition "success or failure"
Sep  4 16:00:01.402: INFO: Trying to get logs from node 192.168.0.166 pod downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b container dapi-container: <nil>
STEP: delete the pod
Sep  4 16:00:01.425: INFO: Waiting for pod downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b to disappear
Sep  4 16:00:01.432: INFO: Pod downward-api-17ed5511-7c45-4e99-ada0-00412a4ab87b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:01.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-454" for this suite.
Sep  4 16:00:07.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:07.499: INFO: namespace downward-api-454 deletion completed in 6.065469515s

• [SLOW TEST:8.201 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:07.500: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 16:00:11.615: INFO: DNS probes using dns-8522/dns-test-d49123ee-aaeb-45cc-93d2-8d5897c7a894 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:11.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8522" for this suite.
Sep  4 16:00:17.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:17.694: INFO: namespace dns-8522 deletion completed in 6.049641127s

• [SLOW TEST:10.194 seconds]
[sig-network] DNS
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:17.695: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  4 16:00:17.781: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  4 16:00:22.783: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:23.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8182" for this suite.
Sep  4 16:00:29.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:29.883: INFO: namespace replication-controller-8182 deletion completed in 6.083604679s

• [SLOW TEST:12.188 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:29.883: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 16:00:29.989: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7194" for this suite.
Sep  4 16:00:38.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:38.806: INFO: namespace init-container-7194 deletion completed in 6.056916075s

• [SLOW TEST:8.923 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:38.807: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep  4 16:00:38.857: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-836" to be "success or failure"
Sep  4 16:00:38.861: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.462315ms
Sep  4 16:00:40.863: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006345412s
STEP: Saw pod success
Sep  4 16:00:40.863: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  4 16:00:40.867: INFO: Trying to get logs from node 192.168.0.166 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  4 16:00:40.925: INFO: Waiting for pod pod-host-path-test to disappear
Sep  4 16:00:40.930: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:40.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-836" for this suite.
Sep  4 16:00:46.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:46.976: INFO: namespace hostpath-836 deletion completed in 6.044431534s

• [SLOW TEST:8.170 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:46.977: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-b5be1043-5582-4da1-af7b-d5e662199ebe
STEP: Creating a pod to test consume secrets
Sep  4 16:00:47.104: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea" in namespace "projected-5680" to be "success or failure"
Sep  4 16:00:47.113: INFO: Pod "pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.829337ms
Sep  4 16:00:49.115: INFO: Pod "pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01096237s
STEP: Saw pod success
Sep  4 16:00:49.115: INFO: Pod "pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea" satisfied condition "success or failure"
Sep  4 16:00:49.117: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 16:00:49.154: INFO: Waiting for pod pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea to disappear
Sep  4 16:00:49.159: INFO: Pod pod-projected-secrets-f85f881c-50ce-41c8-bf30-c35967f293ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:00:49.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5680" for this suite.
Sep  4 16:00:55.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:00:55.212: INFO: namespace projected-5680 deletion completed in 6.051148728s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:00:55.212: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  4 16:00:59.353: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:00:59.372: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:01.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:01.375: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:03.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:03.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:05.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:05.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:07.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:07.375: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:09.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:09.383: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:11.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:11.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:13.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:13.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:15.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:15.375: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:17.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:17.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:19.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:19.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:21.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:21.375: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:23.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:23.374: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 16:01:25.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 16:01:25.374: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:01:25.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1540" for this suite.
Sep  4 16:01:47.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:01:47.430: INFO: namespace container-lifecycle-hook-1540 deletion completed in 22.049450194s

• [SLOW TEST:52.218 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:01:47.430: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 16:01:47.498: INFO: Waiting up to 5m0s for pod "pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca" in namespace "emptydir-6332" to be "success or failure"
Sep  4 16:01:47.512: INFO: Pod "pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca": Phase="Pending", Reason="", readiness=false. Elapsed: 14.590577ms
Sep  4 16:01:49.515: INFO: Pod "pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016641336s
STEP: Saw pod success
Sep  4 16:01:49.515: INFO: Pod "pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca" satisfied condition "success or failure"
Sep  4 16:01:49.516: INFO: Trying to get logs from node 192.168.0.166 pod pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca container test-container: <nil>
STEP: delete the pod
Sep  4 16:01:49.555: INFO: Waiting for pod pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca to disappear
Sep  4 16:01:49.560: INFO: Pod pod-514d5921-0fac-4b5d-9fc7-f217f1ef7fca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:01:49.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6332" for this suite.
Sep  4 16:01:55.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:01:55.605: INFO: namespace emptydir-6332 deletion completed in 6.043598641s

• [SLOW TEST:8.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:01:55.605: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  4 16:01:55.658: INFO: Waiting up to 5m0s for pod "pod-cdbc2789-b709-4076-bf27-1ecfda36a94e" in namespace "emptydir-6269" to be "success or failure"
Sep  4 16:01:55.663: INFO: Pod "pod-cdbc2789-b709-4076-bf27-1ecfda36a94e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497749ms
Sep  4 16:01:57.664: INFO: Pod "pod-cdbc2789-b709-4076-bf27-1ecfda36a94e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006335847s
STEP: Saw pod success
Sep  4 16:01:57.664: INFO: Pod "pod-cdbc2789-b709-4076-bf27-1ecfda36a94e" satisfied condition "success or failure"
Sep  4 16:01:57.666: INFO: Trying to get logs from node 192.168.0.166 pod pod-cdbc2789-b709-4076-bf27-1ecfda36a94e container test-container: <nil>
STEP: delete the pod
Sep  4 16:01:57.675: INFO: Waiting for pod pod-cdbc2789-b709-4076-bf27-1ecfda36a94e to disappear
Sep  4 16:01:57.714: INFO: Pod pod-cdbc2789-b709-4076-bf27-1ecfda36a94e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:01:57.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6269" for this suite.
Sep  4 16:02:03.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:02:03.782: INFO: namespace emptydir-6269 deletion completed in 6.064955738s

• [SLOW TEST:8.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:02:03.783: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep  4 16:02:03.853: INFO: Waiting up to 5m0s for pod "var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20" in namespace "var-expansion-9217" to be "success or failure"
Sep  4 16:02:03.857: INFO: Pod "var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20": Phase="Pending", Reason="", readiness=false. Elapsed: 4.406983ms
Sep  4 16:02:05.859: INFO: Pod "var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00654335s
STEP: Saw pod success
Sep  4 16:02:05.859: INFO: Pod "var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20" satisfied condition "success or failure"
Sep  4 16:02:05.861: INFO: Trying to get logs from node 192.168.0.166 pod var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20 container dapi-container: <nil>
STEP: delete the pod
Sep  4 16:02:05.869: INFO: Waiting for pod var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20 to disappear
Sep  4 16:02:05.874: INFO: Pod var-expansion-a692ce5c-20d2-4089-97dd-ee2e5acfaf20 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:02:05.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9217" for this suite.
Sep  4 16:02:11.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:02:11.939: INFO: namespace var-expansion-9217 deletion completed in 6.062595063s

• [SLOW TEST:8.156 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:02:11.939: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7301.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7301.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 143.248.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.248.143_udp@PTR;check="$$(dig +tcp +noall +answer +search 143.248.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.248.143_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7301.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7301.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7301.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 143.248.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.248.143_udp@PTR;check="$$(dig +tcp +noall +answer +search 143.248.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.248.143_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 16:02:16.094: INFO: Unable to read wheezy_udp@dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.095: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.097: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.099: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.100: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.101: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.103: INFO: Unable to read wheezy_udp@PodARecord from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.104: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.109: INFO: Unable to read jessie_udp@dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.110: INFO: Unable to read jessie_tcp@dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.112: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.113: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local from pod dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33: the server could not find the requested resource (get pods dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33)
Sep  4 16:02:16.123: INFO: Lookups using dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33 failed for: [wheezy_udp@dns-test-service.dns-7301.svc.cluster.local wheezy_tcp@dns-test-service.dns-7301.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local wheezy_udp@_http._tcp.test-service-2.dns-7301.svc.cluster.local wheezy_tcp@_http._tcp.test-service-2.dns-7301.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-7301.svc.cluster.local jessie_tcp@dns-test-service.dns-7301.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7301.svc.cluster.local]

Sep  4 16:02:21.154: INFO: DNS probes using dns-7301/dns-test-30aa1fd6-1f54-4f6d-8f9f-c976a035eb33 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:02:21.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7301" for this suite.
Sep  4 16:02:27.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:02:27.374: INFO: namespace dns-7301 deletion completed in 6.046747704s

• [SLOW TEST:15.435 seconds]
[sig-network] DNS
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:02:27.374: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:02:27.469: INFO: Create a RollingUpdate DaemonSet
Sep  4 16:02:27.471: INFO: Check that daemon pods launch on every node of the cluster
Sep  4 16:02:27.480: INFO: Number of nodes with available pods: 0
Sep  4 16:02:27.480: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 16:02:28.485: INFO: Number of nodes with available pods: 0
Sep  4 16:02:28.485: INFO: Node 192.168.0.165 is running more than one daemon pod
Sep  4 16:02:29.493: INFO: Number of nodes with available pods: 2
Sep  4 16:02:29.493: INFO: Number of running nodes: 2, number of available pods: 2
Sep  4 16:02:29.493: INFO: Update the DaemonSet to trigger a rollout
Sep  4 16:02:29.497: INFO: Updating DaemonSet daemon-set
Sep  4 16:02:35.510: INFO: Roll back the DaemonSet before rollout is complete
Sep  4 16:02:35.513: INFO: Updating DaemonSet daemon-set
Sep  4 16:02:35.513: INFO: Make sure DaemonSet rollback is complete
Sep  4 16:02:35.521: INFO: Wrong image for pod: daemon-set-2jrlt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 16:02:35.521: INFO: Pod daemon-set-2jrlt is not available
Sep  4 16:02:36.530: INFO: Wrong image for pod: daemon-set-2jrlt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 16:02:36.530: INFO: Pod daemon-set-2jrlt is not available
Sep  4 16:02:37.530: INFO: Wrong image for pod: daemon-set-2jrlt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 16:02:37.530: INFO: Pod daemon-set-2jrlt is not available
Sep  4 16:02:38.530: INFO: Pod daemon-set-jr2kt is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9014, will wait for the garbage collector to delete the pods
Sep  4 16:02:38.589: INFO: Deleting DaemonSet.extensions daemon-set took: 2.884926ms
Sep  4 16:02:38.889: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.187052ms
Sep  4 16:02:40.991: INFO: Number of nodes with available pods: 0
Sep  4 16:02:40.991: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 16:02:40.992: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9014/daemonsets","resourceVersion":"17149"},"items":null}

Sep  4 16:02:40.993: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9014/pods","resourceVersion":"17149"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:02:40.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9014" for this suite.
Sep  4 16:02:47.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:02:47.060: INFO: namespace daemonsets-9014 deletion completed in 6.060737605s

• [SLOW TEST:19.686 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:02:47.061: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:02:47.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708" in namespace "projected-4151" to be "success or failure"
Sep  4 16:02:47.146: INFO: Pod "downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708": Phase="Pending", Reason="", readiness=false. Elapsed: 17.527434ms
Sep  4 16:02:49.148: INFO: Pod "downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019598357s
STEP: Saw pod success
Sep  4 16:02:49.148: INFO: Pod "downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708" satisfied condition "success or failure"
Sep  4 16:02:49.150: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708 container client-container: <nil>
STEP: delete the pod
Sep  4 16:02:49.162: INFO: Waiting for pod downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708 to disappear
Sep  4 16:02:49.167: INFO: Pod downwardapi-volume-e5cf2e1f-7b8c-4c39-b207-011d828e8708 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:02:49.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4151" for this suite.
Sep  4 16:02:55.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:02:55.214: INFO: namespace projected-4151 deletion completed in 6.045481527s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:02:55.215: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:02:55.298: INFO: Creating ReplicaSet my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e
Sep  4 16:02:55.310: INFO: Pod name my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e: Found 0 pods out of 1
Sep  4 16:03:00.312: INFO: Pod name my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e: Found 1 pods out of 1
Sep  4 16:03:00.312: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e" is running
Sep  4 16:03:00.313: INFO: Pod "my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e-k944f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 16:02:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 16:02:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 16:02:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 16:02:55 +0000 UTC Reason: Message:}])
Sep  4 16:03:00.313: INFO: Trying to dial the pod
Sep  4 16:03:05.319: INFO: Controller my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e: Got expected result from replica 1 [my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e-k944f]: "my-hostname-basic-c435350d-ea73-4d2c-a5d2-30612f9fdf5e-k944f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:03:05.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2116" for this suite.
Sep  4 16:03:11.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:03:11.371: INFO: namespace replicaset-2116 deletion completed in 6.049650961s

• [SLOW TEST:16.156 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:03:11.371: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  4 16:03:15.480: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 16:03:15.488: INFO: Pod pod-with-prestop-http-hook still exists
Sep  4 16:03:17.488: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 16:03:17.503: INFO: Pod pod-with-prestop-http-hook still exists
Sep  4 16:03:19.488: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 16:03:19.489: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:03:19.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5613" for this suite.
Sep  4 16:03:41.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:03:41.552: INFO: namespace container-lifecycle-hook-5613 deletion completed in 22.0557567s

• [SLOW TEST:30.181 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:03:41.552: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-32baa3b8-495e-42ac-9ff9-e45cf059d35b
STEP: Creating a pod to test consume configMaps
Sep  4 16:03:41.643: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057" in namespace "projected-5869" to be "success or failure"
Sep  4 16:03:41.662: INFO: Pod "pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057": Phase="Pending", Reason="", readiness=false. Elapsed: 18.117468ms
Sep  4 16:03:43.663: INFO: Pod "pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020042034s
STEP: Saw pod success
Sep  4 16:03:43.663: INFO: Pod "pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057" satisfied condition "success or failure"
Sep  4 16:03:43.665: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:03:43.703: INFO: Waiting for pod pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057 to disappear
Sep  4 16:03:43.705: INFO: Pod pod-projected-configmaps-44c08933-5355-4251-a047-3799dd77c057 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:03:43.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5869" for this suite.
Sep  4 16:03:49.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:03:49.761: INFO: namespace projected-5869 deletion completed in 6.053748318s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:03:49.761: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep  4 16:03:49.841: INFO: Waiting up to 5m0s for pod "client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e" in namespace "containers-3925" to be "success or failure"
Sep  4 16:03:49.848: INFO: Pod "client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.172551ms
Sep  4 16:03:51.852: INFO: Pod "client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010556106s
STEP: Saw pod success
Sep  4 16:03:51.852: INFO: Pod "client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e" satisfied condition "success or failure"
Sep  4 16:03:51.853: INFO: Trying to get logs from node 192.168.0.166 pod client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e container test-container: <nil>
STEP: delete the pod
Sep  4 16:03:51.901: INFO: Waiting for pod client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e to disappear
Sep  4 16:03:51.905: INFO: Pod client-containers-febf01f7-89c0-4d71-b842-56c46ae4a08e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:03:51.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3925" for this suite.
Sep  4 16:03:57.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:03:57.952: INFO: namespace containers-3925 deletion completed in 6.04427299s

• [SLOW TEST:8.191 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:03:57.952: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:04:02.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5039" for this suite.
Sep  4 16:04:08.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:04:08.110: INFO: namespace kubelet-test-5039 deletion completed in 6.06258167s

• [SLOW TEST:10.158 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:04:08.110: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-5b4af1b5-11d7-4ee0-b3fb-0fc21fe9285e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5b4af1b5-11d7-4ee0-b3fb-0fc21fe9285e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:04:12.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4070" for this suite.
Sep  4 16:04:34.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:04:34.310: INFO: namespace configmap-4070 deletion completed in 22.056653745s

• [SLOW TEST:26.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:04:34.310: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-xbgl
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 16:04:34.399: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xbgl" in namespace "subpath-6777" to be "success or failure"
Sep  4 16:04:34.417: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Pending", Reason="", readiness=false. Elapsed: 18.180962ms
Sep  4 16:04:36.419: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 2.020736358s
Sep  4 16:04:38.421: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 4.022608551s
Sep  4 16:04:40.423: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 6.024655202s
Sep  4 16:04:42.426: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 8.02765236s
Sep  4 16:04:44.428: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 10.029734396s
Sep  4 16:04:46.430: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 12.031793916s
Sep  4 16:04:48.432: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 14.033680559s
Sep  4 16:04:50.434: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 16.035645361s
Sep  4 16:04:52.436: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 18.03765903s
Sep  4 16:04:54.438: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Running", Reason="", readiness=true. Elapsed: 20.039766824s
Sep  4 16:04:56.441: INFO: Pod "pod-subpath-test-downwardapi-xbgl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.041985651s
STEP: Saw pod success
Sep  4 16:04:56.441: INFO: Pod "pod-subpath-test-downwardapi-xbgl" satisfied condition "success or failure"
Sep  4 16:04:56.442: INFO: Trying to get logs from node 192.168.0.166 pod pod-subpath-test-downwardapi-xbgl container test-container-subpath-downwardapi-xbgl: <nil>
STEP: delete the pod
Sep  4 16:04:56.469: INFO: Waiting for pod pod-subpath-test-downwardapi-xbgl to disappear
Sep  4 16:04:56.483: INFO: Pod pod-subpath-test-downwardapi-xbgl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xbgl
Sep  4 16:04:56.483: INFO: Deleting pod "pod-subpath-test-downwardapi-xbgl" in namespace "subpath-6777"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:04:56.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6777" for this suite.
Sep  4 16:05:02.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:05:02.580: INFO: namespace subpath-6777 deletion completed in 6.069359139s

• [SLOW TEST:28.270 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:05:02.580: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-m6gw
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 16:05:02.662: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-m6gw" in namespace "subpath-5172" to be "success or failure"
Sep  4 16:05:02.666: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.450266ms
Sep  4 16:05:04.668: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 2.006122554s
Sep  4 16:05:06.670: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 4.008127551s
Sep  4 16:05:08.672: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 6.009970443s
Sep  4 16:05:10.691: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 8.029339209s
Sep  4 16:05:12.693: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 10.031117461s
Sep  4 16:05:14.695: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 12.032887078s
Sep  4 16:05:16.737: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 14.075068797s
Sep  4 16:05:18.739: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 16.076780443s
Sep  4 16:05:20.741: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 18.079028266s
Sep  4 16:05:22.743: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Running", Reason="", readiness=true. Elapsed: 20.080900414s
Sep  4 16:05:24.745: INFO: Pod "pod-subpath-test-projected-m6gw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.082735829s
STEP: Saw pod success
Sep  4 16:05:24.745: INFO: Pod "pod-subpath-test-projected-m6gw" satisfied condition "success or failure"
Sep  4 16:05:24.746: INFO: Trying to get logs from node 192.168.0.166 pod pod-subpath-test-projected-m6gw container test-container-subpath-projected-m6gw: <nil>
STEP: delete the pod
Sep  4 16:05:24.759: INFO: Waiting for pod pod-subpath-test-projected-m6gw to disappear
Sep  4 16:05:24.769: INFO: Pod pod-subpath-test-projected-m6gw no longer exists
STEP: Deleting pod pod-subpath-test-projected-m6gw
Sep  4 16:05:24.769: INFO: Deleting pod "pod-subpath-test-projected-m6gw" in namespace "subpath-5172"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:05:24.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5172" for this suite.
Sep  4 16:05:30.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:05:30.817: INFO: namespace subpath-5172 deletion completed in 6.045011272s

• [SLOW TEST:28.237 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:05:30.818: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2628, will wait for the garbage collector to delete the pods
Sep  4 16:05:32.945: INFO: Deleting Job.batch foo took: 2.897969ms
Sep  4 16:05:33.245: INFO: Terminating Job.batch foo pods took: 300.13603ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:06:15.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2628" for this suite.
Sep  4 16:06:21.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:06:21.401: INFO: namespace job-2628 deletion completed in 6.052135245s

• [SLOW TEST:50.583 seconds]
[sig-apps] Job
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:06:21.401: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7722
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 16:06:21.446: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 16:06:39.593: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.166.161:8080/dial?request=hostName&protocol=http&host=172.30.166.157&port=8080&tries=1'] Namespace:pod-network-test-7722 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 16:06:39.593: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 16:06:40.675: INFO: Waiting for endpoints: map[]
Sep  4 16:06:40.677: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.166.161:8080/dial?request=hostName&protocol=http&host=172.30.135.142&port=8080&tries=1'] Namespace:pod-network-test-7722 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 16:06:40.677: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 16:06:40.756: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:06:40.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7722" for this suite.
Sep  4 16:07:02.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:07:02.813: INFO: namespace pod-network-test-7722 deletion completed in 22.052841293s

• [SLOW TEST:41.413 seconds]
[sig-network] Networking
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:07:02.814: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9433
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9433
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9433
Sep  4 16:07:02.908: INFO: Found 0 stateful pods, waiting for 1
Sep  4 16:07:12.926: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  4 16:07:12.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:07:13.082: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:07:13.082: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:07:13.082: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 16:07:13.084: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 16:07:23.087: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 16:07:23.087: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 16:07:23.097: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 16:07:23.097: INFO: ss-0  192.168.0.166  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  }]
Sep  4 16:07:23.097: INFO: 
Sep  4 16:07:23.097: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  4 16:07:24.100: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994213471s
Sep  4 16:07:25.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991394201s
Sep  4 16:07:26.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988751111s
Sep  4 16:07:27.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986219297s
Sep  4 16:07:28.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984163881s
Sep  4 16:07:29.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981931751s
Sep  4 16:07:30.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966176812s
Sep  4 16:07:31.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963829176s
Sep  4 16:07:32.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.611487ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9433
Sep  4 16:07:33.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 16:07:33.299: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 16:07:33.299: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 16:07:33.299: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 16:07:33.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 16:07:33.448: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  4 16:07:33.448: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 16:07:33.448: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 16:07:33.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 16:07:33.592: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  4 16:07:33.592: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 16:07:33.592: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 16:07:33.594: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  4 16:07:43.597: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 16:07:43.597: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 16:07:43.597: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  4 16:07:43.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:07:43.759: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:07:43.759: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:07:43.759: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 16:07:43.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:07:43.908: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:07:43.908: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:07:43.908: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 16:07:43.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-9433 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:07:44.074: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:07:44.074: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:07:44.074: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 16:07:44.074: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 16:07:44.076: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  4 16:07:54.080: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 16:07:54.080: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 16:07:54.080: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 16:07:54.092: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 16:07:54.092: INFO: ss-0  192.168.0.166  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  }]
Sep  4 16:07:54.092: INFO: ss-1  192.168.0.165  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  }]
Sep  4 16:07:54.092: INFO: ss-2  192.168.0.166  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  }]
Sep  4 16:07:54.092: INFO: 
Sep  4 16:07:54.092: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 16:07:55.103: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 16:07:55.103: INFO: ss-0  192.168.0.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:02 +0000 UTC  }]
Sep  4 16:07:55.103: INFO: ss-1  192.168.0.165  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  }]
Sep  4 16:07:55.103: INFO: ss-2  192.168.0.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 16:07:23 +0000 UTC  }]
Sep  4 16:07:55.103: INFO: 
Sep  4 16:07:55.103: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 16:07:56.105: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.979798177s
Sep  4 16:07:57.106: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.978241479s
Sep  4 16:07:58.108: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.976668699s
Sep  4 16:07:59.110: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.974659079s
Sep  4 16:08:00.112: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.973058205s
Sep  4 16:08:01.114: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.971104807s
Sep  4 16:08:02.125: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.969122616s
Sep  4 16:08:03.127: INFO: Verifying statefulset ss doesn't scale past 0 for another 957.589862ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9433
Sep  4 16:08:04.129: INFO: Scaling statefulset ss to 0
Sep  4 16:08:04.134: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 16:08:04.135: INFO: Deleting all statefulset in ns statefulset-9433
Sep  4 16:08:04.136: INFO: Scaling statefulset ss to 0
Sep  4 16:08:04.140: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 16:08:04.141: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:08:04.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9433" for this suite.
Sep  4 16:08:10.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:08:10.205: INFO: namespace statefulset-9433 deletion completed in 6.052557357s

• [SLOW TEST:67.391 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:08:10.205: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  4 16:08:10.294: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-resource-version,UID:1ff729a5-9c42-4841-b04b-867508e8438f,ResourceVersion:18369,Generation:0,CreationTimestamp:2019-09-04 16:08:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 16:08:10.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-resource-version,UID:1ff729a5-9c42-4841-b04b-867508e8438f,ResourceVersion:18370,Generation:0,CreationTimestamp:2019-09-04 16:08:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:08:10.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2277" for this suite.
Sep  4 16:08:16.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:08:16.353: INFO: namespace watch-2277 deletion completed in 6.054949094s

• [SLOW TEST:6.149 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:08:16.353: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vwdgm in namespace proxy-1559
I0904 16:08:16.447086      17 runners.go:180] Created replication controller with name: proxy-service-vwdgm, namespace: proxy-1559, replica count: 1
I0904 16:08:17.497399      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 16:08:18.497547      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:19.497697      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:20.497844      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:21.497972      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:22.498142      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:23.498281      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:24.498421      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:25.498572      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 16:08:26.498746      17 runners.go:180] proxy-service-vwdgm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 16:08:26.500: INFO: setup took 10.099220041s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  4 16:08:26.503: INFO: (0) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.927422ms)
Sep  4 16:08:26.503: INFO: (0) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.262125ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.808436ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.837729ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 3.82304ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.800384ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.78303ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.857324ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.90824ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.925761ms)
Sep  4 16:08:26.504: INFO: (0) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.93082ms)
Sep  4 16:08:26.509: INFO: (0) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 9.120766ms)
Sep  4 16:08:26.509: INFO: (0) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 9.326361ms)
Sep  4 16:08:26.510: INFO: (0) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 9.426054ms)
Sep  4 16:08:26.510: INFO: (0) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 9.436208ms)
Sep  4 16:08:26.510: INFO: (0) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 9.456703ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.039048ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.282661ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.418222ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.528545ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.573533ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.765919ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.741231ms)
Sep  4 16:08:26.512: INFO: (1) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.878212ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.889632ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.841418ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.910331ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.909847ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.901129ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.962061ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.72056ms)
Sep  4 16:08:26.513: INFO: (1) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.741608ms)
Sep  4 16:08:26.515: INFO: (2) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 1.598011ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.387469ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.826185ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.784105ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.736234ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.7735ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.76523ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.78198ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.861825ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.793182ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.825827ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.864245ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 2.922799ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.916864ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.929815ms)
Sep  4 16:08:26.516: INFO: (2) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.000647ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.233092ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.30572ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.359754ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.237442ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.506025ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.582161ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.649718ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.778352ms)
Sep  4 16:08:26.519: INFO: (3) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.823192ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.029623ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.026963ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.971351ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.028112ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.013295ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.993003ms)
Sep  4 16:08:26.520: INFO: (3) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.06995ms)
Sep  4 16:08:26.522: INFO: (4) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.279964ms)
Sep  4 16:08:26.522: INFO: (4) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.451921ms)
Sep  4 16:08:26.522: INFO: (4) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.58866ms)
Sep  4 16:08:26.522: INFO: (4) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.732335ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.080317ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.061367ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.080704ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.091671ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.155234ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.083006ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 3.139718ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.162833ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.207656ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 3.23852ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.182881ms)
Sep  4 16:08:26.523: INFO: (4) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.201331ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 1.936267ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.214526ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.36652ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.344702ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.353072ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.336127ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.362227ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.398351ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.396507ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.493753ms)
Sep  4 16:08:26.525: INFO: (5) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.541788ms)
Sep  4 16:08:26.526: INFO: (5) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.751011ms)
Sep  4 16:08:26.526: INFO: (5) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.996006ms)
Sep  4 16:08:26.526: INFO: (5) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.978688ms)
Sep  4 16:08:26.526: INFO: (5) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.027666ms)
Sep  4 16:08:26.526: INFO: (5) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.999596ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 1.979563ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.055728ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.158872ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.203956ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.333774ms)
Sep  4 16:08:26.528: INFO: (6) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.332408ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.335868ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.446893ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.432371ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.427093ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.418243ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.822183ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.902972ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 2.94662ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.941481ms)
Sep  4 16:08:26.529: INFO: (6) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.964139ms)
Sep  4 16:08:26.531: INFO: (7) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.09663ms)
Sep  4 16:08:26.531: INFO: (7) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.187277ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.473009ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.556623ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.50274ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.528566ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.503277ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.594415ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.536571ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.516102ms)
Sep  4 16:08:26.532: INFO: (7) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.168597ms)
Sep  4 16:08:26.533: INFO: (7) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.259023ms)
Sep  4 16:08:26.533: INFO: (7) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.278824ms)
Sep  4 16:08:26.533: INFO: (7) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.319581ms)
Sep  4 16:08:26.533: INFO: (7) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.250498ms)
Sep  4 16:08:26.533: INFO: (7) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.285177ms)
Sep  4 16:08:26.534: INFO: (8) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 1.720534ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.172187ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.174514ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.373409ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.346234ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.337033ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.386169ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.429425ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.443461ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 2.510311ms)
Sep  4 16:08:26.535: INFO: (8) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.473892ms)
Sep  4 16:08:26.536: INFO: (8) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.065148ms)
Sep  4 16:08:26.536: INFO: (8) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.112968ms)
Sep  4 16:08:26.536: INFO: (8) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.216369ms)
Sep  4 16:08:26.536: INFO: (8) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.187135ms)
Sep  4 16:08:26.536: INFO: (8) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.220124ms)
Sep  4 16:08:26.538: INFO: (9) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 1.725766ms)
Sep  4 16:08:26.538: INFO: (9) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 1.964256ms)
Sep  4 16:08:26.538: INFO: (9) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 1.995756ms)
Sep  4 16:08:26.539: INFO: (9) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.186653ms)
Sep  4 16:08:26.539: INFO: (9) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.12667ms)
Sep  4 16:08:26.539: INFO: (9) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.306057ms)
Sep  4 16:08:26.539: INFO: (9) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.265801ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.616659ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.674714ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.651871ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.604247ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.626484ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.671419ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.669796ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.694642ms)
Sep  4 16:08:26.540: INFO: (9) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 3.693929ms)
Sep  4 16:08:26.542: INFO: (10) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.639451ms)
Sep  4 16:08:26.542: INFO: (10) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.674981ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.963488ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.047075ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.07019ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.994481ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.172642ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 3.18445ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.142848ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.223828ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.250431ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.27435ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.285398ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.342011ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.264786ms)
Sep  4 16:08:26.543: INFO: (10) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.383437ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.951297ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.921129ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.90572ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.894105ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.008681ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.130408ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.15398ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.205583ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.147112ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 3.28002ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.271265ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.262969ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.284918ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.303695ms)
Sep  4 16:08:26.546: INFO: (11) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 3.338963ms)
Sep  4 16:08:26.547: INFO: (11) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.338833ms)
Sep  4 16:08:26.549: INFO: (12) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.599777ms)
Sep  4 16:08:26.549: INFO: (12) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.609496ms)
Sep  4 16:08:26.549: INFO: (12) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.779033ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.92222ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.060927ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.080077ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.116461ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.256098ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.220953ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.277411ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.406574ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.354884ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.408489ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.468967ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.532825ms)
Sep  4 16:08:26.550: INFO: (12) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.519497ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.446625ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.46264ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.474715ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.831944ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.045259ms)
Sep  4 16:08:26.553: INFO: (13) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.242959ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.323278ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.232758ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.22954ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.439335ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 3.42032ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.464517ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.590034ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.550402ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.609258ms)
Sep  4 16:08:26.554: INFO: (13) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.64699ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 6.945653ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 7.222445ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 7.206523ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 7.241222ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 7.261043ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 7.466475ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 7.469764ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 7.535631ms)
Sep  4 16:08:26.561: INFO: (14) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 7.513004ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 7.744566ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 8.058051ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 8.081134ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 8.195128ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 8.12569ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 8.208504ms)
Sep  4 16:08:26.562: INFO: (14) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 8.299455ms)
Sep  4 16:08:26.564: INFO: (15) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 1.704803ms)
Sep  4 16:08:26.564: INFO: (15) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.131456ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.265261ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.238865ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.583984ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.977104ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.962649ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.955943ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.077076ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.116428ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.238326ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.252431ms)
Sep  4 16:08:26.565: INFO: (15) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.218274ms)
Sep  4 16:08:26.566: INFO: (15) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 3.243953ms)
Sep  4 16:08:26.566: INFO: (15) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.257596ms)
Sep  4 16:08:26.566: INFO: (15) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.278671ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 1.955553ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.184315ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.149508ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 2.386561ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.609126ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.742912ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.729951ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.729311ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.78705ms)
Sep  4 16:08:26.568: INFO: (16) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.765924ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 2.877584ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.945548ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.983522ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 2.972432ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.003485ms)
Sep  4 16:08:26.569: INFO: (16) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.035269ms)
Sep  4 16:08:26.570: INFO: (17) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 1.658262ms)
Sep  4 16:08:26.571: INFO: (17) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.555454ms)
Sep  4 16:08:26.571: INFO: (17) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 2.622276ms)
Sep  4 16:08:26.571: INFO: (17) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.60989ms)
Sep  4 16:08:26.571: INFO: (17) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 2.561141ms)
Sep  4 16:08:26.571: INFO: (17) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.612482ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.835197ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.810797ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.878764ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.904474ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.939024ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 2.943163ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.007535ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.009873ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.060773ms)
Sep  4 16:08:26.572: INFO: (17) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.202228ms)
Sep  4 16:08:26.574: INFO: (18) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.302255ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.81513ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.849039ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 2.9574ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.991497ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.009326ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.001622ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 3.09597ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.135022ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.124581ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 3.11691ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.204658ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.17858ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 3.157725ms)
Sep  4 16:08:26.575: INFO: (18) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.214273ms)
Sep  4 16:08:26.576: INFO: (18) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.421784ms)
Sep  4 16:08:26.577: INFO: (19) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">... (200; 1.801227ms)
Sep  4 16:08:26.578: INFO: (19) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 2.172623ms)
Sep  4 16:08:26.578: INFO: (19) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:460/proxy/: tls baz (200; 2.24293ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname1/proxy/: foo (200; 2.839021ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 2.951497ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname2/proxy/: bar (200; 2.881426ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:462/proxy/: tls qux (200; 2.882797ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/http:proxy-service-vwdgm:portname1/proxy/: foo (200; 3.014116ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:1080/proxy/rewriteme">test<... (200; 2.999025ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk/proxy/rewriteme">test</a> (200; 3.014933ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/proxy-service-vwdgm-4xwkk:162/proxy/: bar (200; 3.130515ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname1/proxy/: tls baz (200; 3.119783ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/https:proxy-service-vwdgm:tlsportname2/proxy/: tls qux (200; 3.205659ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/http:proxy-service-vwdgm-4xwkk:160/proxy/: foo (200; 3.127537ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/services/proxy-service-vwdgm:portname2/proxy/: bar (200; 3.213459ms)
Sep  4 16:08:26.579: INFO: (19) /api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/: <a href="/api/v1/namespaces/proxy-1559/pods/https:proxy-service-vwdgm-4xwkk:443/proxy/tlsrewritem... (200; 3.293547ms)
STEP: deleting ReplicationController proxy-service-vwdgm in namespace proxy-1559, will wait for the garbage collector to delete the pods
Sep  4 16:08:26.633: INFO: Deleting ReplicationController proxy-service-vwdgm took: 2.686522ms
Sep  4 16:08:26.733: INFO: Terminating ReplicationController proxy-service-vwdgm pods took: 100.127996ms
[AfterEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:08:28.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1559" for this suite.
Sep  4 16:08:34.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:08:34.292: INFO: namespace proxy-1559 deletion completed in 6.055906491s

• [SLOW TEST:17.939 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:08:34.292: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5143
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 16:08:34.340: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 16:08:58.447: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.135.144 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5143 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 16:08:58.447: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 16:08:59.517: INFO: Found all expected endpoints: [netserver-0]
Sep  4 16:08:59.519: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.166.164 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5143 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 16:08:59.519: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
Sep  4 16:09:00.571: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:09:00.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5143" for this suite.
Sep  4 16:09:14.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:09:14.634: INFO: namespace pod-network-test-5143 deletion completed in 14.060517692s

• [SLOW TEST:40.341 seconds]
[sig-network] Networking
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:09:14.634: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:09:14.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 version'
Sep  4 16:09:14.782: INFO: stderr: ""
Sep  4 16:09:14.782: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.0\", GitCommit:\"e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529\", GitTreeState:\"clean\", BuildDate:\"2019-06-19T16:40:16Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.0\", GitCommit:\"e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529\", GitTreeState:\"clean\", BuildDate:\"2019-06-19T16:32:14Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:09:14.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8713" for this suite.
Sep  4 16:09:20.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:09:20.890: INFO: namespace kubectl-8713 deletion completed in 6.105922981s

• [SLOW TEST:6.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:09:20.890: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  4 16:09:20.955: INFO: Waiting up to 5m0s for pod "pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd" in namespace "emptydir-570" to be "success or failure"
Sep  4 16:09:20.962: INFO: Pod "pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.196248ms
Sep  4 16:09:22.964: INFO: Pod "pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008358846s
STEP: Saw pod success
Sep  4 16:09:22.964: INFO: Pod "pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd" satisfied condition "success or failure"
Sep  4 16:09:22.965: INFO: Trying to get logs from node 192.168.0.166 pod pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd container test-container: <nil>
STEP: delete the pod
Sep  4 16:09:23.023: INFO: Waiting for pod pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd to disappear
Sep  4 16:09:23.030: INFO: Pod pod-6465a8ea-5d27-4eaa-9460-52f220d4cddd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:09:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-570" for this suite.
Sep  4 16:09:29.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:09:29.077: INFO: namespace emptydir-570 deletion completed in 6.044885753s

• [SLOW TEST:8.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:09:29.077: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-ee0609e8-945c-49e5-b8d3-0cde14ddf8fe
STEP: Creating a pod to test consume configMaps
Sep  4 16:09:29.155: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf" in namespace "projected-4869" to be "success or failure"
Sep  4 16:09:29.172: INFO: Pod "pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.570705ms
Sep  4 16:09:31.174: INFO: Pod "pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018694199s
STEP: Saw pod success
Sep  4 16:09:31.174: INFO: Pod "pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf" satisfied condition "success or failure"
Sep  4 16:09:31.175: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:09:31.186: INFO: Waiting for pod pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf to disappear
Sep  4 16:09:31.211: INFO: Pod pod-projected-configmaps-089b4610-0729-407d-9dc7-58a3fcf261cf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:09:31.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4869" for this suite.
Sep  4 16:09:37.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:09:37.298: INFO: namespace projected-4869 deletion completed in 6.084760493s

• [SLOW TEST:8.221 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:09:37.298: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 in namespace container-probe-6780
Sep  4 16:09:39.398: INFO: Started pod liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 in namespace container-probe-6780
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 16:09:39.400: INFO: Initial restart count of pod liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is 0
Sep  4 16:09:55.416: INFO: Restart count of pod container-probe-6780/liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is now 1 (16.016695988s elapsed)
Sep  4 16:10:15.451: INFO: Restart count of pod container-probe-6780/liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is now 2 (36.051457263s elapsed)
Sep  4 16:10:35.476: INFO: Restart count of pod container-probe-6780/liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is now 3 (56.076775656s elapsed)
Sep  4 16:10:55.508: INFO: Restart count of pod container-probe-6780/liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is now 4 (1m16.108201295s elapsed)
Sep  4 16:12:07.631: INFO: Restart count of pod container-probe-6780/liveness-6e60a7fe-6235-4002-aad5-5b2c362cd763 is now 5 (2m28.23123425s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:12:07.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6780" for this suite.
Sep  4 16:12:13.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:12:13.711: INFO: namespace container-probe-6780 deletion completed in 6.050316217s

• [SLOW TEST:156.413 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:12:13.712: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:12:13.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1649" for this suite.
Sep  4 16:12:35.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:12:35.885: INFO: namespace pods-1649 deletion completed in 22.109924482s

• [SLOW TEST:22.174 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:12:35.885: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:12:35.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e" in namespace "projected-2309" to be "success or failure"
Sep  4 16:12:36.004: INFO: Pod "downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.29411ms
Sep  4 16:12:38.006: INFO: Pod "downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018759503s
STEP: Saw pod success
Sep  4 16:12:38.006: INFO: Pod "downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e" satisfied condition "success or failure"
Sep  4 16:12:38.008: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e container client-container: <nil>
STEP: delete the pod
Sep  4 16:12:38.022: INFO: Waiting for pod downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e to disappear
Sep  4 16:12:38.026: INFO: Pod downwardapi-volume-33ddc156-c746-4dea-956b-a02d39385a6e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:12:38.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2309" for this suite.
Sep  4 16:12:44.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:12:44.076: INFO: namespace projected-2309 deletion completed in 6.04761783s

• [SLOW TEST:8.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:12:44.077: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:12:44.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9" in namespace "downward-api-9577" to be "success or failure"
Sep  4 16:12:44.175: INFO: Pod "downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078699ms
Sep  4 16:12:46.196: INFO: Pod "downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024372074s
STEP: Saw pod success
Sep  4 16:12:46.196: INFO: Pod "downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9" satisfied condition "success or failure"
Sep  4 16:12:46.204: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9 container client-container: <nil>
STEP: delete the pod
Sep  4 16:12:46.216: INFO: Waiting for pod downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9 to disappear
Sep  4 16:12:46.235: INFO: Pod downwardapi-volume-1400e82f-d04c-48dd-a516-7232da9f20f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:12:46.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9577" for this suite.
Sep  4 16:12:52.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:12:52.285: INFO: namespace downward-api-9577 deletion completed in 6.047201513s

• [SLOW TEST:8.208 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:12:52.285: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 16:12:52.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2777'
Sep  4 16:12:52.471: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 16:12:52.471: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  4 16:12:52.517: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cdrxg]
Sep  4 16:12:52.517: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cdrxg" in namespace "kubectl-2777" to be "running and ready"
Sep  4 16:12:52.519: INFO: Pod "e2e-test-nginx-rc-cdrxg": Phase="Pending", Reason="", readiness=false. Elapsed: 1.696694ms
Sep  4 16:12:54.521: INFO: Pod "e2e-test-nginx-rc-cdrxg": Phase="Running", Reason="", readiness=true. Elapsed: 2.003672086s
Sep  4 16:12:54.521: INFO: Pod "e2e-test-nginx-rc-cdrxg" satisfied condition "running and ready"
Sep  4 16:12:54.521: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cdrxg]
Sep  4 16:12:54.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 logs rc/e2e-test-nginx-rc --namespace=kubectl-2777'
Sep  4 16:12:54.607: INFO: stderr: ""
Sep  4 16:12:54.607: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep  4 16:12:54.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete rc e2e-test-nginx-rc --namespace=kubectl-2777'
Sep  4 16:12:54.686: INFO: stderr: ""
Sep  4 16:12:54.686: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:12:54.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2777" for this suite.
Sep  4 16:13:16.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:13:16.738: INFO: namespace kubectl-2777 deletion completed in 22.049802742s

• [SLOW TEST:24.453 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:13:16.738: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 16:13:16.817: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 16:13:16.841: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 16:13:16.843: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.165 before test
Sep  4 16:13:16.848: INFO: default-http-backend-7f744bb697-nkz9c from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  4 16:13:16.848: INFO: ckecsi-provisioner-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 16:13:16.848: INFO: nginx-ingress-controller-slhvq from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  4 16:13:16.848: INFO: ckecsi-8lpfb from default started at 2019-09-04 14:44:58 +0000 UTC (2 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 16:13:16.848: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 16:13:16.848: INFO: kubernetes-dashboard-5cd5576947-pplbs from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  4 16:13:16.848: INFO: sonobuoy-e2e-job-57060aab3bac4fe0 from heptio-sonobuoy started at 2019-09-04 15:05:14 +0000 UTC (2 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container e2e ready: true, restart count 0
Sep  4 16:13:16.848: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 16:13:16.848: INFO: calico-kube-controllers-568647f5b9-n6xm7 from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 16:13:16.848: INFO: coredns-55d8c6f4f-h7pxd from kube-system started at 2019-09-04 14:44:59 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container coredns ready: true, restart count 0
Sep  4 16:13:16.848: INFO: ckecsi-attacher-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.848: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep  4 16:13:16.848: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.166 before test
Sep  4 16:13:16.851: INFO: ckecsi-ks4dd from default started at 2019-09-04 14:45:05 +0000 UTC (2 container statuses recorded)
Sep  4 16:13:16.851: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 16:13:16.851: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 16:13:16.851: INFO: ckecsi-provisioner-1 from default started at 2019-09-04 14:46:43 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.851: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 16:13:16.851: INFO: ckecsi-attacher-1 from default started at 2019-09-04 14:46:48 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.851: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep  4 16:13:16.851: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 15:05:11 +0000 UTC (1 container statuses recorded)
Sep  4 16:13:16.851: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-414efa80-d722-4c86-9c8d-543a4496899e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-414efa80-d722-4c86-9c8d-543a4496899e off the node 192.168.0.166
STEP: verifying the node doesn't have the label kubernetes.io/e2e-414efa80-d722-4c86-9c8d-543a4496899e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:13:20.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5514" for this suite.
Sep  4 16:13:28.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:13:29.022: INFO: namespace sched-pred-5514 deletion completed in 8.061783604s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.284 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:13:29.022: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3753
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep  4 16:13:29.130: INFO: Found 0 stateful pods, waiting for 3
Sep  4 16:13:39.133: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 16:13:39.133: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 16:13:39.133: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 16:13:39.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-3753 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:13:39.318: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:13:39.318: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:13:39.318: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  4 16:13:49.339: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  4 16:13:59.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-3753 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 16:13:59.520: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 16:13:59.520: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 16:13:59.520: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 16:14:09.531: INFO: Waiting for StatefulSet statefulset-3753/ss2 to complete update
Sep  4 16:14:09.531: INFO: Waiting for Pod statefulset-3753/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep  4 16:14:19.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-3753 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 16:14:19.699: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 16:14:19.699: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 16:14:19.699: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 16:14:29.720: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  4 16:14:39.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 exec --namespace=statefulset-3753 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 16:14:39.908: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 16:14:39.908: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 16:14:39.908: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 16:14:39.985: INFO: Waiting for StatefulSet statefulset-3753/ss2 to complete update
Sep  4 16:14:39.985: INFO: Waiting for Pod statefulset-3753/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 16:14:39.985: INFO: Waiting for Pod statefulset-3753/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 16:14:39.985: INFO: Waiting for Pod statefulset-3753/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 16:14:49.990: INFO: Waiting for StatefulSet statefulset-3753/ss2 to complete update
Sep  4 16:14:49.990: INFO: Waiting for Pod statefulset-3753/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 16:14:49.990: INFO: Waiting for Pod statefulset-3753/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 16:14:59.989: INFO: Deleting all statefulset in ns statefulset-3753
Sep  4 16:14:59.990: INFO: Scaling statefulset ss2 to 0
Sep  4 16:15:10.014: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 16:15:10.015: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:15:10.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3753" for this suite.
Sep  4 16:15:16.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:15:16.085: INFO: namespace statefulset-3753 deletion completed in 6.057263819s

• [SLOW TEST:107.063 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:15:16.085: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-d2760437-af41-4ede-8fa6-e14d2a3965b5 in namespace container-probe-2563
Sep  4 16:15:18.184: INFO: Started pod busybox-d2760437-af41-4ede-8fa6-e14d2a3965b5 in namespace container-probe-2563
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 16:15:18.186: INFO: Initial restart count of pod busybox-d2760437-af41-4ede-8fa6-e14d2a3965b5 is 0
Sep  4 16:16:04.232: INFO: Restart count of pod container-probe-2563/busybox-d2760437-af41-4ede-8fa6-e14d2a3965b5 is now 1 (46.046230873s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:16:04.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2563" for this suite.
Sep  4 16:16:10.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:16:10.318: INFO: namespace container-probe-2563 deletion completed in 6.052301769s

• [SLOW TEST:54.232 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:16:10.318: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:16:10.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379" in namespace "projected-3457" to be "success or failure"
Sep  4 16:16:10.406: INFO: Pod "downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379": Phase="Pending", Reason="", readiness=false. Elapsed: 14.645826ms
Sep  4 16:16:12.408: INFO: Pod "downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016901253s
STEP: Saw pod success
Sep  4 16:16:12.408: INFO: Pod "downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379" satisfied condition "success or failure"
Sep  4 16:16:12.410: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379 container client-container: <nil>
STEP: delete the pod
Sep  4 16:16:12.426: INFO: Waiting for pod downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379 to disappear
Sep  4 16:16:12.430: INFO: Pod downwardapi-volume-1ceca8eb-ed93-4473-bfba-d8de07e4e379 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:16:12.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3457" for this suite.
Sep  4 16:16:18.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:16:18.486: INFO: namespace projected-3457 deletion completed in 6.053469275s

• [SLOW TEST:8.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:16:18.486: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-8703
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8703
STEP: Deleting pre-stop pod
Sep  4 16:16:27.586: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:16:27.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8703" for this suite.
Sep  4 16:17:05.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:17:05.649: INFO: namespace prestop-8703 deletion completed in 38.051761835s

• [SLOW TEST:47.163 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:17:05.649: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:17:05.725: INFO: (0) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 7.013549ms)
Sep  4 16:17:05.726: INFO: (1) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.834445ms)
Sep  4 16:17:05.728: INFO: (2) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.637958ms)
Sep  4 16:17:05.730: INFO: (3) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.589382ms)
Sep  4 16:17:05.731: INFO: (4) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.668073ms)
Sep  4 16:17:05.733: INFO: (5) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.641953ms)
Sep  4 16:17:05.735: INFO: (6) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.609744ms)
Sep  4 16:17:05.736: INFO: (7) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.546925ms)
Sep  4 16:17:05.738: INFO: (8) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.596297ms)
Sep  4 16:17:05.740: INFO: (9) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.699295ms)
Sep  4 16:17:05.741: INFO: (10) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.527583ms)
Sep  4 16:17:05.743: INFO: (11) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.539902ms)
Sep  4 16:17:05.744: INFO: (12) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.657383ms)
Sep  4 16:17:05.746: INFO: (13) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.596443ms)
Sep  4 16:17:05.748: INFO: (14) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.686537ms)
Sep  4 16:17:05.749: INFO: (15) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.568419ms)
Sep  4 16:17:05.751: INFO: (16) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.532615ms)
Sep  4 16:17:05.753: INFO: (17) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.718017ms)
Sep  4 16:17:05.754: INFO: (18) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.64388ms)
Sep  4 16:17:05.756: INFO: (19) /api/v1/nodes/192.168.0.165:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.640159ms)
[AfterEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:17:05.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6042" for this suite.
Sep  4 16:17:11.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:17:11.830: INFO: namespace proxy-6042 deletion completed in 6.072213344s

• [SLOW TEST:6.181 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:17:11.830: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:18:11.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4111" for this suite.
Sep  4 16:18:33.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:18:33.954: INFO: namespace container-probe-4111 deletion completed in 22.054376747s

• [SLOW TEST:82.124 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:18:33.954: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 16:18:34.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3689'
Sep  4 16:18:34.094: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 16:18:34.094: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep  4 16:18:34.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete jobs e2e-test-nginx-job --namespace=kubectl-3689'
Sep  4 16:18:34.195: INFO: stderr: ""
Sep  4 16:18:34.195: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:18:34.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3689" for this suite.
Sep  4 16:18:40.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:18:40.258: INFO: namespace kubectl-3689 deletion completed in 6.061355708s

• [SLOW TEST:6.304 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:18:40.258: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 16:18:40.393: INFO: Waiting up to 5m0s for pod "downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00" in namespace "downward-api-119" to be "success or failure"
Sep  4 16:18:40.409: INFO: Pod "downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00": Phase="Pending", Reason="", readiness=false. Elapsed: 15.481952ms
Sep  4 16:18:42.427: INFO: Pod "downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03347409s
STEP: Saw pod success
Sep  4 16:18:42.427: INFO: Pod "downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00" satisfied condition "success or failure"
Sep  4 16:18:42.451: INFO: Trying to get logs from node 192.168.0.166 pod downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00 container dapi-container: <nil>
STEP: delete the pod
Sep  4 16:18:42.482: INFO: Waiting for pod downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00 to disappear
Sep  4 16:18:42.489: INFO: Pod downward-api-5a75ee5c-90f8-45ce-bb6a-baddd3320e00 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:18:42.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-119" for this suite.
Sep  4 16:18:48.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:18:48.536: INFO: namespace downward-api-119 deletion completed in 6.045220256s

• [SLOW TEST:8.278 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:18:48.537: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep  4 16:18:48.603: INFO: Waiting up to 5m0s for pod "client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b" in namespace "containers-2741" to be "success or failure"
Sep  4 16:18:48.619: INFO: Pod "client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.578458ms
Sep  4 16:18:50.621: INFO: Pod "client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018447755s
STEP: Saw pod success
Sep  4 16:18:50.621: INFO: Pod "client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b" satisfied condition "success or failure"
Sep  4 16:18:50.623: INFO: Trying to get logs from node 192.168.0.166 pod client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b container test-container: <nil>
STEP: delete the pod
Sep  4 16:18:50.647: INFO: Waiting for pod client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b to disappear
Sep  4 16:18:50.655: INFO: Pod client-containers-0cec67fa-81db-44c4-97e9-d4ead49b416b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:18:50.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2741" for this suite.
Sep  4 16:18:56.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:18:56.701: INFO: namespace containers-2741 deletion completed in 6.043843548s

• [SLOW TEST:8.165 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:18:56.701: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:18:56.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622" in namespace "downward-api-9009" to be "success or failure"
Sep  4 16:18:56.767: INFO: Pod "downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622": Phase="Pending", Reason="", readiness=false. Elapsed: 13.805318ms
Sep  4 16:18:58.769: INFO: Pod "downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015805778s
STEP: Saw pod success
Sep  4 16:18:58.769: INFO: Pod "downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622" satisfied condition "success or failure"
Sep  4 16:18:58.771: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622 container client-container: <nil>
STEP: delete the pod
Sep  4 16:18:58.788: INFO: Waiting for pod downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622 to disappear
Sep  4 16:18:58.811: INFO: Pod downwardapi-volume-61dc8adb-b39b-4bb2-829b-c2cda0460622 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:18:58.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9009" for this suite.
Sep  4 16:19:04.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:19:04.862: INFO: namespace downward-api-9009 deletion completed in 6.049114528s

• [SLOW TEST:8.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:19:04.862: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8682
I0904 16:19:04.941688      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8682, replica count: 1
I0904 16:19:05.991952      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 16:19:06.992097      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 16:19:07.108: INFO: Created: latency-svc-zjmdc
Sep  4 16:19:07.113: INFO: Got endpoints: latency-svc-zjmdc [20.888589ms]
Sep  4 16:19:07.137: INFO: Created: latency-svc-lnwbc
Sep  4 16:19:07.171: INFO: Got endpoints: latency-svc-lnwbc [58.404986ms]
Sep  4 16:19:07.172: INFO: Created: latency-svc-bvxlh
Sep  4 16:19:07.182: INFO: Got endpoints: latency-svc-bvxlh [68.796213ms]
Sep  4 16:19:07.217: INFO: Created: latency-svc-2flqm
Sep  4 16:19:07.234: INFO: Got endpoints: latency-svc-2flqm [121.399506ms]
Sep  4 16:19:07.251: INFO: Created: latency-svc-p592z
Sep  4 16:19:07.256: INFO: Got endpoints: latency-svc-p592z [143.040253ms]
Sep  4 16:19:07.297: INFO: Created: latency-svc-xwr42
Sep  4 16:19:07.320: INFO: Got endpoints: latency-svc-xwr42 [207.088386ms]
Sep  4 16:19:07.320: INFO: Created: latency-svc-7pwsg
Sep  4 16:19:07.324: INFO: Got endpoints: latency-svc-7pwsg [211.543801ms]
Sep  4 16:19:07.343: INFO: Created: latency-svc-8kwj8
Sep  4 16:19:07.347: INFO: Got endpoints: latency-svc-8kwj8 [234.474467ms]
Sep  4 16:19:07.366: INFO: Created: latency-svc-fnqdn
Sep  4 16:19:07.370: INFO: Got endpoints: latency-svc-fnqdn [257.374859ms]
Sep  4 16:19:07.389: INFO: Created: latency-svc-nfc8k
Sep  4 16:19:07.393: INFO: Got endpoints: latency-svc-nfc8k [280.563089ms]
Sep  4 16:19:07.434: INFO: Created: latency-svc-l6dxr
Sep  4 16:19:07.458: INFO: Created: latency-svc-ksph4
Sep  4 16:19:07.458: INFO: Got endpoints: latency-svc-l6dxr [344.973552ms]
Sep  4 16:19:07.462: INFO: Got endpoints: latency-svc-ksph4 [349.11928ms]
Sep  4 16:19:07.487: INFO: Created: latency-svc-cnf2x
Sep  4 16:19:07.491: INFO: Got endpoints: latency-svc-cnf2x [377.956096ms]
Sep  4 16:19:07.509: INFO: Created: latency-svc-h8m2w
Sep  4 16:19:07.514: INFO: Got endpoints: latency-svc-h8m2w [400.678059ms]
Sep  4 16:19:07.560: INFO: Created: latency-svc-w25f4
Sep  4 16:19:07.584: INFO: Got endpoints: latency-svc-w25f4 [470.776483ms]
Sep  4 16:19:07.584: INFO: Created: latency-svc-844b6
Sep  4 16:19:07.588: INFO: Got endpoints: latency-svc-844b6 [474.705225ms]
Sep  4 16:19:07.607: INFO: Created: latency-svc-pncsr
Sep  4 16:19:07.611: INFO: Got endpoints: latency-svc-pncsr [439.509083ms]
Sep  4 16:19:07.630: INFO: Created: latency-svc-cgh44
Sep  4 16:19:07.634: INFO: Got endpoints: latency-svc-cgh44 [452.047877ms]
Sep  4 16:19:07.653: INFO: Created: latency-svc-ncvjm
Sep  4 16:19:07.656: INFO: Got endpoints: latency-svc-ncvjm [422.261959ms]
Sep  4 16:19:07.702: INFO: Created: latency-svc-t9zmm
Sep  4 16:19:07.721: INFO: Got endpoints: latency-svc-t9zmm [465.543577ms]
Sep  4 16:19:07.722: INFO: Created: latency-svc-cchl7
Sep  4 16:19:07.744: INFO: Got endpoints: latency-svc-cchl7 [424.297549ms]
Sep  4 16:19:07.768: INFO: Created: latency-svc-g9lf5
Sep  4 16:19:07.777: INFO: Got endpoints: latency-svc-g9lf5 [452.243575ms]
Sep  4 16:19:07.796: INFO: Created: latency-svc-sdpws
Sep  4 16:19:07.842: INFO: Got endpoints: latency-svc-sdpws [494.952662ms]
Sep  4 16:19:07.843: INFO: Created: latency-svc-9jl46
Sep  4 16:19:07.865: INFO: Got endpoints: latency-svc-9jl46 [494.419737ms]
Sep  4 16:19:07.888: INFO: Created: latency-svc-cft6v
Sep  4 16:19:07.897: INFO: Got endpoints: latency-svc-cft6v [503.391462ms]
Sep  4 16:19:07.917: INFO: Created: latency-svc-fj46p
Sep  4 16:19:07.926: INFO: Got endpoints: latency-svc-fj46p [467.70714ms]
Sep  4 16:19:07.965: INFO: Created: latency-svc-sk5qp
Sep  4 16:19:07.986: INFO: Got endpoints: latency-svc-sk5qp [523.605653ms]
Sep  4 16:19:07.986: INFO: Created: latency-svc-csqbz
Sep  4 16:19:07.994: INFO: Got endpoints: latency-svc-csqbz [503.285902ms]
Sep  4 16:19:08.014: INFO: Created: latency-svc-lrznm
Sep  4 16:19:08.023: INFO: Got endpoints: latency-svc-lrznm [509.234998ms]
Sep  4 16:19:08.043: INFO: Created: latency-svc-w54dx
Sep  4 16:19:08.106: INFO: Got endpoints: latency-svc-w54dx [522.476447ms]
Sep  4 16:19:08.107: INFO: Created: latency-svc-sms9t
Sep  4 16:19:08.114: INFO: Got endpoints: latency-svc-sms9t [526.532155ms]
Sep  4 16:19:08.134: INFO: Created: latency-svc-cghd9
Sep  4 16:19:08.143: INFO: Got endpoints: latency-svc-cghd9 [532.026984ms]
Sep  4 16:19:08.163: INFO: Created: latency-svc-wqhnc
Sep  4 16:19:08.171: INFO: Got endpoints: latency-svc-wqhnc [537.831323ms]
Sep  4 16:19:08.192: INFO: Created: latency-svc-srlvs
Sep  4 16:19:08.200: INFO: Got endpoints: latency-svc-srlvs [543.722388ms]
Sep  4 16:19:08.245: INFO: Created: latency-svc-gjbd4
Sep  4 16:19:08.266: INFO: Got endpoints: latency-svc-gjbd4 [544.570441ms]
Sep  4 16:19:08.266: INFO: Created: latency-svc-g7l7g
Sep  4 16:19:08.274: INFO: Got endpoints: latency-svc-g7l7g [530.058542ms]
Sep  4 16:19:08.295: INFO: Created: latency-svc-2dmzf
Sep  4 16:19:08.303: INFO: Got endpoints: latency-svc-2dmzf [526.206141ms]
Sep  4 16:19:08.323: INFO: Created: latency-svc-zzpwz
Sep  4 16:19:08.332: INFO: Got endpoints: latency-svc-zzpwz [489.210948ms]
Sep  4 16:19:08.377: INFO: Created: latency-svc-xgkft
Sep  4 16:19:08.398: INFO: Created: latency-svc-h5z5m
Sep  4 16:19:08.398: INFO: Got endpoints: latency-svc-xgkft [533.443602ms]
Sep  4 16:19:08.415: INFO: Got endpoints: latency-svc-h5z5m [518.173232ms]
Sep  4 16:19:08.432: INFO: Created: latency-svc-fg9tl
Sep  4 16:19:08.440: INFO: Got endpoints: latency-svc-fg9tl [514.871158ms]
Sep  4 16:19:08.455: INFO: Created: latency-svc-jggjg
Sep  4 16:19:08.463: INFO: Got endpoints: latency-svc-jggjg [477.742947ms]
Sep  4 16:19:08.497: INFO: Created: latency-svc-n4p2k
Sep  4 16:19:08.512: INFO: Got endpoints: latency-svc-n4p2k [518.252251ms]
Sep  4 16:19:08.513: INFO: Created: latency-svc-f8p9t
Sep  4 16:19:08.521: INFO: Got endpoints: latency-svc-f8p9t [497.770512ms]
Sep  4 16:19:08.536: INFO: Created: latency-svc-dx9dw
Sep  4 16:19:08.544: INFO: Got endpoints: latency-svc-dx9dw [437.484325ms]
Sep  4 16:19:08.559: INFO: Created: latency-svc-nphvv
Sep  4 16:19:08.576: INFO: Got endpoints: latency-svc-nphvv [461.614973ms]
Sep  4 16:19:08.593: INFO: Created: latency-svc-95qhg
Sep  4 16:19:08.639: INFO: Got endpoints: latency-svc-95qhg [496.418559ms]
Sep  4 16:19:08.640: INFO: Created: latency-svc-7b7qj
Sep  4 16:19:08.646: INFO: Got endpoints: latency-svc-7b7qj [474.931786ms]
Sep  4 16:19:08.662: INFO: Created: latency-svc-kt75q
Sep  4 16:19:08.669: INFO: Got endpoints: latency-svc-kt75q [469.012298ms]
Sep  4 16:19:08.685: INFO: Created: latency-svc-p9w8l
Sep  4 16:19:08.692: INFO: Got endpoints: latency-svc-p9w8l [426.149766ms]
Sep  4 16:19:08.708: INFO: Created: latency-svc-bjck4
Sep  4 16:19:08.715: INFO: Got endpoints: latency-svc-bjck4 [440.782407ms]
Sep  4 16:19:08.731: INFO: Created: latency-svc-cnt5c
Sep  4 16:19:08.738: INFO: Got endpoints: latency-svc-cnt5c [435.136417ms]
Sep  4 16:19:08.783: INFO: Created: latency-svc-dw9t4
Sep  4 16:19:08.800: INFO: Created: latency-svc-zdpcn
Sep  4 16:19:08.800: INFO: Got endpoints: latency-svc-dw9t4 [468.176611ms]
Sep  4 16:19:08.807: INFO: Got endpoints: latency-svc-zdpcn [408.49717ms]
Sep  4 16:19:08.822: INFO: Created: latency-svc-q9npw
Sep  4 16:19:08.830: INFO: Got endpoints: latency-svc-q9npw [414.846177ms]
Sep  4 16:19:08.846: INFO: Created: latency-svc-h7jnz
Sep  4 16:19:08.853: INFO: Got endpoints: latency-svc-h7jnz [412.670577ms]
Sep  4 16:19:08.874: INFO: Created: latency-svc-vcwds
Sep  4 16:19:08.882: INFO: Got endpoints: latency-svc-vcwds [418.319466ms]
Sep  4 16:19:08.954: INFO: Created: latency-svc-5kddx
Sep  4 16:19:08.971: INFO: Got endpoints: latency-svc-5kddx [458.72418ms]
Sep  4 16:19:08.971: INFO: Created: latency-svc-7dsts
Sep  4 16:19:08.988: INFO: Got endpoints: latency-svc-7dsts [467.713489ms]
Sep  4 16:19:09.012: INFO: Created: latency-svc-w5x2c
Sep  4 16:19:09.019: INFO: Got endpoints: latency-svc-w5x2c [475.297695ms]
Sep  4 16:19:09.035: INFO: Created: latency-svc-trmvd
Sep  4 16:19:09.042: INFO: Got endpoints: latency-svc-trmvd [465.879593ms]
Sep  4 16:19:09.104: INFO: Created: latency-svc-w2k9n
Sep  4 16:19:09.109: INFO: Got endpoints: latency-svc-w2k9n [469.755313ms]
Sep  4 16:19:09.126: INFO: Created: latency-svc-vxgnd
Sep  4 16:19:09.133: INFO: Got endpoints: latency-svc-vxgnd [486.559553ms]
Sep  4 16:19:09.149: INFO: Created: latency-svc-7dcf5
Sep  4 16:19:09.156: INFO: Got endpoints: latency-svc-7dcf5 [486.606381ms]
Sep  4 16:19:09.172: INFO: Created: latency-svc-lvcb8
Sep  4 16:19:09.179: INFO: Got endpoints: latency-svc-lvcb8 [486.603204ms]
Sep  4 16:19:09.195: INFO: Created: latency-svc-zdcfq
Sep  4 16:19:09.202: INFO: Got endpoints: latency-svc-zdcfq [486.45652ms]
Sep  4 16:19:09.251: INFO: Created: latency-svc-q4dlr
Sep  4 16:19:09.270: INFO: Got endpoints: latency-svc-q4dlr [531.661084ms]
Sep  4 16:19:09.270: INFO: Created: latency-svc-nhg6g
Sep  4 16:19:09.276: INFO: Got endpoints: latency-svc-nhg6g [476.395552ms]
Sep  4 16:19:09.292: INFO: Created: latency-svc-bkvkq
Sep  4 16:19:09.299: INFO: Got endpoints: latency-svc-bkvkq [492.315175ms]
Sep  4 16:19:09.316: INFO: Created: latency-svc-ppd6w
Sep  4 16:19:09.322: INFO: Got endpoints: latency-svc-ppd6w [492.018457ms]
Sep  4 16:19:09.339: INFO: Created: latency-svc-pmlfx
Sep  4 16:19:09.346: INFO: Got endpoints: latency-svc-pmlfx [492.297607ms]
Sep  4 16:19:09.394: INFO: Created: latency-svc-jdvgv
Sep  4 16:19:09.413: INFO: Got endpoints: latency-svc-jdvgv [531.306697ms]
Sep  4 16:19:09.413: INFO: Created: latency-svc-bv5h7
Sep  4 16:19:09.420: INFO: Got endpoints: latency-svc-bv5h7 [448.35618ms]
Sep  4 16:19:09.442: INFO: Created: latency-svc-qb5pv
Sep  4 16:19:09.448: INFO: Got endpoints: latency-svc-qb5pv [459.95842ms]
Sep  4 16:19:09.465: INFO: Created: latency-svc-px5hj
Sep  4 16:19:09.482: INFO: Got endpoints: latency-svc-px5hj [462.950478ms]
Sep  4 16:19:09.551: INFO: Created: latency-svc-vs6qk
Sep  4 16:19:09.557: INFO: Got endpoints: latency-svc-vs6qk [514.808299ms]
Sep  4 16:19:09.574: INFO: Created: latency-svc-6qm78
Sep  4 16:19:09.586: INFO: Got endpoints: latency-svc-6qm78 [476.776827ms]
Sep  4 16:19:09.603: INFO: Created: latency-svc-b5bn6
Sep  4 16:19:09.608: INFO: Got endpoints: latency-svc-b5bn6 [475.079552ms]
Sep  4 16:19:09.626: INFO: Created: latency-svc-8hf6t
Sep  4 16:19:09.631: INFO: Got endpoints: latency-svc-8hf6t [475.185581ms]
Sep  4 16:19:09.680: INFO: Created: latency-svc-z7rqf
Sep  4 16:19:09.701: INFO: Got endpoints: latency-svc-z7rqf [521.680491ms]
Sep  4 16:19:09.701: INFO: Created: latency-svc-vjdnq
Sep  4 16:19:09.705: INFO: Got endpoints: latency-svc-vjdnq [503.670646ms]
Sep  4 16:19:09.723: INFO: Created: latency-svc-82mr8
Sep  4 16:19:09.728: INFO: Got endpoints: latency-svc-82mr8 [458.378987ms]
Sep  4 16:19:09.746: INFO: Created: latency-svc-g7zvf
Sep  4 16:19:09.769: INFO: Got endpoints: latency-svc-g7zvf [492.480204ms]
Sep  4 16:19:09.769: INFO: Created: latency-svc-4lwlk
Sep  4 16:19:09.838: INFO: Created: latency-svc-pqc5b
Sep  4 16:19:09.843: INFO: Got endpoints: latency-svc-4lwlk [544.280463ms]
Sep  4 16:19:09.861: INFO: Got endpoints: latency-svc-pqc5b [538.759095ms]
Sep  4 16:19:09.861: INFO: Created: latency-svc-8bgvc
Sep  4 16:19:09.884: INFO: Created: latency-svc-rwlzm
Sep  4 16:19:09.907: INFO: Created: latency-svc-6xnfj
Sep  4 16:19:09.911: INFO: Got endpoints: latency-svc-8bgvc [565.844802ms]
Sep  4 16:19:09.930: INFO: Created: latency-svc-kbdlp
Sep  4 16:19:09.989: INFO: Created: latency-svc-fgshb
Sep  4 16:19:09.989: INFO: Got endpoints: latency-svc-rwlzm [575.701953ms]
Sep  4 16:19:10.016: INFO: Got endpoints: latency-svc-6xnfj [596.252384ms]
Sep  4 16:19:10.016: INFO: Created: latency-svc-rpkbp
Sep  4 16:19:10.050: INFO: Created: latency-svc-2bfdx
Sep  4 16:19:10.073: INFO: Got endpoints: latency-svc-kbdlp [624.374694ms]
Sep  4 16:19:10.073: INFO: Created: latency-svc-9df8g
Sep  4 16:19:10.120: INFO: Got endpoints: latency-svc-fgshb [637.528058ms]
Sep  4 16:19:10.120: INFO: Created: latency-svc-8tt2f
Sep  4 16:19:10.148: INFO: Created: latency-svc-cfmgn
Sep  4 16:19:10.170: INFO: Got endpoints: latency-svc-rpkbp [613.803706ms]
Sep  4 16:19:10.171: INFO: Created: latency-svc-gszn5
Sep  4 16:19:10.193: INFO: Created: latency-svc-nk8k7
Sep  4 16:19:10.216: INFO: Created: latency-svc-gsn97
Sep  4 16:19:10.216: INFO: Got endpoints: latency-svc-2bfdx [630.675546ms]
Sep  4 16:19:10.258: INFO: Created: latency-svc-tfckw
Sep  4 16:19:10.279: INFO: Got endpoints: latency-svc-9df8g [671.226171ms]
Sep  4 16:19:10.297: INFO: Created: latency-svc-wj24k
Sep  4 16:19:10.320: INFO: Created: latency-svc-5mq9h
Sep  4 16:19:10.320: INFO: Got endpoints: latency-svc-8tt2f [688.816122ms]
Sep  4 16:19:10.342: INFO: Created: latency-svc-zqnjq
Sep  4 16:19:10.394: INFO: Got endpoints: latency-svc-cfmgn [693.49654ms]
Sep  4 16:19:10.394: INFO: Created: latency-svc-r2px2
Sep  4 16:19:10.417: INFO: Created: latency-svc-64znv
Sep  4 16:19:10.417: INFO: Got endpoints: latency-svc-gszn5 [711.676934ms]
Sep  4 16:19:10.440: INFO: Created: latency-svc-49dcc
Sep  4 16:19:10.469: INFO: Created: latency-svc-6zttx
Sep  4 16:19:10.469: INFO: Got endpoints: latency-svc-nk8k7 [740.566373ms]
Sep  4 16:19:10.520: INFO: Got endpoints: latency-svc-gsn97 [750.877093ms]
Sep  4 16:19:10.520: INFO: Created: latency-svc-rk28l
Sep  4 16:19:10.549: INFO: Created: latency-svc-fhl5s
Sep  4 16:19:10.578: INFO: Created: latency-svc-59zss
Sep  4 16:19:10.578: INFO: Got endpoints: latency-svc-tfckw [734.254787ms]
Sep  4 16:19:10.606: INFO: Created: latency-svc-2sff6
Sep  4 16:19:10.616: INFO: Got endpoints: latency-svc-wj24k [754.804439ms]
Sep  4 16:19:10.662: INFO: Created: latency-svc-5z92m
Sep  4 16:19:10.662: INFO: Got endpoints: latency-svc-5mq9h [750.959476ms]
Sep  4 16:19:10.687: INFO: Created: latency-svc-2czdb
Sep  4 16:19:10.715: INFO: Got endpoints: latency-svc-zqnjq [726.188432ms]
Sep  4 16:19:10.715: INFO: Created: latency-svc-qhbxq
Sep  4 16:19:10.761: INFO: Created: latency-svc-668v9
Sep  4 16:19:10.761: INFO: Got endpoints: latency-svc-r2px2 [745.297179ms]
Sep  4 16:19:10.808: INFO: Created: latency-svc-b9s28
Sep  4 16:19:10.816: INFO: Got endpoints: latency-svc-64znv [743.006109ms]
Sep  4 16:19:10.836: INFO: Created: latency-svc-zlkqv
Sep  4 16:19:10.864: INFO: Created: latency-svc-bvn7c
Sep  4 16:19:10.864: INFO: Got endpoints: latency-svc-49dcc [744.695608ms]
Sep  4 16:19:10.925: INFO: Created: latency-svc-jpdrw
Sep  4 16:19:10.925: INFO: Got endpoints: latency-svc-6zttx [754.98733ms]
Sep  4 16:19:10.950: INFO: Created: latency-svc-rrwmn
Sep  4 16:19:10.979: INFO: Created: latency-svc-d4srn
Sep  4 16:19:10.979: INFO: Got endpoints: latency-svc-rk28l [762.34781ms]
Sep  4 16:19:11.007: INFO: Created: latency-svc-h5f6q
Sep  4 16:19:11.016: INFO: Got endpoints: latency-svc-fhl5s [736.760662ms]
Sep  4 16:19:11.062: INFO: Got endpoints: latency-svc-59zss [742.281811ms]
Sep  4 16:19:11.063: INFO: Created: latency-svc-2hrd5
Sep  4 16:19:11.088: INFO: Created: latency-svc-cs5jc
Sep  4 16:19:11.116: INFO: Got endpoints: latency-svc-2sff6 [722.271926ms]
Sep  4 16:19:11.117: INFO: Created: latency-svc-smtm6
Sep  4 16:19:11.162: INFO: Got endpoints: latency-svc-5z92m [745.254503ms]
Sep  4 16:19:11.163: INFO: Created: latency-svc-s2t9g
Sep  4 16:19:11.214: INFO: Got endpoints: latency-svc-2czdb [744.889939ms]
Sep  4 16:19:11.214: INFO: Created: latency-svc-t5r28
Sep  4 16:19:11.237: INFO: Created: latency-svc-g72zj
Sep  4 16:19:11.260: INFO: Got endpoints: latency-svc-qhbxq [740.30294ms]
Sep  4 16:19:11.289: INFO: Created: latency-svc-wrdh6
Sep  4 16:19:11.320: INFO: Got endpoints: latency-svc-668v9 [741.919681ms]
Sep  4 16:19:11.340: INFO: Created: latency-svc-fkp2b
Sep  4 16:19:11.360: INFO: Got endpoints: latency-svc-b9s28 [744.532418ms]
Sep  4 16:19:11.381: INFO: Created: latency-svc-trm7r
Sep  4 16:19:11.410: INFO: Got endpoints: latency-svc-zlkqv [747.712456ms]
Sep  4 16:19:11.472: INFO: Got endpoints: latency-svc-bvn7c [756.726393ms]
Sep  4 16:19:11.472: INFO: Created: latency-svc-lrjks
Sep  4 16:19:11.495: INFO: Created: latency-svc-jthgr
Sep  4 16:19:11.510: INFO: Got endpoints: latency-svc-jpdrw [748.887143ms]
Sep  4 16:19:11.529: INFO: Created: latency-svc-w54vc
Sep  4 16:19:11.581: INFO: Got endpoints: latency-svc-rrwmn [764.926688ms]
Sep  4 16:19:11.604: INFO: Created: latency-svc-r66rd
Sep  4 16:19:11.611: INFO: Got endpoints: latency-svc-d4srn [746.563457ms]
Sep  4 16:19:11.632: INFO: Created: latency-svc-f9znk
Sep  4 16:19:11.660: INFO: Got endpoints: latency-svc-h5f6q [734.343699ms]
Sep  4 16:19:11.714: INFO: Got endpoints: latency-svc-2hrd5 [734.912667ms]
Sep  4 16:19:11.714: INFO: Created: latency-svc-f42kb
Sep  4 16:19:11.736: INFO: Created: latency-svc-4b4f6
Sep  4 16:19:11.760: INFO: Got endpoints: latency-svc-cs5jc [743.81979ms]
Sep  4 16:19:11.781: INFO: Created: latency-svc-pjkpf
Sep  4 16:19:11.810: INFO: Got endpoints: latency-svc-smtm6 [747.945254ms]
Sep  4 16:19:11.856: INFO: Created: latency-svc-r9cff
Sep  4 16:19:11.862: INFO: Got endpoints: latency-svc-s2t9g [745.977783ms]
Sep  4 16:19:11.884: INFO: Created: latency-svc-pmt9s
Sep  4 16:19:11.910: INFO: Got endpoints: latency-svc-t5r28 [747.803604ms]
Sep  4 16:19:11.936: INFO: Created: latency-svc-2578z
Sep  4 16:19:11.965: INFO: Got endpoints: latency-svc-g72zj [751.38136ms]
Sep  4 16:19:11.989: INFO: Created: latency-svc-7df68
Sep  4 16:19:12.010: INFO: Got endpoints: latency-svc-wrdh6 [749.714356ms]
Sep  4 16:19:12.028: INFO: Created: latency-svc-9ff4x
Sep  4 16:19:12.059: INFO: Got endpoints: latency-svc-fkp2b [739.814659ms]
Sep  4 16:19:12.097: INFO: Created: latency-svc-g4sn6
Sep  4 16:19:12.110: INFO: Got endpoints: latency-svc-trm7r [749.928567ms]
Sep  4 16:19:12.142: INFO: Created: latency-svc-drz56
Sep  4 16:19:12.160: INFO: Got endpoints: latency-svc-lrjks [749.764581ms]
Sep  4 16:19:12.194: INFO: Created: latency-svc-nf6rf
Sep  4 16:19:12.222: INFO: Got endpoints: latency-svc-jthgr [750.432039ms]
Sep  4 16:19:12.246: INFO: Created: latency-svc-5dgcj
Sep  4 16:19:12.260: INFO: Got endpoints: latency-svc-w54vc [749.589056ms]
Sep  4 16:19:12.280: INFO: Created: latency-svc-hq8p4
Sep  4 16:19:12.310: INFO: Got endpoints: latency-svc-r66rd [728.699131ms]
Sep  4 16:19:12.354: INFO: Created: latency-svc-6pbsx
Sep  4 16:19:12.360: INFO: Got endpoints: latency-svc-f9znk [748.586798ms]
Sep  4 16:19:12.383: INFO: Created: latency-svc-626jt
Sep  4 16:19:12.410: INFO: Got endpoints: latency-svc-f42kb [750.041176ms]
Sep  4 16:19:12.429: INFO: Created: latency-svc-gp8qh
Sep  4 16:19:12.480: INFO: Got endpoints: latency-svc-4b4f6 [765.665965ms]
Sep  4 16:19:12.503: INFO: Created: latency-svc-gf2kk
Sep  4 16:19:12.520: INFO: Got endpoints: latency-svc-pjkpf [760.027469ms]
Sep  4 16:19:12.544: INFO: Created: latency-svc-nwbsk
Sep  4 16:19:12.560: INFO: Got endpoints: latency-svc-r9cff [749.549872ms]
Sep  4 16:19:12.600: INFO: Created: latency-svc-wx47w
Sep  4 16:19:12.610: INFO: Got endpoints: latency-svc-pmt9s [747.284027ms]
Sep  4 16:19:12.646: INFO: Created: latency-svc-qphpd
Sep  4 16:19:12.660: INFO: Got endpoints: latency-svc-2578z [749.355031ms]
Sep  4 16:19:12.680: INFO: Created: latency-svc-6x28r
Sep  4 16:19:12.719: INFO: Got endpoints: latency-svc-7df68 [754.102851ms]
Sep  4 16:19:12.743: INFO: Created: latency-svc-96kb5
Sep  4 16:19:12.759: INFO: Got endpoints: latency-svc-9ff4x [749.674974ms]
Sep  4 16:19:12.778: INFO: Created: latency-svc-hd8qp
Sep  4 16:19:12.809: INFO: Got endpoints: latency-svc-g4sn6 [749.878923ms]
Sep  4 16:19:12.851: INFO: Created: latency-svc-jgkzp
Sep  4 16:19:12.859: INFO: Got endpoints: latency-svc-drz56 [749.140936ms]
Sep  4 16:19:12.887: INFO: Created: latency-svc-7cw4p
Sep  4 16:19:12.909: INFO: Got endpoints: latency-svc-nf6rf [749.244032ms]
Sep  4 16:19:12.932: INFO: Created: latency-svc-vnxnj
Sep  4 16:19:12.971: INFO: Got endpoints: latency-svc-5dgcj [748.418883ms]
Sep  4 16:19:12.996: INFO: Created: latency-svc-4fwrf
Sep  4 16:19:13.010: INFO: Got endpoints: latency-svc-hq8p4 [749.984934ms]
Sep  4 16:19:13.030: INFO: Created: latency-svc-bmvdf
Sep  4 16:19:13.060: INFO: Got endpoints: latency-svc-6pbsx [750.327686ms]
Sep  4 16:19:13.110: INFO: Created: latency-svc-pmcfq
Sep  4 16:19:13.116: INFO: Got endpoints: latency-svc-626jt [756.11423ms]
Sep  4 16:19:13.139: INFO: Created: latency-svc-6b6tv
Sep  4 16:19:13.160: INFO: Got endpoints: latency-svc-gp8qh [749.773298ms]
Sep  4 16:19:13.179: INFO: Created: latency-svc-9vg9v
Sep  4 16:19:13.210: INFO: Got endpoints: latency-svc-gf2kk [730.255604ms]
Sep  4 16:19:13.265: INFO: Created: latency-svc-jcl5n
Sep  4 16:19:13.265: INFO: Got endpoints: latency-svc-nwbsk [744.978993ms]
Sep  4 16:19:13.300: INFO: Created: latency-svc-d526v
Sep  4 16:19:13.310: INFO: Got endpoints: latency-svc-wx47w [750.248047ms]
Sep  4 16:19:13.334: INFO: Created: latency-svc-v2thf
Sep  4 16:19:13.365: INFO: Got endpoints: latency-svc-qphpd [755.231701ms]
Sep  4 16:19:13.391: INFO: Created: latency-svc-6lr5h
Sep  4 16:19:13.410: INFO: Got endpoints: latency-svc-6x28r [750.098481ms]
Sep  4 16:19:13.448: INFO: Created: latency-svc-2jzq4
Sep  4 16:19:13.460: INFO: Got endpoints: latency-svc-96kb5 [740.332978ms]
Sep  4 16:19:13.495: INFO: Created: latency-svc-dggqr
Sep  4 16:19:13.509: INFO: Got endpoints: latency-svc-hd8qp [750.036575ms]
Sep  4 16:19:13.534: INFO: Created: latency-svc-q67tg
Sep  4 16:19:13.560: INFO: Got endpoints: latency-svc-jgkzp [750.150251ms]
Sep  4 16:19:13.617: INFO: Got endpoints: latency-svc-7cw4p [757.565031ms]
Sep  4 16:19:13.617: INFO: Created: latency-svc-79tkh
Sep  4 16:19:13.643: INFO: Created: latency-svc-k7s5r
Sep  4 16:19:13.660: INFO: Got endpoints: latency-svc-vnxnj [750.748909ms]
Sep  4 16:19:13.683: INFO: Created: latency-svc-rx8xm
Sep  4 16:19:13.711: INFO: Got endpoints: latency-svc-4fwrf [739.687541ms]
Sep  4 16:19:13.769: INFO: Got endpoints: latency-svc-bmvdf [759.276861ms]
Sep  4 16:19:13.769: INFO: Created: latency-svc-sv85r
Sep  4 16:19:13.792: INFO: Created: latency-svc-dkdvz
Sep  4 16:19:13.810: INFO: Got endpoints: latency-svc-pmcfq [750.145844ms]
Sep  4 16:19:13.832: INFO: Created: latency-svc-nnrl9
Sep  4 16:19:13.874: INFO: Got endpoints: latency-svc-6b6tv [758.177653ms]
Sep  4 16:19:13.895: INFO: Created: latency-svc-lbrfq
Sep  4 16:19:13.910: INFO: Got endpoints: latency-svc-9vg9v [749.939662ms]
Sep  4 16:19:13.935: INFO: Created: latency-svc-c7p2r
Sep  4 16:19:13.960: INFO: Got endpoints: latency-svc-jcl5n [749.936137ms]
Sep  4 16:19:14.011: INFO: Got endpoints: latency-svc-d526v [745.738563ms]
Sep  4 16:19:14.012: INFO: Created: latency-svc-5mw29
Sep  4 16:19:14.038: INFO: Created: latency-svc-klj4x
Sep  4 16:19:14.061: INFO: Got endpoints: latency-svc-v2thf [750.9103ms]
Sep  4 16:19:14.096: INFO: Created: latency-svc-vxpqd
Sep  4 16:19:14.110: INFO: Got endpoints: latency-svc-6lr5h [744.878757ms]
Sep  4 16:19:14.153: INFO: Created: latency-svc-drn7c
Sep  4 16:19:14.162: INFO: Got endpoints: latency-svc-2jzq4 [752.102211ms]
Sep  4 16:19:14.205: INFO: Created: latency-svc-pvrnq
Sep  4 16:19:14.213: INFO: Got endpoints: latency-svc-dggqr [753.668966ms]
Sep  4 16:19:14.262: INFO: Got endpoints: latency-svc-q67tg [752.850717ms]
Sep  4 16:19:14.262: INFO: Created: latency-svc-2plls
Sep  4 16:19:14.290: INFO: Created: latency-svc-blwhx
Sep  4 16:19:14.310: INFO: Got endpoints: latency-svc-79tkh [750.008755ms]
Sep  4 16:19:14.348: INFO: Created: latency-svc-q29wc
Sep  4 16:19:14.359: INFO: Got endpoints: latency-svc-k7s5r [742.54757ms]
Sep  4 16:19:14.395: INFO: Created: latency-svc-dzbst
Sep  4 16:19:14.410: INFO: Got endpoints: latency-svc-rx8xm [749.522799ms]
Sep  4 16:19:14.434: INFO: Created: latency-svc-r6wwb
Sep  4 16:19:14.460: INFO: Got endpoints: latency-svc-sv85r [749.44003ms]
Sep  4 16:19:14.485: INFO: Created: latency-svc-jrttw
Sep  4 16:19:14.513: INFO: Got endpoints: latency-svc-dkdvz [744.378415ms]
Sep  4 16:19:14.543: INFO: Created: latency-svc-rh5qv
Sep  4 16:19:14.560: INFO: Got endpoints: latency-svc-nnrl9 [749.4378ms]
Sep  4 16:19:14.583: INFO: Created: latency-svc-wj9vw
Sep  4 16:19:14.610: INFO: Got endpoints: latency-svc-lbrfq [736.095469ms]
Sep  4 16:19:14.674: INFO: Created: latency-svc-x5clc
Sep  4 16:19:14.674: INFO: Got endpoints: latency-svc-c7p2r [764.450009ms]
Sep  4 16:19:14.703: INFO: Created: latency-svc-6wd29
Sep  4 16:19:14.711: INFO: Got endpoints: latency-svc-5mw29 [751.323919ms]
Sep  4 16:19:14.737: INFO: Created: latency-svc-gbgdt
Sep  4 16:19:14.783: INFO: Got endpoints: latency-svc-klj4x [772.307002ms]
Sep  4 16:19:14.812: INFO: Got endpoints: latency-svc-vxpqd [750.51347ms]
Sep  4 16:19:14.812: INFO: Created: latency-svc-krg9t
Sep  4 16:19:14.840: INFO: Created: latency-svc-rzkc7
Sep  4 16:19:14.860: INFO: Got endpoints: latency-svc-drn7c [749.71273ms]
Sep  4 16:19:14.880: INFO: Created: latency-svc-g5nfl
Sep  4 16:19:14.910: INFO: Got endpoints: latency-svc-pvrnq [748.016028ms]
Sep  4 16:19:14.932: INFO: Created: latency-svc-rrd9h
Sep  4 16:19:14.960: INFO: Got endpoints: latency-svc-2plls [746.414993ms]
Sep  4 16:19:15.028: INFO: Got endpoints: latency-svc-blwhx [765.65967ms]
Sep  4 16:19:15.060: INFO: Got endpoints: latency-svc-q29wc [750.400765ms]
Sep  4 16:19:15.110: INFO: Got endpoints: latency-svc-dzbst [750.481962ms]
Sep  4 16:19:15.160: INFO: Got endpoints: latency-svc-r6wwb [750.432872ms]
Sep  4 16:19:15.211: INFO: Got endpoints: latency-svc-jrttw [750.531231ms]
Sep  4 16:19:15.260: INFO: Got endpoints: latency-svc-rh5qv [746.66318ms]
Sep  4 16:19:15.310: INFO: Got endpoints: latency-svc-wj9vw [750.200906ms]
Sep  4 16:19:15.377: INFO: Got endpoints: latency-svc-x5clc [766.57356ms]
Sep  4 16:19:15.410: INFO: Got endpoints: latency-svc-6wd29 [735.515463ms]
Sep  4 16:19:15.460: INFO: Got endpoints: latency-svc-gbgdt [748.56594ms]
Sep  4 16:19:15.510: INFO: Got endpoints: latency-svc-krg9t [726.403327ms]
Sep  4 16:19:15.565: INFO: Got endpoints: latency-svc-rzkc7 [753.187788ms]
Sep  4 16:19:15.610: INFO: Got endpoints: latency-svc-g5nfl [750.732203ms]
Sep  4 16:19:15.660: INFO: Got endpoints: latency-svc-rrd9h [749.983118ms]
Sep  4 16:19:15.660: INFO: Latencies: [58.404986ms 68.796213ms 121.399506ms 143.040253ms 207.088386ms 211.543801ms 234.474467ms 257.374859ms 280.563089ms 344.973552ms 349.11928ms 377.956096ms 400.678059ms 408.49717ms 412.670577ms 414.846177ms 418.319466ms 422.261959ms 424.297549ms 426.149766ms 435.136417ms 437.484325ms 439.509083ms 440.782407ms 448.35618ms 452.047877ms 452.243575ms 458.378987ms 458.72418ms 459.95842ms 461.614973ms 462.950478ms 465.543577ms 465.879593ms 467.70714ms 467.713489ms 468.176611ms 469.012298ms 469.755313ms 470.776483ms 474.705225ms 474.931786ms 475.079552ms 475.185581ms 475.297695ms 476.395552ms 476.776827ms 477.742947ms 486.45652ms 486.559553ms 486.603204ms 486.606381ms 489.210948ms 492.018457ms 492.297607ms 492.315175ms 492.480204ms 494.419737ms 494.952662ms 496.418559ms 497.770512ms 503.285902ms 503.391462ms 503.670646ms 509.234998ms 514.808299ms 514.871158ms 518.173232ms 518.252251ms 521.680491ms 522.476447ms 523.605653ms 526.206141ms 526.532155ms 530.058542ms 531.306697ms 531.661084ms 532.026984ms 533.443602ms 537.831323ms 538.759095ms 543.722388ms 544.280463ms 544.570441ms 565.844802ms 575.701953ms 596.252384ms 613.803706ms 624.374694ms 630.675546ms 637.528058ms 671.226171ms 688.816122ms 693.49654ms 711.676934ms 722.271926ms 726.188432ms 726.403327ms 728.699131ms 730.255604ms 734.254787ms 734.343699ms 734.912667ms 735.515463ms 736.095469ms 736.760662ms 739.687541ms 739.814659ms 740.30294ms 740.332978ms 740.566373ms 741.919681ms 742.281811ms 742.54757ms 743.006109ms 743.81979ms 744.378415ms 744.532418ms 744.695608ms 744.878757ms 744.889939ms 744.978993ms 745.254503ms 745.297179ms 745.738563ms 745.977783ms 746.414993ms 746.563457ms 746.66318ms 747.284027ms 747.712456ms 747.803604ms 747.945254ms 748.016028ms 748.418883ms 748.56594ms 748.586798ms 748.887143ms 749.140936ms 749.244032ms 749.355031ms 749.4378ms 749.44003ms 749.522799ms 749.549872ms 749.589056ms 749.674974ms 749.71273ms 749.714356ms 749.764581ms 749.773298ms 749.878923ms 749.928567ms 749.936137ms 749.939662ms 749.983118ms 749.984934ms 750.008755ms 750.036575ms 750.041176ms 750.098481ms 750.145844ms 750.150251ms 750.200906ms 750.248047ms 750.327686ms 750.400765ms 750.432039ms 750.432872ms 750.481962ms 750.51347ms 750.531231ms 750.732203ms 750.748909ms 750.877093ms 750.9103ms 750.959476ms 751.323919ms 751.38136ms 752.102211ms 752.850717ms 753.187788ms 753.668966ms 754.102851ms 754.804439ms 754.98733ms 755.231701ms 756.11423ms 756.726393ms 757.565031ms 758.177653ms 759.276861ms 760.027469ms 762.34781ms 764.450009ms 764.926688ms 765.65967ms 765.665965ms 766.57356ms 772.307002ms]
Sep  4 16:19:15.660: INFO: 50 %ile: 734.254787ms
Sep  4 16:19:15.660: INFO: 90 %ile: 752.850717ms
Sep  4 16:19:15.660: INFO: 99 %ile: 766.57356ms
Sep  4 16:19:15.660: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:19:15.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8682" for this suite.
Sep  4 16:19:31.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:19:31.712: INFO: namespace svc-latency-8682 deletion completed in 16.045999968s

• [SLOW TEST:26.851 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:19:31.713: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-36c80a05-8494-455f-b238-9dd2f01c6356
STEP: Creating a pod to test consume secrets
Sep  4 16:19:31.902: INFO: Waiting up to 5m0s for pod "pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e" in namespace "secrets-3471" to be "success or failure"
Sep  4 16:19:31.903: INFO: Pod "pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.14822ms
Sep  4 16:19:33.905: INFO: Pod "pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003050578s
STEP: Saw pod success
Sep  4 16:19:33.905: INFO: Pod "pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e" satisfied condition "success or failure"
Sep  4 16:19:33.907: INFO: Trying to get logs from node 192.168.0.166 pod pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 16:19:33.922: INFO: Waiting for pod pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e to disappear
Sep  4 16:19:33.927: INFO: Pod pod-secrets-4c59f612-3437-434f-92a9-ded22b5bcd4e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:19:33.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3471" for this suite.
Sep  4 16:19:39.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:19:40.014: INFO: namespace secrets-3471 deletion completed in 6.084431787s
STEP: Destroying namespace "secret-namespace-1125" for this suite.
Sep  4 16:19:46.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:19:46.068: INFO: namespace secret-namespace-1125 deletion completed in 6.053728365s

• [SLOW TEST:14.355 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:19:46.068: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-6eb58440-1d2a-4eb8-92e7-f959f9959cbc
STEP: Creating a pod to test consume configMaps
Sep  4 16:19:46.185: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16" in namespace "projected-3897" to be "success or failure"
Sep  4 16:19:46.190: INFO: Pod "pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557838ms
Sep  4 16:19:48.192: INFO: Pod "pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006811861s
STEP: Saw pod success
Sep  4 16:19:48.192: INFO: Pod "pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16" satisfied condition "success or failure"
Sep  4 16:19:48.194: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:19:48.220: INFO: Waiting for pod pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16 to disappear
Sep  4 16:19:48.224: INFO: Pod pod-projected-configmaps-addf6737-3802-48c0-b7f6-ce08b0badc16 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:19:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3897" for this suite.
Sep  4 16:19:54.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:19:54.277: INFO: namespace projected-3897 deletion completed in 6.050545089s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:19:54.277: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 16:19:54.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5238'
Sep  4 16:19:54.407: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 16:19:54.407: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  4 16:19:54.422: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  4 16:19:54.430: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  4 16:19:54.437: INFO: scanned /root for discovery docs: <nil>
Sep  4 16:19:54.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5238'
Sep  4 16:20:10.222: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 16:20:10.222: INFO: stdout: "Created e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6\nScaling up e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  4 16:20:10.222: INFO: stdout: "Created e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6\nScaling up e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  4 16:20:10.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-5238'
Sep  4 16:20:10.293: INFO: stderr: ""
Sep  4 16:20:10.293: INFO: stdout: "e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6-kbnxt "
Sep  4 16:20:10.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6-kbnxt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5238'
Sep  4 16:20:10.374: INFO: stderr: ""
Sep  4 16:20:10.374: INFO: stdout: "true"
Sep  4 16:20:10.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6-kbnxt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5238'
Sep  4 16:20:10.457: INFO: stderr: ""
Sep  4 16:20:10.457: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  4 16:20:10.457: INFO: e2e-test-nginx-rc-7e17dd8c7e4e2f0e8c36468600e99eb6-kbnxt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep  4 16:20:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete rc e2e-test-nginx-rc --namespace=kubectl-5238'
Sep  4 16:20:10.541: INFO: stderr: ""
Sep  4 16:20:10.541: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:20:10.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5238" for this suite.
Sep  4 16:20:16.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:20:16.599: INFO: namespace kubectl-5238 deletion completed in 6.05313815s

• [SLOW TEST:22.322 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:20:16.599: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:20:16.673: INFO: (0) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.889164ms)
Sep  4 16:20:16.675: INFO: (1) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.631194ms)
Sep  4 16:20:16.677: INFO: (2) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.690433ms)
Sep  4 16:20:16.678: INFO: (3) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.586445ms)
Sep  4 16:20:16.680: INFO: (4) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.576528ms)
Sep  4 16:20:16.682: INFO: (5) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.57777ms)
Sep  4 16:20:16.683: INFO: (6) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.732499ms)
Sep  4 16:20:16.685: INFO: (7) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.612007ms)
Sep  4 16:20:16.687: INFO: (8) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.636108ms)
Sep  4 16:20:16.688: INFO: (9) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.666245ms)
Sep  4 16:20:16.690: INFO: (10) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.553261ms)
Sep  4 16:20:16.691: INFO: (11) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.659887ms)
Sep  4 16:20:16.693: INFO: (12) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.594434ms)
Sep  4 16:20:16.695: INFO: (13) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.532977ms)
Sep  4 16:20:16.696: INFO: (14) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.603426ms)
Sep  4 16:20:16.698: INFO: (15) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.557202ms)
Sep  4 16:20:16.699: INFO: (16) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.567506ms)
Sep  4 16:20:16.701: INFO: (17) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.551603ms)
Sep  4 16:20:16.703: INFO: (18) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.527796ms)
Sep  4 16:20:16.704: INFO: (19) /api/v1/nodes/192.168.0.165/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.558617ms)
[AfterEach] version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:20:16.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7444" for this suite.
Sep  4 16:20:22.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:20:22.752: INFO: namespace proxy-7444 deletion completed in 6.045955891s

• [SLOW TEST:6.153 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:20:22.752: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  4 16:20:25.909: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:20:26.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2804" for this suite.
Sep  4 16:20:48.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:20:48.981: INFO: namespace replicaset-2804 deletion completed in 22.048990932s

• [SLOW TEST:26.229 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:20:48.982: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-88b75503-2199-4d5f-9f93-2e03a44f90dc
STEP: Creating a pod to test consume configMaps
Sep  4 16:20:49.073: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a" in namespace "projected-7752" to be "success or failure"
Sep  4 16:20:49.077: INFO: Pod "pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.582189ms
Sep  4 16:20:51.079: INFO: Pod "pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006353078s
STEP: Saw pod success
Sep  4 16:20:51.079: INFO: Pod "pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a" satisfied condition "success or failure"
Sep  4 16:20:51.083: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:20:51.109: INFO: Waiting for pod pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a to disappear
Sep  4 16:20:51.117: INFO: Pod pod-projected-configmaps-d0bc9ce1-a322-4655-8933-541430f7699a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:20:51.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7752" for this suite.
Sep  4 16:20:57.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:20:57.198: INFO: namespace projected-7752 deletion completed in 6.078887829s

• [SLOW TEST:8.216 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:20:57.198: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 16:20:57.250: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb" in namespace "downward-api-2731" to be "success or failure"
Sep  4 16:20:57.265: INFO: Pod "downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.899306ms
Sep  4 16:20:59.267: INFO: Pod "downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016941801s
STEP: Saw pod success
Sep  4 16:20:59.267: INFO: Pod "downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb" satisfied condition "success or failure"
Sep  4 16:20:59.268: INFO: Trying to get logs from node 192.168.0.166 pod downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb container client-container: <nil>
STEP: delete the pod
Sep  4 16:20:59.284: INFO: Waiting for pod downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb to disappear
Sep  4 16:20:59.289: INFO: Pod downwardapi-volume-c6732aad-ebb3-4a51-ab9d-f2320f51d2cb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:20:59.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2731" for this suite.
Sep  4 16:21:05.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:21:05.336: INFO: namespace downward-api-2731 deletion completed in 6.045224413s

• [SLOW TEST:8.138 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:21:05.337: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-9431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9431 to expose endpoints map[]
Sep  4 16:21:05.444: INFO: successfully validated that service endpoint-test2 in namespace services-9431 exposes endpoints map[] (6.287356ms elapsed)
STEP: Creating pod pod1 in namespace services-9431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9431 to expose endpoints map[pod1:[80]]
Sep  4 16:21:06.508: INFO: successfully validated that service endpoint-test2 in namespace services-9431 exposes endpoints map[pod1:[80]] (1.046348966s elapsed)
STEP: Creating pod pod2 in namespace services-9431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9431 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  4 16:21:08.576: INFO: successfully validated that service endpoint-test2 in namespace services-9431 exposes endpoints map[pod1:[80] pod2:[80]] (2.065890521s elapsed)
STEP: Deleting pod pod1 in namespace services-9431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9431 to expose endpoints map[pod2:[80]]
Sep  4 16:21:09.607: INFO: successfully validated that service endpoint-test2 in namespace services-9431 exposes endpoints map[pod2:[80]] (1.028701056s elapsed)
STEP: Deleting pod pod2 in namespace services-9431
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9431 to expose endpoints map[]
Sep  4 16:21:10.617: INFO: successfully validated that service endpoint-test2 in namespace services-9431 exposes endpoints map[] (1.008065856s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:21:10.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9431" for this suite.
Sep  4 16:21:16.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:21:16.753: INFO: namespace services-9431 deletion completed in 6.053976235s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:11.416 seconds]
[sig-network] Services
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:21:16.753: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-866fb6d5-941b-48e8-9764-83d5701a949e
STEP: Creating a pod to test consume configMaps
Sep  4 16:21:16.840: INFO: Waiting up to 5m0s for pod "pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc" in namespace "configmap-1389" to be "success or failure"
Sep  4 16:21:16.849: INFO: Pod "pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.955874ms
Sep  4 16:21:18.851: INFO: Pod "pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010963671s
STEP: Saw pod success
Sep  4 16:21:18.851: INFO: Pod "pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc" satisfied condition "success or failure"
Sep  4 16:21:18.853: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:21:18.909: INFO: Waiting for pod pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc to disappear
Sep  4 16:21:18.924: INFO: Pod pod-configmaps-22639f81-0754-4b30-b903-c5b195462fbc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:21:18.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1389" for this suite.
Sep  4 16:21:24.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:21:25.021: INFO: namespace configmap-1389 deletion completed in 6.09560059s

• [SLOW TEST:8.268 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:21:25.021: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 16:21:25.137: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 16:21:25.149: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 16:21:25.150: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.165 before test
Sep  4 16:21:25.155: INFO: default-http-backend-7f744bb697-nkz9c from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  4 16:21:25.155: INFO: nginx-ingress-controller-slhvq from ingress-igr1 started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  4 16:21:25.155: INFO: ckecsi-8lpfb from default started at 2019-09-04 14:44:58 +0000 UTC (2 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 16:21:25.155: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 16:21:25.155: INFO: kubernetes-dashboard-5cd5576947-pplbs from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  4 16:21:25.155: INFO: ckecsi-provisioner-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 16:21:25.155: INFO: sonobuoy-e2e-job-57060aab3bac4fe0 from heptio-sonobuoy started at 2019-09-04 15:05:14 +0000 UTC (2 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container e2e ready: true, restart count 0
Sep  4 16:21:25.155: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 16:21:25.155: INFO: coredns-55d8c6f4f-h7pxd from kube-system started at 2019-09-04 14:44:59 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container coredns ready: true, restart count 0
Sep  4 16:21:25.155: INFO: ckecsi-attacher-0 from default started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep  4 16:21:25.155: INFO: calico-kube-controllers-568647f5b9-n6xm7 from kube-system started at 2019-09-04 14:44:58 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.155: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 16:21:25.155: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.166 before test
Sep  4 16:21:25.158: INFO: ckecsi-ks4dd from default started at 2019-09-04 14:45:05 +0000 UTC (2 container statuses recorded)
Sep  4 16:21:25.158: INFO: 	Container ckecsi ready: true, restart count 0
Sep  4 16:21:25.158: INFO: 	Container driver-registrar ready: true, restart count 1
Sep  4 16:21:25.158: INFO: ckecsi-provisioner-1 from default started at 2019-09-04 14:46:43 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.158: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep  4 16:21:25.158: INFO: ckecsi-attacher-1 from default started at 2019-09-04 14:46:48 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.158: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep  4 16:21:25.158: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 15:05:11 +0000 UTC (1 container statuses recorded)
Sep  4 16:21:25.158: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 192.168.0.165
STEP: verifying the node has the label node 192.168.0.166
Sep  4 16:21:25.208: INFO: Pod ckecsi-8lpfb requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod ckecsi-attacher-0 requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod ckecsi-attacher-1 requesting resource cpu=0m on Node 192.168.0.166
Sep  4 16:21:25.208: INFO: Pod ckecsi-ks4dd requesting resource cpu=0m on Node 192.168.0.166
Sep  4 16:21:25.208: INFO: Pod ckecsi-provisioner-0 requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod ckecsi-provisioner-1 requesting resource cpu=0m on Node 192.168.0.166
Sep  4 16:21:25.208: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.0.166
Sep  4 16:21:25.208: INFO: Pod sonobuoy-e2e-job-57060aab3bac4fe0 requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod default-http-backend-7f744bb697-nkz9c requesting resource cpu=10m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod nginx-ingress-controller-slhvq requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod calico-kube-controllers-568647f5b9-n6xm7 requesting resource cpu=0m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod coredns-55d8c6f4f-h7pxd requesting resource cpu=100m on Node 192.168.0.165
Sep  4 16:21:25.208: INFO: Pod kubernetes-dashboard-5cd5576947-pplbs requesting resource cpu=0m on Node 192.168.0.165
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35346a7a-9909-4742-bd68-807b6954864d.15c148b476f28e4d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-626/filler-pod-35346a7a-9909-4742-bd68-807b6954864d to 192.168.0.165]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35346a7a-9909-4742-bd68-807b6954864d.15c148b4a3e8c00c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35346a7a-9909-4742-bd68-807b6954864d.15c148b4a46a1804], Reason = [Created], Message = [Created container filler-pod-35346a7a-9909-4742-bd68-807b6954864d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35346a7a-9909-4742-bd68-807b6954864d.15c148b4ad1190d2], Reason = [Started], Message = [Started container filler-pod-35346a7a-9909-4742-bd68-807b6954864d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06.15c148b477363ebb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-626/filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06 to 192.168.0.166]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06.15c148b4a644cc7b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06.15c148b4a6c7f502], Reason = [Created], Message = [Created container filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06.15c148b4aea69197], Reason = [Started], Message = [Started container filler-pod-85b2a27a-813e-4de0-a49e-8704a5a21c06]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c148b4eee7b958], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 192.168.0.165
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.0.166
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:21:28.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-626" for this suite.
Sep  4 16:21:34.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:21:34.414: INFO: namespace sched-pred-626 deletion completed in 6.052810555s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.393 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:21:34.415: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-768aa9b9-8d4a-41ed-9e85-0cc998f0f22c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-768aa9b9-8d4a-41ed-9e85-0cc998f0f22c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:21:38.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2598" for this suite.
Sep  4 16:22:00.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:22:00.605: INFO: namespace projected-2598 deletion completed in 22.071072222s

• [SLOW TEST:26.191 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:22:00.606: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:22:24.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8156" for this suite.
Sep  4 16:22:30.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:22:30.880: INFO: namespace namespaces-8156 deletion completed in 6.052035516s
STEP: Destroying namespace "nsdeletetest-2769" for this suite.
Sep  4 16:22:30.881: INFO: Namespace nsdeletetest-2769 was already deleted
STEP: Destroying namespace "nsdeletetest-7014" for this suite.
Sep  4 16:22:36.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:22:36.929: INFO: namespace nsdeletetest-7014 deletion completed in 6.047199214s

• [SLOW TEST:36.323 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:22:36.929: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-a57de090-ef5c-4c18-9ba8-4125aae80e2f in namespace container-probe-8851
Sep  4 16:22:39.010: INFO: Started pod liveness-a57de090-ef5c-4c18-9ba8-4125aae80e2f in namespace container-probe-8851
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 16:22:39.011: INFO: Initial restart count of pod liveness-a57de090-ef5c-4c18-9ba8-4125aae80e2f is 0
Sep  4 16:22:57.031: INFO: Restart count of pod container-probe-8851/liveness-a57de090-ef5c-4c18-9ba8-4125aae80e2f is now 1 (18.019420042s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:22:57.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8851" for this suite.
Sep  4 16:23:03.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:23:03.109: INFO: namespace container-probe-8851 deletion completed in 6.063035008s

• [SLOW TEST:26.180 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:23:03.109: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:23:08.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5990" for this suite.
Sep  4 16:23:14.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:23:14.815: INFO: namespace watch-5990 deletion completed in 6.151089186s

• [SLOW TEST:11.705 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:23:14.816: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0904 16:23:24.879754      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 16:23:24.879: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:23:24.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3643" for this suite.
Sep  4 16:23:30.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:23:30.929: INFO: namespace gc-3643 deletion completed in 6.047939228s

• [SLOW TEST:16.114 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:23:30.929: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep  4 16:23:30.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-513'
Sep  4 16:23:31.153: INFO: stderr: ""
Sep  4 16:23:31.153: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 16:23:31.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:31.271: INFO: stderr: ""
Sep  4 16:23:31.271: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-th469 "
Sep  4 16:23:31.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:31.357: INFO: stderr: ""
Sep  4 16:23:31.357: INFO: stdout: ""
Sep  4 16:23:31.357: INFO: update-demo-nautilus-8f6xh is created but not running
Sep  4 16:23:36.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:36.427: INFO: stderr: ""
Sep  4 16:23:36.427: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-th469 "
Sep  4 16:23:36.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:36.492: INFO: stderr: ""
Sep  4 16:23:36.492: INFO: stdout: "true"
Sep  4 16:23:36.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:36.558: INFO: stderr: ""
Sep  4 16:23:36.558: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:36.558: INFO: validating pod update-demo-nautilus-8f6xh
Sep  4 16:23:36.561: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:36.561: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:36.561: INFO: update-demo-nautilus-8f6xh is verified up and running
Sep  4 16:23:36.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-th469 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:36.628: INFO: stderr: ""
Sep  4 16:23:36.628: INFO: stdout: "true"
Sep  4 16:23:36.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-th469 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:36.694: INFO: stderr: ""
Sep  4 16:23:36.694: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:36.694: INFO: validating pod update-demo-nautilus-th469
Sep  4 16:23:36.699: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:36.699: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:36.699: INFO: update-demo-nautilus-th469 is verified up and running
STEP: scaling down the replication controller
Sep  4 16:23:36.700: INFO: scanned /root for discovery docs: <nil>
Sep  4 16:23:36.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-513'
Sep  4 16:23:37.783: INFO: stderr: ""
Sep  4 16:23:37.783: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 16:23:37.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:37.855: INFO: stderr: ""
Sep  4 16:23:37.855: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-th469 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  4 16:23:42.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:42.932: INFO: stderr: ""
Sep  4 16:23:42.932: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-th469 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  4 16:23:47.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:48.014: INFO: stderr: ""
Sep  4 16:23:48.014: INFO: stdout: "update-demo-nautilus-8f6xh "
Sep  4 16:23:48.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:48.080: INFO: stderr: ""
Sep  4 16:23:48.080: INFO: stdout: "true"
Sep  4 16:23:48.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:48.146: INFO: stderr: ""
Sep  4 16:23:48.146: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:48.146: INFO: validating pod update-demo-nautilus-8f6xh
Sep  4 16:23:48.148: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:48.148: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:48.148: INFO: update-demo-nautilus-8f6xh is verified up and running
STEP: scaling up the replication controller
Sep  4 16:23:48.149: INFO: scanned /root for discovery docs: <nil>
Sep  4 16:23:48.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-513'
Sep  4 16:23:49.235: INFO: stderr: ""
Sep  4 16:23:49.235: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 16:23:49.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:49.319: INFO: stderr: ""
Sep  4 16:23:49.319: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-rkbp9 "
Sep  4 16:23:49.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:49.389: INFO: stderr: ""
Sep  4 16:23:49.389: INFO: stdout: "true"
Sep  4 16:23:49.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:49.456: INFO: stderr: ""
Sep  4 16:23:49.456: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:49.457: INFO: validating pod update-demo-nautilus-8f6xh
Sep  4 16:23:49.459: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:49.459: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:49.459: INFO: update-demo-nautilus-8f6xh is verified up and running
Sep  4 16:23:49.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-rkbp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:49.525: INFO: stderr: ""
Sep  4 16:23:49.525: INFO: stdout: ""
Sep  4 16:23:49.525: INFO: update-demo-nautilus-rkbp9 is created but not running
Sep  4 16:23:54.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-513'
Sep  4 16:23:54.603: INFO: stderr: ""
Sep  4 16:23:54.603: INFO: stdout: "update-demo-nautilus-8f6xh update-demo-nautilus-rkbp9 "
Sep  4 16:23:54.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:54.669: INFO: stderr: ""
Sep  4 16:23:54.669: INFO: stdout: "true"
Sep  4 16:23:54.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-8f6xh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:54.736: INFO: stderr: ""
Sep  4 16:23:54.736: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:54.736: INFO: validating pod update-demo-nautilus-8f6xh
Sep  4 16:23:54.738: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:54.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:54.738: INFO: update-demo-nautilus-8f6xh is verified up and running
Sep  4 16:23:54.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-rkbp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:54.824: INFO: stderr: ""
Sep  4 16:23:54.824: INFO: stdout: "true"
Sep  4 16:23:54.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods update-demo-nautilus-rkbp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-513'
Sep  4 16:23:54.895: INFO: stderr: ""
Sep  4 16:23:54.895: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 16:23:54.895: INFO: validating pod update-demo-nautilus-rkbp9
Sep  4 16:23:54.897: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 16:23:54.897: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 16:23:54.897: INFO: update-demo-nautilus-rkbp9 is verified up and running
STEP: using delete to clean up resources
Sep  4 16:23:54.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-513'
Sep  4 16:23:54.969: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 16:23:54.969: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 16:23:54.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-513'
Sep  4 16:23:55.038: INFO: stderr: "No resources found.\n"
Sep  4 16:23:55.038: INFO: stdout: ""
Sep  4 16:23:55.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=update-demo --namespace=kubectl-513 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 16:23:55.105: INFO: stderr: ""
Sep  4 16:23:55.105: INFO: stdout: "update-demo-nautilus-8f6xh\nupdate-demo-nautilus-rkbp9\n"
Sep  4 16:23:55.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-513'
Sep  4 16:23:55.675: INFO: stderr: "No resources found.\n"
Sep  4 16:23:55.675: INFO: stdout: ""
Sep  4 16:23:55.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=update-demo --namespace=kubectl-513 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 16:23:55.743: INFO: stderr: ""
Sep  4 16:23:55.743: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:23:55.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-513" for this suite.
Sep  4 16:24:13.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:24:13.793: INFO: namespace kubectl-513 deletion completed in 18.04781526s

• [SLOW TEST:42.864 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:24:13.793: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:24:38.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7204" for this suite.
Sep  4 16:24:44.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:24:44.102: INFO: namespace container-runtime-7204 deletion completed in 6.048770271s

• [SLOW TEST:30.309 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:24:44.102: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0904 16:24:54.267304      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 16:24:54.267: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:24:54.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4722" for this suite.
Sep  4 16:25:00.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:25:00.332: INFO: namespace gc-4722 deletion completed in 6.063185034s

• [SLOW TEST:16.230 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:25:00.332: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep  4 16:25:00.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 api-versions'
Sep  4 16:25:00.465: INFO: stderr: ""
Sep  4 16:25:00.465: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:25:00.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3698" for this suite.
Sep  4 16:25:06.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:25:06.520: INFO: namespace kubectl-3698 deletion completed in 6.052733367s

• [SLOW TEST:6.188 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:25:06.520: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:25:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4336" for this suite.
Sep  4 16:25:12.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:25:12.645: INFO: namespace services-4336 deletion completed in 6.05325629s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.125 seconds]
[sig-network] Services
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:25:12.645: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  4 16:25:12.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23744,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 16:25:12.719: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23745,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 16:25:12.719: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23746,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  4 16:25:22.760: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23762,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 16:25:22.761: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23763,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  4 16:25:22.761: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5846,SelfLink:/api/v1/namespaces/watch-5846/configmaps/e2e-watch-test-label-changed,UID:55338414-1bdc-47fc-b8ca-b8bbd1998504,ResourceVersion:23764,Generation:0,CreationTimestamp:2019-09-04 16:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:25:22.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5846" for this suite.
Sep  4 16:25:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:25:28.817: INFO: namespace watch-5846 deletion completed in 6.04697465s

• [SLOW TEST:16.172 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:25:28.818: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-3645
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3645 to expose endpoints map[]
Sep  4 16:25:28.889: INFO: successfully validated that service multi-endpoint-test in namespace services-3645 exposes endpoints map[] (6.096413ms elapsed)
STEP: Creating pod pod1 in namespace services-3645
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3645 to expose endpoints map[pod1:[100]]
Sep  4 16:25:29.909: INFO: successfully validated that service multi-endpoint-test in namespace services-3645 exposes endpoints map[pod1:[100]] (1.012914166s elapsed)
STEP: Creating pod pod2 in namespace services-3645
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3645 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  4 16:25:31.997: INFO: successfully validated that service multi-endpoint-test in namespace services-3645 exposes endpoints map[pod1:[100] pod2:[101]] (2.085611994s elapsed)
STEP: Deleting pod pod1 in namespace services-3645
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3645 to expose endpoints map[pod2:[101]]
Sep  4 16:25:33.041: INFO: successfully validated that service multi-endpoint-test in namespace services-3645 exposes endpoints map[pod2:[101]] (1.041779695s elapsed)
STEP: Deleting pod pod2 in namespace services-3645
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3645 to expose endpoints map[]
Sep  4 16:25:34.052: INFO: successfully validated that service multi-endpoint-test in namespace services-3645 exposes endpoints map[] (1.008386711s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:25:34.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3645" for this suite.
Sep  4 16:25:40.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:25:40.212: INFO: namespace services-3645 deletion completed in 6.052443043s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:11.394 seconds]
[sig-network] Services
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:25:40.212: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-0ad0a1ff-ac8c-464a-8338-f3ff73469bc7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:25:42.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6094" for this suite.
Sep  4 16:26:04.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:26:04.377: INFO: namespace configmap-6094 deletion completed in 22.049258831s

• [SLOW TEST:24.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:26:04.377: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 16:26:04.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5718'
Sep  4 16:26:04.527: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 16:26:04.527: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep  4 16:26:06.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5718'
Sep  4 16:26:06.618: INFO: stderr: ""
Sep  4 16:26:06.618: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:26:06.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5718" for this suite.
Sep  4 16:26:28.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:26:28.668: INFO: namespace kubectl-5718 deletion completed in 22.048598303s

• [SLOW TEST:24.291 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:26:28.669: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 16:26:30.794: INFO: Waiting up to 5m0s for pod "client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f" in namespace "pods-539" to be "success or failure"
Sep  4 16:26:30.799: INFO: Pod "client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.383783ms
Sep  4 16:26:32.801: INFO: Pod "client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007530801s
STEP: Saw pod success
Sep  4 16:26:32.801: INFO: Pod "client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f" satisfied condition "success or failure"
Sep  4 16:26:32.803: INFO: Trying to get logs from node 192.168.0.166 pod client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f container env3cont: <nil>
STEP: delete the pod
Sep  4 16:26:32.846: INFO: Waiting for pod client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f to disappear
Sep  4 16:26:32.851: INFO: Pod client-envvars-d44d6422-83d1-4e74-956b-5d63f782e63f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:26:32.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-539" for this suite.
Sep  4 16:27:10.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:10.906: INFO: namespace pods-539 deletion completed in 38.053478451s

• [SLOW TEST:42.237 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:27:10.907: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep  4 16:27:10.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 create -f - --namespace=kubectl-7172'
Sep  4 16:27:11.093: INFO: stderr: ""
Sep  4 16:27:11.093: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep  4 16:27:12.095: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 16:27:12.095: INFO: Found 0 / 1
Sep  4 16:27:13.099: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 16:27:13.099: INFO: Found 1 / 1
Sep  4 16:27:13.099: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 16:27:13.101: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 16:27:13.101: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  4 16:27:13.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 logs redis-master-m95hb redis-master --namespace=kubectl-7172'
Sep  4 16:27:13.194: INFO: stderr: ""
Sep  4 16:27:13.194: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 16:27:12.139 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 16:27:12.139 # Server started, Redis version 3.2.12\n1:M 04 Sep 16:27:12.139 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  4 16:27:13.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 log redis-master-m95hb redis-master --namespace=kubectl-7172 --tail=1'
Sep  4 16:27:13.295: INFO: stderr: ""
Sep  4 16:27:13.295: INFO: stdout: "1:M 04 Sep 16:27:12.139 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  4 16:27:13.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 log redis-master-m95hb redis-master --namespace=kubectl-7172 --limit-bytes=1'
Sep  4 16:27:13.374: INFO: stderr: ""
Sep  4 16:27:13.374: INFO: stdout: " "
STEP: exposing timestamps
Sep  4 16:27:13.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 log redis-master-m95hb redis-master --namespace=kubectl-7172 --tail=1 --timestamps'
Sep  4 16:27:13.451: INFO: stderr: ""
Sep  4 16:27:13.451: INFO: stdout: "2019-09-04T16:27:12.139840405Z 1:M 04 Sep 16:27:12.139 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  4 16:27:15.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 log redis-master-m95hb redis-master --namespace=kubectl-7172 --since=1s'
Sep  4 16:27:16.033: INFO: stderr: ""
Sep  4 16:27:16.033: INFO: stdout: ""
Sep  4 16:27:16.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 log redis-master-m95hb redis-master --namespace=kubectl-7172 --since=24h'
Sep  4 16:27:16.112: INFO: stderr: ""
Sep  4 16:27:16.112: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 16:27:12.139 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 16:27:12.139 # Server started, Redis version 3.2.12\n1:M 04 Sep 16:27:12.139 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep  4 16:27:16.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 delete --grace-period=0 --force -f - --namespace=kubectl-7172'
Sep  4 16:27:16.190: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 16:27:16.190: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  4 16:27:16.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7172'
Sep  4 16:27:16.292: INFO: stderr: "No resources found.\n"
Sep  4 16:27:16.292: INFO: stdout: ""
Sep  4 16:27:16.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-227760248 get pods -l name=nginx --namespace=kubectl-7172 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 16:27:16.365: INFO: stderr: ""
Sep  4 16:27:16.365: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:27:16.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7172" for this suite.
Sep  4 16:27:22.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:22.440: INFO: namespace kubectl-7172 deletion completed in 6.071745495s

• [SLOW TEST:11.533 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:27:22.440: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-07fe7550-95f8-49f7-bcb5-7d29d51d7c69
STEP: Creating a pod to test consume secrets
Sep  4 16:27:22.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86" in namespace "projected-5365" to be "success or failure"
Sep  4 16:27:22.526: INFO: Pod "pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.371094ms
Sep  4 16:27:24.528: INFO: Pod "pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006703777s
STEP: Saw pod success
Sep  4 16:27:24.528: INFO: Pod "pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86" satisfied condition "success or failure"
Sep  4 16:27:24.529: INFO: Trying to get logs from node 192.168.0.166 pod pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 16:27:24.583: INFO: Waiting for pod pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86 to disappear
Sep  4 16:27:24.588: INFO: Pod pod-projected-secrets-ed56362a-ca9f-4129-8c91-ef67aec7ab86 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:27:24.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5365" for this suite.
Sep  4 16:27:30.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:30.637: INFO: namespace projected-5365 deletion completed in 6.045794973s

• [SLOW TEST:8.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:27:30.637: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-6a7339a3-9748-4d53-a42d-c587eb5935ba
STEP: Creating a pod to test consume configMaps
Sep  4 16:27:30.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d" in namespace "configmap-3664" to be "success or failure"
Sep  4 16:27:30.703: INFO: Pod "pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548681ms
Sep  4 16:27:32.705: INFO: Pod "pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006668214s
STEP: Saw pod success
Sep  4 16:27:32.705: INFO: Pod "pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d" satisfied condition "success or failure"
Sep  4 16:27:32.706: INFO: Trying to get logs from node 192.168.0.166 pod pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 16:27:32.741: INFO: Waiting for pod pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d to disappear
Sep  4 16:27:32.749: INFO: Pod pod-configmaps-701e600a-20f5-4390-9a4c-7f537957a36d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:27:32.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3664" for this suite.
Sep  4 16:27:38.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:38.797: INFO: namespace configmap-3664 deletion completed in 6.046796888s

• [SLOW TEST:8.161 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:27:38.798: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  4 16:27:38.875: INFO: Waiting up to 5m0s for pod "pod-684c402f-4bfa-42e6-9758-b3092dfed37b" in namespace "emptydir-8353" to be "success or failure"
Sep  4 16:27:38.890: INFO: Pod "pod-684c402f-4bfa-42e6-9758-b3092dfed37b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.857793ms
Sep  4 16:27:40.892: INFO: Pod "pod-684c402f-4bfa-42e6-9758-b3092dfed37b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016603501s
STEP: Saw pod success
Sep  4 16:27:40.892: INFO: Pod "pod-684c402f-4bfa-42e6-9758-b3092dfed37b" satisfied condition "success or failure"
Sep  4 16:27:40.893: INFO: Trying to get logs from node 192.168.0.166 pod pod-684c402f-4bfa-42e6-9758-b3092dfed37b container test-container: <nil>
STEP: delete the pod
Sep  4 16:27:40.919: INFO: Waiting for pod pod-684c402f-4bfa-42e6-9758-b3092dfed37b to disappear
Sep  4 16:27:40.926: INFO: Pod pod-684c402f-4bfa-42e6-9758-b3092dfed37b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:27:40.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8353" for this suite.
Sep  4 16:27:46.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:46.982: INFO: namespace emptydir-8353 deletion completed in 6.053873021s

• [SLOW TEST:8.184 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 16:27:46.982: INFO: >>> kubeConfig: /tmp/kubeconfig-227760248
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep  4 16:27:47.064: INFO: Waiting up to 5m0s for pod "client-containers-88951a95-5e24-41a9-907f-ed689b5bf726" in namespace "containers-3976" to be "success or failure"
Sep  4 16:27:47.069: INFO: Pod "client-containers-88951a95-5e24-41a9-907f-ed689b5bf726": Phase="Pending", Reason="", readiness=false. Elapsed: 4.575998ms
Sep  4 16:27:49.085: INFO: Pod "client-containers-88951a95-5e24-41a9-907f-ed689b5bf726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020633621s
STEP: Saw pod success
Sep  4 16:27:49.085: INFO: Pod "client-containers-88951a95-5e24-41a9-907f-ed689b5bf726" satisfied condition "success or failure"
Sep  4 16:27:49.087: INFO: Trying to get logs from node 192.168.0.166 pod client-containers-88951a95-5e24-41a9-907f-ed689b5bf726 container test-container: <nil>
STEP: delete the pod
Sep  4 16:27:49.269: INFO: Waiting for pod client-containers-88951a95-5e24-41a9-907f-ed689b5bf726 to disappear
Sep  4 16:27:49.275: INFO: Pod client-containers-88951a95-5e24-41a9-907f-ed689b5bf726 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 16:27:49.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3976" for this suite.
Sep  4 16:27:55.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 16:27:55.366: INFO: namespace containers-3976 deletion completed in 6.088959101s

• [SLOW TEST:8.384 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.0-rc.1.19+e8462b5b5dc258/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSep  4 16:27:55.366: INFO: Running AfterSuite actions on all nodes
Sep  4 16:27:55.366: INFO: Running AfterSuite actions on node 1
Sep  4 16:27:55.366: INFO: Skipping dumping logs from cluster

Ran 215 of 4411 Specs in 4944.292 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4196 Skipped
PASS

Ginkgo ran 1 suite in 1h22m26.547797242s
Test Suite Passed
