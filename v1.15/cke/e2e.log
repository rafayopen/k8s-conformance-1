I0904 04:31:05.256231      21 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-172565266
I0904 04:31:05.256319      21 e2e.go:241] Starting e2e run "85566eaa-2f40-407f-a305-309416ea0237" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567571464 - Will randomize all specs
Will run 215 of 4413 specs

Sep  4 04:31:05.383: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:31:05.385: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  4 04:31:05.394: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  4 04:31:05.411: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  4 04:31:05.411: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep  4 04:31:05.411: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  4 04:31:05.416: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep  4 04:31:05.416: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-dns' (0 seconds elapsed)
Sep  4 04:31:05.416: INFO: e2e test version: v1.15.3
Sep  4 04:31:05.417: INFO: kube-apiserver version: v1.15.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:31:05.418: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
Sep  4 04:31:05.440: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep  4 04:31:05.447: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:31:05.571: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c" in namespace "downward-api-5648" to be "success or failure"
Sep  4 04:31:05.573: INFO: Pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090461ms
Sep  4 04:31:07.578: INFO: Pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006793756s
Sep  4 04:31:09.583: INFO: Pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012095837s
Sep  4 04:31:11.603: INFO: Pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03227719s
STEP: Saw pod success
Sep  4 04:31:11.603: INFO: Pod "downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c" satisfied condition "success or failure"
Sep  4 04:31:11.615: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c container client-container: <nil>
STEP: delete the pod
Sep  4 04:31:11.665: INFO: Waiting for pod downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c to disappear
Sep  4 04:31:11.669: INFO: Pod downwardapi-volume-e492ee3c-ce58-450b-b955-8decb1c06d7c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:31:11.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5648" for this suite.
Sep  4 04:31:17.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:31:17.917: INFO: namespace downward-api-5648 deletion completed in 6.245410919s

• [SLOW TEST:12.500 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:31:17.918: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-8c75a030-37c4-40b0-af2a-3fa389066b6f in namespace container-probe-6689
Sep  4 04:31:24.124: INFO: Started pod liveness-8c75a030-37c4-40b0-af2a-3fa389066b6f in namespace container-probe-6689
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 04:31:24.132: INFO: Initial restart count of pod liveness-8c75a030-37c4-40b0-af2a-3fa389066b6f is 0
Sep  4 04:31:48.328: INFO: Restart count of pod container-probe-6689/liveness-8c75a030-37c4-40b0-af2a-3fa389066b6f is now 1 (24.194994343s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:31:48.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6689" for this suite.
Sep  4 04:31:54.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:31:54.637: INFO: namespace container-probe-6689 deletion completed in 6.210028681s

• [SLOW TEST:36.719 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:31:54.637: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-f732efe0-7f55-4020-ac2d-65a8c6e3f967
STEP: Creating a pod to test consume secrets
Sep  4 04:31:54.809: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c" in namespace "projected-8042" to be "success or failure"
Sep  4 04:31:54.839: INFO: Pod "pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c": Phase="Pending", Reason="", readiness=false. Elapsed: 30.153436ms
Sep  4 04:31:56.846: INFO: Pod "pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036945824s
STEP: Saw pod success
Sep  4 04:31:56.846: INFO: Pod "pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c" satisfied condition "success or failure"
Sep  4 04:31:56.851: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 04:31:56.895: INFO: Waiting for pod pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c to disappear
Sep  4 04:31:56.909: INFO: Pod pod-projected-secrets-5ccb3d7c-4a6b-4de7-b658-756548c6e66c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:31:56.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8042" for this suite.
Sep  4 04:32:02.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:32:03.182: INFO: namespace projected-8042 deletion completed in 6.264887794s

• [SLOW TEST:8.545 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:32:03.183: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:32:11.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3440" for this suite.
Sep  4 04:32:59.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:32:59.587: INFO: namespace kubelet-test-3440 deletion completed in 48.102468542s

• [SLOW TEST:56.404 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:32:59.587: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:33:05.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4134" for this suite.
Sep  4 04:33:47.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:33:48.160: INFO: namespace kubelet-test-4134 deletion completed in 42.373053436s

• [SLOW TEST:48.573 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:33:48.160: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 04:33:48.311: INFO: Waiting up to 5m0s for pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244" in namespace "emptydir-7945" to be "success or failure"
Sep  4 04:33:48.317: INFO: Pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244": Phase="Pending", Reason="", readiness=false. Elapsed: 6.447925ms
Sep  4 04:33:50.324: INFO: Pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013426141s
Sep  4 04:33:52.330: INFO: Pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018695669s
Sep  4 04:33:54.332: INFO: Pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021551125s
STEP: Saw pod success
Sep  4 04:33:54.332: INFO: Pod "pod-1328737d-9d2d-4262-8668-75d3c74cd244" satisfied condition "success or failure"
Sep  4 04:33:54.335: INFO: Trying to get logs from node 192.168.1.101 pod pod-1328737d-9d2d-4262-8668-75d3c74cd244 container test-container: <nil>
STEP: delete the pod
Sep  4 04:33:54.351: INFO: Waiting for pod pod-1328737d-9d2d-4262-8668-75d3c74cd244 to disappear
Sep  4 04:33:54.354: INFO: Pod pod-1328737d-9d2d-4262-8668-75d3c74cd244 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:33:54.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7945" for this suite.
Sep  4 04:34:00.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:34:00.448: INFO: namespace emptydir-7945 deletion completed in 6.091224677s

• [SLOW TEST:12.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:34:00.448: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep  4 04:34:00.593: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172565266 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:34:00.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5986" for this suite.
Sep  4 04:34:06.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:34:06.930: INFO: namespace kubectl-5986 deletion completed in 6.17989505s

• [SLOW TEST:6.481 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:34:06.930: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep  4 04:34:07.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 api-versions'
Sep  4 04:34:07.134: INFO: stderr: ""
Sep  4 04:34:07.134: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:34:07.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7736" for this suite.
Sep  4 04:34:13.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:34:13.331: INFO: namespace kubectl-7736 deletion completed in 6.192431192s

• [SLOW TEST:6.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:34:13.331: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:34:13.504: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  4 04:34:18.507: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 04:34:22.519: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  4 04:34:24.563: INFO: Creating deployment "test-rollover-deployment"
Sep  4 04:34:24.612: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  4 04:34:26.640: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  4 04:34:26.667: INFO: Ensure that both replica sets have 1 created replica
Sep  4 04:34:26.698: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  4 04:34:26.708: INFO: Updating deployment test-rollover-deployment
Sep  4 04:34:26.708: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  4 04:34:28.722: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  4 04:34:28.755: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  4 04:34:28.786: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:28.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168466, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:31.309: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:31.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168466, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:32.814: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:32.814: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168472, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:34.815: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:34.816: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168472, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:36.823: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:36.824: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168472, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:38.810: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:38.814: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168472, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:40.815: INFO: all replica sets need to contain the pod-template-hash label
Sep  4 04:34:40.816: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168472, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703168464, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 04:34:42.798: INFO: 
Sep  4 04:34:42.798: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  4 04:34:42.805: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8704,SelfLink:/apis/apps/v1/namespaces/deployment-8704/deployments/test-rollover-deployment,UID:ee099390-9f79-46eb-b246-bdd65b9bbe00,ResourceVersion:1564,Generation:2,CreationTimestamp:2019-09-04 04:34:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-04 04:34:24 +0000 UTC 2019-09-04 04:34:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-04 04:34:42 +0000 UTC 2019-09-04 04:34:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  4 04:34:42.808: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-8704,SelfLink:/apis/apps/v1/namespaces/deployment-8704/replicasets/test-rollover-deployment-854595fc44,UID:45bbd76d-7812-459f-b5e1-f467314d1482,ResourceVersion:1554,Generation:2,CreationTimestamp:2019-09-04 04:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee099390-9f79-46eb-b246-bdd65b9bbe00 0xc00064c0b7 0xc00064c0b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 04:34:42.808: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  4 04:34:42.808: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8704,SelfLink:/apis/apps/v1/namespaces/deployment-8704/replicasets/test-rollover-controller,UID:f60c2c27-5f3e-4d4c-8b73-b00bb87bf473,ResourceVersion:1563,Generation:2,CreationTimestamp:2019-09-04 04:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee099390-9f79-46eb-b246-bdd65b9bbe00 0xc0000c9f0f 0xc0000c9f40}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 04:34:42.808: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-8704,SelfLink:/apis/apps/v1/namespaces/deployment-8704/replicasets/test-rollover-deployment-9b8b997cf,UID:af769427-6ce4-4dbd-8be5-4b6964a5d7fb,ResourceVersion:1511,Generation:2,CreationTimestamp:2019-09-04 04:34:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ee099390-9f79-46eb-b246-bdd65b9bbe00 0xc00064c1a0 0xc00064c1a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 04:34:42.811: INFO: Pod "test-rollover-deployment-854595fc44-j7dgt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-j7dgt,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-8704,SelfLink:/api/v1/namespaces/deployment-8704/pods/test-rollover-deployment-854595fc44-j7dgt,UID:e065e7a7-ef3d-4386-9181-5741ed752307,ResourceVersion:1538,Generation:0,CreationTimestamp:2019-09-04 04:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.13/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 45bbd76d-7812-459f-b5e1-f467314d1482 0xc00064d8a7 0xc00064d8a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pv7t6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pv7t6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pv7t6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00064d980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00064d9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:34:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:34:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:34:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:34:26 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.13,StartTime:2019-09-04 04:34:26 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-04 04:34:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6a7f83a05ef39adb78ddd0ef2c1d59825c2c2e94b50d1c6768bd9efd9c13e083}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:34:42.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8704" for this suite.
Sep  4 04:34:48.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:34:48.986: INFO: namespace deployment-8704 deletion completed in 6.173603977s

• [SLOW TEST:35.655 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:34:48.986: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:34:57.232: INFO: Waiting up to 5m0s for pod "client-envvars-659061cc-c98c-4c72-aa87-f410a2265076" in namespace "pods-9049" to be "success or failure"
Sep  4 04:34:57.248: INFO: Pod "client-envvars-659061cc-c98c-4c72-aa87-f410a2265076": Phase="Pending", Reason="", readiness=false. Elapsed: 16.541948ms
Sep  4 04:34:59.258: INFO: Pod "client-envvars-659061cc-c98c-4c72-aa87-f410a2265076": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026584928s
STEP: Saw pod success
Sep  4 04:34:59.261: INFO: Pod "client-envvars-659061cc-c98c-4c72-aa87-f410a2265076" satisfied condition "success or failure"
Sep  4 04:34:59.276: INFO: Trying to get logs from node 192.168.1.101 pod client-envvars-659061cc-c98c-4c72-aa87-f410a2265076 container env3cont: <nil>
STEP: delete the pod
Sep  4 04:34:59.365: INFO: Waiting for pod client-envvars-659061cc-c98c-4c72-aa87-f410a2265076 to disappear
Sep  4 04:34:59.372: INFO: Pod client-envvars-659061cc-c98c-4c72-aa87-f410a2265076 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:34:59.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9049" for this suite.
Sep  4 04:35:47.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:35:47.488: INFO: namespace pods-9049 deletion completed in 48.110984868s

• [SLOW TEST:58.502 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:35:47.488: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:35:47.648: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8" in namespace "projected-6381" to be "success or failure"
Sep  4 04:35:47.659: INFO: Pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.035652ms
Sep  4 04:35:49.665: INFO: Pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017388882s
Sep  4 04:35:52.138: INFO: Pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.490216031s
Sep  4 04:35:54.149: INFO: Pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.501498108s
STEP: Saw pod success
Sep  4 04:35:54.150: INFO: Pod "downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8" satisfied condition "success or failure"
Sep  4 04:35:54.159: INFO: Trying to get logs from node 192.168.1.103 pod downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8 container client-container: <nil>
STEP: delete the pod
Sep  4 04:35:54.232: INFO: Waiting for pod downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8 to disappear
Sep  4 04:35:54.250: INFO: Pod downwardapi-volume-0acc3eda-3de8-479d-8567-1b5fe87185f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:35:54.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6381" for this suite.
Sep  4 04:36:00.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:36:00.441: INFO: namespace projected-6381 deletion completed in 6.179528942s

• [SLOW TEST:12.952 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:36:00.441: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep  4 04:36:07.218: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0904 04:36:07.218535      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 04:36:07.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9171" for this suite.
Sep  4 04:36:13.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:36:13.396: INFO: namespace gc-9171 deletion completed in 6.175106335s

• [SLOW TEST:12.955 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:36:13.396: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  4 04:36:27.763: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 04:36:27.769: INFO: Pod pod-with-poststart-http-hook still exists
Sep  4 04:36:29.770: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 04:36:29.775: INFO: Pod pod-with-poststart-http-hook still exists
Sep  4 04:36:31.771: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  4 04:36:31.780: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:36:31.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8976" for this suite.
Sep  4 04:36:55.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:36:56.178: INFO: namespace container-lifecycle-hook-8976 deletion completed in 24.38602321s

• [SLOW TEST:42.782 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:36:56.179: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  4 04:36:56.393: INFO: Waiting up to 5m0s for pod "pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9" in namespace "emptydir-3917" to be "success or failure"
Sep  4 04:36:56.417: INFO: Pod "pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9": Phase="Pending", Reason="", readiness=false. Elapsed: 23.468586ms
Sep  4 04:36:58.435: INFO: Pod "pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041516481s
Sep  4 04:37:00.448: INFO: Pod "pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054878316s
STEP: Saw pod success
Sep  4 04:37:00.448: INFO: Pod "pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9" satisfied condition "success or failure"
Sep  4 04:37:00.460: INFO: Trying to get logs from node 192.168.1.101 pod pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9 container test-container: <nil>
STEP: delete the pod
Sep  4 04:37:00.486: INFO: Waiting for pod pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9 to disappear
Sep  4 04:37:00.489: INFO: Pod pod-c6416b79-27af-4e7e-9cbb-fee0a11dc6d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:37:00.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3917" for this suite.
Sep  4 04:37:06.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:37:06.766: INFO: namespace emptydir-3917 deletion completed in 6.27458103s

• [SLOW TEST:10.587 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:37:06.767: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6196
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 04:37:06.945: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 04:37:39.241: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.10.111.134:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:37:39.241: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:37:39.501: INFO: Found all expected endpoints: [netserver-0]
Sep  4 04:37:39.503: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.10.78.68:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:37:39.504: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:37:39.619: INFO: Found all expected endpoints: [netserver-1]
Sep  4 04:37:39.621: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.10.80.23:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:37:39.621: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:37:40.237: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:37:40.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6196" for this suite.
Sep  4 04:38:04.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:38:04.509: INFO: namespace pod-network-test-6196 deletion completed in 24.269307505s

• [SLOW TEST:57.742 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:38:04.509: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4887
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-b226b813-bf8c-4597-9d3e-4f5ff86301a3
STEP: Creating a pod to test consume configMaps
Sep  4 04:38:04.666: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f" in namespace "projected-4887" to be "success or failure"
Sep  4 04:38:04.670: INFO: Pod "pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290177ms
Sep  4 04:38:06.675: INFO: Pod "pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009092257s
Sep  4 04:38:08.688: INFO: Pod "pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022167143s
STEP: Saw pod success
Sep  4 04:38:08.688: INFO: Pod "pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f" satisfied condition "success or failure"
Sep  4 04:38:08.697: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 04:38:08.758: INFO: Waiting for pod pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f to disappear
Sep  4 04:38:08.772: INFO: Pod pod-projected-configmaps-4be36735-9b0a-4334-b621-0df64283f42f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:38:08.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4887" for this suite.
Sep  4 04:38:14.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:38:15.036: INFO: namespace projected-4887 deletion completed in 6.252298503s

• [SLOW TEST:10.527 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:38:15.038: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:38:15.244: INFO: (0) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 30.394408ms)
Sep  4 04:38:15.257: INFO: (1) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 12.629479ms)
Sep  4 04:38:15.272: INFO: (2) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 14.31158ms)
Sep  4 04:38:15.289: INFO: (3) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 16.635377ms)
Sep  4 04:38:15.788: INFO: (4) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 499.193868ms)
Sep  4 04:38:15.808: INFO: (5) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 19.36702ms)
Sep  4 04:38:15.853: INFO: (6) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 45.040281ms)
Sep  4 04:38:15.891: INFO: (7) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 38.418098ms)
Sep  4 04:38:15.900: INFO: (8) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 8.531128ms)
Sep  4 04:38:15.904: INFO: (9) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 3.894549ms)
Sep  4 04:38:15.911: INFO: (10) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 6.610102ms)
Sep  4 04:38:15.916: INFO: (11) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 5.294274ms)
Sep  4 04:38:15.925: INFO: (12) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 8.64048ms)
Sep  4 04:38:15.928: INFO: (13) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 3.229895ms)
Sep  4 04:38:15.931: INFO: (14) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 3.055423ms)
Sep  4 04:38:15.934: INFO: (15) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.472275ms)
Sep  4 04:38:15.936: INFO: (16) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.684489ms)
Sep  4 04:38:15.939: INFO: (17) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.696373ms)
Sep  4 04:38:15.942: INFO: (18) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.661531ms)
Sep  4 04:38:15.944: INFO: (19) /api/v1/nodes/192.168.1.101:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.305666ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:38:15.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3972" for this suite.
Sep  4 04:38:21.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:38:22.251: INFO: namespace proxy-3972 deletion completed in 6.304339058s

• [SLOW TEST:7.213 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:38:22.252: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  4 04:38:27.569: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:38:28.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-397" for this suite.
Sep  4 04:38:52.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:38:52.726: INFO: namespace replicaset-397 deletion completed in 24.133108001s

• [SLOW TEST:30.474 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:38:52.726: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 04:38:52.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-4473'
Sep  4 04:38:53.122: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 04:38:53.122: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep  4 04:38:55.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4473'
Sep  4 04:38:55.241: INFO: stderr: ""
Sep  4 04:38:55.241: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:38:55.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4473" for this suite.
Sep  4 04:39:01.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:39:01.540: INFO: namespace kubectl-4473 deletion completed in 6.296319735s

• [SLOW TEST:8.814 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:39:01.540: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-99d9d3ac-9203-4ea0-9940-36aa7c69512b
STEP: Creating a pod to test consume secrets
Sep  4 04:39:01.744: INFO: Waiting up to 5m0s for pod "pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29" in namespace "secrets-1010" to be "success or failure"
Sep  4 04:39:01.774: INFO: Pod "pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29": Phase="Pending", Reason="", readiness=false. Elapsed: 29.30948ms
Sep  4 04:39:03.784: INFO: Pod "pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039994656s
Sep  4 04:39:05.801: INFO: Pod "pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057026361s
STEP: Saw pod success
Sep  4 04:39:05.802: INFO: Pod "pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29" satisfied condition "success or failure"
Sep  4 04:39:05.810: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 04:39:05.882: INFO: Waiting for pod pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29 to disappear
Sep  4 04:39:05.897: INFO: Pod pod-secrets-96f7368f-0fe8-4c02-89f3-c414fa4b2e29 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:39:05.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1010" for this suite.
Sep  4 04:39:11.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:39:12.202: INFO: namespace secrets-1010 deletion completed in 6.290505534s

• [SLOW TEST:10.662 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:39:12.206: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b in namespace container-probe-8494
Sep  4 04:39:14.453: INFO: Started pod liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b in namespace container-probe-8494
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 04:39:14.460: INFO: Initial restart count of pod liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is 0
Sep  4 04:39:26.553: INFO: Restart count of pod container-probe-8494/liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is now 1 (12.092478156s elapsed)
Sep  4 04:39:46.630: INFO: Restart count of pod container-probe-8494/liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is now 2 (32.169178076s elapsed)
Sep  4 04:40:04.915: INFO: Restart count of pod container-probe-8494/liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is now 3 (50.454777501s elapsed)
Sep  4 04:40:27.284: INFO: Restart count of pod container-probe-8494/liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is now 4 (1m12.823515241s elapsed)
Sep  4 04:41:37.987: INFO: Restart count of pod container-probe-8494/liveness-1a4fa26b-0935-4608-85d9-fe917f5f7d6b is now 5 (2m23.526501538s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:41:38.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8494" for this suite.
Sep  4 04:41:44.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:41:44.284: INFO: namespace container-probe-8494 deletion completed in 6.158264412s

• [SLOW TEST:152.079 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:41:44.285: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:41:46.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3148" for this suite.
Sep  4 04:42:24.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:42:24.706: INFO: namespace kubelet-test-3148 deletion completed in 38.193476705s

• [SLOW TEST:40.422 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:42:24.708: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  4 04:42:35.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:35.020: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:37.024: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:37.033: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:39.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:39.023: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:41.021: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:41.029: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:43.021: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:43.034: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:45.021: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:45.030: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:47.021: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:47.028: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:49.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:49.035: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:51.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:51.026: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:53.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:53.024: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:55.023: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:55.033: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  4 04:42:57.021: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  4 04:42:57.037: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:42:57.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2743" for this suite.
Sep  4 04:43:27.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:43:27.230: INFO: namespace container-lifecycle-hook-2743 deletion completed in 30.178263959s

• [SLOW TEST:62.522 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:43:27.231: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:43:27.365: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03" in namespace "projected-1190" to be "success or failure"
Sep  4 04:43:27.368: INFO: Pod "downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.323392ms
Sep  4 04:43:29.377: INFO: Pod "downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011805472s
STEP: Saw pod success
Sep  4 04:43:29.377: INFO: Pod "downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03" satisfied condition "success or failure"
Sep  4 04:43:29.385: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03 container client-container: <nil>
STEP: delete the pod
Sep  4 04:43:29.430: INFO: Waiting for pod downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03 to disappear
Sep  4 04:43:29.436: INFO: Pod downwardapi-volume-0cf1232a-3052-4026-b172-c560e2500a03 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:43:29.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1190" for this suite.
Sep  4 04:43:35.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:43:35.730: INFO: namespace projected-1190 deletion completed in 6.291353618s

• [SLOW TEST:8.500 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:43:35.730: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-b240df07-74fa-4c2a-8887-3251b4f91ebe
STEP: Creating a pod to test consume secrets
Sep  4 04:43:35.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105" in namespace "projected-718" to be "success or failure"
Sep  4 04:43:35.965: INFO: Pod "pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105": Phase="Pending", Reason="", readiness=false. Elapsed: 16.532555ms
Sep  4 04:43:37.968: INFO: Pod "pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019064026s
Sep  4 04:43:39.978: INFO: Pod "pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028891236s
STEP: Saw pod success
Sep  4 04:43:39.978: INFO: Pod "pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105" satisfied condition "success or failure"
Sep  4 04:43:39.987: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 04:43:40.048: INFO: Waiting for pod pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105 to disappear
Sep  4 04:43:40.057: INFO: Pod pod-projected-secrets-152f41a7-77c0-40cb-a05e-06f3fd52e105 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:43:40.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-718" for this suite.
Sep  4 04:43:46.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:43:46.356: INFO: namespace projected-718 deletion completed in 6.292726993s

• [SLOW TEST:10.625 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:43:46.356: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:43:46.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0" in namespace "projected-2650" to be "success or failure"
Sep  4 04:43:46.595: INFO: Pod "downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.218696ms
Sep  4 04:43:48.604: INFO: Pod "downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027328913s
Sep  4 04:43:50.625: INFO: Pod "downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047854832s
STEP: Saw pod success
Sep  4 04:43:50.625: INFO: Pod "downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0" satisfied condition "success or failure"
Sep  4 04:43:50.635: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0 container client-container: <nil>
STEP: delete the pod
Sep  4 04:43:50.785: INFO: Waiting for pod downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0 to disappear
Sep  4 04:43:50.788: INFO: Pod downwardapi-volume-dc475fb1-615a-4946-a1e0-5b2bcc42aed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:43:50.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2650" for this suite.
Sep  4 04:43:56.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:43:57.134: INFO: namespace projected-2650 deletion completed in 6.34084432s

• [SLOW TEST:10.778 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:43:57.134: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-5c930217-ca8a-40c6-b366-e16f3d606a16
STEP: Creating a pod to test consume configMaps
Sep  4 04:43:57.375: INFO: Waiting up to 5m0s for pod "pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355" in namespace "configmap-9613" to be "success or failure"
Sep  4 04:43:57.387: INFO: Pod "pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355": Phase="Pending", Reason="", readiness=false. Elapsed: 11.627704ms
Sep  4 04:43:59.390: INFO: Pod "pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01477119s
Sep  4 04:44:01.393: INFO: Pod "pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018183068s
STEP: Saw pod success
Sep  4 04:44:01.394: INFO: Pod "pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355" satisfied condition "success or failure"
Sep  4 04:44:01.396: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 04:44:01.431: INFO: Waiting for pod pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355 to disappear
Sep  4 04:44:01.440: INFO: Pod pod-configmaps-96b99657-fbdc-4a3b-8929-eceeccca0355 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:01.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9613" for this suite.
Sep  4 04:44:07.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:44:07.522: INFO: namespace configmap-9613 deletion completed in 6.076949972s

• [SLOW TEST:10.389 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:44:07.523: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-cd67a47e-20b0-4cbf-98aa-cb02b2ba8345
STEP: Creating a pod to test consume secrets
Sep  4 04:44:07.662: INFO: Waiting up to 5m0s for pod "pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7" in namespace "secrets-8206" to be "success or failure"
Sep  4 04:44:07.667: INFO: Pod "pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.34445ms
Sep  4 04:44:09.680: INFO: Pod "pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017779248s
Sep  4 04:44:11.691: INFO: Pod "pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028396432s
STEP: Saw pod success
Sep  4 04:44:11.691: INFO: Pod "pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7" satisfied condition "success or failure"
Sep  4 04:44:11.702: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7 container secret-env-test: <nil>
STEP: delete the pod
Sep  4 04:44:11.777: INFO: Waiting for pod pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7 to disappear
Sep  4 04:44:11.780: INFO: Pod pod-secrets-1bdb6119-e986-42a8-b91d-1f8af684e6d7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:11.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8206" for this suite.
Sep  4 04:44:17.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:44:17.993: INFO: namespace secrets-8206 deletion completed in 6.208312938s

• [SLOW TEST:10.470 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:44:17.993: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1095
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:44:18.152: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:19.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1095" for this suite.
Sep  4 04:44:25.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:44:25.549: INFO: namespace custom-resource-definition-1095 deletion completed in 6.225972676s

• [SLOW TEST:7.555 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:44:25.549: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1261
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 04:44:25.727: INFO: Waiting up to 5m0s for pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97" in namespace "downward-api-1261" to be "success or failure"
Sep  4 04:44:25.787: INFO: Pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97": Phase="Pending", Reason="", readiness=false. Elapsed: 60.074981ms
Sep  4 04:44:27.799: INFO: Pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071597032s
Sep  4 04:44:29.801: INFO: Pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074165416s
Sep  4 04:44:31.807: INFO: Pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.079999912s
STEP: Saw pod success
Sep  4 04:44:31.807: INFO: Pod "downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97" satisfied condition "success or failure"
Sep  4 04:44:31.813: INFO: Trying to get logs from node 192.168.1.103 pod downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97 container dapi-container: <nil>
STEP: delete the pod
Sep  4 04:44:31.869: INFO: Waiting for pod downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97 to disappear
Sep  4 04:44:31.879: INFO: Pod downward-api-405ab9a4-1d4d-4652-8d14-465eb07f5b97 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:31.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1261" for this suite.
Sep  4 04:44:37.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:44:38.190: INFO: namespace downward-api-1261 deletion completed in 6.303824233s

• [SLOW TEST:12.641 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:44:38.190: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep  4 04:44:38.409: INFO: Waiting up to 5m0s for pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627" in namespace "containers-9231" to be "success or failure"
Sep  4 04:44:38.426: INFO: Pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627": Phase="Pending", Reason="", readiness=false. Elapsed: 17.26903ms
Sep  4 04:44:40.439: INFO: Pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029654716s
Sep  4 04:44:42.444: INFO: Pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035011899s
Sep  4 04:44:44.453: INFO: Pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044171661s
STEP: Saw pod success
Sep  4 04:44:44.453: INFO: Pod "client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627" satisfied condition "success or failure"
Sep  4 04:44:44.462: INFO: Trying to get logs from node 192.168.1.101 pod client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627 container test-container: <nil>
STEP: delete the pod
Sep  4 04:44:44.574: INFO: Waiting for pod client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627 to disappear
Sep  4 04:44:44.586: INFO: Pod client-containers-2613cc5d-a43e-4d21-865b-c721baaa0627 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:44.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9231" for this suite.
Sep  4 04:44:50.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:44:50.828: INFO: namespace containers-9231 deletion completed in 6.228126963s

• [SLOW TEST:12.638 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:44:50.828: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ca11a16d-e925-4b92-be01-4b5cdd0e47c0
STEP: Creating a pod to test consume secrets
Sep  4 04:44:51.010: INFO: Waiting up to 5m0s for pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394" in namespace "secrets-1386" to be "success or failure"
Sep  4 04:44:51.037: INFO: Pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394": Phase="Pending", Reason="", readiness=false. Elapsed: 26.638273ms
Sep  4 04:44:53.043: INFO: Pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032371789s
Sep  4 04:44:55.055: INFO: Pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044673266s
Sep  4 04:44:57.071: INFO: Pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.060495278s
STEP: Saw pod success
Sep  4 04:44:57.071: INFO: Pod "pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394" satisfied condition "success or failure"
Sep  4 04:44:57.083: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 04:44:57.167: INFO: Waiting for pod pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394 to disappear
Sep  4 04:44:57.188: INFO: Pod pod-secrets-9d4ea0c2-07c7-497a-92dd-6d80514f6394 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:44:57.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1386" for this suite.
Sep  4 04:45:03.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:45:03.424: INFO: namespace secrets-1386 deletion completed in 6.222339569s

• [SLOW TEST:12.596 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:45:03.425: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep  4 04:45:03.616: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2843" to be "success or failure"
Sep  4 04:45:03.632: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.682919ms
Sep  4 04:45:05.643: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025803231s
Sep  4 04:45:07.661: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04396129s
STEP: Saw pod success
Sep  4 04:45:07.661: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  4 04:45:07.666: INFO: Trying to get logs from node 192.168.1.101 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  4 04:45:07.698: INFO: Waiting for pod pod-host-path-test to disappear
Sep  4 04:45:07.709: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:45:07.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2843" for this suite.
Sep  4 04:45:14.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:45:14.218: INFO: namespace hostpath-2843 deletion completed in 6.501806573s

• [SLOW TEST:10.794 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:45:14.224: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:45:19.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8684" for this suite.
Sep  4 04:45:41.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:45:41.713: INFO: namespace replication-controller-8684 deletion completed in 22.218135406s

• [SLOW TEST:27.490 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:45:41.714: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-1225/secret-test-dc96c72b-a19b-49a4-9c9f-6ff8ca10d812
STEP: Creating a pod to test consume secrets
Sep  4 04:45:41.909: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967" in namespace "secrets-1225" to be "success or failure"
Sep  4 04:45:41.924: INFO: Pod "pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967": Phase="Pending", Reason="", readiness=false. Elapsed: 14.603216ms
Sep  4 04:45:43.928: INFO: Pod "pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018173836s
Sep  4 04:45:45.931: INFO: Pod "pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021909404s
STEP: Saw pod success
Sep  4 04:45:45.932: INFO: Pod "pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967" satisfied condition "success or failure"
Sep  4 04:45:45.935: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967 container env-test: <nil>
STEP: delete the pod
Sep  4 04:45:45.954: INFO: Waiting for pod pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967 to disappear
Sep  4 04:45:45.956: INFO: Pod pod-configmaps-bc4a5584-aed3-4fb7-bdee-5984bce24967 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:45:45.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1225" for this suite.
Sep  4 04:45:51.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:45:52.170: INFO: namespace secrets-1225 deletion completed in 6.210575967s

• [SLOW TEST:10.456 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:45:52.170: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:45:52.369: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 04:45:56.400: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  4 04:45:56.468: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6890,SelfLink:/apis/apps/v1/namespaces/deployment-6890/deployments/test-cleanup-deployment,UID:acf9c655-7cd8-4e74-aa6a-d7cd5b938969,ResourceVersion:3774,Generation:1,CreationTimestamp:2019-09-04 04:45:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  4 04:45:56.500: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-6890,SelfLink:/apis/apps/v1/namespaces/deployment-6890/replicasets/test-cleanup-deployment-55bbcbc84c,UID:c2f6e264-0dc2-41c6-97ec-4b06b32260da,ResourceVersion:3776,Generation:1,CreationTimestamp:2019-09-04 04:45:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment acf9c655-7cd8-4e74-aa6a-d7cd5b938969 0xc003d721d7 0xc003d721d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 04:45:56.500: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep  4 04:45:56.501: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-6890,SelfLink:/apis/apps/v1/namespaces/deployment-6890/replicasets/test-cleanup-controller,UID:23cc55d9-16cd-44c4-b212-858604d79144,ResourceVersion:3775,Generation:1,CreationTimestamp:2019-09-04 04:45:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment acf9c655-7cd8-4e74-aa6a-d7cd5b938969 0xc003d720ff 0xc003d72110}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 04:45:56.527: INFO: Pod "test-cleanup-controller-57tl8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-57tl8,GenerateName:test-cleanup-controller-,Namespace:deployment-6890,SelfLink:/api/v1/namespaces/deployment-6890/pods/test-cleanup-controller-57tl8,UID:67e0f8eb-bb56-499b-b21a-49d83435dccd,ResourceVersion:3771,Generation:0,CreationTimestamp:2019-09-04 04:45:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.44/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 23cc55d9-16cd-44c4-b212-858604d79144 0xc003d72b6f 0xc003d72b90}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hthh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hthh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hthh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003d72c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003d72c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:45:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:45:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:45:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:45:52 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.44,StartTime:2019-09-04 04:45:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 04:45:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://57d3249e73a8b113b77b84b3630c1ee89c940b89711f6928b928d7cae90874ff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 04:45:56.527: INFO: Pod "test-cleanup-deployment-55bbcbc84c-qcglz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-qcglz,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-6890,SelfLink:/api/v1/namespaces/deployment-6890/pods/test-cleanup-deployment-55bbcbc84c-qcglz,UID:b02b016c-819c-4a90-ae1b-b3a07c7a767c,ResourceVersion:3780,Generation:0,CreationTimestamp:2019-09-04 04:45:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c c2f6e264-0dc2-41c6-97ec-4b06b32260da 0xc003d72cf7 0xc003d72cf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hthh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hthh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5hthh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003d72d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003d72d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:45:56 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:45:56.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6890" for this suite.
Sep  4 04:46:02.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:46:02.794: INFO: namespace deployment-6890 deletion completed in 6.250576609s

• [SLOW TEST:10.624 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:46:02.795: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  4 04:46:03.247: INFO: Pod name wrapped-volume-race-9e22e0ca-dc68-46ac-94c3-e9267636aa0f: Found 0 pods out of 5
Sep  4 04:46:08.259: INFO: Pod name wrapped-volume-race-9e22e0ca-dc68-46ac-94c3-e9267636aa0f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9e22e0ca-dc68-46ac-94c3-e9267636aa0f in namespace emptydir-wrapper-4497, will wait for the garbage collector to delete the pods
Sep  4 04:46:20.378: INFO: Deleting ReplicationController wrapped-volume-race-9e22e0ca-dc68-46ac-94c3-e9267636aa0f took: 34.20401ms
Sep  4 04:46:20.578: INFO: Terminating ReplicationController wrapped-volume-race-9e22e0ca-dc68-46ac-94c3-e9267636aa0f pods took: 200.74912ms
STEP: Creating RC which spawns configmap-volume pods
Sep  4 04:47:06.726: INFO: Pod name wrapped-volume-race-dda11111-9d78-457a-8748-1835ed3f672c: Found 0 pods out of 5
Sep  4 04:47:11.733: INFO: Pod name wrapped-volume-race-dda11111-9d78-457a-8748-1835ed3f672c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dda11111-9d78-457a-8748-1835ed3f672c in namespace emptydir-wrapper-4497, will wait for the garbage collector to delete the pods
Sep  4 04:47:21.895: INFO: Deleting ReplicationController wrapped-volume-race-dda11111-9d78-457a-8748-1835ed3f672c took: 36.627988ms
Sep  4 04:47:22.295: INFO: Terminating ReplicationController wrapped-volume-race-dda11111-9d78-457a-8748-1835ed3f672c pods took: 400.585763ms
STEP: Creating RC which spawns configmap-volume pods
Sep  4 04:48:06.716: INFO: Pod name wrapped-volume-race-29e7ecd8-c205-4ab5-b9a4-64ed52c3c523: Found 0 pods out of 5
Sep  4 04:48:11.719: INFO: Pod name wrapped-volume-race-29e7ecd8-c205-4ab5-b9a4-64ed52c3c523: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-29e7ecd8-c205-4ab5-b9a4-64ed52c3c523 in namespace emptydir-wrapper-4497, will wait for the garbage collector to delete the pods
Sep  4 04:48:21.915: INFO: Deleting ReplicationController wrapped-volume-race-29e7ecd8-c205-4ab5-b9a4-64ed52c3c523 took: 58.657084ms
Sep  4 04:48:22.316: INFO: Terminating ReplicationController wrapped-volume-race-29e7ecd8-c205-4ab5-b9a4-64ed52c3c523 pods took: 400.782044ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:49:06.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4497" for this suite.
Sep  4 04:49:14.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:49:14.238: INFO: namespace emptydir-wrapper-4497 deletion completed in 8.17857442s

• [SLOW TEST:191.443 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:49:14.238: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:49:14.381: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:49:18.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2503" for this suite.
Sep  4 04:49:56.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:49:56.853: INFO: namespace pods-2503 deletion completed in 38.288328812s

• [SLOW TEST:42.615 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:49:56.854: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-856
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f717e3f2-b3a4-4a4f-be1b-d470034313e5
STEP: Creating a pod to test consume configMaps
Sep  4 04:49:57.116: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196" in namespace "projected-856" to be "success or failure"
Sep  4 04:49:57.122: INFO: Pod "pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196": Phase="Pending", Reason="", readiness=false. Elapsed: 5.224259ms
Sep  4 04:49:59.125: INFO: Pod "pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007594909s
STEP: Saw pod success
Sep  4 04:49:59.125: INFO: Pod "pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196" satisfied condition "success or failure"
Sep  4 04:49:59.127: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 04:49:59.142: INFO: Waiting for pod pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196 to disappear
Sep  4 04:49:59.146: INFO: Pod pod-projected-configmaps-439ff96a-a0ef-4e67-9de6-95d7bca06196 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:49:59.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-856" for this suite.
Sep  4 04:50:05.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:50:05.547: INFO: namespace projected-856 deletion completed in 6.398110067s

• [SLOW TEST:8.693 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:50:05.547: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  4 04:50:13.896: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 04:50:13.906: INFO: Pod pod-with-prestop-http-hook still exists
Sep  4 04:50:15.911: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 04:50:15.921: INFO: Pod pod-with-prestop-http-hook still exists
Sep  4 04:50:17.910: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  4 04:50:17.926: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:50:17.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2386" for this suite.
Sep  4 04:50:40.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:50:40.221: INFO: namespace container-lifecycle-hook-2386 deletion completed in 22.249459576s

• [SLOW TEST:34.674 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:50:40.221: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 04:51:02.463: INFO: DNS probes using dns-test-dceada82-31c8-4fde-95a2-b5f04032d3b8 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 04:51:04.581: INFO: File wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local from pod  dns-3341/dns-test-20d32901-b5a2-40a9-874d-596d1a07d4e6 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep  4 04:51:04.588: INFO: File jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local from pod  dns-3341/dns-test-20d32901-b5a2-40a9-874d-596d1a07d4e6 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep  4 04:51:04.588: INFO: Lookups using dns-3341/dns-test-20d32901-b5a2-40a9-874d-596d1a07d4e6 failed for: [wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local]

Sep  4 04:51:09.595: INFO: DNS probes using dns-test-20d32901-b5a2-40a9-874d-596d1a07d4e6 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3341.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 04:51:11.691: INFO: File wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local from pod  dns-3341/dns-test-6aeb662a-8807-424f-ac37-3bc8a5516a64 contains 'bar.example.com.
' instead of '10.100.40.199'
Sep  4 04:51:11.701: INFO: File jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local from pod  dns-3341/dns-test-6aeb662a-8807-424f-ac37-3bc8a5516a64 contains 'bar.example.com.
' instead of '10.100.40.199'
Sep  4 04:51:11.702: INFO: Lookups using dns-3341/dns-test-6aeb662a-8807-424f-ac37-3bc8a5516a64 failed for: [wheezy_udp@dns-test-service-3.dns-3341.svc.cluster.local jessie_udp@dns-test-service-3.dns-3341.svc.cluster.local]

Sep  4 04:51:16.725: INFO: DNS probes using dns-test-6aeb662a-8807-424f-ac37-3bc8a5516a64 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:51:16.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3341" for this suite.
Sep  4 04:51:22.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:51:23.167: INFO: namespace dns-3341 deletion completed in 6.270708564s

• [SLOW TEST:42.946 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:51:23.167: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 04:51:23.305: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:51:31.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3697" for this suite.
Sep  4 04:51:37.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:51:38.570: INFO: namespace init-container-3697 deletion completed in 6.650630728s

• [SLOW TEST:15.403 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:51:38.571: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 04:51:38.819: INFO: Waiting up to 5m0s for pod "downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54" in namespace "downward-api-3636" to be "success or failure"
Sep  4 04:51:38.834: INFO: Pod "downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54": Phase="Pending", Reason="", readiness=false. Elapsed: 14.819565ms
Sep  4 04:51:40.843: INFO: Pod "downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024410195s
STEP: Saw pod success
Sep  4 04:51:40.844: INFO: Pod "downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54" satisfied condition "success or failure"
Sep  4 04:51:40.857: INFO: Trying to get logs from node 192.168.1.102 pod downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54 container dapi-container: <nil>
STEP: delete the pod
Sep  4 04:51:40.934: INFO: Waiting for pod downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54 to disappear
Sep  4 04:51:40.956: INFO: Pod downward-api-bddeee83-6707-4b26-b22a-4a3f5b73dc54 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:51:40.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3636" for this suite.
Sep  4 04:51:46.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:51:47.184: INFO: namespace downward-api-3636 deletion completed in 6.218851088s

• [SLOW TEST:8.613 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:51:47.184: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-4e961a6f-615a-4048-b0a3-f11f49fb28d1
STEP: Creating a pod to test consume configMaps
Sep  4 04:51:47.333: INFO: Waiting up to 5m0s for pod "pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd" in namespace "configmap-329" to be "success or failure"
Sep  4 04:51:47.338: INFO: Pod "pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.329292ms
Sep  4 04:51:49.341: INFO: Pod "pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008702911s
Sep  4 04:51:51.352: INFO: Pod "pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019242722s
STEP: Saw pod success
Sep  4 04:51:51.352: INFO: Pod "pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd" satisfied condition "success or failure"
Sep  4 04:51:51.362: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 04:51:51.450: INFO: Waiting for pod pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd to disappear
Sep  4 04:51:51.464: INFO: Pod pod-configmaps-56116376-85d6-45ae-a6ad-f3d44975e0cd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:51:51.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-329" for this suite.
Sep  4 04:51:57.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:51:58.215: INFO: namespace configmap-329 deletion completed in 6.742576511s

• [SLOW TEST:11.031 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:51:58.216: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:51:58.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134" in namespace "downward-api-5792" to be "success or failure"
Sep  4 04:51:58.467: INFO: Pod "downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134": Phase="Pending", Reason="", readiness=false. Elapsed: 20.739886ms
Sep  4 04:52:00.475: INFO: Pod "downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028576935s
STEP: Saw pod success
Sep  4 04:52:00.475: INFO: Pod "downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134" satisfied condition "success or failure"
Sep  4 04:52:00.477: INFO: Trying to get logs from node 192.168.1.103 pod downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134 container client-container: <nil>
STEP: delete the pod
Sep  4 04:52:00.491: INFO: Waiting for pod downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134 to disappear
Sep  4 04:52:00.494: INFO: Pod downwardapi-volume-e8a5874b-46aa-44e3-a316-07dc2d6c6134 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:52:00.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5792" for this suite.
Sep  4 04:52:06.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:52:06.800: INFO: namespace downward-api-5792 deletion completed in 6.303320669s

• [SLOW TEST:8.585 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:52:06.801: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 04:52:09.533: INFO: Successfully updated pod "annotationupdateabc5eb02-272b-48ff-9d22-3d099e4a6b3a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:52:11.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5277" for this suite.
Sep  4 04:52:33.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:52:33.754: INFO: namespace downward-api-5277 deletion completed in 22.112342947s

• [SLOW TEST:26.953 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:52:33.756: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:52:33.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91" in namespace "downward-api-9574" to be "success or failure"
Sep  4 04:52:33.936: INFO: Pod "downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91": Phase="Pending", Reason="", readiness=false. Elapsed: 21.875973ms
Sep  4 04:52:35.947: INFO: Pod "downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033253713s
Sep  4 04:52:37.957: INFO: Pod "downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043582214s
STEP: Saw pod success
Sep  4 04:52:37.958: INFO: Pod "downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91" satisfied condition "success or failure"
Sep  4 04:52:37.969: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91 container client-container: <nil>
STEP: delete the pod
Sep  4 04:52:38.332: INFO: Waiting for pod downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91 to disappear
Sep  4 04:52:38.348: INFO: Pod downwardapi-volume-832c32f6-e62f-49ba-844b-832de1e81a91 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:52:38.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9574" for this suite.
Sep  4 04:52:44.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:52:44.745: INFO: namespace downward-api-9574 deletion completed in 6.38759854s

• [SLOW TEST:10.989 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:52:44.745: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7420
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7420
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 04:52:44.904: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 04:53:11.118: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.13:8080/dial?request=hostName&protocol=udp&host=10.10.80.11&port=8081&tries=1'] Namespace:pod-network-test-7420 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:53:11.119: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:53:11.749: INFO: Waiting for endpoints: map[]
Sep  4 04:53:11.752: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.13:8080/dial?request=hostName&protocol=udp&host=10.10.111.137&port=8081&tries=1'] Namespace:pod-network-test-7420 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:53:11.752: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:53:11.849: INFO: Waiting for endpoints: map[]
Sep  4 04:53:11.852: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.13:8080/dial?request=hostName&protocol=udp&host=10.10.78.71&port=8081&tries=1'] Namespace:pod-network-test-7420 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 04:53:11.852: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 04:53:11.947: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:53:11.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7420" for this suite.
Sep  4 04:53:33.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:53:34.112: INFO: namespace pod-network-test-7420 deletion completed in 22.162948926s

• [SLOW TEST:49.367 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:53:34.112: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4612
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep  4 04:53:34.268: INFO: Found 0 stateful pods, waiting for 3
Sep  4 04:53:44.307: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 04:53:44.307: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 04:53:44.307: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  4 04:53:44.343: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  4 04:53:54.395: INFO: Updating stateful set ss2
Sep  4 04:53:54.411: INFO: Waiting for Pod statefulset-4612/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep  4 04:54:04.611: INFO: Found 2 stateful pods, waiting for 3
Sep  4 04:54:14.624: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 04:54:14.624: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 04:54:14.624: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  4 04:54:14.691: INFO: Updating stateful set ss2
Sep  4 04:54:14.716: INFO: Waiting for Pod statefulset-4612/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  4 04:54:24.797: INFO: Updating stateful set ss2
Sep  4 04:54:24.809: INFO: Waiting for StatefulSet statefulset-4612/ss2 to complete update
Sep  4 04:54:24.809: INFO: Waiting for Pod statefulset-4612/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  4 04:54:34.833: INFO: Waiting for StatefulSet statefulset-4612/ss2 to complete update
Sep  4 04:54:34.834: INFO: Waiting for Pod statefulset-4612/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 04:54:44.830: INFO: Deleting all statefulset in ns statefulset-4612
Sep  4 04:54:44.844: INFO: Scaling statefulset ss2 to 0
Sep  4 04:55:24.905: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 04:55:24.919: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:55:24.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4612" for this suite.
Sep  4 04:55:31.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:55:31.199: INFO: namespace statefulset-4612 deletion completed in 6.220866475s

• [SLOW TEST:117.087 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:55:31.199: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:55:31.391: INFO: (0) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 22.168687ms)
Sep  4 04:55:31.403: INFO: (1) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 11.199357ms)
Sep  4 04:55:31.408: INFO: (2) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 4.752997ms)
Sep  4 04:55:31.412: INFO: (3) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 4.651478ms)
Sep  4 04:55:31.418: INFO: (4) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 5.696019ms)
Sep  4 04:55:31.436: INFO: (5) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 17.880876ms)
Sep  4 04:55:31.439: INFO: (6) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 3.113008ms)
Sep  4 04:55:31.442: INFO: (7) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.622731ms)
Sep  4 04:55:31.445: INFO: (8) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.5924ms)
Sep  4 04:55:31.448: INFO: (9) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.81158ms)
Sep  4 04:55:31.450: INFO: (10) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.381561ms)
Sep  4 04:55:31.453: INFO: (11) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.493722ms)
Sep  4 04:55:31.455: INFO: (12) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.395437ms)
Sep  4 04:55:31.458: INFO: (13) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.599248ms)
Sep  4 04:55:31.460: INFO: (14) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.497583ms)
Sep  4 04:55:31.463: INFO: (15) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.879499ms)
Sep  4 04:55:31.466: INFO: (16) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.540143ms)
Sep  4 04:55:31.468: INFO: (17) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.652719ms)
Sep  4 04:55:31.471: INFO: (18) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.819844ms)
Sep  4 04:55:31.474: INFO: (19) /api/v1/nodes/192.168.1.101/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="bootstrap.... (200; 2.518445ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:55:31.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4627" for this suite.
Sep  4 04:55:37.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:55:37.711: INFO: namespace proxy-4627 deletion completed in 6.23487653s

• [SLOW TEST:6.512 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:55:37.711: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9470
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  4 04:55:37.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6444,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 04:55:37.965: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6445,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 04:55:37.967: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6446,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  4 04:55:48.055: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6461,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 04:55:48.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6462,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  4 04:55:48.057: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9470,SelfLink:/api/v1/namespaces/watch-9470/configmaps/e2e-watch-test-label-changed,UID:164ffcdb-2101-4b4b-8b47-ffba9f414f73,ResourceVersion:6463,Generation:0,CreationTimestamp:2019-09-04 04:55:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:55:48.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9470" for this suite.
Sep  4 04:55:54.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:55:54.323: INFO: namespace watch-9470 deletion completed in 6.249919957s

• [SLOW TEST:16.612 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:55:54.324: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 04:55:54.477: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  4 04:55:54.502: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  4 04:55:59.515: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  4 04:55:59.515: INFO: Creating deployment "test-rolling-update-deployment"
Sep  4 04:55:59.532: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  4 04:55:59.558: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  4 04:56:01.563: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  4 04:56:01.565: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  4 04:56:01.575: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6201,SelfLink:/apis/apps/v1/namespaces/deployment-6201/deployments/test-rolling-update-deployment,UID:de22a1bc-2183-4e8b-aac1-948249247ce2,ResourceVersion:6543,Generation:1,CreationTimestamp:2019-09-04 04:55:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-04 04:55:59 +0000 UTC 2019-09-04 04:55:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-04 04:56:01 +0000 UTC 2019-09-04 04:55:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  4 04:56:01.580: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6201,SelfLink:/apis/apps/v1/namespaces/deployment-6201/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:a5e81e45-a00f-4625-9754-d1473065064b,ResourceVersion:6532,Generation:1,CreationTimestamp:2019-09-04 04:55:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment de22a1bc-2183-4e8b-aac1-948249247ce2 0xc001bc50e7 0xc001bc50e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  4 04:56:01.580: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  4 04:56:01.580: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6201,SelfLink:/apis/apps/v1/namespaces/deployment-6201/replicasets/test-rolling-update-controller,UID:e12a1763-a737-467b-9a1d-1b9846f33055,ResourceVersion:6542,Generation:2,CreationTimestamp:2019-09-04 04:55:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment de22a1bc-2183-4e8b-aac1-948249247ce2 0xc001bc500f 0xc001bc5020}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 04:56:01.582: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-vbl4r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-vbl4r,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6201,SelfLink:/api/v1/namespaces/deployment-6201/pods/test-rolling-update-deployment-79f6b9d75c-vbl4r,UID:4e8c9e58-d527-422a-8ff8-a7f4a6598445,ResourceVersion:6531,Generation:0,CreationTimestamp:2019-09-04 04:55:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.16/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c a5e81e45-a00f-4625-9754-d1473065064b 0xc001bc59e7 0xc001bc59e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p9dp4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p9dp4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p9dp4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc5a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc5a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:55:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 04:55:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.16,StartTime:2019-09-04 04:55:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-04 04:56:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9f212203efbe374e3521437a28e2eff712adf1fd9bc3d0564c4f571d31fb5de8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:56:01.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6201" for this suite.
Sep  4 04:56:07.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:56:07.678: INFO: namespace deployment-6201 deletion completed in 6.093104219s

• [SLOW TEST:13.354 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:56:07.678: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-s9dw
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 04:56:07.841: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-s9dw" in namespace "subpath-3315" to be "success or failure"
Sep  4 04:56:07.860: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Pending", Reason="", readiness=false. Elapsed: 18.43349ms
Sep  4 04:56:10.063: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.222270953s
Sep  4 04:56:12.202: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 4.361199954s
Sep  4 04:56:14.213: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 6.371706802s
Sep  4 04:56:16.224: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 8.382369888s
Sep  4 04:56:18.377: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 10.536278957s
Sep  4 04:56:20.397: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 12.555471987s
Sep  4 04:56:22.410: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 14.56848527s
Sep  4 04:56:24.807: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 16.965600389s
Sep  4 04:56:26.818: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 18.976407702s
Sep  4 04:56:28.828: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 20.98642686s
Sep  4 04:56:30.843: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Running", Reason="", readiness=true. Elapsed: 23.001890498s
Sep  4 04:56:32.855: INFO: Pod "pod-subpath-test-projected-s9dw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 25.01353129s
STEP: Saw pod success
Sep  4 04:56:32.855: INFO: Pod "pod-subpath-test-projected-s9dw" satisfied condition "success or failure"
Sep  4 04:56:32.865: INFO: Trying to get logs from node 192.168.1.101 pod pod-subpath-test-projected-s9dw container test-container-subpath-projected-s9dw: <nil>
STEP: delete the pod
Sep  4 04:56:32.958: INFO: Waiting for pod pod-subpath-test-projected-s9dw to disappear
Sep  4 04:56:32.972: INFO: Pod pod-subpath-test-projected-s9dw no longer exists
STEP: Deleting pod pod-subpath-test-projected-s9dw
Sep  4 04:56:32.972: INFO: Deleting pod "pod-subpath-test-projected-s9dw" in namespace "subpath-3315"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:56:32.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3315" for this suite.
Sep  4 04:56:39.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:56:39.070: INFO: namespace subpath-3315 deletion completed in 6.083572852s

• [SLOW TEST:31.392 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:56:39.070: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  4 04:56:39.260: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  4 04:56:44.272: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:56:45.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-202" for this suite.
Sep  4 04:56:51.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:56:51.537: INFO: namespace replication-controller-202 deletion completed in 6.186367306s

• [SLOW TEST:12.467 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:56:51.537: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-3fe97d2f-9c59-422d-a3a1-459c2c28011a
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:56:51.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3620" for this suite.
Sep  4 04:56:57.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:56:58.012: INFO: namespace secrets-3620 deletion completed in 6.294704623s

• [SLOW TEST:6.474 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:56:58.012: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 04:56:58.168: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15" in namespace "downward-api-9966" to be "success or failure"
Sep  4 04:56:58.179: INFO: Pod "downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15": Phase="Pending", Reason="", readiness=false. Elapsed: 11.246666ms
Sep  4 04:57:00.190: INFO: Pod "downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022485892s
Sep  4 04:57:02.212: INFO: Pod "downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044488616s
STEP: Saw pod success
Sep  4 04:57:02.213: INFO: Pod "downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15" satisfied condition "success or failure"
Sep  4 04:57:02.232: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15 container client-container: <nil>
STEP: delete the pod
Sep  4 04:57:02.303: INFO: Waiting for pod downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15 to disappear
Sep  4 04:57:02.305: INFO: Pod downwardapi-volume-92c437f7-8fde-4c88-b2cc-9acc073e2a15 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:57:02.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9966" for this suite.
Sep  4 04:57:08.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:57:08.873: INFO: namespace downward-api-9966 deletion completed in 6.564226005s

• [SLOW TEST:10.861 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:57:08.873: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 04:57:09.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3394'
Sep  4 04:57:09.162: INFO: stderr: ""
Sep  4 04:57:09.162: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep  4 04:57:09.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete pods e2e-test-nginx-pod --namespace=kubectl-3394'
Sep  4 04:57:15.655: INFO: stderr: ""
Sep  4 04:57:15.655: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:57:15.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3394" for this suite.
Sep  4 04:57:21.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:57:21.943: INFO: namespace kubectl-3394 deletion completed in 6.26394177s

• [SLOW TEST:13.070 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:57:21.943: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8xg4
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 04:57:22.185: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8xg4" in namespace "subpath-4227" to be "success or failure"
Sep  4 04:57:22.203: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.634264ms
Sep  4 04:57:24.213: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028367174s
Sep  4 04:57:26.223: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 4.03814761s
Sep  4 04:57:28.239: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 6.05409793s
Sep  4 04:57:30.258: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 8.073087621s
Sep  4 04:57:32.278: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 10.093100436s
Sep  4 04:57:34.295: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 12.109958884s
Sep  4 04:57:36.308: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 14.122767072s
Sep  4 04:57:38.321: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 16.136008212s
Sep  4 04:57:40.334: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 18.148956607s
Sep  4 04:57:42.346: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 20.160713951s
Sep  4 04:57:44.360: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Running", Reason="", readiness=true. Elapsed: 22.174727997s
Sep  4 04:57:46.370: INFO: Pod "pod-subpath-test-configmap-8xg4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.185592057s
STEP: Saw pod success
Sep  4 04:57:46.371: INFO: Pod "pod-subpath-test-configmap-8xg4" satisfied condition "success or failure"
Sep  4 04:57:46.385: INFO: Trying to get logs from node 192.168.1.101 pod pod-subpath-test-configmap-8xg4 container test-container-subpath-configmap-8xg4: <nil>
STEP: delete the pod
Sep  4 04:57:46.480: INFO: Waiting for pod pod-subpath-test-configmap-8xg4 to disappear
Sep  4 04:57:46.486: INFO: Pod pod-subpath-test-configmap-8xg4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8xg4
Sep  4 04:57:46.486: INFO: Deleting pod "pod-subpath-test-configmap-8xg4" in namespace "subpath-4227"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:57:46.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4227" for this suite.
Sep  4 04:57:52.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:57:52.572: INFO: namespace subpath-4227 deletion completed in 6.079064044s

• [SLOW TEST:30.629 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:57:52.572: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7381
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  4 04:57:52.869: INFO: Waiting up to 5m0s for pod "pod-2579885f-6734-4bfa-a67d-1bd962d77ffe" in namespace "emptydir-7381" to be "success or failure"
Sep  4 04:57:52.908: INFO: Pod "pod-2579885f-6734-4bfa-a67d-1bd962d77ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 37.308502ms
Sep  4 04:57:54.913: INFO: Pod "pod-2579885f-6734-4bfa-a67d-1bd962d77ffe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042025403s
STEP: Saw pod success
Sep  4 04:57:54.913: INFO: Pod "pod-2579885f-6734-4bfa-a67d-1bd962d77ffe" satisfied condition "success or failure"
Sep  4 04:57:54.918: INFO: Trying to get logs from node 192.168.1.101 pod pod-2579885f-6734-4bfa-a67d-1bd962d77ffe container test-container: <nil>
STEP: delete the pod
Sep  4 04:57:54.952: INFO: Waiting for pod pod-2579885f-6734-4bfa-a67d-1bd962d77ffe to disappear
Sep  4 04:57:54.958: INFO: Pod pod-2579885f-6734-4bfa-a67d-1bd962d77ffe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:57:54.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7381" for this suite.
Sep  4 04:58:00.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:58:01.328: INFO: namespace emptydir-7381 deletion completed in 6.363701434s

• [SLOW TEST:8.756 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:58:01.330: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-74b97f44-bb66-46d9-b33a-49a1af4e6647
STEP: Creating secret with name secret-projected-all-test-volume-8a101aba-f173-4d85-838a-42fc16c53941
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  4 04:58:01.533: INFO: Waiting up to 5m0s for pod "projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61" in namespace "projected-8350" to be "success or failure"
Sep  4 04:58:01.539: INFO: Pod "projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61": Phase="Pending", Reason="", readiness=false. Elapsed: 6.537608ms
Sep  4 04:58:03.545: INFO: Pod "projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011971855s
STEP: Saw pod success
Sep  4 04:58:03.545: INFO: Pod "projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61" satisfied condition "success or failure"
Sep  4 04:58:03.550: INFO: Trying to get logs from node 192.168.1.101 pod projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  4 04:58:03.588: INFO: Waiting for pod projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61 to disappear
Sep  4 04:58:03.592: INFO: Pod projected-volume-5a51dbeb-53e6-4532-ae6a-3b76b1164c61 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:58:03.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8350" for this suite.
Sep  4 04:58:09.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:58:09.730: INFO: namespace projected-8350 deletion completed in 6.13033921s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:58:09.731: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3083
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  4 04:58:09.879: INFO: Waiting up to 5m0s for pod "pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1" in namespace "emptydir-3083" to be "success or failure"
Sep  4 04:58:09.882: INFO: Pod "pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.936361ms
Sep  4 04:58:11.893: INFO: Pod "pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014046956s
Sep  4 04:58:13.902: INFO: Pod "pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023241161s
STEP: Saw pod success
Sep  4 04:58:13.903: INFO: Pod "pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1" satisfied condition "success or failure"
Sep  4 04:58:13.911: INFO: Trying to get logs from node 192.168.1.101 pod pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1 container test-container: <nil>
STEP: delete the pod
Sep  4 04:58:13.974: INFO: Waiting for pod pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1 to disappear
Sep  4 04:58:13.987: INFO: Pod pod-71501786-c9de-4b4e-b4a8-0c6c935e9eb1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:58:13.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3083" for this suite.
Sep  4 04:58:20.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:58:20.625: INFO: namespace emptydir-3083 deletion completed in 6.623554496s

• [SLOW TEST:10.895 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:58:20.626: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 04:58:20.800: INFO: Waiting up to 5m0s for pod "downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32" in namespace "downward-api-249" to be "success or failure"
Sep  4 04:58:20.816: INFO: Pod "downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32": Phase="Pending", Reason="", readiness=false. Elapsed: 14.069726ms
Sep  4 04:58:22.820: INFO: Pod "downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017807087s
STEP: Saw pod success
Sep  4 04:58:22.820: INFO: Pod "downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32" satisfied condition "success or failure"
Sep  4 04:58:22.823: INFO: Trying to get logs from node 192.168.1.103 pod downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32 container dapi-container: <nil>
STEP: delete the pod
Sep  4 04:58:22.845: INFO: Waiting for pod downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32 to disappear
Sep  4 04:58:22.848: INFO: Pod downward-api-6682c8c7-0076-4b1c-9c48-d4325a888f32 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:58:22.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-249" for this suite.
Sep  4 04:58:28.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:58:29.051: INFO: namespace downward-api-249 deletion completed in 6.198784599s

• [SLOW TEST:8.426 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:58:29.052: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-f5b18a64-dab8-47f1-8104-568287badba6
STEP: Creating a pod to test consume secrets
Sep  4 04:58:29.236: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde" in namespace "projected-3649" to be "success or failure"
Sep  4 04:58:29.250: INFO: Pod "pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde": Phase="Pending", Reason="", readiness=false. Elapsed: 14.574813ms
Sep  4 04:58:31.254: INFO: Pod "pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018102295s
Sep  4 04:58:33.264: INFO: Pod "pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02829755s
STEP: Saw pod success
Sep  4 04:58:33.264: INFO: Pod "pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde" satisfied condition "success or failure"
Sep  4 04:58:33.273: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 04:58:33.349: INFO: Waiting for pod pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde to disappear
Sep  4 04:58:33.354: INFO: Pod pod-projected-secrets-89d9645a-236c-4372-aa8f-af4e028f5dde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:58:33.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3649" for this suite.
Sep  4 04:58:39.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:58:40.313: INFO: namespace projected-3649 deletion completed in 6.949567714s

• [SLOW TEST:11.262 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:58:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep  4 04:58:40.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-4748'
Sep  4 04:58:40.767: INFO: stderr: ""
Sep  4 04:58:40.767: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 04:58:40.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:40.847: INFO: stderr: ""
Sep  4 04:58:40.847: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-xqp8x "
Sep  4 04:58:40.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:40.894: INFO: stderr: ""
Sep  4 04:58:40.894: INFO: stdout: ""
Sep  4 04:58:40.894: INFO: update-demo-nautilus-cmgt9 is created but not running
Sep  4 04:58:45.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:46.014: INFO: stderr: ""
Sep  4 04:58:46.014: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-xqp8x "
Sep  4 04:58:46.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:46.065: INFO: stderr: ""
Sep  4 04:58:46.065: INFO: stdout: "true"
Sep  4 04:58:46.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:46.130: INFO: stderr: ""
Sep  4 04:58:46.130: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:58:46.130: INFO: validating pod update-demo-nautilus-cmgt9
Sep  4 04:58:46.134: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:58:46.134: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:58:46.134: INFO: update-demo-nautilus-cmgt9 is verified up and running
Sep  4 04:58:46.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-xqp8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:46.184: INFO: stderr: ""
Sep  4 04:58:46.184: INFO: stdout: "true"
Sep  4 04:58:46.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-xqp8x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:46.238: INFO: stderr: ""
Sep  4 04:58:46.238: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:58:46.238: INFO: validating pod update-demo-nautilus-xqp8x
Sep  4 04:58:46.241: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:58:46.241: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:58:46.241: INFO: update-demo-nautilus-xqp8x is verified up and running
STEP: scaling down the replication controller
Sep  4 04:58:46.242: INFO: scanned /root for discovery docs: <nil>
Sep  4 04:58:46.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4748'
Sep  4 04:58:46.317: INFO: stderr: ""
Sep  4 04:58:46.317: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 04:58:46.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:46.379: INFO: stderr: ""
Sep  4 04:58:46.379: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-xqp8x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  4 04:58:51.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:51.590: INFO: stderr: ""
Sep  4 04:58:51.590: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-xqp8x "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  4 04:58:56.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:56.772: INFO: stderr: ""
Sep  4 04:58:56.772: INFO: stdout: "update-demo-nautilus-cmgt9 "
Sep  4 04:58:56.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:56.890: INFO: stderr: ""
Sep  4 04:58:56.890: INFO: stdout: "true"
Sep  4 04:58:56.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:56.977: INFO: stderr: ""
Sep  4 04:58:56.977: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:58:56.977: INFO: validating pod update-demo-nautilus-cmgt9
Sep  4 04:58:56.980: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:58:56.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:58:56.980: INFO: update-demo-nautilus-cmgt9 is verified up and running
STEP: scaling up the replication controller
Sep  4 04:58:56.981: INFO: scanned /root for discovery docs: <nil>
Sep  4 04:58:56.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4748'
Sep  4 04:58:58.079: INFO: stderr: ""
Sep  4 04:58:58.079: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 04:58:58.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:58:58.164: INFO: stderr: ""
Sep  4 04:58:58.164: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-kx8g9 "
Sep  4 04:58:58.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:58.215: INFO: stderr: ""
Sep  4 04:58:58.215: INFO: stdout: "true"
Sep  4 04:58:58.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:58.267: INFO: stderr: ""
Sep  4 04:58:58.267: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:58:58.267: INFO: validating pod update-demo-nautilus-cmgt9
Sep  4 04:58:58.270: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:58:58.270: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:58:58.270: INFO: update-demo-nautilus-cmgt9 is verified up and running
Sep  4 04:58:58.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-kx8g9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:58:58.327: INFO: stderr: ""
Sep  4 04:58:58.327: INFO: stdout: ""
Sep  4 04:58:58.327: INFO: update-demo-nautilus-kx8g9 is created but not running
Sep  4 04:59:03.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4748'
Sep  4 04:59:03.529: INFO: stderr: ""
Sep  4 04:59:03.529: INFO: stdout: "update-demo-nautilus-cmgt9 update-demo-nautilus-kx8g9 "
Sep  4 04:59:03.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:59:03.603: INFO: stderr: ""
Sep  4 04:59:03.603: INFO: stdout: "true"
Sep  4 04:59:03.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cmgt9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:59:03.669: INFO: stderr: ""
Sep  4 04:59:03.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:59:03.669: INFO: validating pod update-demo-nautilus-cmgt9
Sep  4 04:59:03.673: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:59:03.673: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:59:03.673: INFO: update-demo-nautilus-cmgt9 is verified up and running
Sep  4 04:59:03.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-kx8g9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:59:03.738: INFO: stderr: ""
Sep  4 04:59:03.738: INFO: stdout: "true"
Sep  4 04:59:03.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-kx8g9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4748'
Sep  4 04:59:03.797: INFO: stderr: ""
Sep  4 04:59:03.797: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:59:03.797: INFO: validating pod update-demo-nautilus-kx8g9
Sep  4 04:59:03.800: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:59:03.800: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:59:03.800: INFO: update-demo-nautilus-kx8g9 is verified up and running
STEP: using delete to clean up resources
Sep  4 04:59:03.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-4748'
Sep  4 04:59:03.859: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 04:59:03.859: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 04:59:03.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4748'
Sep  4 04:59:03.925: INFO: stderr: "No resources found.\n"
Sep  4 04:59:03.925: INFO: stdout: ""
Sep  4 04:59:03.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=update-demo --namespace=kubectl-4748 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 04:59:03.976: INFO: stderr: ""
Sep  4 04:59:03.976: INFO: stdout: "update-demo-nautilus-cmgt9\nupdate-demo-nautilus-kx8g9\n"
Sep  4 04:59:04.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4748'
Sep  4 04:59:04.546: INFO: stderr: "No resources found.\n"
Sep  4 04:59:04.546: INFO: stdout: ""
Sep  4 04:59:04.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=update-demo --namespace=kubectl-4748 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 04:59:05.056: INFO: stderr: ""
Sep  4 04:59:05.056: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 04:59:05.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4748" for this suite.
Sep  4 04:59:27.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 04:59:27.245: INFO: namespace kubectl-4748 deletion completed in 22.183905911s

• [SLOW TEST:46.931 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 04:59:27.246: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep  4 04:59:27.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-4893'
Sep  4 04:59:27.693: INFO: stderr: ""
Sep  4 04:59:27.693: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 04:59:27.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4893'
Sep  4 04:59:27.765: INFO: stderr: ""
Sep  4 04:59:27.765: INFO: stdout: "update-demo-nautilus-cc6pf update-demo-nautilus-nqhz2 "
Sep  4 04:59:27.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cc6pf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 04:59:27.813: INFO: stderr: ""
Sep  4 04:59:27.813: INFO: stdout: ""
Sep  4 04:59:27.813: INFO: update-demo-nautilus-cc6pf is created but not running
Sep  4 04:59:32.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4893'
Sep  4 04:59:32.929: INFO: stderr: ""
Sep  4 04:59:32.929: INFO: stdout: "update-demo-nautilus-cc6pf update-demo-nautilus-nqhz2 "
Sep  4 04:59:32.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cc6pf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 04:59:32.988: INFO: stderr: ""
Sep  4 04:59:32.988: INFO: stdout: "true"
Sep  4 04:59:32.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-cc6pf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 04:59:33.042: INFO: stderr: ""
Sep  4 04:59:33.042: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:59:33.042: INFO: validating pod update-demo-nautilus-cc6pf
Sep  4 04:59:33.045: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:59:33.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:59:33.045: INFO: update-demo-nautilus-cc6pf is verified up and running
Sep  4 04:59:33.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-nqhz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 04:59:33.095: INFO: stderr: ""
Sep  4 04:59:33.095: INFO: stdout: "true"
Sep  4 04:59:33.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-nqhz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 04:59:33.154: INFO: stderr: ""
Sep  4 04:59:33.154: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 04:59:33.154: INFO: validating pod update-demo-nautilus-nqhz2
Sep  4 04:59:33.156: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 04:59:33.156: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 04:59:33.156: INFO: update-demo-nautilus-nqhz2 is verified up and running
STEP: rolling-update to new replication controller
Sep  4 04:59:33.157: INFO: scanned /root for discovery docs: <nil>
Sep  4 04:59:33.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4893'
Sep  4 05:00:05.682: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 05:00:05.682: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 05:00:05.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4893'
Sep  4 05:00:05.758: INFO: stderr: ""
Sep  4 05:00:05.758: INFO: stdout: "update-demo-kitten-74w5t update-demo-kitten-dvwtl "
Sep  4 05:00:05.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-kitten-74w5t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 05:00:05.825: INFO: stderr: ""
Sep  4 05:00:05.825: INFO: stdout: "true"
Sep  4 05:00:05.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-kitten-74w5t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 05:00:05.885: INFO: stderr: ""
Sep  4 05:00:05.885: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  4 05:00:05.885: INFO: validating pod update-demo-kitten-74w5t
Sep  4 05:00:05.888: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 05:00:05.888: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 05:00:05.888: INFO: update-demo-kitten-74w5t is verified up and running
Sep  4 05:00:05.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-kitten-dvwtl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 05:00:05.945: INFO: stderr: ""
Sep  4 05:00:05.945: INFO: stdout: "true"
Sep  4 05:00:05.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-kitten-dvwtl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4893'
Sep  4 05:00:06.000: INFO: stderr: ""
Sep  4 05:00:06.000: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  4 05:00:06.000: INFO: validating pod update-demo-kitten-dvwtl
Sep  4 05:00:06.002: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  4 05:00:06.002: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  4 05:00:06.002: INFO: update-demo-kitten-dvwtl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:00:06.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4893" for this suite.
Sep  4 05:00:30.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:00:30.102: INFO: namespace kubectl-4893 deletion completed in 24.097086336s

• [SLOW TEST:62.856 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:00:30.102: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3013
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:00:30.253: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08" in namespace "projected-3013" to be "success or failure"
Sep  4 05:00:30.270: INFO: Pod "downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08": Phase="Pending", Reason="", readiness=false. Elapsed: 16.38356ms
Sep  4 05:00:32.281: INFO: Pod "downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02686256s
Sep  4 05:00:34.291: INFO: Pod "downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037238262s
STEP: Saw pod success
Sep  4 05:00:34.291: INFO: Pod "downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08" satisfied condition "success or failure"
Sep  4 05:00:34.301: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08 container client-container: <nil>
STEP: delete the pod
Sep  4 05:00:34.351: INFO: Waiting for pod downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08 to disappear
Sep  4 05:00:34.377: INFO: Pod downwardapi-volume-ab6fded5-da98-49fe-8d7c-b3c198930f08 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:00:34.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3013" for this suite.
Sep  4 05:00:40.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:00:40.603: INFO: namespace projected-3013 deletion completed in 6.214210645s

• [SLOW TEST:10.501 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:00:40.604: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  4 05:00:45.314: INFO: Successfully updated pod "pod-update-activedeadlineseconds-462f3fd3-e512-49fb-9e5a-0d55ed409c50"
Sep  4 05:00:45.314: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-462f3fd3-e512-49fb-9e5a-0d55ed409c50" in namespace "pods-8996" to be "terminated due to deadline exceeded"
Sep  4 05:00:45.322: INFO: Pod "pod-update-activedeadlineseconds-462f3fd3-e512-49fb-9e5a-0d55ed409c50": Phase="Running", Reason="", readiness=true. Elapsed: 7.969141ms
Sep  4 05:00:47.336: INFO: Pod "pod-update-activedeadlineseconds-462f3fd3-e512-49fb-9e5a-0d55ed409c50": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.022125448s
Sep  4 05:00:47.337: INFO: Pod "pod-update-activedeadlineseconds-462f3fd3-e512-49fb-9e5a-0d55ed409c50" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:00:47.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8996" for this suite.
Sep  4 05:00:53.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:00:53.608: INFO: namespace pods-8996 deletion completed in 6.258350422s

• [SLOW TEST:13.005 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:00:53.609: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7030
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-889634c5-699d-4b52-8a5b-b5e782e22f8e in namespace container-probe-7030
Sep  4 05:00:55.780: INFO: Started pod test-webserver-889634c5-699d-4b52-8a5b-b5e782e22f8e in namespace container-probe-7030
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 05:00:55.787: INFO: Initial restart count of pod test-webserver-889634c5-699d-4b52-8a5b-b5e782e22f8e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:04:56.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7030" for this suite.
Sep  4 05:05:02.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:05:02.473: INFO: namespace container-probe-7030 deletion completed in 6.184738323s

• [SLOW TEST:248.863 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:05:02.474: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 05:05:02.624: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:05:06.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4406" for this suite.
Sep  4 05:05:12.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:05:13.247: INFO: namespace init-container-4406 deletion completed in 6.330287129s

• [SLOW TEST:10.773 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:05:13.247: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-8af0a6cf-d72b-41d1-9e8a-d663f6caed5d
STEP: Creating a pod to test consume configMaps
Sep  4 05:05:13.471: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4" in namespace "projected-965" to be "success or failure"
Sep  4 05:05:13.501: INFO: Pod "pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.120597ms
Sep  4 05:05:15.894: INFO: Pod "pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.422247842s
Sep  4 05:05:17.903: INFO: Pod "pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.43169105s
STEP: Saw pod success
Sep  4 05:05:17.903: INFO: Pod "pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4" satisfied condition "success or failure"
Sep  4 05:05:17.911: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:05:18.033: INFO: Waiting for pod pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4 to disappear
Sep  4 05:05:18.045: INFO: Pod pod-projected-configmaps-6132dc22-5d94-4e22-967a-d70570731dc4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:05:18.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-965" for this suite.
Sep  4 05:05:24.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:05:24.341: INFO: namespace projected-965 deletion completed in 6.272467553s

• [SLOW TEST:11.094 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:05:24.342: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-76132e79-9818-4447-8e17-91256afdb95e
STEP: Creating a pod to test consume configMaps
Sep  4 05:05:24.602: INFO: Waiting up to 5m0s for pod "pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35" in namespace "configmap-405" to be "success or failure"
Sep  4 05:05:24.614: INFO: Pod "pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35": Phase="Pending", Reason="", readiness=false. Elapsed: 12.255878ms
Sep  4 05:05:26.629: INFO: Pod "pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026556429s
Sep  4 05:05:28.638: INFO: Pod "pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035663877s
STEP: Saw pod success
Sep  4 05:05:28.638: INFO: Pod "pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35" satisfied condition "success or failure"
Sep  4 05:05:28.647: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:05:28.749: INFO: Waiting for pod pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35 to disappear
Sep  4 05:05:28.756: INFO: Pod pod-configmaps-76b79966-996a-4bc9-8053-6a53eebcea35 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:05:28.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-405" for this suite.
Sep  4 05:05:34.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:05:34.915: INFO: namespace configmap-405 deletion completed in 6.15356354s

• [SLOW TEST:10.574 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:05:34.915: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep  4 05:06:15.213: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0904 05:06:15.213612      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:06:15.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8469" for this suite.
Sep  4 05:06:23.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:06:23.495: INFO: namespace gc-8469 deletion completed in 8.273217613s

• [SLOW TEST:48.580 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:06:23.496: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  4 05:06:23.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8498,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 05:06:23.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8498,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  4 05:06:33.709: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8512,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  4 05:06:33.709: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8512,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  4 05:06:43.720: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8526,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 05:06:43.721: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8526,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  4 05:06:53.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8542,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 05:06:53.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-a,UID:2a4243ec-1a9e-49f2-b1d1-048bd352731a,ResourceVersion:8542,Generation:0,CreationTimestamp:2019-09-04 05:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  4 05:07:03.751: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-b,UID:336a11e9-fbcf-46ca-8b03-c18c3ff25033,ResourceVersion:8554,Generation:0,CreationTimestamp:2019-09-04 05:07:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 05:07:03.752: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-b,UID:336a11e9-fbcf-46ca-8b03-c18c3ff25033,ResourceVersion:8554,Generation:0,CreationTimestamp:2019-09-04 05:07:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  4 05:07:14.045: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-b,UID:336a11e9-fbcf-46ca-8b03-c18c3ff25033,ResourceVersion:8568,Generation:0,CreationTimestamp:2019-09-04 05:07:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 05:07:14.051: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-220,SelfLink:/api/v1/namespaces/watch-220/configmaps/e2e-watch-test-configmap-b,UID:336a11e9-fbcf-46ca-8b03-c18c3ff25033,ResourceVersion:8568,Generation:0,CreationTimestamp:2019-09-04 05:07:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:07:24.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-220" for this suite.
Sep  4 05:07:30.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:07:30.393: INFO: namespace watch-220 deletion completed in 6.32519276s

• [SLOW TEST:66.898 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:07:30.394: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:07:30.549: INFO: Creating ReplicaSet my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9
Sep  4 05:07:30.592: INFO: Pod name my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9: Found 0 pods out of 1
Sep  4 05:07:35.609: INFO: Pod name my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9: Found 1 pods out of 1
Sep  4 05:07:35.609: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9" is running
Sep  4 05:07:35.624: INFO: Pod "my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9-lrnpk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:07:30 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:07:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:07:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:07:30 +0000 UTC Reason: Message:}])
Sep  4 05:07:35.624: INFO: Trying to dial the pod
Sep  4 05:07:40.688: INFO: Controller my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9: Got expected result from replica 1 [my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9-lrnpk]: "my-hostname-basic-ae7946b9-01cb-4e6c-aa85-183e58ed31c9-lrnpk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:07:40.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4208" for this suite.
Sep  4 05:07:47.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:07:47.267: INFO: namespace replicaset-4208 deletion completed in 6.560335646s

• [SLOW TEST:16.873 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:07:47.267: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:07:47.465: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3" in namespace "downward-api-1917" to be "success or failure"
Sep  4 05:07:47.479: INFO: Pod "downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.042908ms
Sep  4 05:07:49.482: INFO: Pod "downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016729714s
STEP: Saw pod success
Sep  4 05:07:49.482: INFO: Pod "downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3" satisfied condition "success or failure"
Sep  4 05:07:49.485: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3 container client-container: <nil>
STEP: delete the pod
Sep  4 05:07:49.501: INFO: Waiting for pod downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3 to disappear
Sep  4 05:07:49.504: INFO: Pod downwardapi-volume-7c613972-80f6-426a-bec6-3fdc14cdc9a3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:07:49.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1917" for this suite.
Sep  4 05:07:55.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:07:55.704: INFO: namespace downward-api-1917 deletion completed in 6.195567827s

• [SLOW TEST:8.437 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:07:55.705: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:07:55.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76" in namespace "downward-api-1371" to be "success or failure"
Sep  4 05:07:55.923: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 22.604489ms
Sep  4 05:07:57.927: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026682091s
Sep  4 05:07:59.929: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028891607s
Sep  4 05:08:01.934: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03332823s
Sep  4 05:08:03.938: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037150919s
Sep  4 05:08:05.953: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052486263s
Sep  4 05:08:07.967: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.066665897s
STEP: Saw pod success
Sep  4 05:08:07.967: INFO: Pod "downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76" satisfied condition "success or failure"
Sep  4 05:08:07.977: INFO: Trying to get logs from node 192.168.1.102 pod downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76 container client-container: <nil>
STEP: delete the pod
Sep  4 05:08:08.102: INFO: Waiting for pod downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76 to disappear
Sep  4 05:08:08.112: INFO: Pod downwardapi-volume-980b70ce-0550-4a1b-be87-e3ba1243be76 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:08:08.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1371" for this suite.
Sep  4 05:08:14.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:08:14.777: INFO: namespace downward-api-1371 deletion completed in 6.651697775s

• [SLOW TEST:19.072 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:08:14.779: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5456.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5456.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5456.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5456.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 204.30.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.30.204_udp@PTR;check="$$(dig +tcp +noall +answer +search 204.30.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.30.204_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5456.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5456.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5456.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5456.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5456.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5456.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 204.30.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.30.204_udp@PTR;check="$$(dig +tcp +noall +answer +search 204.30.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.30.204_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 05:08:19.166: INFO: Unable to read wheezy_udp@dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.188: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.204: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.213: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.229: INFO: Unable to read wheezy_udp@PodARecord from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.233: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.246: INFO: Unable to read jessie_udp@dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.250: INFO: Unable to read jessie_tcp@dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.252: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.256: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.266: INFO: Unable to read jessie_udp@PodARecord from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.270: INFO: Unable to read jessie_tcp@PodARecord from pod dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6: the server could not find the requested resource (get pods dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6)
Sep  4 05:08:19.277: INFO: Lookups using dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6 failed for: [wheezy_udp@dns-test-service.dns-5456.svc.cluster.local wheezy_tcp@dns-test-service.dns-5456.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-5456.svc.cluster.local jessie_tcp@dns-test-service.dns-5456.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5456.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Sep  4 05:08:24.433: INFO: DNS probes using dns-5456/dns-test-1d405a11-a833-41f8-8c1b-a234ea800ca6 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:08:24.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5456" for this suite.
Sep  4 05:08:30.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:08:30.821: INFO: namespace dns-5456 deletion completed in 6.254060476s

• [SLOW TEST:16.042 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:08:30.822: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep  4 05:08:30.970: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172565266 proxy --unix-socket=/tmp/kubectl-proxy-unix599005513/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:08:31.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1856" for this suite.
Sep  4 05:08:37.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:08:37.394: INFO: namespace kubectl-1856 deletion completed in 6.226923071s

• [SLOW TEST:6.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:08:37.394: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  4 05:08:37.601: INFO: Waiting up to 5m0s for pod "pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6" in namespace "emptydir-2355" to be "success or failure"
Sep  4 05:08:37.608: INFO: Pod "pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.86334ms
Sep  4 05:08:39.611: INFO: Pod "pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010166386s
Sep  4 05:08:41.624: INFO: Pod "pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022973522s
STEP: Saw pod success
Sep  4 05:08:41.624: INFO: Pod "pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6" satisfied condition "success or failure"
Sep  4 05:08:41.639: INFO: Trying to get logs from node 192.168.1.101 pod pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6 container test-container: <nil>
STEP: delete the pod
Sep  4 05:08:41.731: INFO: Waiting for pod pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6 to disappear
Sep  4 05:08:41.734: INFO: Pod pod-ac9046ab-5df9-4c5a-a9fa-4a30d199d4d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:08:41.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2355" for this suite.
Sep  4 05:08:47.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:08:48.001: INFO: namespace emptydir-2355 deletion completed in 6.261212056s

• [SLOW TEST:10.607 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:08:48.003: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0904 05:09:18.742301      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 05:09:18.742: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:09:18.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1168" for this suite.
Sep  4 05:09:24.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:09:25.004: INFO: namespace gc-1168 deletion completed in 6.248677068s

• [SLOW TEST:37.001 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:09:25.004: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 05:09:25.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9115'
Sep  4 05:09:25.352: INFO: stderr: ""
Sep  4 05:09:25.352: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  4 05:09:30.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pod e2e-test-nginx-pod --namespace=kubectl-9115 -o json'
Sep  4 05:09:30.563: INFO: stderr: ""
Sep  4 05:09:30.563: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.10.80.47/32\"\n        },\n        \"creationTimestamp\": \"2019-09-04T05:09:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9115\",\n        \"resourceVersion\": \"9047\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9115/pods/e2e-test-nginx-pod\",\n        \"uid\": \"44e79801-1dfd-4b86-ac0d-0240e6ebfd7d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lvvvr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.1.101\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lvvvr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lvvvr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T05:09:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T05:09:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T05:09:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-04T05:09:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://564a074b418c1877146e91b3609e75cc3c36932d5283679f3423f7e8489df1d2\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-04T05:09:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.101\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.10.80.47\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-04T05:09:25Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  4 05:09:30.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 replace -f - --namespace=kubectl-9115'
Sep  4 05:09:30.708: INFO: stderr: ""
Sep  4 05:09:30.708: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep  4 05:09:30.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete pods e2e-test-nginx-pod --namespace=kubectl-9115'
Sep  4 05:09:35.701: INFO: stderr: ""
Sep  4 05:09:35.701: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:09:35.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9115" for this suite.
Sep  4 05:09:41.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:09:41.947: INFO: namespace kubectl-9115 deletion completed in 6.242897642s

• [SLOW TEST:16.944 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:09:41.948: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep  4 05:09:46.208: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172565266 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep  4 05:09:51.485: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:09:51.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4766" for this suite.
Sep  4 05:09:57.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:09:57.607: INFO: namespace pods-4766 deletion completed in 6.105408271s

• [SLOW TEST:15.660 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:09:57.607: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7914
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  4 05:09:57.820: INFO: Waiting up to 5m0s for pod "pod-3f117e8a-9b67-461c-9a94-478dfa537026" in namespace "emptydir-7914" to be "success or failure"
Sep  4 05:09:57.833: INFO: Pod "pod-3f117e8a-9b67-461c-9a94-478dfa537026": Phase="Pending", Reason="", readiness=false. Elapsed: 12.769971ms
Sep  4 05:09:59.837: INFO: Pod "pod-3f117e8a-9b67-461c-9a94-478dfa537026": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017159712s
Sep  4 05:10:01.842: INFO: Pod "pod-3f117e8a-9b67-461c-9a94-478dfa537026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021279693s
STEP: Saw pod success
Sep  4 05:10:01.842: INFO: Pod "pod-3f117e8a-9b67-461c-9a94-478dfa537026" satisfied condition "success or failure"
Sep  4 05:10:01.849: INFO: Trying to get logs from node 192.168.1.101 pod pod-3f117e8a-9b67-461c-9a94-478dfa537026 container test-container: <nil>
STEP: delete the pod
Sep  4 05:10:01.888: INFO: Waiting for pod pod-3f117e8a-9b67-461c-9a94-478dfa537026 to disappear
Sep  4 05:10:01.893: INFO: Pod pod-3f117e8a-9b67-461c-9a94-478dfa537026 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:10:01.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7914" for this suite.
Sep  4 05:10:07.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:10:08.033: INFO: namespace emptydir-7914 deletion completed in 6.133946414s

• [SLOW TEST:10.426 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:10:08.034: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 05:10:10.269: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:10:10.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2008" for this suite.
Sep  4 05:10:16.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:10:16.695: INFO: namespace container-runtime-2008 deletion completed in 6.347153008s

• [SLOW TEST:8.661 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:10:16.696: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep  4 05:10:16.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-4433'
Sep  4 05:10:17.103: INFO: stderr: ""
Sep  4 05:10:17.103: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep  4 05:10:18.107: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:10:18.107: INFO: Found 1 / 1
Sep  4 05:10:18.107: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 05:10:18.109: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:10:18.109: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  4 05:10:18.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 logs redis-master-h6lw5 redis-master --namespace=kubectl-4433'
Sep  4 05:10:18.188: INFO: stderr: ""
Sep  4 05:10:18.188: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 05:10:18.016 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 05:10:18.016 # Server started, Redis version 3.2.12\n1:M 04 Sep 05:10:18.016 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 05:10:18.016 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  4 05:10:18.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 log redis-master-h6lw5 redis-master --namespace=kubectl-4433 --tail=1'
Sep  4 05:10:18.763: INFO: stderr: ""
Sep  4 05:10:18.763: INFO: stdout: "1:M 04 Sep 05:10:18.016 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  4 05:10:18.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 log redis-master-h6lw5 redis-master --namespace=kubectl-4433 --limit-bytes=1'
Sep  4 05:10:18.855: INFO: stderr: ""
Sep  4 05:10:18.855: INFO: stdout: " "
STEP: exposing timestamps
Sep  4 05:10:18.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 log redis-master-h6lw5 redis-master --namespace=kubectl-4433 --tail=1 --timestamps'
Sep  4 05:10:18.933: INFO: stderr: ""
Sep  4 05:10:18.933: INFO: stdout: "2019-09-04T05:10:18.017131948Z 1:M 04 Sep 05:10:18.016 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  4 05:10:21.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 log redis-master-h6lw5 redis-master --namespace=kubectl-4433 --since=1s'
Sep  4 05:10:21.666: INFO: stderr: ""
Sep  4 05:10:21.666: INFO: stdout: ""
Sep  4 05:10:21.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 log redis-master-h6lw5 redis-master --namespace=kubectl-4433 --since=24h'
Sep  4 05:10:21.742: INFO: stderr: ""
Sep  4 05:10:21.742: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 05:10:18.016 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 05:10:18.016 # Server started, Redis version 3.2.12\n1:M 04 Sep 05:10:18.016 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 05:10:18.016 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep  4 05:10:21.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-4433'
Sep  4 05:10:21.811: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:10:21.811: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  4 05:10:21.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4433'
Sep  4 05:10:21.897: INFO: stderr: "No resources found.\n"
Sep  4 05:10:21.897: INFO: stdout: ""
Sep  4 05:10:21.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=nginx --namespace=kubectl-4433 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 05:10:21.968: INFO: stderr: ""
Sep  4 05:10:21.968: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:10:21.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4433" for this suite.
Sep  4 05:10:27.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:10:28.198: INFO: namespace kubectl-4433 deletion completed in 6.225517536s

• [SLOW TEST:11.502 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:10:28.198: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2118
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep  4 05:10:28.388: INFO: Waiting up to 5m0s for pod "var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a" in namespace "var-expansion-2118" to be "success or failure"
Sep  4 05:10:28.412: INFO: Pod "var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a": Phase="Pending", Reason="", readiness=false. Elapsed: 23.790733ms
Sep  4 05:10:30.418: INFO: Pod "var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029247075s
STEP: Saw pod success
Sep  4 05:10:30.418: INFO: Pod "var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a" satisfied condition "success or failure"
Sep  4 05:10:30.420: INFO: Trying to get logs from node 192.168.1.101 pod var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a container dapi-container: <nil>
STEP: delete the pod
Sep  4 05:10:30.441: INFO: Waiting for pod var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a to disappear
Sep  4 05:10:30.446: INFO: Pod var-expansion-5877bfce-9861-4783-96c9-1b1b6c87da4a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:10:30.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2118" for this suite.
Sep  4 05:10:38.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:10:38.746: INFO: namespace var-expansion-2118 deletion completed in 8.29379272s

• [SLOW TEST:10.548 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:10:38.747: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  4 05:10:49.028: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:49.028: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.162: INFO: Exec stderr: ""
Sep  4 05:10:50.162: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.162: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.278: INFO: Exec stderr: ""
Sep  4 05:10:50.278: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.278: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.361: INFO: Exec stderr: ""
Sep  4 05:10:50.362: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.362: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.436: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  4 05:10:50.436: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.436: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.527: INFO: Exec stderr: ""
Sep  4 05:10:50.527: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.527: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.620: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  4 05:10:50.620: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.620: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.707: INFO: Exec stderr: ""
Sep  4 05:10:50.707: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.707: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.793: INFO: Exec stderr: ""
Sep  4 05:10:50.793: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.793: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.868: INFO: Exec stderr: ""
Sep  4 05:10:50.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5835 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:10:50.868: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:10:50.962: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:10:50.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5835" for this suite.
Sep  4 05:11:38.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:11:39.132: INFO: namespace e2e-kubelet-etc-hosts-5835 deletion completed in 48.166358621s

• [SLOW TEST:60.385 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:11:39.133: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:11:39.341: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:11:41.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2626" for this suite.
Sep  4 05:12:29.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:12:29.867: INFO: namespace pods-2626 deletion completed in 48.169884491s

• [SLOW TEST:50.734 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:12:29.867: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep  4 05:12:32.181: INFO: Pod pod-hostip-cdec6a46-9622-4438-b9c9-9f6f76c920aa has hostIP: 192.168.1.101
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:12:32.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4432" for this suite.
Sep  4 05:12:54.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:12:54.484: INFO: namespace pods-4432 deletion completed in 22.277646186s

• [SLOW TEST:24.617 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:12:54.484: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:12:54.753: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"71eb083e-5543-43a9-b269-97f60e2ca87a", Controller:(*bool)(0xc000f628d6), BlockOwnerDeletion:(*bool)(0xc000f628d7)}}
Sep  4 05:12:54.769: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"e40d82b7-0e02-46d3-b1ce-bee454164419", Controller:(*bool)(0xc000f62bf6), BlockOwnerDeletion:(*bool)(0xc000f62bf7)}}
Sep  4 05:12:54.798: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"455c34ec-d0ad-47e9-b70b-8042a3b8a92f", Controller:(*bool)(0xc000f62ea6), BlockOwnerDeletion:(*bool)(0xc000f62ea7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:12:59.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3985" for this suite.
Sep  4 05:13:05.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:13:06.099: INFO: namespace gc-3985 deletion completed in 6.281581995s

• [SLOW TEST:11.615 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:13:06.099: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:13:06.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75" in namespace "projected-4549" to be "success or failure"
Sep  4 05:13:06.435: INFO: Pod "downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75": Phase="Pending", Reason="", readiness=false. Elapsed: 11.558746ms
Sep  4 05:13:08.439: INFO: Pod "downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015587038s
STEP: Saw pod success
Sep  4 05:13:08.439: INFO: Pod "downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75" satisfied condition "success or failure"
Sep  4 05:13:08.441: INFO: Trying to get logs from node 192.168.1.103 pod downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75 container client-container: <nil>
STEP: delete the pod
Sep  4 05:13:08.468: INFO: Waiting for pod downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75 to disappear
Sep  4 05:13:08.471: INFO: Pod downwardapi-volume-0fd5a6e2-98a4-4039-bf80-821720ce8e75 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:13:08.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4549" for this suite.
Sep  4 05:13:14.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:13:14.715: INFO: namespace projected-4549 deletion completed in 6.238919369s

• [SLOW TEST:8.616 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:13:14.716: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep  4 05:13:14.912: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep  4 05:13:24.033: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:13:24.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6474" for this suite.
Sep  4 05:13:30.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:13:30.215: INFO: namespace pods-6474 deletion completed in 6.1431136s

• [SLOW TEST:15.500 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:13:30.215: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3349
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3349
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 05:13:30.378: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 05:13:52.720: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.56:8080/dial?request=hostName&protocol=http&host=10.10.111.146&port=8080&tries=1'] Namespace:pod-network-test-3349 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:13:52.720: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:13:52.969: INFO: Waiting for endpoints: map[]
Sep  4 05:13:52.973: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.56:8080/dial?request=hostName&protocol=http&host=10.10.78.82&port=8080&tries=1'] Namespace:pod-network-test-3349 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:13:52.973: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:13:53.176: INFO: Waiting for endpoints: map[]
Sep  4 05:13:53.179: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.80.56:8080/dial?request=hostName&protocol=http&host=10.10.80.57&port=8080&tries=1'] Namespace:pod-network-test-3349 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:13:53.179: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:13:53.329: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:13:53.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3349" for this suite.
Sep  4 05:14:17.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:14:17.535: INFO: namespace pod-network-test-3349 deletion completed in 24.201969582s

• [SLOW TEST:47.320 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:14:17.536: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7801
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep  4 05:14:28.077: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0904 05:14:28.077406      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:14:28.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7801" for this suite.
Sep  4 05:14:36.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:14:36.227: INFO: namespace gc-7801 deletion completed in 8.130145764s

• [SLOW TEST:18.691 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:14:36.227: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 05:14:39.061: INFO: Successfully updated pod "labelsupdateb603fe06-26bb-41c4-b3f4-bc69b8f374c0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:14:43.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-65" for this suite.
Sep  4 05:15:05.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:15:05.919: INFO: namespace downward-api-65 deletion completed in 22.749184312s

• [SLOW TEST:29.693 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:15:05.922: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5576.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5576.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5576.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5576.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5576.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5576.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 05:15:10.187: INFO: Unable to read wheezy_udp@PodARecord from pod dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88: the server could not find the requested resource (get pods dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88)
Sep  4 05:15:10.193: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88: the server could not find the requested resource (get pods dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88)
Sep  4 05:15:10.206: INFO: Unable to read jessie_udp@PodARecord from pod dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88: the server could not find the requested resource (get pods dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88)
Sep  4 05:15:10.216: INFO: Unable to read jessie_tcp@PodARecord from pod dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88: the server could not find the requested resource (get pods dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88)
Sep  4 05:15:10.216: INFO: Lookups using dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Sep  4 05:15:15.252: INFO: DNS probes using dns-5576/dns-test-14346597-a8ea-4772-8ce6-6143d8ffdf88 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:15:15.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5576" for this suite.
Sep  4 05:15:21.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:15:21.399: INFO: namespace dns-5576 deletion completed in 6.116557379s

• [SLOW TEST:15.478 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:15:21.400: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep  4 05:15:21.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-8351'
Sep  4 05:15:21.727: INFO: stderr: ""
Sep  4 05:15:21.727: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  4 05:15:21.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8351'
Sep  4 05:15:21.843: INFO: stderr: ""
Sep  4 05:15:21.843: INFO: stdout: "update-demo-nautilus-hqrdr update-demo-nautilus-p8cps "
Sep  4 05:15:21.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-hqrdr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8351'
Sep  4 05:15:21.917: INFO: stderr: ""
Sep  4 05:15:21.917: INFO: stdout: ""
Sep  4 05:15:21.917: INFO: update-demo-nautilus-hqrdr is created but not running
Sep  4 05:15:26.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8351'
Sep  4 05:15:27.010: INFO: stderr: ""
Sep  4 05:15:27.010: INFO: stdout: "update-demo-nautilus-hqrdr update-demo-nautilus-p8cps "
Sep  4 05:15:27.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-hqrdr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8351'
Sep  4 05:15:27.124: INFO: stderr: ""
Sep  4 05:15:27.124: INFO: stdout: "true"
Sep  4 05:15:27.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-hqrdr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8351'
Sep  4 05:15:27.733: INFO: stderr: ""
Sep  4 05:15:27.733: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 05:15:27.733: INFO: validating pod update-demo-nautilus-hqrdr
Sep  4 05:15:27.742: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 05:15:27.742: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 05:15:27.742: INFO: update-demo-nautilus-hqrdr is verified up and running
Sep  4 05:15:27.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-p8cps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8351'
Sep  4 05:15:27.849: INFO: stderr: ""
Sep  4 05:15:27.849: INFO: stdout: "true"
Sep  4 05:15:27.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods update-demo-nautilus-p8cps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8351'
Sep  4 05:15:27.924: INFO: stderr: ""
Sep  4 05:15:27.924: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  4 05:15:27.924: INFO: validating pod update-demo-nautilus-p8cps
Sep  4 05:15:27.930: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  4 05:15:27.930: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  4 05:15:27.930: INFO: update-demo-nautilus-p8cps is verified up and running
STEP: using delete to clean up resources
Sep  4 05:15:27.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-8351'
Sep  4 05:15:28.001: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:15:28.001: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  4 05:15:28.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8351'
Sep  4 05:15:28.132: INFO: stderr: "No resources found.\n"
Sep  4 05:15:28.132: INFO: stdout: ""
Sep  4 05:15:28.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=update-demo --namespace=kubectl-8351 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 05:15:28.244: INFO: stderr: ""
Sep  4 05:15:28.244: INFO: stdout: "update-demo-nautilus-hqrdr\nupdate-demo-nautilus-p8cps\n"
Sep  4 05:15:28.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8351'
Sep  4 05:15:28.876: INFO: stderr: "No resources found.\n"
Sep  4 05:15:28.876: INFO: stdout: ""
Sep  4 05:15:28.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=update-demo --namespace=kubectl-8351 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 05:15:28.956: INFO: stderr: ""
Sep  4 05:15:28.956: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:15:28.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8351" for this suite.
Sep  4 05:15:50.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:15:51.154: INFO: namespace kubectl-8351 deletion completed in 22.193434072s

• [SLOW TEST:29.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:15:51.154: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-8819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-8819
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8819
STEP: Deleting pre-stop pod
Sep  4 05:16:04.469: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:16:04.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8819" for this suite.
Sep  4 05:16:42.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:16:42.658: INFO: namespace prestop-8819 deletion completed in 38.096827254s

• [SLOW TEST:51.505 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:16:42.658: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 05:16:42.818: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 05:16:42.844: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 05:16:42.858: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.101 before test
Sep  4 05:16:42.877: INFO: node-dns-bc4lx from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:16:42.877: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:16:42.877: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 04:30:10 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  4 05:16:42.877: INFO: cluster-dns-74877f46df-96tqd from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container coredns ready: true, restart count 0
Sep  4 05:16:42.877: INFO: sonobuoy-e2e-job-ba0b01e0e48b4e68 from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container e2e ready: true, restart count 0
Sep  4 05:16:42.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:16:42.877: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-k4lpq from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:16:42.877: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  4 05:16:42.877: INFO: calico-node-sdb87 from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:16:42.877: INFO: calico-kube-controllers-65b8787765-j25mh from kube-system started at 2019-09-04 04:29:17 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.877: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 05:16:42.877: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.102 before test
Sep  4 05:16:42.898: INFO: node-dns-mvf5k from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.898: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:16:42.898: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:16:42.898: INFO: calico-node-wjlwp from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.898: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:16:42.898: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-7q2hh from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:16:42.898: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  4 05:16:42.898: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.103 before test
Sep  4 05:16:42.904: INFO: calico-node-n4c7b from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.904: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:16:42.904: INFO: cluster-dns-74877f46df-xcqpv from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:16:42.904: INFO: 	Container coredns ready: true, restart count 0
Sep  4 05:16:42.904: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-fjq4x from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.904: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:16:42.904: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  4 05:16:42.904: INFO: node-dns-rzb6n from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:16:42.904: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:16:42.904: INFO: 	Container unbound ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c1246ea47b3f4c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:16:43.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8889" for this suite.
Sep  4 05:16:50.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:16:50.785: INFO: namespace sched-pred-8889 deletion completed in 6.827642114s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:8.127 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:16:50.786: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9580
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9193a802-0bd6-4e9e-b6ec-434537113973
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9193a802-0bd6-4e9e-b6ec-434537113973
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:16:55.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9580" for this suite.
Sep  4 05:17:17.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:17:17.480: INFO: namespace projected-9580 deletion completed in 22.262641252s

• [SLOW TEST:26.695 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:17:17.480: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2804
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-dwwlm in namespace proxy-2804
I0904 05:17:17.688398      21 runners.go:180] Created replication controller with name: proxy-service-dwwlm, namespace: proxy-2804, replica count: 1
I0904 05:17:18.739750      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:17:19.740075      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:17:20.740973      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:17:21.741367      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:17:22.742539      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:17:23.743874      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 05:17:24.744720      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 05:17:25.745380      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 05:17:26.746417      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0904 05:17:27.753126      21 runners.go:180] proxy-service-dwwlm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 05:17:27.772: INFO: setup took 10.129814683s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  4 05:17:27.810: INFO: (0) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 37.141189ms)
Sep  4 05:17:27.839: INFO: (0) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 65.182893ms)
Sep  4 05:17:27.849: INFO: (0) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 75.273069ms)
Sep  4 05:17:27.849: INFO: (0) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 75.355536ms)
Sep  4 05:17:27.849: INFO: (0) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 75.260038ms)
Sep  4 05:17:27.849: INFO: (0) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 74.75031ms)
Sep  4 05:17:27.849: INFO: (0) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 74.898695ms)
Sep  4 05:17:27.850: INFO: (0) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 76.058131ms)
Sep  4 05:17:27.850: INFO: (0) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 76.536835ms)
Sep  4 05:17:27.857: INFO: (0) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 82.11157ms)
Sep  4 05:17:27.857: INFO: (0) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 85.109541ms)
Sep  4 05:17:27.858: INFO: (0) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 83.231394ms)
Sep  4 05:17:27.859: INFO: (0) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 83.900378ms)
Sep  4 05:17:27.861: INFO: (0) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 86.477528ms)
Sep  4 05:17:27.861: INFO: (0) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 87.020263ms)
Sep  4 05:17:27.864: INFO: (0) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 89.598843ms)
Sep  4 05:17:27.871: INFO: (1) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 6.830673ms)
Sep  4 05:17:27.871: INFO: (1) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 6.674398ms)
Sep  4 05:17:27.872: INFO: (1) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 7.313291ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 11.151357ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 11.105647ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 10.691781ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 10.927652ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 11.29986ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.937054ms)
Sep  4 05:17:27.876: INFO: (1) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 11.269949ms)
Sep  4 05:17:27.877: INFO: (1) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 12.269569ms)
Sep  4 05:17:27.878: INFO: (1) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 12.726586ms)
Sep  4 05:17:27.880: INFO: (1) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 14.747023ms)
Sep  4 05:17:27.880: INFO: (1) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 14.784183ms)
Sep  4 05:17:27.881: INFO: (1) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 16.217115ms)
Sep  4 05:17:27.883: INFO: (1) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 18.917961ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 7.999826ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 6.134558ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 6.419437ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 8.252901ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 8.421096ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.691151ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 8.792937ms)
Sep  4 05:17:27.892: INFO: (2) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 8.535454ms)
Sep  4 05:17:27.893: INFO: (2) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.549514ms)
Sep  4 05:17:27.893: INFO: (2) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 8.548402ms)
Sep  4 05:17:27.893: INFO: (2) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.918816ms)
Sep  4 05:17:27.895: INFO: (2) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 10.51783ms)
Sep  4 05:17:27.895: INFO: (2) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 11.466756ms)
Sep  4 05:17:27.896: INFO: (2) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 11.594232ms)
Sep  4 05:17:27.896: INFO: (2) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 11.919646ms)
Sep  4 05:17:27.897: INFO: (2) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 13.026791ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 6.966019ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 5.854173ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 6.544511ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 6.513964ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 6.383705ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 6.812993ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 6.389573ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 6.856418ms)
Sep  4 05:17:27.904: INFO: (3) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 6.44896ms)
Sep  4 05:17:27.911: INFO: (3) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 13.826527ms)
Sep  4 05:17:27.911: INFO: (3) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 13.830103ms)
Sep  4 05:17:27.912: INFO: (3) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.692844ms)
Sep  4 05:17:27.912: INFO: (3) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 14.659492ms)
Sep  4 05:17:27.912: INFO: (3) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 13.980636ms)
Sep  4 05:17:27.912: INFO: (3) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 15.037567ms)
Sep  4 05:17:27.915: INFO: (3) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 17.468365ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 8.08194ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 8.449491ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.192895ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 8.293065ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.17543ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 7.990392ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.340967ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 8.155334ms)
Sep  4 05:17:27.924: INFO: (4) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.087658ms)
Sep  4 05:17:27.927: INFO: (4) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 11.55646ms)
Sep  4 05:17:27.928: INFO: (4) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 11.65363ms)
Sep  4 05:17:27.928: INFO: (4) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 11.778288ms)
Sep  4 05:17:27.928: INFO: (4) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 12.40363ms)
Sep  4 05:17:27.928: INFO: (4) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 12.360328ms)
Sep  4 05:17:27.929: INFO: (4) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 13.763713ms)
Sep  4 05:17:27.930: INFO: (4) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 13.642609ms)
Sep  4 05:17:27.934: INFO: (5) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 4.156167ms)
Sep  4 05:17:27.934: INFO: (5) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 4.62698ms)
Sep  4 05:17:27.938: INFO: (5) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 8.57654ms)
Sep  4 05:17:27.939: INFO: (5) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.809245ms)
Sep  4 05:17:27.939: INFO: (5) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 8.994169ms)
Sep  4 05:17:27.940: INFO: (5) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.028382ms)
Sep  4 05:17:27.940: INFO: (5) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 10.452981ms)
Sep  4 05:17:27.942: INFO: (5) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 12.354886ms)
Sep  4 05:17:27.942: INFO: (5) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 12.340793ms)
Sep  4 05:17:27.943: INFO: (5) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 13.582636ms)
Sep  4 05:17:27.944: INFO: (5) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 14.03353ms)
Sep  4 05:17:27.945: INFO: (5) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 14.800987ms)
Sep  4 05:17:27.946: INFO: (5) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 16.547223ms)
Sep  4 05:17:27.948: INFO: (5) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 18.404485ms)
Sep  4 05:17:27.948: INFO: (5) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 18.445829ms)
Sep  4 05:17:27.948: INFO: (5) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 18.41313ms)
Sep  4 05:17:27.958: INFO: (6) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 9.474437ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 10.407579ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 10.26579ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.0661ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 10.038822ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 10.123733ms)
Sep  4 05:17:27.959: INFO: (6) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 10.660062ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.998373ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 11.233469ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 11.197369ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 11.20721ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 11.466002ms)
Sep  4 05:17:27.960: INFO: (6) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 11.406719ms)
Sep  4 05:17:27.966: INFO: (6) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 16.565277ms)
Sep  4 05:17:27.966: INFO: (6) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 16.638298ms)
Sep  4 05:17:27.966: INFO: (6) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 17.072782ms)
Sep  4 05:17:27.972: INFO: (7) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 6.313963ms)
Sep  4 05:17:27.972: INFO: (7) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 6.439735ms)
Sep  4 05:17:27.972: INFO: (7) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 6.516824ms)
Sep  4 05:17:27.975: INFO: (7) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.148348ms)
Sep  4 05:17:27.976: INFO: (7) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 9.069632ms)
Sep  4 05:17:27.976: INFO: (7) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 9.306372ms)
Sep  4 05:17:27.976: INFO: (7) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 10.240731ms)
Sep  4 05:17:27.976: INFO: (7) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 10.199201ms)
Sep  4 05:17:27.977: INFO: (7) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 10.799249ms)
Sep  4 05:17:27.977: INFO: (7) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 10.533182ms)
Sep  4 05:17:27.977: INFO: (7) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.33671ms)
Sep  4 05:17:27.977: INFO: (7) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 10.727565ms)
Sep  4 05:17:27.978: INFO: (7) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 12.323581ms)
Sep  4 05:17:27.979: INFO: (7) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 12.188237ms)
Sep  4 05:17:27.979: INFO: (7) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 12.553738ms)
Sep  4 05:17:27.979: INFO: (7) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 12.982248ms)
Sep  4 05:17:27.984: INFO: (8) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 4.385343ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 13.789895ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 13.605454ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 13.764144ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 13.666822ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 13.787579ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.090425ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 13.902824ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 13.688868ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 13.9069ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 14.032838ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 13.925971ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 13.772181ms)
Sep  4 05:17:27.993: INFO: (8) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 13.87313ms)
Sep  4 05:17:27.994: INFO: (8) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 13.914217ms)
Sep  4 05:17:27.994: INFO: (8) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 13.911817ms)
Sep  4 05:17:27.998: INFO: (9) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 4.461466ms)
Sep  4 05:17:28.005: INFO: (9) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 11.063372ms)
Sep  4 05:17:28.007: INFO: (9) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 13.351244ms)
Sep  4 05:17:28.008: INFO: (9) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 13.40577ms)
Sep  4 05:17:28.008: INFO: (9) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 13.456545ms)
Sep  4 05:17:28.008: INFO: (9) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 13.914413ms)
Sep  4 05:17:28.008: INFO: (9) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 13.814531ms)
Sep  4 05:17:28.008: INFO: (9) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.135447ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 15.051398ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 14.741527ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 14.647529ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 14.739013ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 14.960529ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 15.052973ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 14.579445ms)
Sep  4 05:17:28.009: INFO: (9) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 14.97194ms)
Sep  4 05:17:28.020: INFO: (10) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 10.591118ms)
Sep  4 05:17:28.021: INFO: (10) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 11.106507ms)
Sep  4 05:17:28.021: INFO: (10) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 11.535807ms)
Sep  4 05:17:28.021: INFO: (10) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 11.46859ms)
Sep  4 05:17:28.021: INFO: (10) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 11.124573ms)
Sep  4 05:17:28.021: INFO: (10) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 11.438546ms)
Sep  4 05:17:28.022: INFO: (10) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 12.445993ms)
Sep  4 05:17:28.023: INFO: (10) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 13.113952ms)
Sep  4 05:17:28.024: INFO: (10) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 13.995251ms)
Sep  4 05:17:28.024: INFO: (10) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 13.998905ms)
Sep  4 05:17:28.024: INFO: (10) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.319925ms)
Sep  4 05:17:28.025: INFO: (10) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 15.13343ms)
Sep  4 05:17:28.025: INFO: (10) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 15.336953ms)
Sep  4 05:17:28.025: INFO: (10) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 15.245638ms)
Sep  4 05:17:28.025: INFO: (10) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 15.767614ms)
Sep  4 05:17:28.026: INFO: (10) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 16.376952ms)
Sep  4 05:17:28.032: INFO: (11) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 5.938698ms)
Sep  4 05:17:28.033: INFO: (11) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 6.171341ms)
Sep  4 05:17:28.038: INFO: (11) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 11.169848ms)
Sep  4 05:17:28.042: INFO: (11) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 15.186481ms)
Sep  4 05:17:28.042: INFO: (11) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 16.120883ms)
Sep  4 05:17:28.042: INFO: (11) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 15.503231ms)
Sep  4 05:17:28.042: INFO: (11) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 15.614246ms)
Sep  4 05:17:28.043: INFO: (11) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 15.780649ms)
Sep  4 05:17:28.044: INFO: (11) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 17.530617ms)
Sep  4 05:17:28.045: INFO: (11) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 17.647953ms)
Sep  4 05:17:28.047: INFO: (11) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 20.608986ms)
Sep  4 05:17:28.048: INFO: (11) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 20.251679ms)
Sep  4 05:17:28.048: INFO: (11) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 20.661102ms)
Sep  4 05:17:28.048: INFO: (11) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 21.265313ms)
Sep  4 05:17:28.049: INFO: (11) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 21.426598ms)
Sep  4 05:17:28.051: INFO: (11) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 23.586634ms)
Sep  4 05:17:28.055: INFO: (12) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 4.330957ms)
Sep  4 05:17:28.057: INFO: (12) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 6.346477ms)
Sep  4 05:17:28.061: INFO: (12) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 9.386828ms)
Sep  4 05:17:28.066: INFO: (12) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 14.248049ms)
Sep  4 05:17:28.066: INFO: (12) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 14.547042ms)
Sep  4 05:17:28.067: INFO: (12) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 15.567245ms)
Sep  4 05:17:28.067: INFO: (12) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 15.362667ms)
Sep  4 05:17:28.067: INFO: (12) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 15.645541ms)
Sep  4 05:17:28.069: INFO: (12) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 16.892475ms)
Sep  4 05:17:28.069: INFO: (12) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 17.537521ms)
Sep  4 05:17:28.069: INFO: (12) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 17.571078ms)
Sep  4 05:17:28.070: INFO: (12) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 18.642242ms)
Sep  4 05:17:28.070: INFO: (12) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 18.644042ms)
Sep  4 05:17:28.070: INFO: (12) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 18.286985ms)
Sep  4 05:17:28.070: INFO: (12) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 18.580474ms)
Sep  4 05:17:28.071: INFO: (12) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 19.416473ms)
Sep  4 05:17:28.080: INFO: (13) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.019819ms)
Sep  4 05:17:28.080: INFO: (13) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.940407ms)
Sep  4 05:17:28.080: INFO: (13) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 8.873591ms)
Sep  4 05:17:28.080: INFO: (13) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 9.056721ms)
Sep  4 05:17:28.081: INFO: (13) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.881641ms)
Sep  4 05:17:28.081: INFO: (13) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 8.969381ms)
Sep  4 05:17:28.081: INFO: (13) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 9.434992ms)
Sep  4 05:17:28.081: INFO: (13) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 9.009054ms)
Sep  4 05:17:28.082: INFO: (13) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 10.45673ms)
Sep  4 05:17:28.082: INFO: (13) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 10.645906ms)
Sep  4 05:17:28.082: INFO: (13) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 10.773679ms)
Sep  4 05:17:28.083: INFO: (13) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 11.408854ms)
Sep  4 05:17:28.084: INFO: (13) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 12.280352ms)
Sep  4 05:17:28.085: INFO: (13) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 13.29393ms)
Sep  4 05:17:28.086: INFO: (13) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 14.118152ms)
Sep  4 05:17:28.090: INFO: (13) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 18.664291ms)
Sep  4 05:17:28.100: INFO: (14) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 9.165233ms)
Sep  4 05:17:28.100: INFO: (14) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 9.456637ms)
Sep  4 05:17:28.101: INFO: (14) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 9.64824ms)
Sep  4 05:17:28.102: INFO: (14) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 10.852299ms)
Sep  4 05:17:28.104: INFO: (14) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 12.820053ms)
Sep  4 05:17:28.104: INFO: (14) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 12.579159ms)
Sep  4 05:17:28.104: INFO: (14) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 12.891589ms)
Sep  4 05:17:28.104: INFO: (14) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 13.241513ms)
Sep  4 05:17:28.106: INFO: (14) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 14.877076ms)
Sep  4 05:17:28.106: INFO: (14) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 15.172915ms)
Sep  4 05:17:28.107: INFO: (14) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 15.278635ms)
Sep  4 05:17:28.107: INFO: (14) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 16.047633ms)
Sep  4 05:17:28.107: INFO: (14) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 16.025729ms)
Sep  4 05:17:28.108: INFO: (14) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 16.643194ms)
Sep  4 05:17:28.110: INFO: (14) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 18.159585ms)
Sep  4 05:17:28.111: INFO: (14) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 19.205123ms)
Sep  4 05:17:28.119: INFO: (15) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 7.66538ms)
Sep  4 05:17:28.119: INFO: (15) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.045851ms)
Sep  4 05:17:28.119: INFO: (15) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 8.588585ms)
Sep  4 05:17:28.119: INFO: (15) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 8.702257ms)
Sep  4 05:17:28.120: INFO: (15) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 9.328901ms)
Sep  4 05:17:28.120: INFO: (15) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 9.555649ms)
Sep  4 05:17:28.123: INFO: (15) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 11.59101ms)
Sep  4 05:17:28.124: INFO: (15) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 12.795015ms)
Sep  4 05:17:28.124: INFO: (15) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 13.439345ms)
Sep  4 05:17:28.126: INFO: (15) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 15.384348ms)
Sep  4 05:17:28.128: INFO: (15) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 16.791737ms)
Sep  4 05:17:28.128: INFO: (15) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 17.566588ms)
Sep  4 05:17:28.128: INFO: (15) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 17.738112ms)
Sep  4 05:17:28.128: INFO: (15) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 17.453819ms)
Sep  4 05:17:28.129: INFO: (15) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 17.758038ms)
Sep  4 05:17:28.130: INFO: (15) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 18.704908ms)
Sep  4 05:17:28.139: INFO: (16) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 8.886091ms)
Sep  4 05:17:28.139: INFO: (16) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 9.094595ms)
Sep  4 05:17:28.139: INFO: (16) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 9.030021ms)
Sep  4 05:17:28.140: INFO: (16) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 9.907868ms)
Sep  4 05:17:28.140: INFO: (16) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 9.952699ms)
Sep  4 05:17:28.140: INFO: (16) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 9.937418ms)
Sep  4 05:17:28.141: INFO: (16) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 10.991841ms)
Sep  4 05:17:28.142: INFO: (16) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 12.008238ms)
Sep  4 05:17:28.142: INFO: (16) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 11.84456ms)
Sep  4 05:17:28.143: INFO: (16) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 12.850314ms)
Sep  4 05:17:28.144: INFO: (16) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 14.29001ms)
Sep  4 05:17:28.144: INFO: (16) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 14.22121ms)
Sep  4 05:17:28.145: INFO: (16) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 14.562159ms)
Sep  4 05:17:28.145: INFO: (16) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 14.233838ms)
Sep  4 05:17:28.145: INFO: (16) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 14.341396ms)
Sep  4 05:17:28.145: INFO: (16) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.941256ms)
Sep  4 05:17:28.153: INFO: (17) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 8.130545ms)
Sep  4 05:17:28.153: INFO: (17) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 7.804906ms)
Sep  4 05:17:28.153: INFO: (17) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 7.897253ms)
Sep  4 05:17:28.154: INFO: (17) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 8.040407ms)
Sep  4 05:17:28.155: INFO: (17) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 9.238478ms)
Sep  4 05:17:28.155: INFO: (17) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 9.100452ms)
Sep  4 05:17:28.155: INFO: (17) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 8.950659ms)
Sep  4 05:17:28.156: INFO: (17) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.620747ms)
Sep  4 05:17:28.157: INFO: (17) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 10.714267ms)
Sep  4 05:17:28.158: INFO: (17) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 12.222396ms)
Sep  4 05:17:28.158: INFO: (17) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 12.319222ms)
Sep  4 05:17:28.160: INFO: (17) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 14.241563ms)
Sep  4 05:17:28.160: INFO: (17) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 14.552104ms)
Sep  4 05:17:28.160: INFO: (17) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 14.065434ms)
Sep  4 05:17:28.160: INFO: (17) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 14.432231ms)
Sep  4 05:17:28.160: INFO: (17) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 14.738672ms)
Sep  4 05:17:28.167: INFO: (18) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 6.719099ms)
Sep  4 05:17:28.168: INFO: (18) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 7.532037ms)
Sep  4 05:17:28.169: INFO: (18) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 8.128646ms)
Sep  4 05:17:28.169: INFO: (18) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 8.10093ms)
Sep  4 05:17:28.179: INFO: (18) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 18.363131ms)
Sep  4 05:17:28.179: INFO: (18) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 18.161396ms)
Sep  4 05:17:28.182: INFO: (18) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 21.004178ms)
Sep  4 05:17:28.182: INFO: (18) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 21.028644ms)
Sep  4 05:17:28.182: INFO: (18) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 21.120455ms)
Sep  4 05:17:28.183: INFO: (18) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 21.964438ms)
Sep  4 05:17:28.183: INFO: (18) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 22.017352ms)
Sep  4 05:17:28.183: INFO: (18) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 21.969748ms)
Sep  4 05:17:28.183: INFO: (18) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 22.371486ms)
Sep  4 05:17:28.185: INFO: (18) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 23.698504ms)
Sep  4 05:17:28.185: INFO: (18) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 23.937459ms)
Sep  4 05:17:28.185: INFO: (18) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 24.624317ms)
Sep  4 05:17:28.197: INFO: (19) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:443/proxy/tlsrewritem... (200; 10.743759ms)
Sep  4 05:17:28.197: INFO: (19) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 10.926521ms)
Sep  4 05:17:28.197: INFO: (19) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:462/proxy/: tls qux (200; 10.443262ms)
Sep  4 05:17:28.197: INFO: (19) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">test<... (200; 11.300902ms)
Sep  4 05:17:28.197: INFO: (19) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 10.999195ms)
Sep  4 05:17:28.200: INFO: (19) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:1080/proxy/rewriteme">... (200; 14.093772ms)
Sep  4 05:17:28.202: INFO: (19) /api/v1/namespaces/proxy-2804/pods/https:proxy-service-dwwlm-89bc9:460/proxy/: tls baz (200; 16.177092ms)
Sep  4 05:17:28.203: INFO: (19) /api/v1/namespaces/proxy-2804/pods/http:proxy-service-dwwlm-89bc9:160/proxy/: foo (200; 16.722427ms)
Sep  4 05:17:28.203: INFO: (19) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname1/proxy/: foo (200; 17.548163ms)
Sep  4 05:17:28.203: INFO: (19) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9:162/proxy/: bar (200; 17.317189ms)
Sep  4 05:17:28.203: INFO: (19) /api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/: <a href="/api/v1/namespaces/proxy-2804/pods/proxy-service-dwwlm-89bc9/proxy/rewriteme">test</a> (200; 17.141246ms)
Sep  4 05:17:28.207: INFO: (19) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname2/proxy/: tls qux (200; 20.161487ms)
Sep  4 05:17:28.207: INFO: (19) /api/v1/namespaces/proxy-2804/services/proxy-service-dwwlm:portname2/proxy/: bar (200; 20.338432ms)
Sep  4 05:17:28.207: INFO: (19) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname2/proxy/: bar (200; 20.328973ms)
Sep  4 05:17:28.207: INFO: (19) /api/v1/namespaces/proxy-2804/services/https:proxy-service-dwwlm:tlsportname1/proxy/: tls baz (200; 20.728413ms)
Sep  4 05:17:28.208: INFO: (19) /api/v1/namespaces/proxy-2804/services/http:proxy-service-dwwlm:portname1/proxy/: foo (200; 21.390534ms)
STEP: deleting ReplicationController proxy-service-dwwlm in namespace proxy-2804, will wait for the garbage collector to delete the pods
Sep  4 05:17:28.266: INFO: Deleting ReplicationController proxy-service-dwwlm took: 5.0583ms
Sep  4 05:17:28.667: INFO: Terminating ReplicationController proxy-service-dwwlm pods took: 400.404327ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:17:35.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2804" for this suite.
Sep  4 05:17:41.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:17:41.894: INFO: namespace proxy-2804 deletion completed in 6.11994683s

• [SLOW TEST:24.413 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:17:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4413
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-58dbf786-4fe2-4ec7-aa78-3cd9f4fb2064
STEP: Creating secret with name s-test-opt-upd-9481da14-b715-47c4-8763-2bcde9ed24aa
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-58dbf786-4fe2-4ec7-aa78-3cd9f4fb2064
STEP: Updating secret s-test-opt-upd-9481da14-b715-47c4-8763-2bcde9ed24aa
STEP: Creating secret with name s-test-opt-create-17850c5a-fe1c-44bb-9468-d9492fbd1227
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:17:46.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4413" for this suite.
Sep  4 05:18:08.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:18:08.584: INFO: namespace projected-4413 deletion completed in 22.27683826s

• [SLOW TEST:26.690 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:18:08.584: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9671
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-5193d105-3941-4bf1-b4a3-864386159cc5
STEP: Creating a pod to test consume configMaps
Sep  4 05:18:08.800: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4" in namespace "configmap-9671" to be "success or failure"
Sep  4 05:18:08.809: INFO: Pod "pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.362539ms
Sep  4 05:18:10.820: INFO: Pod "pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02014133s
Sep  4 05:18:12.825: INFO: Pod "pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025644234s
STEP: Saw pod success
Sep  4 05:18:12.826: INFO: Pod "pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4" satisfied condition "success or failure"
Sep  4 05:18:12.831: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:18:12.862: INFO: Waiting for pod pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4 to disappear
Sep  4 05:18:12.868: INFO: Pod pod-configmaps-9e1272bd-0973-425f-a8a5-d11f184979c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:18:12.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9671" for this suite.
Sep  4 05:18:18.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:18:19.116: INFO: namespace configmap-9671 deletion completed in 6.23883913s

• [SLOW TEST:10.531 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:18:19.116: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  4 05:18:19.295: INFO: Waiting up to 5m0s for pod "pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b" in namespace "emptydir-1669" to be "success or failure"
Sep  4 05:18:19.301: INFO: Pod "pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.109483ms
Sep  4 05:18:21.304: INFO: Pod "pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009075484s
STEP: Saw pod success
Sep  4 05:18:21.304: INFO: Pod "pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b" satisfied condition "success or failure"
Sep  4 05:18:21.306: INFO: Trying to get logs from node 192.168.1.101 pod pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b container test-container: <nil>
STEP: delete the pod
Sep  4 05:18:21.328: INFO: Waiting for pod pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b to disappear
Sep  4 05:18:21.330: INFO: Pod pod-b1b3e162-0f44-4007-81e5-772ff76a6e2b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:18:21.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1669" for this suite.
Sep  4 05:18:27.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:18:27.509: INFO: namespace emptydir-1669 deletion completed in 6.176271768s

• [SLOW TEST:8.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:18:27.510: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep  4 05:18:27.680: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep  4 05:18:28.275: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep  4 05:18:30.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:32.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:34.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:36.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:38.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:40.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:42.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:44.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:46.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703171108, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  4 05:18:49.325: INFO: Waited 904.302356ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:18:49.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3851" for this suite.
Sep  4 05:18:55.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:18:56.135: INFO: namespace aggregator-3851 deletion completed in 6.380567813s

• [SLOW TEST:28.625 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:18:56.135: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-6307b635-60b3-4a1f-89ee-1d3d6c28f7d4
STEP: Creating a pod to test consume secrets
Sep  4 05:18:56.350: INFO: Waiting up to 5m0s for pod "pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd" in namespace "secrets-7818" to be "success or failure"
Sep  4 05:18:56.356: INFO: Pod "pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.143418ms
Sep  4 05:18:58.360: INFO: Pod "pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010530919s
Sep  4 05:19:00.363: INFO: Pod "pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013577778s
STEP: Saw pod success
Sep  4 05:19:00.363: INFO: Pod "pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd" satisfied condition "success or failure"
Sep  4 05:19:00.366: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:19:00.386: INFO: Waiting for pod pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd to disappear
Sep  4 05:19:00.389: INFO: Pod pod-secrets-499f2bc5-c2bd-4dec-bf5d-088ea77511dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:19:00.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7818" for this suite.
Sep  4 05:19:06.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:19:06.485: INFO: namespace secrets-7818 deletion completed in 6.092437187s

• [SLOW TEST:10.350 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:19:06.486: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep  4 05:19:09.204: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-603 pod-service-account-493c20d0-a90c-4064-93d0-18411e2b7bc8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep  4 05:19:09.491: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-603 pod-service-account-493c20d0-a90c-4064-93d0-18411e2b7bc8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep  4 05:19:10.262: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-603 pod-service-account-493c20d0-a90c-4064-93d0-18411e2b7bc8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:19:10.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-603" for this suite.
Sep  4 05:19:16.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:19:16.632: INFO: namespace svcaccounts-603 deletion completed in 6.180859057s

• [SLOW TEST:10.147 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:19:16.633: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-204b3039-663d-4851-a332-c96192408c85
STEP: Creating a pod to test consume secrets
Sep  4 05:19:16.876: INFO: Waiting up to 5m0s for pod "pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182" in namespace "secrets-6254" to be "success or failure"
Sep  4 05:19:16.910: INFO: Pod "pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182": Phase="Pending", Reason="", readiness=false. Elapsed: 34.365326ms
Sep  4 05:19:18.925: INFO: Pod "pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049359447s
STEP: Saw pod success
Sep  4 05:19:18.925: INFO: Pod "pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182" satisfied condition "success or failure"
Sep  4 05:19:18.939: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:19:19.002: INFO: Waiting for pod pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182 to disappear
Sep  4 05:19:19.024: INFO: Pod pod-secrets-3de7a79d-de35-48f2-83f6-a24ca109e182 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:19:19.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6254" for this suite.
Sep  4 05:19:25.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:19:25.368: INFO: namespace secrets-6254 deletion completed in 6.317778644s

• [SLOW TEST:8.734 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:19:25.368: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9711
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4832
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:19:32.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1023" for this suite.
Sep  4 05:19:38.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:19:38.321: INFO: namespace namespaces-1023 deletion completed in 6.234233331s
STEP: Destroying namespace "nsdeletetest-9711" for this suite.
Sep  4 05:19:38.324: INFO: Namespace nsdeletetest-9711 was already deleted
STEP: Destroying namespace "nsdeletetest-4832" for this suite.
Sep  4 05:19:44.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:19:44.471: INFO: namespace nsdeletetest-4832 deletion completed in 6.146103347s

• [SLOW TEST:19.102 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:19:44.472: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-292
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-292
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-292
Sep  4 05:19:44.752: INFO: Found 0 stateful pods, waiting for 1
Sep  4 05:19:54.769: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  4 05:19:54.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:19:55.493: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:19:55.493: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:19:55.493: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:19:55.497: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 05:20:05.510: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:20:05.510: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:20:05.587: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998891s
Sep  4 05:20:06.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.986496168s
Sep  4 05:20:07.596: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982359324s
Sep  4 05:20:08.610: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979219814s
Sep  4 05:20:09.615: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.965137368s
Sep  4 05:20:10.627: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960080657s
Sep  4 05:20:11.633: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.947768111s
Sep  4 05:20:12.645: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.941017804s
Sep  4 05:20:13.651: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.928410421s
Sep  4 05:20:14.664: INFO: Verifying statefulset ss doesn't scale past 1 for another 924.467136ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-292
Sep  4 05:20:15.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:20:15.885: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:20:15.885: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:20:15.885: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:20:15.888: INFO: Found 1 stateful pods, waiting for 3
Sep  4 05:20:25.906: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:20:25.906: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:20:25.906: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  4 05:20:25.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:20:26.182: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:20:26.182: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:20:26.182: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:20:26.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:20:26.377: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:20:26.377: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:20:26.377: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:20:26.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:20:26.583: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:20:26.583: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:20:26.583: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:20:26.583: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:20:26.587: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  4 05:20:36.612: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:20:36.612: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:20:36.612: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:20:36.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998768s
Sep  4 05:20:37.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.971784887s
Sep  4 05:20:38.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.953935545s
Sep  4 05:20:39.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.940338225s
Sep  4 05:20:40.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.927694773s
Sep  4 05:20:41.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.903040769s
Sep  4 05:20:42.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.888574111s
Sep  4 05:20:43.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.873436843s
Sep  4 05:20:44.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.868106863s
Sep  4 05:20:46.033: INFO: Verifying statefulset ss doesn't scale past 3 for another 850.496032ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-292
Sep  4 05:20:47.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:20:47.458: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:20:47.458: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:20:47.458: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:20:47.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:20:47.627: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:20:47.628: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:20:47.628: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:20:47.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-292 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:20:47.783: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:20:47.784: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:20:47.784: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:20:47.784: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 05:20:57.803: INFO: Deleting all statefulset in ns statefulset-292
Sep  4 05:20:57.806: INFO: Scaling statefulset ss to 0
Sep  4 05:20:57.815: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:20:57.817: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:20:57.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-292" for this suite.
Sep  4 05:21:03.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:21:04.197: INFO: namespace statefulset-292 deletion completed in 6.362065886s

• [SLOW TEST:79.726 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:21:04.198: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1525
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1525
STEP: Creating statefulset with conflicting port in namespace statefulset-1525
STEP: Waiting until pod test-pod will start running in namespace statefulset-1525
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1525
Sep  4 05:21:08.771: INFO: Observed stateful pod in namespace: statefulset-1525, name: ss-0, uid: f96c724f-a8e1-465e-b0f9-14ebf66beb70, status phase: Failed. Waiting for statefulset controller to delete.
Sep  4 05:21:08.782: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1525
STEP: Removing pod with conflicting port in namespace statefulset-1525
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1525 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 05:21:12.850: INFO: Deleting all statefulset in ns statefulset-1525
Sep  4 05:21:12.863: INFO: Scaling statefulset ss to 0
Sep  4 05:21:22.930: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:21:22.947: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:21:23.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1525" for this suite.
Sep  4 05:21:29.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:21:29.158: INFO: namespace statefulset-1525 deletion completed in 6.149158966s

• [SLOW TEST:24.960 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:21:29.159: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 05:21:29.307: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:21:35.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1096" for this suite.
Sep  4 05:21:57.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:21:58.049: INFO: namespace init-container-1096 deletion completed in 22.201810488s

• [SLOW TEST:28.890 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:21:58.049: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-d34d966e-728a-4280-8240-80ee582800b5
STEP: Creating a pod to test consume secrets
Sep  4 05:21:58.220: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52" in namespace "projected-9209" to be "success or failure"
Sep  4 05:21:58.261: INFO: Pod "pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52": Phase="Pending", Reason="", readiness=false. Elapsed: 40.86164ms
Sep  4 05:22:00.267: INFO: Pod "pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04667795s
Sep  4 05:22:02.277: INFO: Pod "pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056712762s
STEP: Saw pod success
Sep  4 05:22:02.278: INFO: Pod "pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52" satisfied condition "success or failure"
Sep  4 05:22:02.303: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:22:02.399: INFO: Waiting for pod pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52 to disappear
Sep  4 05:22:02.412: INFO: Pod pod-projected-secrets-f6283b27-f032-4cc6-a0f5-b3dbd401ba52 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:22:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9209" for this suite.
Sep  4 05:22:08.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:22:08.649: INFO: namespace projected-9209 deletion completed in 6.232847938s

• [SLOW TEST:10.601 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:22:08.650: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:23:08.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9944" for this suite.
Sep  4 05:23:31.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:23:31.365: INFO: namespace container-probe-9944 deletion completed in 22.40453011s

• [SLOW TEST:82.716 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:23:31.366: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:23:36.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5415" for this suite.
Sep  4 05:23:43.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:23:43.473: INFO: namespace watch-5415 deletion completed in 6.439163044s

• [SLOW TEST:12.108 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:23:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0b3815c9-da81-4812-ae25-c9289ed3c476
STEP: Creating a pod to test consume secrets
Sep  4 05:23:43.629: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50" in namespace "projected-9648" to be "success or failure"
Sep  4 05:23:43.636: INFO: Pod "pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50": Phase="Pending", Reason="", readiness=false. Elapsed: 6.543372ms
Sep  4 05:23:45.639: INFO: Pod "pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009002176s
Sep  4 05:23:47.647: INFO: Pod "pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01754133s
STEP: Saw pod success
Sep  4 05:23:47.647: INFO: Pod "pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50" satisfied condition "success or failure"
Sep  4 05:23:47.660: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:23:47.763: INFO: Waiting for pod pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50 to disappear
Sep  4 05:23:47.770: INFO: Pod pod-projected-secrets-02b0da45-7828-4577-99c2-13129c0a1b50 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:23:47.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9648" for this suite.
Sep  4 05:23:53.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:23:54.023: INFO: namespace projected-9648 deletion completed in 6.248651403s

• [SLOW TEST:10.549 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:23:54.023: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep  4 05:23:54.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-7578'
Sep  4 05:23:54.545: INFO: stderr: ""
Sep  4 05:23:54.545: INFO: stdout: "pod/pause created\n"
Sep  4 05:23:54.545: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  4 05:23:54.545: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7578" to be "running and ready"
Sep  4 05:23:54.551: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054945ms
Sep  4 05:23:56.554: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008260541s
Sep  4 05:23:58.557: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.011587985s
Sep  4 05:23:58.557: INFO: Pod "pause" satisfied condition "running and ready"
Sep  4 05:23:58.557: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  4 05:23:58.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 label pods pause testing-label=testing-label-value --namespace=kubectl-7578'
Sep  4 05:23:58.663: INFO: stderr: ""
Sep  4 05:23:58.663: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  4 05:23:58.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pod pause -L testing-label --namespace=kubectl-7578'
Sep  4 05:23:58.740: INFO: stderr: ""
Sep  4 05:23:58.740: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  4 05:23:58.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 label pods pause testing-label- --namespace=kubectl-7578'
Sep  4 05:23:58.816: INFO: stderr: ""
Sep  4 05:23:58.817: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  4 05:23:58.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pod pause -L testing-label --namespace=kubectl-7578'
Sep  4 05:23:58.872: INFO: stderr: ""
Sep  4 05:23:58.872: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep  4 05:23:58.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-7578'
Sep  4 05:23:58.940: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:23:58.940: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  4 05:23:58.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get rc,svc -l name=pause --no-headers --namespace=kubectl-7578'
Sep  4 05:23:59.029: INFO: stderr: "No resources found.\n"
Sep  4 05:23:59.029: INFO: stdout: ""
Sep  4 05:23:59.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -l name=pause --namespace=kubectl-7578 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  4 05:23:59.094: INFO: stderr: ""
Sep  4 05:23:59.094: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:23:59.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7578" for this suite.
Sep  4 05:24:05.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:24:05.360: INFO: namespace kubectl-7578 deletion completed in 6.25811887s

• [SLOW TEST:11.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:24:05.360: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  4 05:24:05.553: INFO: Waiting up to 5m0s for pod "pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72" in namespace "emptydir-4753" to be "success or failure"
Sep  4 05:24:05.581: INFO: Pod "pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72": Phase="Pending", Reason="", readiness=false. Elapsed: 27.520562ms
Sep  4 05:24:07.584: INFO: Pod "pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030851384s
STEP: Saw pod success
Sep  4 05:24:07.584: INFO: Pod "pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72" satisfied condition "success or failure"
Sep  4 05:24:07.589: INFO: Trying to get logs from node 192.168.1.101 pod pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72 container test-container: <nil>
STEP: delete the pod
Sep  4 05:24:07.608: INFO: Waiting for pod pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72 to disappear
Sep  4 05:24:07.611: INFO: Pod pod-f7fc316c-55e1-4b0b-b652-cda288bc5a72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:24:07.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4753" for this suite.
Sep  4 05:24:13.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:24:13.727: INFO: namespace emptydir-4753 deletion completed in 6.112161792s

• [SLOW TEST:8.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:24:13.728: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-259
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  4 05:24:13.897: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  4 05:24:38.047: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.10.78.88 8081 | grep -v '^\s*$'] Namespace:pod-network-test-259 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:24:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:24:39.345: INFO: Found all expected endpoints: [netserver-0]
Sep  4 05:24:39.349: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.10.80.27 8081 | grep -v '^\s*$'] Namespace:pod-network-test-259 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:24:39.349: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:24:40.465: INFO: Found all expected endpoints: [netserver-1]
Sep  4 05:24:40.468: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.10.111.152 8081 | grep -v '^\s*$'] Namespace:pod-network-test-259 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  4 05:24:40.468: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
Sep  4 05:24:42.172: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:24:42.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-259" for this suite.
Sep  4 05:25:06.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:25:06.470: INFO: namespace pod-network-test-259 deletion completed in 24.290673624s

• [SLOW TEST:52.742 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:25:06.471: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 05:25:06.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4809'
Sep  4 05:25:06.831: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 05:25:06.831: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  4 05:25:06.845: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  4 05:25:06.850: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  4 05:25:06.864: INFO: scanned /root for discovery docs: <nil>
Sep  4 05:25:06.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4809'
Sep  4 05:25:22.963: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  4 05:25:22.963: INFO: stdout: "Created e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd\nScaling up e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  4 05:25:22.963: INFO: stdout: "Created e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd\nScaling up e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  4 05:25:22.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4809'
Sep  4 05:25:23.073: INFO: stderr: ""
Sep  4 05:25:23.073: INFO: stdout: "e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd-txtnt e2e-test-nginx-rc-tp4cc "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Sep  4 05:25:28.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4809'
Sep  4 05:25:28.371: INFO: stderr: ""
Sep  4 05:25:28.371: INFO: stdout: "e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd-txtnt "
Sep  4 05:25:28.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd-txtnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4809'
Sep  4 05:25:28.552: INFO: stderr: ""
Sep  4 05:25:28.552: INFO: stdout: "true"
Sep  4 05:25:28.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 get pods e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd-txtnt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4809'
Sep  4 05:25:28.628: INFO: stderr: ""
Sep  4 05:25:28.628: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  4 05:25:28.628: INFO: e2e-test-nginx-rc-226a9da2950920e32c90dbbedf6a41bd-txtnt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep  4 05:25:28.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete rc e2e-test-nginx-rc --namespace=kubectl-4809'
Sep  4 05:25:28.687: INFO: stderr: ""
Sep  4 05:25:28.687: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:25:28.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4809" for this suite.
Sep  4 05:25:52.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:25:52.801: INFO: namespace kubectl-4809 deletion completed in 24.1074226s

• [SLOW TEST:46.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:25:52.802: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1408
STEP: Creating secret with name secret-test-89f19508-0db4-426e-9574-821b9b2584c9
STEP: Creating a pod to test consume secrets
Sep  4 05:25:53.227: INFO: Waiting up to 5m0s for pod "pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc" in namespace "secrets-7091" to be "success or failure"
Sep  4 05:25:53.235: INFO: Pod "pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.153858ms
Sep  4 05:25:55.243: INFO: Pod "pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016451525s
Sep  4 05:25:57.249: INFO: Pod "pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022333313s
STEP: Saw pod success
Sep  4 05:25:57.249: INFO: Pod "pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc" satisfied condition "success or failure"
Sep  4 05:25:57.258: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:25:57.302: INFO: Waiting for pod pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc to disappear
Sep  4 05:25:57.306: INFO: Pod pod-secrets-1dfb4563-e403-4dd2-aa08-5d7f066587cc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:25:57.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7091" for this suite.
Sep  4 05:26:03.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:26:03.450: INFO: namespace secrets-7091 deletion completed in 6.136143954s
STEP: Destroying namespace "secret-namespace-1408" for this suite.
Sep  4 05:26:09.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:26:09.611: INFO: namespace secret-namespace-1408 deletion completed in 6.161021813s

• [SLOW TEST:16.809 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:26:09.612: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-164163ea-5432-43a3-bcc9-79c07f470ce2
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:26:09.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5333" for this suite.
Sep  4 05:26:15.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:26:15.954: INFO: namespace configmap-5333 deletion completed in 6.182501669s

• [SLOW TEST:6.342 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:26:15.954: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep  4 05:26:16.115: INFO: namespace kubectl-8478
Sep  4 05:26:16.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-8478'
Sep  4 05:26:16.388: INFO: stderr: ""
Sep  4 05:26:16.388: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 05:26:17.594: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:26:17.594: INFO: Found 0 / 1
Sep  4 05:26:18.400: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:26:18.400: INFO: Found 0 / 1
Sep  4 05:26:19.394: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:26:19.394: INFO: Found 1 / 1
Sep  4 05:26:19.394: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 05:26:19.398: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:26:19.398: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 05:26:19.398: INFO: wait on redis-master startup in kubectl-8478 
Sep  4 05:26:19.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 logs redis-master-vv4vb redis-master --namespace=kubectl-8478'
Sep  4 05:26:19.500: INFO: stderr: ""
Sep  4 05:26:19.500: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Sep 05:26:18.454 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Sep 05:26:18.454 # Server started, Redis version 3.2.12\n1:M 04 Sep 05:26:18.454 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Sep 05:26:18.454 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  4 05:26:19.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8478'
Sep  4 05:26:19.618: INFO: stderr: ""
Sep  4 05:26:19.618: INFO: stdout: "service/rm2 exposed\n"
Sep  4 05:26:19.622: INFO: Service rm2 in namespace kubectl-8478 found.
STEP: exposing service
Sep  4 05:26:21.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8478'
Sep  4 05:26:21.708: INFO: stderr: ""
Sep  4 05:26:21.708: INFO: stdout: "service/rm3 exposed\n"
Sep  4 05:26:21.711: INFO: Service rm3 in namespace kubectl-8478 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:26:23.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8478" for this suite.
Sep  4 05:26:45.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:26:45.831: INFO: namespace kubectl-8478 deletion completed in 22.106978709s

• [SLOW TEST:29.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:26:45.832: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:26:45.994: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep  4 05:26:48.107: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:26:49.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-873" for this suite.
Sep  4 05:26:55.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:26:55.250: INFO: namespace replication-controller-873 deletion completed in 6.133251078s

• [SLOW TEST:9.419 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:26:55.251: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:26:55.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c" in namespace "projected-6031" to be "success or failure"
Sep  4 05:26:55.536: INFO: Pod "downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c": Phase="Pending", Reason="", readiness=false. Elapsed: 40.177947ms
Sep  4 05:26:57.554: INFO: Pod "downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059038096s
STEP: Saw pod success
Sep  4 05:26:57.556: INFO: Pod "downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c" satisfied condition "success or failure"
Sep  4 05:26:57.565: INFO: Trying to get logs from node 192.168.1.102 pod downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c container client-container: <nil>
STEP: delete the pod
Sep  4 05:26:57.640: INFO: Waiting for pod downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c to disappear
Sep  4 05:26:57.645: INFO: Pod downwardapi-volume-dbf27941-64fd-4b9b-b87a-754769652f7c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:26:57.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6031" for this suite.
Sep  4 05:27:03.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:27:03.812: INFO: namespace projected-6031 deletion completed in 6.15568952s

• [SLOW TEST:8.561 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:27:03.814: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 05:27:08.629: INFO: Successfully updated pod "annotationupdate5d0340b4-1146-46c8-aca7-0dddd3f021af"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:27:10.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5200" for this suite.
Sep  4 05:27:34.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:27:34.790: INFO: namespace projected-5200 deletion completed in 24.126195008s

• [SLOW TEST:30.977 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:27:34.792: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-5f156597-ce18-453e-9d24-27f74176ebdb in namespace container-probe-4472
Sep  4 05:27:38.981: INFO: Started pod busybox-5f156597-ce18-453e-9d24-27f74176ebdb in namespace container-probe-4472
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 05:27:38.992: INFO: Initial restart count of pod busybox-5f156597-ce18-453e-9d24-27f74176ebdb is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:31:39.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4472" for this suite.
Sep  4 05:31:45.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:31:45.773: INFO: namespace container-probe-4472 deletion completed in 6.295844895s

• [SLOW TEST:250.981 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:31:45.773: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4213
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-319ab656-7084-4b47-bc68-254c797d119d
STEP: Creating secret with name s-test-opt-upd-478c1c0e-fc6c-4efc-836d-4739a1e8a2b8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-319ab656-7084-4b47-bc68-254c797d119d
STEP: Updating secret s-test-opt-upd-478c1c0e-fc6c-4efc-836d-4739a1e8a2b8
STEP: Creating secret with name s-test-opt-create-c09e62ea-3fb3-44b6-b464-a5d9958590f5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:31:52.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4213" for this suite.
Sep  4 05:32:14.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:32:15.153: INFO: namespace secrets-4213 deletion completed in 22.345248494s

• [SLOW TEST:29.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:32:15.155: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:32:15.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e" in namespace "projected-8121" to be "success or failure"
Sep  4 05:32:15.402: INFO: Pod "downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.060748ms
Sep  4 05:32:17.406: INFO: Pod "downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018620702s
Sep  4 05:32:19.421: INFO: Pod "downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033508529s
STEP: Saw pod success
Sep  4 05:32:19.421: INFO: Pod "downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e" satisfied condition "success or failure"
Sep  4 05:32:19.444: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e container client-container: <nil>
STEP: delete the pod
Sep  4 05:32:19.508: INFO: Waiting for pod downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e to disappear
Sep  4 05:32:19.516: INFO: Pod downwardapi-volume-2b45abb2-c420-4986-95d6-96bd6318125e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:32:19.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8121" for this suite.
Sep  4 05:32:25.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:32:25.765: INFO: namespace projected-8121 deletion completed in 6.243299667s

• [SLOW TEST:10.610 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:32:25.766: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 05:32:26.004: INFO: Waiting up to 5m0s for pod "downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb" in namespace "downward-api-3416" to be "success or failure"
Sep  4 05:32:26.020: INFO: Pod "downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.977496ms
Sep  4 05:32:28.029: INFO: Pod "downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024610405s
STEP: Saw pod success
Sep  4 05:32:28.029: INFO: Pod "downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb" satisfied condition "success or failure"
Sep  4 05:32:28.042: INFO: Trying to get logs from node 192.168.1.103 pod downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb container dapi-container: <nil>
STEP: delete the pod
Sep  4 05:32:28.104: INFO: Waiting for pod downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb to disappear
Sep  4 05:32:28.112: INFO: Pod downward-api-b4eba50c-82fd-43e7-8190-a6cce47ff0cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:32:28.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3416" for this suite.
Sep  4 05:32:34.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:32:34.339: INFO: namespace downward-api-3416 deletion completed in 6.21908211s

• [SLOW TEST:8.573 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:32:34.339: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2039
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 05:32:34.595: INFO: Waiting up to 5m0s for pod "pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee" in namespace "emptydir-2039" to be "success or failure"
Sep  4 05:32:34.607: INFO: Pod "pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee": Phase="Pending", Reason="", readiness=false. Elapsed: 12.057824ms
Sep  4 05:32:36.610: INFO: Pod "pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015559958s
Sep  4 05:32:38.620: INFO: Pod "pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025291348s
STEP: Saw pod success
Sep  4 05:32:38.620: INFO: Pod "pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee" satisfied condition "success or failure"
Sep  4 05:32:38.632: INFO: Trying to get logs from node 192.168.1.101 pod pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee container test-container: <nil>
STEP: delete the pod
Sep  4 05:32:38.750: INFO: Waiting for pod pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee to disappear
Sep  4 05:32:38.770: INFO: Pod pod-3f3a689b-16fb-4974-9c4a-4a4103a82bee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:32:38.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2039" for this suite.
Sep  4 05:32:44.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:32:44.930: INFO: namespace emptydir-2039 deletion completed in 6.152826359s

• [SLOW TEST:10.591 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:32:44.931: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-813/configmap-test-a4517999-004e-4e94-969b-ea90cc937b56
STEP: Creating a pod to test consume configMaps
Sep  4 05:32:45.118: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17" in namespace "configmap-813" to be "success or failure"
Sep  4 05:32:45.147: INFO: Pod "pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17": Phase="Pending", Reason="", readiness=false. Elapsed: 25.945956ms
Sep  4 05:32:47.150: INFO: Pod "pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028715621s
Sep  4 05:32:49.153: INFO: Pod "pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032031143s
STEP: Saw pod success
Sep  4 05:32:49.153: INFO: Pod "pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17" satisfied condition "success or failure"
Sep  4 05:32:49.157: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17 container env-test: <nil>
STEP: delete the pod
Sep  4 05:32:49.177: INFO: Waiting for pod pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17 to disappear
Sep  4 05:32:49.180: INFO: Pod pod-configmaps-4eb6b725-d35d-4bf4-86ed-d67961e7ac17 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:32:49.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-813" for this suite.
Sep  4 05:32:55.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:32:55.828: INFO: namespace configmap-813 deletion completed in 6.640673681s

• [SLOW TEST:10.898 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:32:55.852: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 05:32:56.165: INFO: Number of nodes with available pods: 0
Sep  4 05:32:56.165: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:32:57.203: INFO: Number of nodes with available pods: 0
Sep  4 05:32:57.203: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:32:58.187: INFO: Number of nodes with available pods: 2
Sep  4 05:32:58.187: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:32:59.172: INFO: Number of nodes with available pods: 3
Sep  4 05:32:59.172: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  4 05:32:59.193: INFO: Number of nodes with available pods: 2
Sep  4 05:32:59.193: INFO: Node 192.168.1.102 is running more than one daemon pod
Sep  4 05:33:00.202: INFO: Number of nodes with available pods: 2
Sep  4 05:33:00.202: INFO: Node 192.168.1.102 is running more than one daemon pod
Sep  4 05:33:01.200: INFO: Number of nodes with available pods: 3
Sep  4 05:33:01.200: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7229, will wait for the garbage collector to delete the pods
Sep  4 05:33:01.268: INFO: Deleting DaemonSet.extensions daemon-set took: 8.587604ms
Sep  4 05:33:01.668: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.527704ms
Sep  4 05:33:15.791: INFO: Number of nodes with available pods: 0
Sep  4 05:33:15.791: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 05:33:15.795: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7229/daemonsets","resourceVersion":"13962"},"items":null}

Sep  4 05:33:15.798: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7229/pods","resourceVersion":"13962"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:33:15.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7229" for this suite.
Sep  4 05:33:21.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:33:21.929: INFO: namespace daemonsets-7229 deletion completed in 6.113646117s

• [SLOW TEST:26.078 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:33:21.930: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8526
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7803
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:33:46.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2357" for this suite.
Sep  4 05:33:52.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:33:52.867: INFO: namespace namespaces-2357 deletion completed in 6.2824736s
STEP: Destroying namespace "nsdeletetest-8526" for this suite.
Sep  4 05:33:52.871: INFO: Namespace nsdeletetest-8526 was already deleted
STEP: Destroying namespace "nsdeletetest-7803" for this suite.
Sep  4 05:33:58.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:33:59.050: INFO: namespace nsdeletetest-7803 deletion completed in 6.178832874s

• [SLOW TEST:37.120 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:33:59.050: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4341, will wait for the garbage collector to delete the pods
Sep  4 05:34:03.298: INFO: Deleting Job.batch foo took: 12.158264ms
Sep  4 05:34:03.698: INFO: Terminating Job.batch foo pods took: 400.201434ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:34:45.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4341" for this suite.
Sep  4 05:34:51.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:34:51.881: INFO: namespace job-4341 deletion completed in 6.174576581s

• [SLOW TEST:52.831 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:34:51.881: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9419/configmap-test-72cc9e5b-bdf0-4d26-aedb-3ce426353f33
STEP: Creating a pod to test consume configMaps
Sep  4 05:34:52.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589" in namespace "configmap-9419" to be "success or failure"
Sep  4 05:34:52.167: INFO: Pod "pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589": Phase="Pending", Reason="", readiness=false. Elapsed: 31.600773ms
Sep  4 05:34:54.173: INFO: Pod "pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03688293s
Sep  4 05:34:56.190: INFO: Pod "pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054417145s
STEP: Saw pod success
Sep  4 05:34:56.190: INFO: Pod "pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589" satisfied condition "success or failure"
Sep  4 05:34:56.213: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589 container env-test: <nil>
STEP: delete the pod
Sep  4 05:34:56.243: INFO: Waiting for pod pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589 to disappear
Sep  4 05:34:56.248: INFO: Pod pod-configmaps-abd6bcee-a936-4b9f-b3f0-6c8019173589 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:34:56.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9419" for this suite.
Sep  4 05:35:02.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:35:02.451: INFO: namespace configmap-9419 deletion completed in 6.190571837s

• [SLOW TEST:10.570 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:35:02.452: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep  4 05:35:02.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-638'
Sep  4 05:35:02.864: INFO: stderr: ""
Sep  4 05:35:02.864: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 05:35:03.944: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:03.944: INFO: Found 0 / 1
Sep  4 05:35:04.867: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:04.867: INFO: Found 0 / 1
Sep  4 05:35:05.887: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:05.887: INFO: Found 0 / 1
Sep  4 05:35:06.874: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:06.875: INFO: Found 1 / 1
Sep  4 05:35:06.875: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  4 05:35:06.883: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:06.883: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 05:35:06.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 patch pod redis-master-lbn4m --namespace=kubectl-638 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  4 05:35:07.000: INFO: stderr: ""
Sep  4 05:35:07.000: INFO: stdout: "pod/redis-master-lbn4m patched\n"
STEP: checking annotations
Sep  4 05:35:07.010: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:35:07.010: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:35:07.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-638" for this suite.
Sep  4 05:35:29.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:35:29.116: INFO: namespace kubectl-638 deletion completed in 22.101892918s

• [SLOW TEST:26.664 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:35:29.116: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep  4 05:35:29.317: INFO: Waiting up to 5m0s for pod "var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910" in namespace "var-expansion-6230" to be "success or failure"
Sep  4 05:35:29.363: INFO: Pod "var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910": Phase="Pending", Reason="", readiness=false. Elapsed: 46.158363ms
Sep  4 05:35:31.375: INFO: Pod "var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.058260152s
STEP: Saw pod success
Sep  4 05:35:31.375: INFO: Pod "var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910" satisfied condition "success or failure"
Sep  4 05:35:31.388: INFO: Trying to get logs from node 192.168.1.101 pod var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910 container dapi-container: <nil>
STEP: delete the pod
Sep  4 05:35:31.471: INFO: Waiting for pod var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910 to disappear
Sep  4 05:35:31.481: INFO: Pod var-expansion-0289009d-2ea3-453c-bbd5-891ac0c03910 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:35:31.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6230" for this suite.
Sep  4 05:35:37.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:35:38.002: INFO: namespace var-expansion-6230 deletion completed in 6.514221659s

• [SLOW TEST:8.886 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:35:38.006: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 05:35:41.281: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:35:41.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6084" for this suite.
Sep  4 05:35:47.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:35:47.469: INFO: namespace container-runtime-6084 deletion completed in 6.164778587s

• [SLOW TEST:9.463 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:35:47.469: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:35:47.618: INFO: Creating deployment "nginx-deployment"
Sep  4 05:35:47.626: INFO: Waiting for observed generation 1
Sep  4 05:35:49.639: INFO: Waiting for all required pods to come up
Sep  4 05:35:49.645: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  4 05:35:51.673: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  4 05:35:51.685: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  4 05:35:51.693: INFO: Updating deployment nginx-deployment
Sep  4 05:35:51.693: INFO: Waiting for observed generation 2
Sep  4 05:35:53.705: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  4 05:35:53.708: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  4 05:35:53.710: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  4 05:35:53.720: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  4 05:35:53.720: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  4 05:35:53.723: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  4 05:35:53.728: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  4 05:35:53.728: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  4 05:35:53.737: INFO: Updating deployment nginx-deployment
Sep  4 05:35:53.737: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  4 05:35:53.745: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  4 05:35:53.751: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  4 05:35:53.785: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7876,SelfLink:/apis/apps/v1/namespaces/deployment-7876/deployments/nginx-deployment,UID:bc1ba3eb-cfbb-48fa-a302-126100b2e7db,ResourceVersion:14707,Generation:3,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-09-04 05:35:51 +0000 UTC 2019-09-04 05:35:47 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-09-04 05:35:53 +0000 UTC 2019-09-04 05:35:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  4 05:35:53.795: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-7876,SelfLink:/apis/apps/v1/namespaces/deployment-7876/replicasets/nginx-deployment-55fb7cb77f,UID:f7a3246f-8e07-4404-8e78-b426995f4f9f,ResourceVersion:14698,Generation:3,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc1ba3eb-cfbb-48fa-a302-126100b2e7db 0xc002754e67 0xc002754e68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 05:35:53.795: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  4 05:35:53.795: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-7876,SelfLink:/apis/apps/v1/namespaces/deployment-7876/replicasets/nginx-deployment-7b8c6f4498,UID:9865c87e-3551-4905-aa78-e16215febdf9,ResourceVersion:14697,Generation:3,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc1ba3eb-cfbb-48fa-a302-126100b2e7db 0xc002754f37 0xc002754f38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  4 05:35:53.819: INFO: Pod "nginx-deployment-55fb7cb77f-dtr78" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dtr78,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-dtr78,UID:6a2d03b8-0e72-4e9d-a747-d792c1138ca2,ResourceVersion:14690,Generation:0,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.53/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc0027558d7 0xc0027558d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002755950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002755970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:,StartTime:2019-09-04 05:35:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-55fb7cb77f-gbpwj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gbpwj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-gbpwj,UID:0e1a12d4-d605-45fe-9deb-8708598ac174,ResourceVersion:14713,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc002755a40 0xc002755a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002755ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002755ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-55fb7cb77f-mhmh5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mhmh5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-mhmh5,UID:3bce9611-4c4b-4e40-9b9a-fa0719c0e932,ResourceVersion:14676,Generation:0,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.111.159/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc002755b70 0xc002755b71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002755bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002755c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.103,PodIP:,StartTime:2019-09-04 05:35:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-55fb7cb77f-nvqnz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nvqnz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-nvqnz,UID:198821c1-dab6-44fb-9cb1-f262f9f4488d,ResourceVersion:14682,Generation:0,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.51/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc002755d10 0xc002755d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002755d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002755db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:,StartTime:2019-09-04 05:35:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-55fb7cb77f-vjvdf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vjvdf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-vjvdf,UID:21000fbb-26ff-4748-8073-2880e726dc6d,ResourceVersion:14686,Generation:0,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.55/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc002755e90 0xc002755e91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002755f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002755f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:,StartTime:2019-09-04 05:35:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-55fb7cb77f-ztms2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ztms2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-55fb7cb77f-ztms2,UID:6fa69587-4f9c-43c4-a774-7e8744514d09,ResourceVersion:14675,Generation:0,CreationTimestamp:2019-09-04 05:35:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.78.95/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f7a3246f-8e07-4404-8e78-b426995f4f9f 0xc003fbc010 0xc003fbc011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.102,PodIP:,StartTime:2019-09-04 05:35:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.820: INFO: Pod "nginx-deployment-7b8c6f4498-8gvlq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8gvlq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-8gvlq,UID:76610fcb-03c4-46ba-84a6-6a48cf46433d,ResourceVersion:14611,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.111.158/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc190 0xc003fbc191}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.103,PodIP:10.10.111.158,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a0dc5b468b74a17a34e7a10768fd591a7d9b92701af5129dcb8ffa8cc274a5c5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.821: INFO: Pod "nginx-deployment-7b8c6f4498-bn9rj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bn9rj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-bn9rj,UID:159107e8-c5d2-4b31-bace-8db339462b68,ResourceVersion:14712,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc2f7 0xc003fbc2f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.821: INFO: Pod "nginx-deployment-7b8c6f4498-bz6v7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bz6v7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-bz6v7,UID:7827ebcf-99ae-46af-83c2-64ba8482c459,ResourceVersion:14607,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.111.157/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc420 0xc003fbc421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.103,PodIP:10.10.111.157,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d5cf9bcb5733ccc2bfa066ade5657cd360ffaac2d390b7d5ea3c69718ab879d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.821: INFO: Pod "nginx-deployment-7b8c6f4498-cd7gr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cd7gr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-cd7gr,UID:d4a9ab5b-abef-400e-986b-f09ad235d41e,ResourceVersion:14601,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.111.156/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc597 0xc003fbc598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.103,PodIP:10.10.111.156,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://20c807853b4bc2f102ea45ba6f460482563d143271619e4c6f752110d513cd37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.821: INFO: Pod "nginx-deployment-7b8c6f4498-hc8fq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hc8fq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-hc8fq,UID:c3fac082-4a20-445b-a63f-e48667f1df8e,ResourceVersion:14714,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc707 0xc003fbc708}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc7a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.821: INFO: Pod "nginx-deployment-7b8c6f4498-kkl7s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kkl7s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-kkl7s,UID:b2c93540-faef-44fb-863c-345fc8dd476a,ResourceVersion:14608,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.50/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc830 0xc003fbc831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbc8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.50,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d8ed12713de36cc49c00d53a3fe4b6d8683249351946a54be75b2019b1a080cd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.822: INFO: Pod "nginx-deployment-7b8c6f4498-l892v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l892v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-l892v,UID:1dbca127-eb79-4c98-bb9f-aab029862a22,ResourceVersion:14711,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbc990 0xc003fbc991}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbc9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbca10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.822: INFO: Pod "nginx-deployment-7b8c6f4498-mt6sh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mt6sh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-mt6sh,UID:7f68776a-b25a-499b-9b4f-e4ad822b510b,ResourceVersion:14604,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.46/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbca87 0xc003fbca88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbcb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbcb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.46,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c6456b74f1d6f09adc59bee923d7a0b10bfc9e6d691ecd97da5249a2cccf07af}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.822: INFO: Pod "nginx-deployment-7b8c6f4498-pj2vk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pj2vk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-pj2vk,UID:3ae914de-44a0-4c14-9559-fb96e76ed22c,ResourceVersion:14584,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.78.93/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbcc00 0xc003fbcc01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbcc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbcc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.102,PodIP:10.10.78.93,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d1d045e094123545ace456bd57450b8851fda96831c9efa7e2190a04bf27bacb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.822: INFO: Pod "nginx-deployment-7b8c6f4498-qwr5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qwr5g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-qwr5g,UID:e2b10dd3-c071-4560-bd3b-c4fbff0e48fc,ResourceVersion:14587,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.78.92/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbcd70 0xc003fbcd71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbcde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbce00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.102,PodIP:10.10.78.92,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://47e4a96b71d7d4773767a469c2d057949019d18d87108357224501e3a689a47e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.823: INFO: Pod "nginx-deployment-7b8c6f4498-rt5kd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rt5kd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-rt5kd,UID:4eab5214-4420-4e73-a167-620449d88e63,ResourceVersion:14590,Generation:0,CreationTimestamp:2019-09-04 05:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.78.94/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbcee0 0xc003fbcee1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbcf50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbcf70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.102,PodIP:10.10.78.94,StartTime:2019-09-04 05:35:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-04 05:35:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c2969faf2f027d242a4771b0465809957d14d486376d435e3ecae372b69428b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.823: INFO: Pod "nginx-deployment-7b8c6f4498-xsdzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xsdzh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-xsdzh,UID:2d0c24aa-5cd8-4e38-ba99-a11659e9ed23,ResourceVersion:14715,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbd040 0xc003fbd041}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbd0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbd0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  4 05:35:53.823: INFO: Pod "nginx-deployment-7b8c6f4498-z2nbd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z2nbd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7876,SelfLink:/api/v1/namespaces/deployment-7876/pods/nginx-deployment-7b8c6f4498-z2nbd,UID:8c3622a5-550c-446f-9d38-7ad17253c14e,ResourceVersion:14701,Generation:0,CreationTimestamp:2019-09-04 05:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 9865c87e-3551-4905-aa78-e16215febdf9 0xc003fbd150 0xc003fbd151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwp6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwp6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwp6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fbd1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fbd1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:35:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:35:53.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7876" for this suite.
Sep  4 05:36:01.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:02.004: INFO: namespace deployment-7876 deletion completed in 8.174723574s

• [SLOW TEST:14.535 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:02.004: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1014
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  4 05:36:02.182: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1014,SelfLink:/api/v1/namespaces/watch-1014/configmaps/e2e-watch-test-resource-version,UID:804419bc-e107-4757-a95c-c3a6070dec84,ResourceVersion:15009,Generation:0,CreationTimestamp:2019-09-04 05:36:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 05:36:02.182: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1014,SelfLink:/api/v1/namespaces/watch-1014/configmaps/e2e-watch-test-resource-version,UID:804419bc-e107-4757-a95c-c3a6070dec84,ResourceVersion:15010,Generation:0,CreationTimestamp:2019-09-04 05:36:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:02.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1014" for this suite.
Sep  4 05:36:08.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:08.378: INFO: namespace watch-1014 deletion completed in 6.192275519s

• [SLOW TEST:6.374 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:08.379: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-6dc7180a-cb18-4a4c-9da9-289ff5230d97
STEP: Creating a pod to test consume secrets
Sep  4 05:36:08.620: INFO: Waiting up to 5m0s for pod "pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14" in namespace "secrets-5858" to be "success or failure"
Sep  4 05:36:08.631: INFO: Pod "pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14": Phase="Pending", Reason="", readiness=false. Elapsed: 11.066627ms
Sep  4 05:36:10.643: INFO: Pod "pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022876269s
STEP: Saw pod success
Sep  4 05:36:10.643: INFO: Pod "pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14" satisfied condition "success or failure"
Sep  4 05:36:10.677: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:36:10.740: INFO: Waiting for pod pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14 to disappear
Sep  4 05:36:10.744: INFO: Pod pod-secrets-ca1d3231-4835-4378-8428-8b20d73c9e14 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:10.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5858" for this suite.
Sep  4 05:36:16.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:16.953: INFO: namespace secrets-5858 deletion completed in 6.204415499s

• [SLOW TEST:8.574 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:16.953: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-80405cdc-073c-4ac5-828e-99dfebd35807
STEP: Creating a pod to test consume configMaps
Sep  4 05:36:17.156: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421" in namespace "projected-9096" to be "success or failure"
Sep  4 05:36:17.191: INFO: Pod "pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421": Phase="Pending", Reason="", readiness=false. Elapsed: 34.045179ms
Sep  4 05:36:19.194: INFO: Pod "pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037004463s
Sep  4 05:36:21.202: INFO: Pod "pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045800134s
STEP: Saw pod success
Sep  4 05:36:21.203: INFO: Pod "pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421" satisfied condition "success or failure"
Sep  4 05:36:21.211: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:36:21.320: INFO: Waiting for pod pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421 to disappear
Sep  4 05:36:21.328: INFO: Pod pod-projected-configmaps-148912b5-0a7d-401d-9d7c-1aa212caf421 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:21.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9096" for this suite.
Sep  4 05:36:27.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:27.686: INFO: namespace projected-9096 deletion completed in 6.348808511s

• [SLOW TEST:10.733 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:27.686: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1f9eb39d-b9b9-4e47-a154-a2b5c2a34c59
STEP: Creating a pod to test consume configMaps
Sep  4 05:36:27.906: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093" in namespace "configmap-8169" to be "success or failure"
Sep  4 05:36:27.909: INFO: Pod "pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093": Phase="Pending", Reason="", readiness=false. Elapsed: 2.495633ms
Sep  4 05:36:29.917: INFO: Pod "pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010851086s
Sep  4 05:36:31.925: INFO: Pod "pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018432044s
STEP: Saw pod success
Sep  4 05:36:31.925: INFO: Pod "pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093" satisfied condition "success or failure"
Sep  4 05:36:31.937: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:36:31.997: INFO: Waiting for pod pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093 to disappear
Sep  4 05:36:32.009: INFO: Pod pod-configmaps-a7676fee-dcd6-4454-8367-bd7070e2b093 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:32.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8169" for this suite.
Sep  4 05:36:38.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:38.133: INFO: namespace configmap-8169 deletion completed in 6.117198757s

• [SLOW TEST:10.447 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:38.133: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-379
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 05:36:38.338: INFO: Waiting up to 5m0s for pod "pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d" in namespace "emptydir-379" to be "success or failure"
Sep  4 05:36:38.366: INFO: Pod "pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d": Phase="Pending", Reason="", readiness=false. Elapsed: 27.139266ms
Sep  4 05:36:40.369: INFO: Pod "pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030917577s
STEP: Saw pod success
Sep  4 05:36:40.370: INFO: Pod "pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d" satisfied condition "success or failure"
Sep  4 05:36:40.374: INFO: Trying to get logs from node 192.168.1.101 pod pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d container test-container: <nil>
STEP: delete the pod
Sep  4 05:36:40.402: INFO: Waiting for pod pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d to disappear
Sep  4 05:36:40.408: INFO: Pod pod-e36a6e3b-069c-4e3a-9689-2905158fbc3d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:40.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-379" for this suite.
Sep  4 05:36:46.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:46.693: INFO: namespace emptydir-379 deletion completed in 6.268709138s

• [SLOW TEST:8.559 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:46.693: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep  4 05:36:46.889: INFO: Waiting up to 5m0s for pod "client-containers-db164e59-46e9-4858-be2b-a80b5fad1849" in namespace "containers-5643" to be "success or failure"
Sep  4 05:36:46.916: INFO: Pod "client-containers-db164e59-46e9-4858-be2b-a80b5fad1849": Phase="Pending", Reason="", readiness=false. Elapsed: 26.315556ms
Sep  4 05:36:48.931: INFO: Pod "client-containers-db164e59-46e9-4858-be2b-a80b5fad1849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041046491s
Sep  4 05:36:50.946: INFO: Pod "client-containers-db164e59-46e9-4858-be2b-a80b5fad1849": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055575419s
STEP: Saw pod success
Sep  4 05:36:50.946: INFO: Pod "client-containers-db164e59-46e9-4858-be2b-a80b5fad1849" satisfied condition "success or failure"
Sep  4 05:36:50.971: INFO: Trying to get logs from node 192.168.1.101 pod client-containers-db164e59-46e9-4858-be2b-a80b5fad1849 container test-container: <nil>
STEP: delete the pod
Sep  4 05:36:51.056: INFO: Waiting for pod client-containers-db164e59-46e9-4858-be2b-a80b5fad1849 to disappear
Sep  4 05:36:51.058: INFO: Pod client-containers-db164e59-46e9-4858-be2b-a80b5fad1849 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:36:51.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5643" for this suite.
Sep  4 05:36:57.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:36:57.338: INFO: namespace containers-5643 deletion completed in 6.273687557s

• [SLOW TEST:10.645 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:36:57.339: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-d6c9729b-d82d-46fc-ade8-614660529e1b in namespace container-probe-6602
Sep  4 05:37:01.571: INFO: Started pod busybox-d6c9729b-d82d-46fc-ade8-614660529e1b in namespace container-probe-6602
STEP: checking the pod's current state and verifying that restartCount is present
Sep  4 05:37:01.576: INFO: Initial restart count of pod busybox-d6c9729b-d82d-46fc-ade8-614660529e1b is 0
Sep  4 05:37:47.777: INFO: Restart count of pod container-probe-6602/busybox-d6c9729b-d82d-46fc-ade8-614660529e1b is now 1 (46.200779246s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:37:47.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6602" for this suite.
Sep  4 05:37:53.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:37:54.072: INFO: namespace container-probe-6602 deletion completed in 6.271952226s

• [SLOW TEST:56.733 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:37:54.072: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-3754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3754 to expose endpoints map[]
Sep  4 05:37:54.306: INFO: successfully validated that service endpoint-test2 in namespace services-3754 exposes endpoints map[] (29.373409ms elapsed)
STEP: Creating pod pod1 in namespace services-3754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3754 to expose endpoints map[pod1:[80]]
Sep  4 05:37:57.409: INFO: successfully validated that service endpoint-test2 in namespace services-3754 exposes endpoints map[pod1:[80]] (3.074861686s elapsed)
STEP: Creating pod pod2 in namespace services-3754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3754 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  4 05:38:01.543: INFO: Unexpected endpoints: found map[88ee77ec-af49-40c3-b197-a4080069fff0:[80]], expected map[pod1:[80] pod2:[80]] (4.129608724s elapsed, will retry)
Sep  4 05:38:02.611: INFO: successfully validated that service endpoint-test2 in namespace services-3754 exposes endpoints map[pod1:[80] pod2:[80]] (5.197117451s elapsed)
STEP: Deleting pod pod1 in namespace services-3754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3754 to expose endpoints map[pod2:[80]]
Sep  4 05:38:03.676: INFO: successfully validated that service endpoint-test2 in namespace services-3754 exposes endpoints map[pod2:[80]] (1.034581796s elapsed)
STEP: Deleting pod pod2 in namespace services-3754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3754 to expose endpoints map[]
Sep  4 05:38:03.699: INFO: successfully validated that service endpoint-test2 in namespace services-3754 exposes endpoints map[] (14.930513ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:38:03.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3754" for this suite.
Sep  4 05:38:09.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:38:09.846: INFO: namespace services-3754 deletion completed in 6.104239592s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:15.774 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:38:09.846: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep  4 05:38:10.624: INFO: created pod pod-service-account-defaultsa
Sep  4 05:38:10.624: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  4 05:38:10.667: INFO: created pod pod-service-account-mountsa
Sep  4 05:38:10.667: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  4 05:38:10.682: INFO: created pod pod-service-account-nomountsa
Sep  4 05:38:10.683: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  4 05:38:10.696: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  4 05:38:10.696: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  4 05:38:10.703: INFO: created pod pod-service-account-mountsa-mountspec
Sep  4 05:38:10.703: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  4 05:38:10.708: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  4 05:38:10.708: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  4 05:38:10.725: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  4 05:38:10.725: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  4 05:38:10.736: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  4 05:38:10.736: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  4 05:38:10.744: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  4 05:38:10.744: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:38:10.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4266" for this suite.
Sep  4 05:38:34.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:38:35.042: INFO: namespace svcaccounts-4266 deletion completed in 24.292071549s

• [SLOW TEST:25.196 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:38:35.043: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep  4 05:38:35.197: INFO: Waiting up to 5m0s for pod "downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e" in namespace "downward-api-1246" to be "success or failure"
Sep  4 05:38:35.203: INFO: Pod "downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.152484ms
Sep  4 05:38:37.206: INFO: Pod "downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008695038s
STEP: Saw pod success
Sep  4 05:38:37.206: INFO: Pod "downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e" satisfied condition "success or failure"
Sep  4 05:38:37.210: INFO: Trying to get logs from node 192.168.1.101 pod downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e container dapi-container: <nil>
STEP: delete the pod
Sep  4 05:38:37.255: INFO: Waiting for pod downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e to disappear
Sep  4 05:38:37.259: INFO: Pod downward-api-7bfda487-0bde-4dbc-a91c-85acbbe4988e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:38:37.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1246" for this suite.
Sep  4 05:38:43.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:38:43.544: INFO: namespace downward-api-1246 deletion completed in 6.277145522s

• [SLOW TEST:8.501 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:38:43.544: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:39:08.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2429" for this suite.
Sep  4 05:39:14.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:39:14.392: INFO: namespace container-runtime-2429 deletion completed in 6.201744159s

• [SLOW TEST:30.848 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:39:14.394: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  4 05:39:18.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:18.808: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:20.813: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:20.816: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:22.815: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:22.824: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:24.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:24.830: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:26.816: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:26.828: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:28.816: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:28.821: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:30.819: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:30.851: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:32.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:32.819: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:34.813: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:34.827: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:36.813: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:36.994: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:38.817: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:38.842: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:40.816: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:40.851: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:42.813: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:42.816: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:44.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:44.834: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  4 05:39:46.816: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  4 05:39:46.830: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:39:46.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6928" for this suite.
Sep  4 05:40:08.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:40:09.166: INFO: namespace container-lifecycle-hook-6928 deletion completed in 22.29047777s

• [SLOW TEST:54.772 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:40:09.166: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6173
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  4 05:40:09.361: INFO: Waiting up to 5m0s for pod "pod-0264d939-6415-45a3-9af4-88f546ec71e2" in namespace "emptydir-6173" to be "success or failure"
Sep  4 05:40:09.389: INFO: Pod "pod-0264d939-6415-45a3-9af4-88f546ec71e2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.96319ms
Sep  4 05:40:11.400: INFO: Pod "pod-0264d939-6415-45a3-9af4-88f546ec71e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039284948s
STEP: Saw pod success
Sep  4 05:40:11.400: INFO: Pod "pod-0264d939-6415-45a3-9af4-88f546ec71e2" satisfied condition "success or failure"
Sep  4 05:40:11.419: INFO: Trying to get logs from node 192.168.1.101 pod pod-0264d939-6415-45a3-9af4-88f546ec71e2 container test-container: <nil>
STEP: delete the pod
Sep  4 05:40:11.516: INFO: Waiting for pod pod-0264d939-6415-45a3-9af4-88f546ec71e2 to disappear
Sep  4 05:40:11.527: INFO: Pod pod-0264d939-6415-45a3-9af4-88f546ec71e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:40:11.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6173" for this suite.
Sep  4 05:40:17.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:40:17.760: INFO: namespace emptydir-6173 deletion completed in 6.22679177s

• [SLOW TEST:8.593 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:40:17.760: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:40:17.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4695" for this suite.
Sep  4 05:40:23.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:40:24.109: INFO: namespace services-4695 deletion completed in 6.184483652s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.350 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:40:24.109: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-c693a795-2ee7-47e4-9bc8-576a01ce5b0f
STEP: Creating a pod to test consume configMaps
Sep  4 05:40:24.326: INFO: Waiting up to 5m0s for pod "pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729" in namespace "configmap-7571" to be "success or failure"
Sep  4 05:40:24.361: INFO: Pod "pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729": Phase="Pending", Reason="", readiness=false. Elapsed: 34.319177ms
Sep  4 05:40:26.373: INFO: Pod "pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046452787s
STEP: Saw pod success
Sep  4 05:40:26.374: INFO: Pod "pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729" satisfied condition "success or failure"
Sep  4 05:40:26.388: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:40:26.418: INFO: Waiting for pod pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729 to disappear
Sep  4 05:40:26.420: INFO: Pod pod-configmaps-867cb7a6-5ed1-4499-986c-5c2f89bc1729 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:40:26.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7571" for this suite.
Sep  4 05:40:32.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:40:32.771: INFO: namespace configmap-7571 deletion completed in 6.347473913s

• [SLOW TEST:8.662 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:40:32.771: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:40:33.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5" in namespace "downward-api-5593" to be "success or failure"
Sep  4 05:40:33.049: INFO: Pod "downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5": Phase="Pending", Reason="", readiness=false. Elapsed: 35.384439ms
Sep  4 05:40:35.068: INFO: Pod "downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053921891s
STEP: Saw pod success
Sep  4 05:40:35.068: INFO: Pod "downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5" satisfied condition "success or failure"
Sep  4 05:40:35.086: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5 container client-container: <nil>
STEP: delete the pod
Sep  4 05:40:35.148: INFO: Waiting for pod downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5 to disappear
Sep  4 05:40:35.154: INFO: Pod downwardapi-volume-41e7fa02-30c1-45e4-9160-2fb2adfcf2f5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:40:35.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5593" for this suite.
Sep  4 05:40:41.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:40:41.325: INFO: namespace downward-api-5593 deletion completed in 6.163036623s

• [SLOW TEST:8.553 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:40:41.325: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-ffvf
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 05:40:41.557: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ffvf" in namespace "subpath-2669" to be "success or failure"
Sep  4 05:40:41.564: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.524491ms
Sep  4 05:40:43.577: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 2.019486756s
Sep  4 05:40:45.607: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 4.04931647s
Sep  4 05:40:47.611: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 6.053582588s
Sep  4 05:40:49.617: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 8.059734939s
Sep  4 05:40:51.630: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 10.072514488s
Sep  4 05:40:53.635: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 12.077504874s
Sep  4 05:40:55.647: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 14.089416862s
Sep  4 05:40:57.653: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 16.095802155s
Sep  4 05:40:59.656: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 18.098454115s
Sep  4 05:41:01.662: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Running", Reason="", readiness=true. Elapsed: 20.104365452s
Sep  4 05:41:03.922: INFO: Pod "pod-subpath-test-downwardapi-ffvf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.36448372s
STEP: Saw pod success
Sep  4 05:41:03.922: INFO: Pod "pod-subpath-test-downwardapi-ffvf" satisfied condition "success or failure"
Sep  4 05:41:03.925: INFO: Trying to get logs from node 192.168.1.101 pod pod-subpath-test-downwardapi-ffvf container test-container-subpath-downwardapi-ffvf: <nil>
STEP: delete the pod
Sep  4 05:41:03.953: INFO: Waiting for pod pod-subpath-test-downwardapi-ffvf to disappear
Sep  4 05:41:03.966: INFO: Pod pod-subpath-test-downwardapi-ffvf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ffvf
Sep  4 05:41:03.966: INFO: Deleting pod "pod-subpath-test-downwardapi-ffvf" in namespace "subpath-2669"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:41:03.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2669" for this suite.
Sep  4 05:41:10.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:41:10.206: INFO: namespace subpath-2669 deletion completed in 6.221144955s

• [SLOW TEST:28.881 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:41:10.208: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:41:14.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9671" for this suite.
Sep  4 05:41:20.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:41:20.579: INFO: namespace kubelet-test-9671 deletion completed in 6.177902172s

• [SLOW TEST:10.372 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:41:20.581: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep  4 05:41:21.851: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0904 05:41:21.851324      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 05:41:21.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8564" for this suite.
Sep  4 05:41:27.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:41:27.982: INFO: namespace gc-8564 deletion completed in 6.124015494s

• [SLOW TEST:7.401 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:41:27.982: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep  4 05:41:28.133: INFO: Waiting up to 5m0s for pod "client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498" in namespace "containers-769" to be "success or failure"
Sep  4 05:41:28.137: INFO: Pod "client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498": Phase="Pending", Reason="", readiness=false. Elapsed: 3.858791ms
Sep  4 05:41:30.148: INFO: Pod "client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014803608s
STEP: Saw pod success
Sep  4 05:41:30.149: INFO: Pod "client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498" satisfied condition "success or failure"
Sep  4 05:41:30.175: INFO: Trying to get logs from node 192.168.1.101 pod client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498 container test-container: <nil>
STEP: delete the pod
Sep  4 05:41:30.221: INFO: Waiting for pod client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498 to disappear
Sep  4 05:41:30.226: INFO: Pod client-containers-b04faf0e-7ff3-496f-a42f-b4f34a522498 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:41:30.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-769" for this suite.
Sep  4 05:41:36.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:41:36.371: INFO: namespace containers-769 deletion completed in 6.138534215s

• [SLOW TEST:8.389 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:41:36.371: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-334
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-334
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-334
Sep  4 05:41:36.620: INFO: Found 0 stateful pods, waiting for 1
Sep  4 05:41:46.633: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  4 05:41:46.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:41:47.227: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:41:47.227: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:41:47.227: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:41:47.232: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  4 05:41:57.242: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:41:57.242: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:41:57.265: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:41:57.265: INFO: ss-0  192.168.1.101  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:41:57.265: INFO: 
Sep  4 05:41:57.265: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  4 05:41:58.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993253153s
Sep  4 05:41:59.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988173286s
Sep  4 05:42:00.306: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.956455378s
Sep  4 05:42:01.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952949333s
Sep  4 05:42:02.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933738964s
Sep  4 05:42:03.332: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.930724168s
Sep  4 05:42:04.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.926614682s
Sep  4 05:42:05.351: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.914786539s
Sep  4 05:42:06.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 907.826005ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-334
Sep  4 05:42:07.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:42:07.670: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:42:07.670: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:42:07.670: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:42:07.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:42:07.853: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  4 05:42:07.853: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:42:07.853: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:42:07.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:42:08.037: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  4 05:42:08.038: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:42:08.038: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:42:08.042: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  4 05:42:18.048: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:42:18.048: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:42:18.048: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  4 05:42:18.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:42:18.264: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:42:18.264: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:42:18.264: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:42:18.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:42:18.463: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:42:18.463: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:42:18.463: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:42:18.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-334 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:42:18.658: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:42:18.658: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:42:18.658: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:42:18.658: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:42:18.665: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  4 05:42:28.706: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:42:28.706: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:42:28.706: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  4 05:42:28.775: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:28.775: INFO: ss-0  192.168.1.101  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:28.775: INFO: ss-1  192.168.1.102  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:28.775: INFO: ss-2  192.168.1.103  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:28.775: INFO: 
Sep  4 05:42:28.775: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:29.782: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:29.782: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:29.782: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:29.782: INFO: ss-2  192.168.1.103  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:29.782: INFO: 
Sep  4 05:42:29.782: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:30.816: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:30.817: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:30.818: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:30.819: INFO: ss-2  192.168.1.103  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:30.820: INFO: 
Sep  4 05:42:30.823: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:31.841: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:31.841: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:31.842: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:31.843: INFO: ss-2  192.168.1.103  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:31.843: INFO: 
Sep  4 05:42:31.843: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:32.862: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:32.862: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:32.867: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:32.868: INFO: ss-2  192.168.1.103  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:32.868: INFO: 
Sep  4 05:42:32.868: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:33.885: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:33.885: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:33.885: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:33.885: INFO: ss-2  192.168.1.103  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:33.885: INFO: 
Sep  4 05:42:33.885: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:34.901: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  4 05:42:34.902: INFO: ss-0  192.168.1.101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:36 +0000 UTC  }]
Sep  4 05:42:34.902: INFO: ss-1  192.168.1.102  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:34.905: INFO: ss-2  192.168.1.103  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:42:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:41:57 +0000 UTC  }]
Sep  4 05:42:34.908: INFO: 
Sep  4 05:42:34.912: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  4 05:42:35.929: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.845128623s
Sep  4 05:42:36.935: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.827363027s
Sep  4 05:42:37.951: INFO: Verifying statefulset ss doesn't scale past 0 for another 823.08305ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-334
Sep  4 05:42:38.966: INFO: Scaling statefulset ss to 0
Sep  4 05:42:38.997: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 05:42:39.002: INFO: Deleting all statefulset in ns statefulset-334
Sep  4 05:42:39.022: INFO: Scaling statefulset ss to 0
Sep  4 05:42:39.032: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:42:39.036: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:42:39.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-334" for this suite.
Sep  4 05:42:45.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:42:45.296: INFO: namespace statefulset-334 deletion completed in 6.235109127s

• [SLOW TEST:68.925 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:42:45.297: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 05:42:45.502: INFO: Number of nodes with available pods: 0
Sep  4 05:42:45.502: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:42:46.516: INFO: Number of nodes with available pods: 0
Sep  4 05:42:46.516: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:42:47.509: INFO: Number of nodes with available pods: 2
Sep  4 05:42:47.509: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:48.548: INFO: Number of nodes with available pods: 3
Sep  4 05:42:48.548: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  4 05:42:48.614: INFO: Number of nodes with available pods: 2
Sep  4 05:42:48.614: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:49.619: INFO: Number of nodes with available pods: 2
Sep  4 05:42:49.619: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:50.630: INFO: Number of nodes with available pods: 2
Sep  4 05:42:50.630: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:51.630: INFO: Number of nodes with available pods: 2
Sep  4 05:42:51.630: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:52.623: INFO: Number of nodes with available pods: 2
Sep  4 05:42:52.623: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:53.658: INFO: Number of nodes with available pods: 2
Sep  4 05:42:53.658: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:42:54.647: INFO: Number of nodes with available pods: 3
Sep  4 05:42:54.647: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8845, will wait for the garbage collector to delete the pods
Sep  4 05:42:54.774: INFO: Deleting DaemonSet.extensions daemon-set took: 12.402228ms
Sep  4 05:42:54.875: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.581063ms
Sep  4 05:43:05.785: INFO: Number of nodes with available pods: 0
Sep  4 05:43:05.785: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 05:43:05.800: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8845/daemonsets","resourceVersion":"16705"},"items":null}

Sep  4 05:43:05.824: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8845/pods","resourceVersion":"16705"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:43:05.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8845" for this suite.
Sep  4 05:43:11.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:43:12.144: INFO: namespace daemonsets-8845 deletion completed in 6.250041962s

• [SLOW TEST:26.848 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:43:12.147: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1171
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-a4755119-2718-41ad-8604-8291aa2adf3a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-a4755119-2718-41ad-8604-8291aa2adf3a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:44:16.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1171" for this suite.
Sep  4 05:44:38.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:44:38.459: INFO: namespace configmap-1171 deletion completed in 22.175649886s

• [SLOW TEST:86.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:44:38.467: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3831
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-03d667e6-19ef-417c-8ff2-d8b5feed4232
STEP: Creating configMap with name cm-test-opt-upd-c0b8a80f-4d1c-4f9d-b66b-6a51b8a5d6f9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-03d667e6-19ef-417c-8ff2-d8b5feed4232
STEP: Updating configmap cm-test-opt-upd-c0b8a80f-4d1c-4f9d-b66b-6a51b8a5d6f9
STEP: Creating configMap with name cm-test-opt-create-f9e51d9d-0e57-48d5-a0ff-319b65d6225f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:44:44.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3831" for this suite.
Sep  4 05:45:06.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:45:07.094: INFO: namespace configmap-3831 deletion completed in 22.119168912s

• [SLOW TEST:28.628 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:45:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep  4 05:45:07.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 --namespace=kubectl-884 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  4 05:45:09.286: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  4 05:45:09.286: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:45:11.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-884" for this suite.
Sep  4 05:45:17.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:45:17.522: INFO: namespace kubectl-884 deletion completed in 6.194486741s

• [SLOW TEST:10.427 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:45:17.522: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-27
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  4 05:45:20.235: INFO: Successfully updated pod "pod-update-5a3909a6-338e-4673-9566-57578dc7ff00"
STEP: verifying the updated pod is in kubernetes
Sep  4 05:45:20.254: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:45:20.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-27" for this suite.
Sep  4 05:45:42.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:45:42.434: INFO: namespace pods-27 deletion completed in 22.175122609s

• [SLOW TEST:24.911 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:45:42.434: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep  4 05:45:42.580: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  4 05:45:42.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:43.015: INFO: stderr: ""
Sep  4 05:45:43.015: INFO: stdout: "service/redis-slave created\n"
Sep  4 05:45:43.015: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  4 05:45:43.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:43.764: INFO: stderr: ""
Sep  4 05:45:43.764: INFO: stdout: "service/redis-master created\n"
Sep  4 05:45:43.764: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  4 05:45:43.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:43.959: INFO: stderr: ""
Sep  4 05:45:43.959: INFO: stdout: "service/frontend created\n"
Sep  4 05:45:43.959: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  4 05:45:43.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:44.181: INFO: stderr: ""
Sep  4 05:45:44.181: INFO: stdout: "deployment.apps/frontend created\n"
Sep  4 05:45:44.181: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  4 05:45:44.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:44.379: INFO: stderr: ""
Sep  4 05:45:44.379: INFO: stdout: "deployment.apps/redis-master created\n"
Sep  4 05:45:44.379: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  4 05:45:44.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-9105'
Sep  4 05:45:44.588: INFO: stderr: ""
Sep  4 05:45:44.588: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep  4 05:45:44.588: INFO: Waiting for all frontend pods to be Running.
Sep  4 05:46:14.643: INFO: Waiting for frontend to serve content.
Sep  4 05:46:14.667: INFO: Trying to add a new entry to the guestbook.
Sep  4 05:46:14.689: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  4 05:46:14.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:14.811: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:14.812: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 05:46:14.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:14.939: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:14.939: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 05:46:14.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:15.064: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:15.064: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 05:46:15.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:15.212: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:15.212: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 05:46:15.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:15.318: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:15.319: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  4 05:46:15.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete --grace-period=0 --force -f - --namespace=kubectl-9105'
Sep  4 05:46:15.395: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  4 05:46:15.395: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:46:15.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9105" for this suite.
Sep  4 05:46:57.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:46:58.024: INFO: namespace kubectl-9105 deletion completed in 42.620233684s

• [SLOW TEST:75.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:46:58.030: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-5b743e9d-693a-44cc-ad1b-2f1cb0aa47d9
STEP: Creating a pod to test consume configMaps
Sep  4 05:46:58.245: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4" in namespace "projected-4273" to be "success or failure"
Sep  4 05:46:58.256: INFO: Pod "pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.804675ms
Sep  4 05:47:00.266: INFO: Pod "pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020002731s
Sep  4 05:47:02.281: INFO: Pod "pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034998422s
STEP: Saw pod success
Sep  4 05:47:02.281: INFO: Pod "pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4" satisfied condition "success or failure"
Sep  4 05:47:02.297: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:47:02.402: INFO: Waiting for pod pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4 to disappear
Sep  4 05:47:02.415: INFO: Pod pod-projected-configmaps-0e5f2a70-248c-4b24-a1d6-4e0071ae0ff4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:02.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4273" for this suite.
Sep  4 05:47:08.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:08.591: INFO: namespace projected-4273 deletion completed in 6.165368917s

• [SLOW TEST:10.562 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:08.592: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9679
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep  4 05:47:12.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec pod-sharedvolume-192422bf-0ba3-4879-9b47-ef97b34e1ab3 -c busybox-main-container --namespace=emptydir-9679 -- cat /usr/share/volumeshare/shareddata.txt'
Sep  4 05:47:13.155: INFO: stderr: ""
Sep  4 05:47:13.155: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:13.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9679" for this suite.
Sep  4 05:47:19.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:19.438: INFO: namespace emptydir-9679 deletion completed in 6.278853406s

• [SLOW TEST:10.846 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:19.438: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-51533ede-b08f-4b48-b26b-4541392a3850
STEP: Creating a pod to test consume configMaps
Sep  4 05:47:19.605: INFO: Waiting up to 5m0s for pod "pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806" in namespace "configmap-8091" to be "success or failure"
Sep  4 05:47:19.612: INFO: Pod "pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806": Phase="Pending", Reason="", readiness=false. Elapsed: 6.18658ms
Sep  4 05:47:21.618: INFO: Pod "pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012131596s
Sep  4 05:47:23.632: INFO: Pod "pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026228133s
STEP: Saw pod success
Sep  4 05:47:23.632: INFO: Pod "pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806" satisfied condition "success or failure"
Sep  4 05:47:23.635: INFO: Trying to get logs from node 192.168.1.101 pod pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:47:23.658: INFO: Waiting for pod pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806 to disappear
Sep  4 05:47:23.671: INFO: Pod pod-configmaps-65128d59-1d9c-49af-b4cb-44bc3f90e806 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:23.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8091" for this suite.
Sep  4 05:47:29.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:29.848: INFO: namespace configmap-8091 deletion completed in 6.168477067s

• [SLOW TEST:10.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:29.848: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:47:30.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285" in namespace "projected-7343" to be "success or failure"
Sep  4 05:47:30.064: INFO: Pod "downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285": Phase="Pending", Reason="", readiness=false. Elapsed: 20.499371ms
Sep  4 05:47:32.068: INFO: Pod "downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024954318s
STEP: Saw pod success
Sep  4 05:47:32.068: INFO: Pod "downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285" satisfied condition "success or failure"
Sep  4 05:47:32.074: INFO: Trying to get logs from node 192.168.1.102 pod downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285 container client-container: <nil>
STEP: delete the pod
Sep  4 05:47:32.110: INFO: Waiting for pod downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285 to disappear
Sep  4 05:47:32.116: INFO: Pod downwardapi-volume-7d66c38e-0b7f-4ace-8e00-a6096e9b0285 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:32.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7343" for this suite.
Sep  4 05:47:38.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:38.319: INFO: namespace projected-7343 deletion completed in 6.1985788s

• [SLOW TEST:8.471 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:38.320: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  4 05:47:38.518: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8602,SelfLink:/api/v1/namespaces/watch-8602/configmaps/e2e-watch-test-watch-closed,UID:d4a468f4-be25-40da-9b43-238df3838544,ResourceVersion:17621,Generation:0,CreationTimestamp:2019-09-04 05:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  4 05:47:38.518: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8602,SelfLink:/api/v1/namespaces/watch-8602/configmaps/e2e-watch-test-watch-closed,UID:d4a468f4-be25-40da-9b43-238df3838544,ResourceVersion:17622,Generation:0,CreationTimestamp:2019-09-04 05:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  4 05:47:38.536: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8602,SelfLink:/api/v1/namespaces/watch-8602/configmaps/e2e-watch-test-watch-closed,UID:d4a468f4-be25-40da-9b43-238df3838544,ResourceVersion:17623,Generation:0,CreationTimestamp:2019-09-04 05:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  4 05:47:38.536: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8602,SelfLink:/api/v1/namespaces/watch-8602/configmaps/e2e-watch-test-watch-closed,UID:d4a468f4-be25-40da-9b43-238df3838544,ResourceVersion:17624,Generation:0,CreationTimestamp:2019-09-04 05:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:38.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8602" for this suite.
Sep  4 05:47:44.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:44.742: INFO: namespace watch-8602 deletion completed in 6.20154926s

• [SLOW TEST:6.422 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:44.743: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:47:44.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 version'
Sep  4 05:47:45.098: INFO: stderr: ""
Sep  4 05:47:45.098: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"archive\", BuildDate:\"2019-08-22T05:39:58Z\", GoVersion:\"go1.12.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:45.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-443" for this suite.
Sep  4 05:47:51.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:47:51.838: INFO: namespace kubectl-443 deletion completed in 6.735085822s

• [SLOW TEST:7.095 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:47:51.838: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:47:52.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3612" for this suite.
Sep  4 05:48:10.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:48:10.404: INFO: namespace pods-3612 deletion completed in 18.308449755s

• [SLOW TEST:18.567 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:48:10.405: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-6dbde037-35ca-499c-a5a1-e0d548ba0d46
STEP: Creating a pod to test consume secrets
Sep  4 05:48:10.662: INFO: Waiting up to 5m0s for pod "pod-secrets-c526c148-4aee-4b37-a825-552645ffc439" in namespace "secrets-8333" to be "success or failure"
Sep  4 05:48:10.671: INFO: Pod "pod-secrets-c526c148-4aee-4b37-a825-552645ffc439": Phase="Pending", Reason="", readiness=false. Elapsed: 9.194105ms
Sep  4 05:48:12.678: INFO: Pod "pod-secrets-c526c148-4aee-4b37-a825-552645ffc439": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016512642s
STEP: Saw pod success
Sep  4 05:48:12.678: INFO: Pod "pod-secrets-c526c148-4aee-4b37-a825-552645ffc439" satisfied condition "success or failure"
Sep  4 05:48:12.684: INFO: Trying to get logs from node 192.168.1.101 pod pod-secrets-c526c148-4aee-4b37-a825-552645ffc439 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 05:48:12.716: INFO: Waiting for pod pod-secrets-c526c148-4aee-4b37-a825-552645ffc439 to disappear
Sep  4 05:48:12.723: INFO: Pod pod-secrets-c526c148-4aee-4b37-a825-552645ffc439 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:48:12.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8333" for this suite.
Sep  4 05:48:18.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:48:19.395: INFO: namespace secrets-8333 deletion completed in 6.664291441s

• [SLOW TEST:8.990 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:48:19.395: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 05:48:19.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-885'
Sep  4 05:48:19.726: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 05:48:19.726: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep  4 05:48:19.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete jobs e2e-test-nginx-job --namespace=kubectl-885'
Sep  4 05:48:19.833: INFO: stderr: ""
Sep  4 05:48:19.833: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:48:19.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-885" for this suite.
Sep  4 05:48:25.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:48:26.037: INFO: namespace kubectl-885 deletion completed in 6.198291299s

• [SLOW TEST:6.642 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:48:26.037: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0904 05:48:36.336835      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  4 05:48:36.337: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:48:36.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4929" for this suite.
Sep  4 05:48:42.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:48:42.568: INFO: namespace gc-4929 deletion completed in 6.195850981s

• [SLOW TEST:16.530 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:48:42.568: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 05:48:45.881: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:48:45.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5056" for this suite.
Sep  4 05:48:51.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:48:52.087: INFO: namespace container-runtime-5056 deletion completed in 6.163529223s

• [SLOW TEST:9.519 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:48:52.090: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:48:52.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-4967'
Sep  4 05:48:52.563: INFO: stderr: ""
Sep  4 05:48:52.563: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  4 05:48:52.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 create -f - --namespace=kubectl-4967'
Sep  4 05:48:52.769: INFO: stderr: ""
Sep  4 05:48:52.769: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  4 05:48:53.773: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:48:53.773: INFO: Found 0 / 1
Sep  4 05:48:54.775: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:48:54.775: INFO: Found 1 / 1
Sep  4 05:48:54.775: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  4 05:48:54.784: INFO: Selector matched 1 pods for map[app:redis]
Sep  4 05:48:54.784: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  4 05:48:54.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 describe pod redis-master-jbdqm --namespace=kubectl-4967'
Sep  4 05:48:54.902: INFO: stderr: ""
Sep  4 05:48:54.902: INFO: stdout: "Name:           redis-master-jbdqm\nNamespace:      kubectl-4967\nPriority:       0\nNode:           192.168.1.101/192.168.1.101\nStart Time:     Wed, 04 Sep 2019 05:48:52 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 10.10.80.40/32\nStatus:         Running\nIP:             10.10.80.40\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://24aaf22e3f5d31b50a8a4432a647b4da2745aecda313b8191fe849482940fd58\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 04 Sep 2019 05:48:54 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kz54x (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kz54x:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kz54x\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned kubectl-4967/redis-master-jbdqm to 192.168.1.101\n  Normal  Pulled     1s    kubelet, 192.168.1.101  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 192.168.1.101  Created container redis-master\n  Normal  Started    0s    kubelet, 192.168.1.101  Started container redis-master\n"
Sep  4 05:48:54.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 describe rc redis-master --namespace=kubectl-4967'
Sep  4 05:48:55.038: INFO: stderr: ""
Sep  4 05:48:55.038: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4967\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-jbdqm\n"
Sep  4 05:48:55.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 describe service redis-master --namespace=kubectl-4967'
Sep  4 05:48:55.120: INFO: stderr: ""
Sep  4 05:48:55.120: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4967\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.93.62\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.10.80.40:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  4 05:48:55.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 describe node 192.168.1.101'
Sep  4 05:48:55.226: INFO: stderr: ""
Sep  4 05:48:55.226: INFO: stdout: "Name:               192.168.1.101\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cke.cybozu.com/master=true\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.1.101\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.1.101/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.10.80.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 04 Sep 2019 04:28:15 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 04 Sep 2019 04:29:22 +0000   Wed, 04 Sep 2019 04:29:22 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 04 Sep 2019 05:48:29 +0000   Wed, 04 Sep 2019 04:28:15 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 04 Sep 2019 05:48:29 +0000   Wed, 04 Sep 2019 04:28:15 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 04 Sep 2019 05:48:29 +0000   Wed, 04 Sep 2019 04:28:15 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 04 Sep 2019 05:48:29 +0000   Wed, 04 Sep 2019 04:29:15 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.101\n  Hostname:    192.168.1.101\nCapacity:\n cpu:                4\n ephemeral-storage:  16326512Ki\n hugepages-2Mi:      0\n memory:             4040128Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  15046513435\n hugepages-2Mi:      0\n memory:             3937728Ki\n pods:               110\nSystem Info:\n Machine ID:                 400ad88a99f846c2ba94fe1242b9aa14\n System UUID:                49a1a8cb-75c1-4ba9-8625-e458d60fa4b0\n Boot ID:                    1ad7f287-eac5-4fa2-b97e-4e2f197d9805\n Kernel Version:             4.19.66-coreos\n OS Image:                   Container Linux by CoreOS 2191.4.1 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  heptio-sonobuoy            sonobuoy-e2e-job-ba0b01e0e48b4e68                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-k4lpq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  kube-system                calico-kube-controllers-65b8787765-j25mh                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                calico-node-sdb87                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                cluster-dns-74877f46df-96tqd                               100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     78m\n  kube-system                node-dns-bc4lx                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kubectl-4967               redis-master-jbdqm                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                350m (8%)  0 (0%)\n  memory             70Mi (1%)  170Mi (4%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:              <none>\n"
Sep  4 05:48:55.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 describe namespace kubectl-4967'
Sep  4 05:48:55.296: INFO: stderr: ""
Sep  4 05:48:55.296: INFO: stdout: "Name:         kubectl-4967\nLabels:       e2e-framework=kubectl\n              e2e-run=85566eaa-2f40-407f-a305-309416ea0237\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:48:55.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4967" for this suite.
Sep  4 05:49:19.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:49:19.765: INFO: namespace kubectl-4967 deletion completed in 24.466393252s

• [SLOW TEST:27.675 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:49:19.765: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-4941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4941
I0904 05:49:20.031319      21 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4941, replica count: 1
I0904 05:49:21.082045      21 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:49:22.082673      21 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0904 05:49:23.084859      21 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  4 05:49:23.193: INFO: Created: latency-svc-cxjht
Sep  4 05:49:23.200: INFO: Got endpoints: latency-svc-cxjht [14.930536ms]
Sep  4 05:49:23.218: INFO: Created: latency-svc-62ccb
Sep  4 05:49:23.228: INFO: Got endpoints: latency-svc-62ccb [27.671451ms]
Sep  4 05:49:23.241: INFO: Created: latency-svc-8x2tt
Sep  4 05:49:23.265: INFO: Created: latency-svc-85s26
Sep  4 05:49:23.268: INFO: Got endpoints: latency-svc-85s26 [66.825395ms]
Sep  4 05:49:23.286: INFO: Got endpoints: latency-svc-8x2tt [84.748347ms]
Sep  4 05:49:23.286: INFO: Created: latency-svc-z9mff
Sep  4 05:49:23.292: INFO: Got endpoints: latency-svc-z9mff [91.47269ms]
Sep  4 05:49:23.299: INFO: Created: latency-svc-svkr5
Sep  4 05:49:23.306: INFO: Got endpoints: latency-svc-svkr5 [105.111491ms]
Sep  4 05:49:23.322: INFO: Created: latency-svc-6b8qm
Sep  4 05:49:23.332: INFO: Created: latency-svc-rrw22
Sep  4 05:49:23.334: INFO: Got endpoints: latency-svc-6b8qm [47.925248ms]
Sep  4 05:49:23.345: INFO: Created: latency-svc-r97hs
Sep  4 05:49:23.346: INFO: Got endpoints: latency-svc-rrw22 [145.256853ms]
Sep  4 05:49:23.360: INFO: Got endpoints: latency-svc-r97hs [158.866687ms]
Sep  4 05:49:23.367: INFO: Created: latency-svc-4shdw
Sep  4 05:49:23.377: INFO: Got endpoints: latency-svc-4shdw [175.928127ms]
Sep  4 05:49:23.384: INFO: Created: latency-svc-2r9xh
Sep  4 05:49:23.393: INFO: Got endpoints: latency-svc-2r9xh [191.743401ms]
Sep  4 05:49:23.402: INFO: Created: latency-svc-s7rbb
Sep  4 05:49:23.416: INFO: Created: latency-svc-p4s8p
Sep  4 05:49:23.416: INFO: Got endpoints: latency-svc-s7rbb [214.947898ms]
Sep  4 05:49:23.428: INFO: Got endpoints: latency-svc-p4s8p [226.810592ms]
Sep  4 05:49:23.429: INFO: Created: latency-svc-dsv4r
Sep  4 05:49:23.439: INFO: Created: latency-svc-9lpbt
Sep  4 05:49:23.450: INFO: Got endpoints: latency-svc-dsv4r [249.442009ms]
Sep  4 05:49:23.469: INFO: Got endpoints: latency-svc-9lpbt [267.640446ms]
Sep  4 05:49:23.477: INFO: Created: latency-svc-9tnh7
Sep  4 05:49:23.483: INFO: Got endpoints: latency-svc-9tnh7 [282.025766ms]
Sep  4 05:49:23.487: INFO: Created: latency-svc-d4dkc
Sep  4 05:49:23.493: INFO: Got endpoints: latency-svc-d4dkc [292.081142ms]
Sep  4 05:49:23.518: INFO: Created: latency-svc-l2vzv
Sep  4 05:49:23.527: INFO: Created: latency-svc-pzw7d
Sep  4 05:49:23.558: INFO: Got endpoints: latency-svc-pzw7d [289.771341ms]
Sep  4 05:49:23.558: INFO: Got endpoints: latency-svc-l2vzv [330.617201ms]
Sep  4 05:49:23.574: INFO: Created: latency-svc-r425g
Sep  4 05:49:23.594: INFO: Created: latency-svc-gm7lz
Sep  4 05:49:23.612: INFO: Got endpoints: latency-svc-r425g [319.910228ms]
Sep  4 05:49:23.614: INFO: Created: latency-svc-pwhmb
Sep  4 05:49:23.614: INFO: Got endpoints: latency-svc-gm7lz [308.249336ms]
Sep  4 05:49:23.642: INFO: Got endpoints: latency-svc-pwhmb [307.857851ms]
Sep  4 05:49:23.642: INFO: Created: latency-svc-7ff4b
Sep  4 05:49:23.642: INFO: Got endpoints: latency-svc-7ff4b [296.186927ms]
Sep  4 05:49:23.649: INFO: Created: latency-svc-pbpdq
Sep  4 05:49:23.660: INFO: Got endpoints: latency-svc-pbpdq [299.801893ms]
Sep  4 05:49:23.670: INFO: Created: latency-svc-4shl7
Sep  4 05:49:23.686: INFO: Created: latency-svc-pqqf4
Sep  4 05:49:23.697: INFO: Got endpoints: latency-svc-4shl7 [319.881081ms]
Sep  4 05:49:23.700: INFO: Created: latency-svc-78txb
Sep  4 05:49:23.710: INFO: Got endpoints: latency-svc-pqqf4 [316.946156ms]
Sep  4 05:49:23.715: INFO: Got endpoints: latency-svc-78txb [298.728338ms]
Sep  4 05:49:23.715: INFO: Created: latency-svc-pcdkz
Sep  4 05:49:23.740: INFO: Created: latency-svc-klm7n
Sep  4 05:49:23.746: INFO: Got endpoints: latency-svc-pcdkz [318.46459ms]
Sep  4 05:49:23.757: INFO: Created: latency-svc-jvlvq
Sep  4 05:49:23.776: INFO: Got endpoints: latency-svc-klm7n [325.728405ms]
Sep  4 05:49:23.776: INFO: Got endpoints: latency-svc-jvlvq [307.486503ms]
Sep  4 05:49:23.783: INFO: Created: latency-svc-4zrjr
Sep  4 05:49:23.784: INFO: Created: latency-svc-7q9qd
Sep  4 05:49:23.789: INFO: Got endpoints: latency-svc-4zrjr [305.79242ms]
Sep  4 05:49:23.798: INFO: Got endpoints: latency-svc-7q9qd [305.020434ms]
Sep  4 05:49:23.803: INFO: Created: latency-svc-9p42p
Sep  4 05:49:23.810: INFO: Created: latency-svc-4xppw
Sep  4 05:49:23.822: INFO: Got endpoints: latency-svc-4xppw [263.21716ms]
Sep  4 05:49:23.822: INFO: Got endpoints: latency-svc-9p42p [263.97953ms]
Sep  4 05:49:23.834: INFO: Created: latency-svc-z8vq4
Sep  4 05:49:23.834: INFO: Created: latency-svc-v6whn
Sep  4 05:49:23.842: INFO: Got endpoints: latency-svc-v6whn [229.271265ms]
Sep  4 05:49:23.847: INFO: Got endpoints: latency-svc-z8vq4 [232.487809ms]
Sep  4 05:49:23.856: INFO: Created: latency-svc-2hwg4
Sep  4 05:49:23.868: INFO: Created: latency-svc-275qr
Sep  4 05:49:23.874: INFO: Got endpoints: latency-svc-2hwg4 [232.663155ms]
Sep  4 05:49:23.893: INFO: Created: latency-svc-wkkfs
Sep  4 05:49:23.897: INFO: Got endpoints: latency-svc-275qr [255.081516ms]
Sep  4 05:49:23.907: INFO: Created: latency-svc-6vq84
Sep  4 05:49:23.915: INFO: Got endpoints: latency-svc-wkkfs [255.174506ms]
Sep  4 05:49:23.918: INFO: Created: latency-svc-7j2c9
Sep  4 05:49:23.927: INFO: Got endpoints: latency-svc-6vq84 [230.413475ms]
Sep  4 05:49:23.933: INFO: Created: latency-svc-m8qcx
Sep  4 05:49:23.941: INFO: Got endpoints: latency-svc-7j2c9 [231.599792ms]
Sep  4 05:49:23.952: INFO: Created: latency-svc-d2ngs
Sep  4 05:49:23.955: INFO: Got endpoints: latency-svc-m8qcx [239.720624ms]
Sep  4 05:49:23.965: INFO: Created: latency-svc-246b5
Sep  4 05:49:23.980: INFO: Got endpoints: latency-svc-d2ngs [233.650679ms]
Sep  4 05:49:23.980: INFO: Got endpoints: latency-svc-246b5 [204.016761ms]
Sep  4 05:49:23.982: INFO: Created: latency-svc-d4vg4
Sep  4 05:49:23.997: INFO: Got endpoints: latency-svc-d4vg4 [220.691396ms]
Sep  4 05:49:24.005: INFO: Created: latency-svc-jvk9c
Sep  4 05:49:24.009: INFO: Created: latency-svc-qcx6j
Sep  4 05:49:24.017: INFO: Got endpoints: latency-svc-jvk9c [228.352231ms]
Sep  4 05:49:24.030: INFO: Created: latency-svc-wbnkt
Sep  4 05:49:24.033: INFO: Created: latency-svc-75289
Sep  4 05:49:24.041: INFO: Created: latency-svc-pn249
Sep  4 05:49:24.054: INFO: Created: latency-svc-gt72g
Sep  4 05:49:24.065: INFO: Got endpoints: latency-svc-qcx6j [266.633545ms]
Sep  4 05:49:24.077: INFO: Created: latency-svc-hftjt
Sep  4 05:49:24.095: INFO: Created: latency-svc-rfjrc
Sep  4 05:49:24.109: INFO: Got endpoints: latency-svc-75289 [286.988731ms]
Sep  4 05:49:24.112: INFO: Created: latency-svc-fffdq
Sep  4 05:49:24.114: INFO: Created: latency-svc-tfq6m
Sep  4 05:49:24.122: INFO: Created: latency-svc-754f2
Sep  4 05:49:24.143: INFO: Created: latency-svc-dzxk4
Sep  4 05:49:24.159: INFO: Got endpoints: latency-svc-wbnkt [336.49858ms]
Sep  4 05:49:24.177: INFO: Created: latency-svc-6b269
Sep  4 05:49:24.180: INFO: Created: latency-svc-f2b8x
Sep  4 05:49:24.203: INFO: Got endpoints: latency-svc-pn249 [355.785226ms]
Sep  4 05:49:24.206: INFO: Created: latency-svc-hgwp9
Sep  4 05:49:24.222: INFO: Created: latency-svc-2629b
Sep  4 05:49:24.232: INFO: Created: latency-svc-cd98j
Sep  4 05:49:24.265: INFO: Created: latency-svc-d8klx
Sep  4 05:49:24.266: INFO: Got endpoints: latency-svc-gt72g [424.186039ms]
Sep  4 05:49:24.275: INFO: Created: latency-svc-qmldg
Sep  4 05:49:24.282: INFO: Created: latency-svc-qpcrv
Sep  4 05:49:24.292: INFO: Created: latency-svc-txp8h
Sep  4 05:49:24.304: INFO: Got endpoints: latency-svc-hftjt [407.265125ms]
Sep  4 05:49:24.317: INFO: Created: latency-svc-l9mmq
Sep  4 05:49:24.349: INFO: Got endpoints: latency-svc-rfjrc [474.410786ms]
Sep  4 05:49:24.360: INFO: Created: latency-svc-72xck
Sep  4 05:49:24.400: INFO: Got endpoints: latency-svc-tfq6m [484.609537ms]
Sep  4 05:49:24.412: INFO: Created: latency-svc-j7h6w
Sep  4 05:49:24.453: INFO: Got endpoints: latency-svc-fffdq [524.957103ms]
Sep  4 05:49:24.473: INFO: Created: latency-svc-xk5wd
Sep  4 05:49:24.511: INFO: Got endpoints: latency-svc-754f2 [569.611719ms]
Sep  4 05:49:24.538: INFO: Created: latency-svc-mclr4
Sep  4 05:49:24.549: INFO: Got endpoints: latency-svc-dzxk4 [593.933254ms]
Sep  4 05:49:24.563: INFO: Created: latency-svc-k8z5m
Sep  4 05:49:24.597: INFO: Got endpoints: latency-svc-6b269 [617.080355ms]
Sep  4 05:49:24.609: INFO: Created: latency-svc-pfqhc
Sep  4 05:49:24.648: INFO: Got endpoints: latency-svc-f2b8x [667.574171ms]
Sep  4 05:49:24.658: INFO: Created: latency-svc-br6pj
Sep  4 05:49:24.705: INFO: Got endpoints: latency-svc-hgwp9 [708.134908ms]
Sep  4 05:49:24.731: INFO: Created: latency-svc-qxb97
Sep  4 05:49:24.749: INFO: Got endpoints: latency-svc-2629b [732.297881ms]
Sep  4 05:49:24.764: INFO: Created: latency-svc-npbvg
Sep  4 05:49:24.801: INFO: Got endpoints: latency-svc-cd98j [735.990236ms]
Sep  4 05:49:24.821: INFO: Created: latency-svc-g2ktt
Sep  4 05:49:24.856: INFO: Got endpoints: latency-svc-d8klx [747.694403ms]
Sep  4 05:49:24.877: INFO: Created: latency-svc-474xq
Sep  4 05:49:24.903: INFO: Got endpoints: latency-svc-qmldg [744.051767ms]
Sep  4 05:49:24.935: INFO: Created: latency-svc-2sjvq
Sep  4 05:49:24.951: INFO: Got endpoints: latency-svc-qpcrv [748.384456ms]
Sep  4 05:49:24.970: INFO: Created: latency-svc-f8lrw
Sep  4 05:49:24.999: INFO: Got endpoints: latency-svc-txp8h [733.191764ms]
Sep  4 05:49:25.021: INFO: Created: latency-svc-8zws7
Sep  4 05:49:25.053: INFO: Got endpoints: latency-svc-l9mmq [748.719193ms]
Sep  4 05:49:25.068: INFO: Created: latency-svc-v4xdr
Sep  4 05:49:25.100: INFO: Got endpoints: latency-svc-72xck [750.607441ms]
Sep  4 05:49:25.110: INFO: Created: latency-svc-m5hv8
Sep  4 05:49:25.151: INFO: Got endpoints: latency-svc-j7h6w [751.769367ms]
Sep  4 05:49:25.165: INFO: Created: latency-svc-bglm6
Sep  4 05:49:25.201: INFO: Got endpoints: latency-svc-xk5wd [748.461434ms]
Sep  4 05:49:25.214: INFO: Created: latency-svc-b7sbl
Sep  4 05:49:25.250: INFO: Got endpoints: latency-svc-mclr4 [738.728061ms]
Sep  4 05:49:25.263: INFO: Created: latency-svc-5n27z
Sep  4 05:49:25.298: INFO: Got endpoints: latency-svc-k8z5m [749.869139ms]
Sep  4 05:49:25.310: INFO: Created: latency-svc-r6v9l
Sep  4 05:49:25.349: INFO: Got endpoints: latency-svc-pfqhc [752.240542ms]
Sep  4 05:49:25.371: INFO: Created: latency-svc-znq24
Sep  4 05:49:25.405: INFO: Got endpoints: latency-svc-br6pj [756.779652ms]
Sep  4 05:49:25.418: INFO: Created: latency-svc-v9tsp
Sep  4 05:49:25.450: INFO: Got endpoints: latency-svc-qxb97 [744.006068ms]
Sep  4 05:49:25.463: INFO: Created: latency-svc-wx2t2
Sep  4 05:49:25.502: INFO: Got endpoints: latency-svc-npbvg [752.959802ms]
Sep  4 05:49:25.523: INFO: Created: latency-svc-9hs42
Sep  4 05:49:25.552: INFO: Got endpoints: latency-svc-g2ktt [750.639792ms]
Sep  4 05:49:25.572: INFO: Created: latency-svc-dcfw5
Sep  4 05:49:25.600: INFO: Got endpoints: latency-svc-474xq [742.160882ms]
Sep  4 05:49:25.616: INFO: Created: latency-svc-knj5x
Sep  4 05:49:25.651: INFO: Got endpoints: latency-svc-2sjvq [748.05504ms]
Sep  4 05:49:25.674: INFO: Created: latency-svc-kgftg
Sep  4 05:49:25.704: INFO: Got endpoints: latency-svc-f8lrw [752.363952ms]
Sep  4 05:49:25.717: INFO: Created: latency-svc-xxjpm
Sep  4 05:49:25.749: INFO: Got endpoints: latency-svc-8zws7 [749.528047ms]
Sep  4 05:49:25.760: INFO: Created: latency-svc-p24tj
Sep  4 05:49:25.799: INFO: Got endpoints: latency-svc-v4xdr [745.675783ms]
Sep  4 05:49:25.810: INFO: Created: latency-svc-2pf7s
Sep  4 05:49:25.852: INFO: Got endpoints: latency-svc-m5hv8 [751.942598ms]
Sep  4 05:49:25.865: INFO: Created: latency-svc-pdw78
Sep  4 05:49:25.901: INFO: Got endpoints: latency-svc-bglm6 [749.634862ms]
Sep  4 05:49:25.915: INFO: Created: latency-svc-zkrkn
Sep  4 05:49:25.951: INFO: Got endpoints: latency-svc-b7sbl [749.549301ms]
Sep  4 05:49:25.968: INFO: Created: latency-svc-gmgln
Sep  4 05:49:26.000: INFO: Got endpoints: latency-svc-5n27z [749.543943ms]
Sep  4 05:49:26.012: INFO: Created: latency-svc-wmzdg
Sep  4 05:49:26.057: INFO: Got endpoints: latency-svc-r6v9l [758.094458ms]
Sep  4 05:49:26.079: INFO: Created: latency-svc-xhd9z
Sep  4 05:49:26.118: INFO: Got endpoints: latency-svc-znq24 [768.858378ms]
Sep  4 05:49:26.149: INFO: Created: latency-svc-jbwq9
Sep  4 05:49:26.155: INFO: Got endpoints: latency-svc-v9tsp [750.461044ms]
Sep  4 05:49:26.173: INFO: Created: latency-svc-xbbp2
Sep  4 05:49:26.209: INFO: Got endpoints: latency-svc-wx2t2 [758.41325ms]
Sep  4 05:49:26.229: INFO: Created: latency-svc-sxxhn
Sep  4 05:49:26.249: INFO: Got endpoints: latency-svc-9hs42 [746.518591ms]
Sep  4 05:49:26.266: INFO: Created: latency-svc-t2n2t
Sep  4 05:49:26.300: INFO: Got endpoints: latency-svc-dcfw5 [747.579526ms]
Sep  4 05:49:26.312: INFO: Created: latency-svc-5shn8
Sep  4 05:49:26.352: INFO: Got endpoints: latency-svc-knj5x [751.928655ms]
Sep  4 05:49:26.367: INFO: Created: latency-svc-m55vl
Sep  4 05:49:26.399: INFO: Got endpoints: latency-svc-kgftg [747.802276ms]
Sep  4 05:49:26.412: INFO: Created: latency-svc-ttptm
Sep  4 05:49:26.450: INFO: Got endpoints: latency-svc-xxjpm [746.257206ms]
Sep  4 05:49:26.465: INFO: Created: latency-svc-4jjth
Sep  4 05:49:26.503: INFO: Got endpoints: latency-svc-p24tj [754.446334ms]
Sep  4 05:49:26.536: INFO: Created: latency-svc-snbwj
Sep  4 05:49:26.559: INFO: Got endpoints: latency-svc-2pf7s [760.017383ms]
Sep  4 05:49:26.575: INFO: Created: latency-svc-rmxrp
Sep  4 05:49:26.598: INFO: Got endpoints: latency-svc-pdw78 [746.745764ms]
Sep  4 05:49:26.622: INFO: Created: latency-svc-fxcvj
Sep  4 05:49:26.650: INFO: Got endpoints: latency-svc-zkrkn [748.946671ms]
Sep  4 05:49:26.662: INFO: Created: latency-svc-f29rl
Sep  4 05:49:26.702: INFO: Got endpoints: latency-svc-gmgln [751.224161ms]
Sep  4 05:49:26.720: INFO: Created: latency-svc-vm9zt
Sep  4 05:49:26.750: INFO: Got endpoints: latency-svc-wmzdg [750.440674ms]
Sep  4 05:49:26.763: INFO: Created: latency-svc-64ntf
Sep  4 05:49:26.800: INFO: Got endpoints: latency-svc-xhd9z [743.605437ms]
Sep  4 05:49:26.810: INFO: Created: latency-svc-7bjs5
Sep  4 05:49:26.851: INFO: Got endpoints: latency-svc-jbwq9 [732.968042ms]
Sep  4 05:49:26.868: INFO: Created: latency-svc-dkxkd
Sep  4 05:49:26.905: INFO: Got endpoints: latency-svc-xbbp2 [749.11044ms]
Sep  4 05:49:26.922: INFO: Created: latency-svc-t2hlq
Sep  4 05:49:26.951: INFO: Got endpoints: latency-svc-sxxhn [741.292625ms]
Sep  4 05:49:26.966: INFO: Created: latency-svc-f7znc
Sep  4 05:49:27.003: INFO: Got endpoints: latency-svc-t2n2t [754.029894ms]
Sep  4 05:49:27.025: INFO: Created: latency-svc-8tbdm
Sep  4 05:49:27.056: INFO: Got endpoints: latency-svc-5shn8 [755.999481ms]
Sep  4 05:49:27.097: INFO: Created: latency-svc-pg964
Sep  4 05:49:27.131: INFO: Got endpoints: latency-svc-m55vl [778.11443ms]
Sep  4 05:49:27.148: INFO: Created: latency-svc-kjx5h
Sep  4 05:49:27.168: INFO: Got endpoints: latency-svc-ttptm [767.855875ms]
Sep  4 05:49:27.192: INFO: Created: latency-svc-lv2q2
Sep  4 05:49:27.206: INFO: Got endpoints: latency-svc-4jjth [756.066043ms]
Sep  4 05:49:27.237: INFO: Created: latency-svc-jsrbl
Sep  4 05:49:27.250: INFO: Got endpoints: latency-svc-snbwj [746.558041ms]
Sep  4 05:49:27.268: INFO: Created: latency-svc-qmbpf
Sep  4 05:49:27.309: INFO: Got endpoints: latency-svc-rmxrp [748.695563ms]
Sep  4 05:49:27.334: INFO: Created: latency-svc-jzqdn
Sep  4 05:49:27.354: INFO: Got endpoints: latency-svc-fxcvj [755.837589ms]
Sep  4 05:49:27.379: INFO: Created: latency-svc-mzgmd
Sep  4 05:49:27.405: INFO: Got endpoints: latency-svc-f29rl [754.732981ms]
Sep  4 05:49:27.433: INFO: Created: latency-svc-8m5tj
Sep  4 05:49:27.455: INFO: Got endpoints: latency-svc-vm9zt [753.295295ms]
Sep  4 05:49:27.493: INFO: Created: latency-svc-j9n9x
Sep  4 05:49:27.516: INFO: Got endpoints: latency-svc-64ntf [765.962865ms]
Sep  4 05:49:27.545: INFO: Created: latency-svc-xhs9h
Sep  4 05:49:27.570: INFO: Got endpoints: latency-svc-7bjs5 [769.634627ms]
Sep  4 05:49:27.611: INFO: Got endpoints: latency-svc-dkxkd [759.483396ms]
Sep  4 05:49:27.616: INFO: Created: latency-svc-vw4wg
Sep  4 05:49:27.646: INFO: Created: latency-svc-69wpl
Sep  4 05:49:27.656: INFO: Got endpoints: latency-svc-t2hlq [751.394309ms]
Sep  4 05:49:27.679: INFO: Created: latency-svc-kv5zs
Sep  4 05:49:27.704: INFO: Got endpoints: latency-svc-f7znc [753.403836ms]
Sep  4 05:49:27.723: INFO: Created: latency-svc-gf9p7
Sep  4 05:49:27.755: INFO: Got endpoints: latency-svc-8tbdm [752.040637ms]
Sep  4 05:49:27.780: INFO: Created: latency-svc-7mz2h
Sep  4 05:49:27.802: INFO: Got endpoints: latency-svc-pg964 [745.945731ms]
Sep  4 05:49:27.821: INFO: Created: latency-svc-48hkf
Sep  4 05:49:27.852: INFO: Got endpoints: latency-svc-kjx5h [720.751913ms]
Sep  4 05:49:27.872: INFO: Created: latency-svc-n9pw4
Sep  4 05:49:27.898: INFO: Got endpoints: latency-svc-lv2q2 [730.662336ms]
Sep  4 05:49:27.913: INFO: Created: latency-svc-7czs5
Sep  4 05:49:27.953: INFO: Got endpoints: latency-svc-jsrbl [747.03702ms]
Sep  4 05:49:27.977: INFO: Created: latency-svc-2qv5p
Sep  4 05:49:28.000: INFO: Got endpoints: latency-svc-qmbpf [749.554775ms]
Sep  4 05:49:28.028: INFO: Created: latency-svc-67cks
Sep  4 05:49:28.055: INFO: Got endpoints: latency-svc-jzqdn [746.182978ms]
Sep  4 05:49:28.072: INFO: Created: latency-svc-8v8d6
Sep  4 05:49:28.100: INFO: Got endpoints: latency-svc-mzgmd [745.101671ms]
Sep  4 05:49:28.116: INFO: Created: latency-svc-2x2vd
Sep  4 05:49:28.162: INFO: Got endpoints: latency-svc-8m5tj [757.535716ms]
Sep  4 05:49:28.184: INFO: Created: latency-svc-jp7bt
Sep  4 05:49:28.206: INFO: Got endpoints: latency-svc-j9n9x [750.871168ms]
Sep  4 05:49:28.227: INFO: Created: latency-svc-8w8hz
Sep  4 05:49:28.249: INFO: Got endpoints: latency-svc-xhs9h [732.783573ms]
Sep  4 05:49:28.259: INFO: Created: latency-svc-65pm6
Sep  4 05:49:28.298: INFO: Got endpoints: latency-svc-vw4wg [728.126755ms]
Sep  4 05:49:28.310: INFO: Created: latency-svc-mnq2n
Sep  4 05:49:28.351: INFO: Got endpoints: latency-svc-69wpl [739.395822ms]
Sep  4 05:49:28.362: INFO: Created: latency-svc-x5v4g
Sep  4 05:49:28.400: INFO: Got endpoints: latency-svc-kv5zs [743.063381ms]
Sep  4 05:49:28.411: INFO: Created: latency-svc-wwg8d
Sep  4 05:49:28.448: INFO: Got endpoints: latency-svc-gf9p7 [742.973234ms]
Sep  4 05:49:28.458: INFO: Created: latency-svc-ntsrx
Sep  4 05:49:28.508: INFO: Got endpoints: latency-svc-7mz2h [752.175537ms]
Sep  4 05:49:28.523: INFO: Created: latency-svc-mn4xs
Sep  4 05:49:28.548: INFO: Got endpoints: latency-svc-48hkf [746.636885ms]
Sep  4 05:49:28.564: INFO: Created: latency-svc-csbcv
Sep  4 05:49:28.601: INFO: Got endpoints: latency-svc-n9pw4 [749.108681ms]
Sep  4 05:49:28.622: INFO: Created: latency-svc-knlpx
Sep  4 05:49:28.659: INFO: Got endpoints: latency-svc-7czs5 [760.634652ms]
Sep  4 05:49:28.682: INFO: Created: latency-svc-2qgpg
Sep  4 05:49:28.703: INFO: Got endpoints: latency-svc-2qv5p [750.096871ms]
Sep  4 05:49:28.745: INFO: Created: latency-svc-g7q5l
Sep  4 05:49:28.756: INFO: Got endpoints: latency-svc-67cks [756.593584ms]
Sep  4 05:49:28.776: INFO: Created: latency-svc-n8btv
Sep  4 05:49:28.801: INFO: Got endpoints: latency-svc-8v8d6 [746.341776ms]
Sep  4 05:49:28.815: INFO: Created: latency-svc-dwf24
Sep  4 05:49:28.855: INFO: Got endpoints: latency-svc-2x2vd [755.715362ms]
Sep  4 05:49:28.870: INFO: Created: latency-svc-rwv6x
Sep  4 05:49:28.899: INFO: Got endpoints: latency-svc-jp7bt [736.757527ms]
Sep  4 05:49:28.919: INFO: Created: latency-svc-dflcc
Sep  4 05:49:28.952: INFO: Got endpoints: latency-svc-8w8hz [745.364684ms]
Sep  4 05:49:28.975: INFO: Created: latency-svc-ksmj6
Sep  4 05:49:29.002: INFO: Got endpoints: latency-svc-65pm6 [752.5812ms]
Sep  4 05:49:29.036: INFO: Created: latency-svc-nkwkg
Sep  4 05:49:29.060: INFO: Got endpoints: latency-svc-mnq2n [760.956179ms]
Sep  4 05:49:29.086: INFO: Created: latency-svc-mfpsb
Sep  4 05:49:29.132: INFO: Got endpoints: latency-svc-x5v4g [780.896606ms]
Sep  4 05:49:29.162: INFO: Got endpoints: latency-svc-wwg8d [762.620714ms]
Sep  4 05:49:29.169: INFO: Created: latency-svc-9hhp9
Sep  4 05:49:29.212: INFO: Created: latency-svc-z9mf4
Sep  4 05:49:29.221: INFO: Got endpoints: latency-svc-ntsrx [772.549472ms]
Sep  4 05:49:29.247: INFO: Created: latency-svc-9pff5
Sep  4 05:49:29.254: INFO: Got endpoints: latency-svc-mn4xs [746.301846ms]
Sep  4 05:49:29.266: INFO: Created: latency-svc-z6zt6
Sep  4 05:49:29.300: INFO: Got endpoints: latency-svc-csbcv [752.052178ms]
Sep  4 05:49:29.316: INFO: Created: latency-svc-zrfx9
Sep  4 05:49:29.356: INFO: Got endpoints: latency-svc-knlpx [755.009709ms]
Sep  4 05:49:29.371: INFO: Created: latency-svc-64dpf
Sep  4 05:49:29.401: INFO: Got endpoints: latency-svc-2qgpg [741.732521ms]
Sep  4 05:49:29.420: INFO: Created: latency-svc-wkv2m
Sep  4 05:49:29.461: INFO: Got endpoints: latency-svc-g7q5l [757.523739ms]
Sep  4 05:49:29.510: INFO: Created: latency-svc-pdltv
Sep  4 05:49:29.519: INFO: Got endpoints: latency-svc-n8btv [762.681335ms]
Sep  4 05:49:29.550: INFO: Created: latency-svc-zddbd
Sep  4 05:49:29.558: INFO: Got endpoints: latency-svc-dwf24 [756.838487ms]
Sep  4 05:49:29.589: INFO: Created: latency-svc-bjf5c
Sep  4 05:49:29.612: INFO: Got endpoints: latency-svc-rwv6x [755.915813ms]
Sep  4 05:49:29.635: INFO: Created: latency-svc-jcgm9
Sep  4 05:49:29.655: INFO: Got endpoints: latency-svc-dflcc [753.058032ms]
Sep  4 05:49:29.673: INFO: Created: latency-svc-q2zmn
Sep  4 05:49:29.701: INFO: Got endpoints: latency-svc-ksmj6 [748.431526ms]
Sep  4 05:49:29.714: INFO: Created: latency-svc-29shr
Sep  4 05:49:29.751: INFO: Got endpoints: latency-svc-nkwkg [749.356419ms]
Sep  4 05:49:29.768: INFO: Created: latency-svc-9fg6n
Sep  4 05:49:29.803: INFO: Got endpoints: latency-svc-mfpsb [743.597433ms]
Sep  4 05:49:29.819: INFO: Created: latency-svc-86cck
Sep  4 05:49:29.850: INFO: Got endpoints: latency-svc-9hhp9 [717.968308ms]
Sep  4 05:49:29.863: INFO: Created: latency-svc-4qj64
Sep  4 05:49:29.899: INFO: Got endpoints: latency-svc-z9mf4 [736.500115ms]
Sep  4 05:49:29.945: INFO: Created: latency-svc-6zmsk
Sep  4 05:49:29.961: INFO: Got endpoints: latency-svc-9pff5 [740.259036ms]
Sep  4 05:49:29.977: INFO: Created: latency-svc-rjvzz
Sep  4 05:49:30.003: INFO: Got endpoints: latency-svc-z6zt6 [748.612521ms]
Sep  4 05:49:30.018: INFO: Created: latency-svc-27kdm
Sep  4 05:49:30.050: INFO: Got endpoints: latency-svc-zrfx9 [749.79428ms]
Sep  4 05:49:30.067: INFO: Created: latency-svc-jmcsm
Sep  4 05:49:30.100: INFO: Got endpoints: latency-svc-64dpf [743.180886ms]
Sep  4 05:49:30.108: INFO: Created: latency-svc-s22td
Sep  4 05:49:30.148: INFO: Got endpoints: latency-svc-wkv2m [746.722529ms]
Sep  4 05:49:30.162: INFO: Created: latency-svc-npnss
Sep  4 05:49:30.202: INFO: Got endpoints: latency-svc-pdltv [736.000143ms]
Sep  4 05:49:30.216: INFO: Created: latency-svc-8njqv
Sep  4 05:49:30.255: INFO: Got endpoints: latency-svc-zddbd [735.848218ms]
Sep  4 05:49:30.267: INFO: Created: latency-svc-jh5gn
Sep  4 05:49:30.300: INFO: Got endpoints: latency-svc-bjf5c [741.760735ms]
Sep  4 05:49:30.322: INFO: Created: latency-svc-mr5h6
Sep  4 05:49:30.349: INFO: Got endpoints: latency-svc-jcgm9 [737.000482ms]
Sep  4 05:49:30.364: INFO: Created: latency-svc-95krk
Sep  4 05:49:30.399: INFO: Got endpoints: latency-svc-q2zmn [744.317287ms]
Sep  4 05:49:30.416: INFO: Created: latency-svc-cfd27
Sep  4 05:49:30.451: INFO: Got endpoints: latency-svc-29shr [749.778163ms]
Sep  4 05:49:30.477: INFO: Created: latency-svc-kgnr2
Sep  4 05:49:30.513: INFO: Got endpoints: latency-svc-9fg6n [762.264321ms]
Sep  4 05:49:30.532: INFO: Created: latency-svc-nqlft
Sep  4 05:49:30.549: INFO: Got endpoints: latency-svc-86cck [745.492445ms]
Sep  4 05:49:30.560: INFO: Created: latency-svc-gxpvn
Sep  4 05:49:30.599: INFO: Got endpoints: latency-svc-4qj64 [748.815929ms]
Sep  4 05:49:30.609: INFO: Created: latency-svc-cq4jz
Sep  4 05:49:30.647: INFO: Got endpoints: latency-svc-6zmsk [748.325992ms]
Sep  4 05:49:30.664: INFO: Created: latency-svc-b8ll8
Sep  4 05:49:30.699: INFO: Got endpoints: latency-svc-rjvzz [737.82033ms]
Sep  4 05:49:30.710: INFO: Created: latency-svc-kp7dd
Sep  4 05:49:30.751: INFO: Got endpoints: latency-svc-27kdm [747.584574ms]
Sep  4 05:49:30.762: INFO: Created: latency-svc-rr4jl
Sep  4 05:49:30.801: INFO: Got endpoints: latency-svc-jmcsm [750.141682ms]
Sep  4 05:49:30.812: INFO: Created: latency-svc-lfttt
Sep  4 05:49:30.851: INFO: Got endpoints: latency-svc-s22td [751.345231ms]
Sep  4 05:49:30.861: INFO: Created: latency-svc-59qhz
Sep  4 05:49:30.899: INFO: Got endpoints: latency-svc-npnss [751.019664ms]
Sep  4 05:49:30.912: INFO: Created: latency-svc-44256
Sep  4 05:49:30.950: INFO: Got endpoints: latency-svc-8njqv [748.086129ms]
Sep  4 05:49:30.960: INFO: Created: latency-svc-sq4c4
Sep  4 05:49:30.998: INFO: Got endpoints: latency-svc-jh5gn [742.921053ms]
Sep  4 05:49:31.021: INFO: Created: latency-svc-2s9vk
Sep  4 05:49:31.048: INFO: Got endpoints: latency-svc-mr5h6 [748.197322ms]
Sep  4 05:49:31.098: INFO: Got endpoints: latency-svc-95krk [749.199553ms]
Sep  4 05:49:31.150: INFO: Got endpoints: latency-svc-cfd27 [750.898805ms]
Sep  4 05:49:31.199: INFO: Got endpoints: latency-svc-kgnr2 [748.00069ms]
Sep  4 05:49:31.250: INFO: Got endpoints: latency-svc-nqlft [736.662879ms]
Sep  4 05:49:31.299: INFO: Got endpoints: latency-svc-gxpvn [749.623792ms]
Sep  4 05:49:31.348: INFO: Got endpoints: latency-svc-cq4jz [749.479943ms]
Sep  4 05:49:31.398: INFO: Got endpoints: latency-svc-b8ll8 [750.972704ms]
Sep  4 05:49:31.450: INFO: Got endpoints: latency-svc-kp7dd [750.47815ms]
Sep  4 05:49:31.501: INFO: Got endpoints: latency-svc-rr4jl [749.76665ms]
Sep  4 05:49:31.547: INFO: Got endpoints: latency-svc-lfttt [746.910707ms]
Sep  4 05:49:31.605: INFO: Got endpoints: latency-svc-59qhz [754.276578ms]
Sep  4 05:49:31.649: INFO: Got endpoints: latency-svc-44256 [750.386366ms]
Sep  4 05:49:31.698: INFO: Got endpoints: latency-svc-sq4c4 [748.104596ms]
Sep  4 05:49:31.748: INFO: Got endpoints: latency-svc-2s9vk [749.835988ms]
Sep  4 05:49:31.748: INFO: Latencies: [27.671451ms 47.925248ms 66.825395ms 84.748347ms 91.47269ms 105.111491ms 145.256853ms 158.866687ms 175.928127ms 191.743401ms 204.016761ms 214.947898ms 220.691396ms 226.810592ms 228.352231ms 229.271265ms 230.413475ms 231.599792ms 232.487809ms 232.663155ms 233.650679ms 239.720624ms 249.442009ms 255.081516ms 255.174506ms 263.21716ms 263.97953ms 266.633545ms 267.640446ms 282.025766ms 286.988731ms 289.771341ms 292.081142ms 296.186927ms 298.728338ms 299.801893ms 305.020434ms 305.79242ms 307.486503ms 307.857851ms 308.249336ms 316.946156ms 318.46459ms 319.881081ms 319.910228ms 325.728405ms 330.617201ms 336.49858ms 355.785226ms 407.265125ms 424.186039ms 474.410786ms 484.609537ms 524.957103ms 569.611719ms 593.933254ms 617.080355ms 667.574171ms 708.134908ms 717.968308ms 720.751913ms 728.126755ms 730.662336ms 732.297881ms 732.783573ms 732.968042ms 733.191764ms 735.848218ms 735.990236ms 736.000143ms 736.500115ms 736.662879ms 736.757527ms 737.000482ms 737.82033ms 738.728061ms 739.395822ms 740.259036ms 741.292625ms 741.732521ms 741.760735ms 742.160882ms 742.921053ms 742.973234ms 743.063381ms 743.180886ms 743.597433ms 743.605437ms 744.006068ms 744.051767ms 744.317287ms 745.101671ms 745.364684ms 745.492445ms 745.675783ms 745.945731ms 746.182978ms 746.257206ms 746.301846ms 746.341776ms 746.518591ms 746.558041ms 746.636885ms 746.722529ms 746.745764ms 746.910707ms 747.03702ms 747.579526ms 747.584574ms 747.694403ms 747.802276ms 748.00069ms 748.05504ms 748.086129ms 748.104596ms 748.197322ms 748.325992ms 748.384456ms 748.431526ms 748.461434ms 748.612521ms 748.695563ms 748.719193ms 748.815929ms 748.946671ms 749.108681ms 749.11044ms 749.199553ms 749.356419ms 749.479943ms 749.528047ms 749.543943ms 749.549301ms 749.554775ms 749.623792ms 749.634862ms 749.76665ms 749.778163ms 749.79428ms 749.835988ms 749.869139ms 750.096871ms 750.141682ms 750.386366ms 750.440674ms 750.461044ms 750.47815ms 750.607441ms 750.639792ms 750.871168ms 750.898805ms 750.972704ms 751.019664ms 751.224161ms 751.345231ms 751.394309ms 751.769367ms 751.928655ms 751.942598ms 752.040637ms 752.052178ms 752.175537ms 752.240542ms 752.363952ms 752.5812ms 752.959802ms 753.058032ms 753.295295ms 753.403836ms 754.029894ms 754.276578ms 754.446334ms 754.732981ms 755.009709ms 755.715362ms 755.837589ms 755.915813ms 755.999481ms 756.066043ms 756.593584ms 756.779652ms 756.838487ms 757.523739ms 757.535716ms 758.094458ms 758.41325ms 759.483396ms 760.017383ms 760.634652ms 760.956179ms 762.264321ms 762.620714ms 762.681335ms 765.962865ms 767.855875ms 768.858378ms 769.634627ms 772.549472ms 778.11443ms 780.896606ms]
Sep  4 05:49:31.748: INFO: 50 %ile: 746.518591ms
Sep  4 05:49:31.748: INFO: 90 %ile: 756.779652ms
Sep  4 05:49:31.748: INFO: 99 %ile: 778.11443ms
Sep  4 05:49:31.748: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:49:31.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4941" for this suite.
Sep  4 05:49:57.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:49:58.067: INFO: namespace svc-latency-4941 deletion completed in 26.305876745s

• [SLOW TEST:38.302 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:49:58.070: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-7gfv
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 05:49:58.321: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7gfv" in namespace "subpath-7563" to be "success or failure"
Sep  4 05:49:58.335: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Pending", Reason="", readiness=false. Elapsed: 13.507623ms
Sep  4 05:50:00.345: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023191923s
Sep  4 05:50:02.354: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 4.03239119s
Sep  4 05:50:04.378: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 6.05662483s
Sep  4 05:50:06.392: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 8.070333355s
Sep  4 05:50:08.404: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 10.08223453s
Sep  4 05:50:10.425: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 12.103037112s
Sep  4 05:50:12.442: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 14.120453822s
Sep  4 05:50:14.453: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 16.130922516s
Sep  4 05:50:16.462: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 18.140646465s
Sep  4 05:50:18.473: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 20.150936776s
Sep  4 05:50:20.480: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Running", Reason="", readiness=true. Elapsed: 22.158524808s
Sep  4 05:50:22.492: INFO: Pod "pod-subpath-test-configmap-7gfv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.170783648s
STEP: Saw pod success
Sep  4 05:50:22.493: INFO: Pod "pod-subpath-test-configmap-7gfv" satisfied condition "success or failure"
Sep  4 05:50:23.008: INFO: Trying to get logs from node 192.168.1.101 pod pod-subpath-test-configmap-7gfv container test-container-subpath-configmap-7gfv: <nil>
STEP: delete the pod
Sep  4 05:50:23.115: INFO: Waiting for pod pod-subpath-test-configmap-7gfv to disappear
Sep  4 05:50:23.118: INFO: Pod pod-subpath-test-configmap-7gfv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7gfv
Sep  4 05:50:23.119: INFO: Deleting pod "pod-subpath-test-configmap-7gfv" in namespace "subpath-7563"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:50:23.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7563" for this suite.
Sep  4 05:50:29.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:50:29.252: INFO: namespace subpath-7563 deletion completed in 6.120656001s

• [SLOW TEST:31.182 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:50:29.252: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4675
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  4 05:50:29.449: INFO: Waiting up to 5m0s for pod "pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a" in namespace "emptydir-4675" to be "success or failure"
Sep  4 05:50:29.467: INFO: Pod "pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.944927ms
Sep  4 05:50:31.479: INFO: Pod "pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029228924s
Sep  4 05:50:33.494: INFO: Pod "pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044359713s
STEP: Saw pod success
Sep  4 05:50:33.494: INFO: Pod "pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a" satisfied condition "success or failure"
Sep  4 05:50:33.518: INFO: Trying to get logs from node 192.168.1.101 pod pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a container test-container: <nil>
STEP: delete the pod
Sep  4 05:50:33.619: INFO: Waiting for pod pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a to disappear
Sep  4 05:50:33.624: INFO: Pod pod-dab4e8fd-117b-4e48-b26d-54427abc7f8a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:50:33.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4675" for this suite.
Sep  4 05:50:39.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:50:40.114: INFO: namespace emptydir-4675 deletion completed in 6.472989404s

• [SLOW TEST:10.862 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:50:40.114: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:50:40.349: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  4 05:50:40.378: INFO: Number of nodes with available pods: 0
Sep  4 05:50:40.378: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  4 05:50:40.400: INFO: Number of nodes with available pods: 0
Sep  4 05:50:40.400: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:41.420: INFO: Number of nodes with available pods: 0
Sep  4 05:50:41.420: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:42.420: INFO: Number of nodes with available pods: 0
Sep  4 05:50:42.421: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:43.420: INFO: Number of nodes with available pods: 1
Sep  4 05:50:43.421: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  4 05:50:43.469: INFO: Number of nodes with available pods: 1
Sep  4 05:50:43.469: INFO: Number of running nodes: 0, number of available pods: 1
Sep  4 05:50:44.486: INFO: Number of nodes with available pods: 0
Sep  4 05:50:44.487: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  4 05:50:44.547: INFO: Number of nodes with available pods: 0
Sep  4 05:50:44.547: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:45.556: INFO: Number of nodes with available pods: 0
Sep  4 05:50:45.556: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:46.562: INFO: Number of nodes with available pods: 0
Sep  4 05:50:46.562: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:47.566: INFO: Number of nodes with available pods: 0
Sep  4 05:50:47.566: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:48.560: INFO: Number of nodes with available pods: 0
Sep  4 05:50:48.561: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:49.558: INFO: Number of nodes with available pods: 0
Sep  4 05:50:49.558: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:50.568: INFO: Number of nodes with available pods: 0
Sep  4 05:50:50.569: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:51.568: INFO: Number of nodes with available pods: 0
Sep  4 05:50:51.568: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:52.562: INFO: Number of nodes with available pods: 0
Sep  4 05:50:52.565: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:53.557: INFO: Number of nodes with available pods: 0
Sep  4 05:50:53.557: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:54.563: INFO: Number of nodes with available pods: 0
Sep  4 05:50:54.565: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:55.572: INFO: Number of nodes with available pods: 0
Sep  4 05:50:55.573: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:56.563: INFO: Number of nodes with available pods: 0
Sep  4 05:50:56.564: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:57.571: INFO: Number of nodes with available pods: 0
Sep  4 05:50:57.571: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:50:58.577: INFO: Number of nodes with available pods: 1
Sep  4 05:50:58.577: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7850, will wait for the garbage collector to delete the pods
Sep  4 05:50:58.693: INFO: Deleting DaemonSet.extensions daemon-set took: 6.091522ms
Sep  4 05:50:59.095: INFO: Terminating DaemonSet.extensions daemon-set pods took: 401.392248ms
Sep  4 05:51:02.308: INFO: Number of nodes with available pods: 0
Sep  4 05:51:02.308: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 05:51:02.311: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7850/daemonsets","resourceVersion":"19534"},"items":null}

Sep  4 05:51:02.316: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7850/pods","resourceVersion":"19534"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:51:02.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7850" for this suite.
Sep  4 05:51:08.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:51:08.610: INFO: namespace daemonsets-7850 deletion completed in 6.253825563s

• [SLOW TEST:28.496 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:51:08.611: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8250
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:51:08.809: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626" in namespace "projected-8250" to be "success or failure"
Sep  4 05:51:08.825: INFO: Pod "downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626": Phase="Pending", Reason="", readiness=false. Elapsed: 16.363511ms
Sep  4 05:51:10.834: INFO: Pod "downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025289857s
Sep  4 05:51:12.850: INFO: Pod "downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040959517s
STEP: Saw pod success
Sep  4 05:51:12.850: INFO: Pod "downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626" satisfied condition "success or failure"
Sep  4 05:51:12.872: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626 container client-container: <nil>
STEP: delete the pod
Sep  4 05:51:12.970: INFO: Waiting for pod downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626 to disappear
Sep  4 05:51:12.974: INFO: Pod downwardapi-volume-19558e4c-339f-469b-ba64-f70587612626 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:51:12.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8250" for this suite.
Sep  4 05:51:19.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:51:19.137: INFO: namespace projected-8250 deletion completed in 6.157960711s

• [SLOW TEST:10.526 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:51:19.137: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:51:19.348: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252" in namespace "downward-api-8854" to be "success or failure"
Sep  4 05:51:19.360: INFO: Pod "downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252": Phase="Pending", Reason="", readiness=false. Elapsed: 12.423713ms
Sep  4 05:51:21.394: INFO: Pod "downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046302871s
Sep  4 05:51:23.410: INFO: Pod "downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062345011s
STEP: Saw pod success
Sep  4 05:51:23.411: INFO: Pod "downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252" satisfied condition "success or failure"
Sep  4 05:51:23.435: INFO: Trying to get logs from node 192.168.1.101 pod downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252 container client-container: <nil>
STEP: delete the pod
Sep  4 05:51:23.495: INFO: Waiting for pod downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252 to disappear
Sep  4 05:51:23.503: INFO: Pod downwardapi-volume-6969a44b-8b15-4a20-880d-da39cfc95252 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:51:23.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8854" for this suite.
Sep  4 05:51:29.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:51:29.627: INFO: namespace downward-api-8854 deletion completed in 6.114624623s

• [SLOW TEST:10.490 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:51:29.627: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep  4 05:51:29.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 cluster-info'
Sep  4 05:51:29.817: INFO: stderr: ""
Sep  4 05:51:29.817: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:51:29.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3819" for this suite.
Sep  4 05:51:35.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:51:36.179: INFO: namespace kubectl-3819 deletion completed in 6.358556147s

• [SLOW TEST:6.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:51:36.181: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-9hxq
STEP: Creating a pod to test atomic-volume-subpath
Sep  4 05:51:36.495: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9hxq" in namespace "subpath-1886" to be "success or failure"
Sep  4 05:51:36.518: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Pending", Reason="", readiness=false. Elapsed: 23.356437ms
Sep  4 05:51:38.523: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028305342s
Sep  4 05:51:40.528: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 4.033234934s
Sep  4 05:51:42.543: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 6.047908379s
Sep  4 05:51:44.553: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 8.057828351s
Sep  4 05:51:46.564: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 10.06891295s
Sep  4 05:51:48.575: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 12.079962194s
Sep  4 05:51:50.586: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 14.09068814s
Sep  4 05:51:52.590: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 16.094580517s
Sep  4 05:51:54.600: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 18.105384985s
Sep  4 05:51:56.606: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Running", Reason="", readiness=true. Elapsed: 20.110422107s
Sep  4 05:51:58.610: INFO: Pod "pod-subpath-test-secret-9hxq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.114433988s
STEP: Saw pod success
Sep  4 05:51:58.610: INFO: Pod "pod-subpath-test-secret-9hxq" satisfied condition "success or failure"
Sep  4 05:51:58.613: INFO: Trying to get logs from node 192.168.1.101 pod pod-subpath-test-secret-9hxq container test-container-subpath-secret-9hxq: <nil>
STEP: delete the pod
Sep  4 05:51:58.638: INFO: Waiting for pod pod-subpath-test-secret-9hxq to disappear
Sep  4 05:51:58.648: INFO: Pod pod-subpath-test-secret-9hxq no longer exists
STEP: Deleting pod pod-subpath-test-secret-9hxq
Sep  4 05:51:58.648: INFO: Deleting pod "pod-subpath-test-secret-9hxq" in namespace "subpath-1886"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:51:58.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1886" for this suite.
Sep  4 05:52:04.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:52:04.766: INFO: namespace subpath-1886 deletion completed in 6.111416051s

• [SLOW TEST:28.585 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:52:04.767: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 05:52:04.928: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 05:52:04.965: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 05:52:04.984: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.101 before test
Sep  4 05:52:05.022: INFO: cluster-dns-74877f46df-96tqd from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.022: INFO: 	Container coredns ready: true, restart count 0
Sep  4 05:52:05.022: INFO: calico-node-sdb87 from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.022: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:52:05.022: INFO: sonobuoy-e2e-job-ba0b01e0e48b4e68 from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.022: INFO: 	Container e2e ready: true, restart count 0
Sep  4 05:52:05.022: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:52:05.022: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-k4lpq from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.022: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:52:05.022: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  4 05:52:05.022: INFO: calico-kube-controllers-65b8787765-j25mh from kube-system started at 2019-09-04 04:29:17 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.022: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 05:52:05.022: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 04:30:10 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.024: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  4 05:52:05.024: INFO: node-dns-bc4lx from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.024: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:52:05.024: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:52:05.024: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.102 before test
Sep  4 05:52:05.048: INFO: node-dns-mvf5k from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.048: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:52:05.048: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:52:05.048: INFO: calico-node-wjlwp from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.048: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:52:05.048: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-7q2hh from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.048: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:52:05.048: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  4 05:52:05.048: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.103 before test
Sep  4 05:52:05.068: INFO: node-dns-rzb6n from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.068: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:52:05.068: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:52:05.068: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-fjq4x from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:52:05.068: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:52:05.068: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  4 05:52:05.068: INFO: calico-node-n4c7b from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.068: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:52:05.068: INFO: cluster-dns-74877f46df-xcqpv from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:52:05.068: INFO: 	Container coredns ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 192.168.1.101
STEP: verifying the node has the label node 192.168.1.102
STEP: verifying the node has the label node 192.168.1.103
Sep  4 05:52:05.118: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod sonobuoy-e2e-job-ba0b01e0e48b4e68 requesting resource cpu=0m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-7q2hh requesting resource cpu=0m on Node 192.168.1.102
Sep  4 05:52:05.118: INFO: Pod sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-fjq4x requesting resource cpu=0m on Node 192.168.1.103
Sep  4 05:52:05.118: INFO: Pod sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-k4lpq requesting resource cpu=0m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod calico-kube-controllers-65b8787765-j25mh requesting resource cpu=0m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod calico-node-n4c7b requesting resource cpu=250m on Node 192.168.1.103
Sep  4 05:52:05.118: INFO: Pod calico-node-sdb87 requesting resource cpu=250m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod calico-node-wjlwp requesting resource cpu=250m on Node 192.168.1.102
Sep  4 05:52:05.118: INFO: Pod cluster-dns-74877f46df-96tqd requesting resource cpu=100m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod cluster-dns-74877f46df-xcqpv requesting resource cpu=100m on Node 192.168.1.103
Sep  4 05:52:05.118: INFO: Pod node-dns-bc4lx requesting resource cpu=0m on Node 192.168.1.101
Sep  4 05:52:05.118: INFO: Pod node-dns-mvf5k requesting resource cpu=0m on Node 192.168.1.102
Sep  4 05:52:05.118: INFO: Pod node-dns-rzb6n requesting resource cpu=0m on Node 192.168.1.103
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8.15c1265cc2c18a1c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3996/filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8 to 192.168.1.102]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8.15c1265cf5c27341], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8.15c1265cfba12980], Reason = [Created], Message = [Created container filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8.15c1265d0380a474], Reason = [Started], Message = [Started container filler-pod-1e3c1c37-e42a-493d-bdba-b82335e1feb8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e.15c1265cc40db5fa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3996/filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e to 192.168.1.103]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e.15c1265cf906f88d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e.15c1265cfcb4868f], Reason = [Created], Message = [Created container filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e.15c1265d0420fa42], Reason = [Started], Message = [Started container filler-pod-dff9dc74-dcde-4eb2-adb6-992e60d3089e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6674a58-edbe-45da-aa01-7245131cca34.15c1265cc22de624], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3996/filler-pod-e6674a58-edbe-45da-aa01-7245131cca34 to 192.168.1.101]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6674a58-edbe-45da-aa01-7245131cca34.15c1265cfab45e77], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6674a58-edbe-45da-aa01-7245131cca34.15c1265cff3f0bad], Reason = [Created], Message = [Created container filler-pod-e6674a58-edbe-45da-aa01-7245131cca34]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6674a58-edbe-45da-aa01-7245131cca34.15c1265d09384e59], Reason = [Started], Message = [Started container filler-pod-e6674a58-edbe-45da-aa01-7245131cca34]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c1265d3bc29dd4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 192.168.1.102
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.1.103
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.1.101
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:52:08.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3996" for this suite.
Sep  4 05:52:14.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:52:14.461: INFO: namespace sched-pred-3996 deletion completed in 6.208592533s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.694 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:52:14.461: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6330
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-93bc271d-efc5-4f67-86e7-58c88fb915f1
STEP: Creating a pod to test consume configMaps
Sep  4 05:52:14.694: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0" in namespace "projected-6330" to be "success or failure"
Sep  4 05:52:14.699: INFO: Pod "pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.963581ms
Sep  4 05:52:16.706: INFO: Pod "pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011818785s
Sep  4 05:52:18.710: INFO: Pod "pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015082288s
STEP: Saw pod success
Sep  4 05:52:18.710: INFO: Pod "pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0" satisfied condition "success or failure"
Sep  4 05:52:18.713: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 05:52:18.738: INFO: Waiting for pod pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0 to disappear
Sep  4 05:52:18.741: INFO: Pod pod-projected-configmaps-309a18bc-6214-4e9f-94dc-7282c44445d0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:52:18.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6330" for this suite.
Sep  4 05:52:24.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:52:24.899: INFO: namespace projected-6330 deletion completed in 6.151725653s

• [SLOW TEST:10.437 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:52:24.900: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2134 to expose endpoints map[]
Sep  4 05:52:25.259: INFO: Get endpoints failed (31.218988ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  4 05:52:26.270: INFO: successfully validated that service multi-endpoint-test in namespace services-2134 exposes endpoints map[] (1.042311695s elapsed)
STEP: Creating pod pod1 in namespace services-2134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2134 to expose endpoints map[pod1:[100]]
Sep  4 05:52:30.797: INFO: successfully validated that service multi-endpoint-test in namespace services-2134 exposes endpoints map[pod1:[100]] (4.485626085s elapsed)
STEP: Creating pod pod2 in namespace services-2134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2134 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  4 05:52:32.880: INFO: successfully validated that service multi-endpoint-test in namespace services-2134 exposes endpoints map[pod1:[100] pod2:[101]] (2.075841519s elapsed)
STEP: Deleting pod pod1 in namespace services-2134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2134 to expose endpoints map[pod2:[101]]
Sep  4 05:52:33.990: INFO: successfully validated that service multi-endpoint-test in namespace services-2134 exposes endpoints map[pod2:[101]] (1.082125516s elapsed)
STEP: Deleting pod pod2 in namespace services-2134
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2134 to expose endpoints map[]
Sep  4 05:52:35.059: INFO: successfully validated that service multi-endpoint-test in namespace services-2134 exposes endpoints map[] (1.048409004s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:52:35.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2134" for this suite.
Sep  4 05:52:57.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:52:57.363: INFO: namespace services-2134 deletion completed in 22.2041184s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:32.463 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:52:57.363: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9285
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  4 05:52:57.535: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f" in namespace "downward-api-9285" to be "success or failure"
Sep  4 05:52:57.543: INFO: Pod "downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.647847ms
Sep  4 05:52:59.555: INFO: Pod "downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020054781s
Sep  4 05:53:01.570: INFO: Pod "downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035224341s
STEP: Saw pod success
Sep  4 05:53:01.570: INFO: Pod "downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f" satisfied condition "success or failure"
Sep  4 05:53:01.580: INFO: Trying to get logs from node 192.168.1.103 pod downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f container client-container: <nil>
STEP: delete the pod
Sep  4 05:53:01.696: INFO: Waiting for pod downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f to disappear
Sep  4 05:53:01.707: INFO: Pod downwardapi-volume-4f4e7a95-aaa7-4253-b3f8-ef47fd9b7a6f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:53:01.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9285" for this suite.
Sep  4 05:53:07.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:53:07.824: INFO: namespace downward-api-9285 deletion completed in 6.111286284s

• [SLOW TEST:10.461 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:53:07.838: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep  4 05:53:08.045: INFO: Waiting up to 5m0s for pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949" in namespace "var-expansion-1414" to be "success or failure"
Sep  4 05:53:08.064: INFO: Pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949": Phase="Pending", Reason="", readiness=false. Elapsed: 18.410952ms
Sep  4 05:53:10.158: INFO: Pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949": Phase="Pending", Reason="", readiness=false. Elapsed: 2.112587239s
Sep  4 05:53:12.223: INFO: Pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949": Phase="Pending", Reason="", readiness=false. Elapsed: 4.177049794s
Sep  4 05:53:14.243: INFO: Pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.197575513s
STEP: Saw pod success
Sep  4 05:53:14.243: INFO: Pod "var-expansion-33644883-d0cc-46fc-bdb3-33229d011949" satisfied condition "success or failure"
Sep  4 05:53:14.263: INFO: Trying to get logs from node 192.168.1.101 pod var-expansion-33644883-d0cc-46fc-bdb3-33229d011949 container dapi-container: <nil>
STEP: delete the pod
Sep  4 05:53:14.340: INFO: Waiting for pod var-expansion-33644883-d0cc-46fc-bdb3-33229d011949 to disappear
Sep  4 05:53:14.345: INFO: Pod var-expansion-33644883-d0cc-46fc-bdb3-33229d011949 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:53:14.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1414" for this suite.
Sep  4 05:53:20.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:53:20.497: INFO: namespace var-expansion-1414 deletion completed in 6.142002413s

• [SLOW TEST:12.660 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:53:20.499: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:53:20.742: INFO: Create a RollingUpdate DaemonSet
Sep  4 05:53:20.754: INFO: Check that daemon pods launch on every node of the cluster
Sep  4 05:53:20.776: INFO: Number of nodes with available pods: 0
Sep  4 05:53:20.776: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:53:21.793: INFO: Number of nodes with available pods: 0
Sep  4 05:53:21.793: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:53:22.784: INFO: Number of nodes with available pods: 3
Sep  4 05:53:22.784: INFO: Number of running nodes: 3, number of available pods: 3
Sep  4 05:53:22.784: INFO: Update the DaemonSet to trigger a rollout
Sep  4 05:53:22.793: INFO: Updating DaemonSet daemon-set
Sep  4 05:53:26.823: INFO: Roll back the DaemonSet before rollout is complete
Sep  4 05:53:26.842: INFO: Updating DaemonSet daemon-set
Sep  4 05:53:26.842: INFO: Make sure DaemonSet rollback is complete
Sep  4 05:53:26.858: INFO: Wrong image for pod: daemon-set-9brmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 05:53:26.858: INFO: Pod daemon-set-9brmm is not available
Sep  4 05:53:28.314: INFO: Wrong image for pod: daemon-set-9brmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 05:53:28.314: INFO: Pod daemon-set-9brmm is not available
Sep  4 05:53:28.892: INFO: Wrong image for pod: daemon-set-9brmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  4 05:53:28.892: INFO: Pod daemon-set-9brmm is not available
Sep  4 05:53:29.874: INFO: Pod daemon-set-nspgf is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1389, will wait for the garbage collector to delete the pods
Sep  4 05:53:29.993: INFO: Deleting DaemonSet.extensions daemon-set took: 32.793882ms
Sep  4 05:53:30.396: INFO: Terminating DaemonSet.extensions daemon-set pods took: 402.107936ms
Sep  4 05:53:35.831: INFO: Number of nodes with available pods: 0
Sep  4 05:53:35.832: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 05:53:35.850: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1389/daemonsets","resourceVersion":"20237"},"items":null}

Sep  4 05:53:35.863: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1389/pods","resourceVersion":"20237"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:53:35.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1389" for this suite.
Sep  4 05:53:41.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:53:42.285: INFO: namespace daemonsets-1389 deletion completed in 6.337191106s

• [SLOW TEST:21.786 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:53:42.286: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:53:46.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2063" for this suite.
Sep  4 05:53:52.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:53:52.852: INFO: namespace emptydir-wrapper-2063 deletion completed in 6.133979841s

• [SLOW TEST:10.565 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:53:52.852: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8855
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep  4 05:53:53.124: INFO: Found 0 stateful pods, waiting for 3
Sep  4 05:54:03.137: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:54:03.137: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:54:03.137: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  4 05:54:03.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-8855 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:54:03.384: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:54:03.385: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:54:03.385: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  4 05:54:13.457: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  4 05:54:23.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-8855 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:54:23.832: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:54:23.832: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:54:23.832: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:54:43.878: INFO: Waiting for StatefulSet statefulset-8855/ss2 to complete update
STEP: Rolling back to a previous revision
Sep  4 05:54:53.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-8855 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  4 05:54:54.135: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  4 05:54:54.135: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  4 05:54:54.135: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  4 05:55:04.206: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  4 05:55:14.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 exec --namespace=statefulset-8855 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  4 05:55:14.959: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  4 05:55:14.959: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  4 05:55:14.959: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  4 05:55:25.176: INFO: Waiting for StatefulSet statefulset-8855/ss2 to complete update
Sep  4 05:55:25.176: INFO: Waiting for Pod statefulset-8855/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 05:55:25.176: INFO: Waiting for Pod statefulset-8855/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 05:55:25.176: INFO: Waiting for Pod statefulset-8855/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 05:55:35.205: INFO: Waiting for StatefulSet statefulset-8855/ss2 to complete update
Sep  4 05:55:35.205: INFO: Waiting for Pod statefulset-8855/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep  4 05:55:45.196: INFO: Waiting for StatefulSet statefulset-8855/ss2 to complete update
Sep  4 05:55:45.196: INFO: Waiting for Pod statefulset-8855/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  4 05:55:55.203: INFO: Deleting all statefulset in ns statefulset-8855
Sep  4 05:55:55.219: INFO: Scaling statefulset ss2 to 0
Sep  4 05:56:25.276: INFO: Waiting for statefulset status.replicas updated to 0
Sep  4 05:56:25.279: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:56:25.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8855" for this suite.
Sep  4 05:56:31.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:56:31.462: INFO: namespace statefulset-8855 deletion completed in 6.166909155s

• [SLOW TEST:158.609 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:56:31.462: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 05:56:31.654: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  4 05:56:31.678: INFO: Number of nodes with available pods: 0
Sep  4 05:56:31.678: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:56:32.687: INFO: Number of nodes with available pods: 0
Sep  4 05:56:32.687: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:56:33.702: INFO: Number of nodes with available pods: 1
Sep  4 05:56:33.702: INFO: Node 192.168.1.101 is running more than one daemon pod
Sep  4 05:56:34.724: INFO: Number of nodes with available pods: 3
Sep  4 05:56:34.724: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  4 05:56:34.799: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:34.799: INFO: Wrong image for pod: daemon-set-prdm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:34.799: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:35.830: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:35.831: INFO: Wrong image for pod: daemon-set-prdm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:35.831: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:36.824: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:36.824: INFO: Wrong image for pod: daemon-set-prdm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:36.824: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:37.834: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:37.835: INFO: Wrong image for pod: daemon-set-prdm5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:37.835: INFO: Pod daemon-set-prdm5 is not available
Sep  4 05:56:37.835: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:39.284: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:39.284: INFO: Pod daemon-set-82x4t is not available
Sep  4 05:56:39.284: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:39.826: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:39.826: INFO: Pod daemon-set-82x4t is not available
Sep  4 05:56:39.826: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:40.826: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:40.826: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:41.836: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:41.836: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:42.841: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:42.841: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:42.841: INFO: Pod daemon-set-z5l7d is not available
Sep  4 05:56:43.826: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:43.826: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:43.826: INFO: Pod daemon-set-z5l7d is not available
Sep  4 05:56:44.825: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:44.825: INFO: Wrong image for pod: daemon-set-z5l7d. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:44.825: INFO: Pod daemon-set-z5l7d is not available
Sep  4 05:56:45.853: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:45.853: INFO: Pod daemon-set-d2gvs is not available
Sep  4 05:56:46.863: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:46.866: INFO: Pod daemon-set-d2gvs is not available
Sep  4 05:56:47.826: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:47.826: INFO: Pod daemon-set-d2gvs is not available
Sep  4 05:56:48.846: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:48.846: INFO: Pod daemon-set-d2gvs is not available
Sep  4 05:56:49.828: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:49.828: INFO: Pod daemon-set-d2gvs is not available
Sep  4 05:56:50.825: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:51.862: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:52.844: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:52.844: INFO: Pod daemon-set-7v697 is not available
Sep  4 05:56:53.827: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:53.827: INFO: Pod daemon-set-7v697 is not available
Sep  4 05:56:54.842: INFO: Wrong image for pod: daemon-set-7v697. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  4 05:56:54.842: INFO: Pod daemon-set-7v697 is not available
Sep  4 05:56:55.829: INFO: Pod daemon-set-gg7sg is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  4 05:56:55.859: INFO: Number of nodes with available pods: 2
Sep  4 05:56:55.859: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:56:56.868: INFO: Number of nodes with available pods: 2
Sep  4 05:56:56.868: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:56:57.885: INFO: Number of nodes with available pods: 2
Sep  4 05:56:57.885: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:56:58.869: INFO: Number of nodes with available pods: 2
Sep  4 05:56:58.869: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:56:59.867: INFO: Number of nodes with available pods: 2
Sep  4 05:56:59.867: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:57:00.867: INFO: Number of nodes with available pods: 2
Sep  4 05:57:00.867: INFO: Node 192.168.1.103 is running more than one daemon pod
Sep  4 05:57:01.880: INFO: Number of nodes with available pods: 3
Sep  4 05:57:01.880: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7466, will wait for the garbage collector to delete the pods
Sep  4 05:57:01.963: INFO: Deleting DaemonSet.extensions daemon-set took: 5.948478ms
Sep  4 05:57:02.364: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.308023ms
Sep  4 05:57:16.273: INFO: Number of nodes with available pods: 0
Sep  4 05:57:16.273: INFO: Number of running nodes: 0, number of available pods: 0
Sep  4 05:57:16.279: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7466/daemonsets","resourceVersion":"21150"},"items":null}

Sep  4 05:57:16.283: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7466/pods","resourceVersion":"21150"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:57:16.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7466" for this suite.
Sep  4 05:57:22.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:57:22.525: INFO: namespace daemonsets-7466 deletion completed in 6.225140349s

• [SLOW TEST:51.064 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:57:22.526: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d
Sep  4 05:57:22.761: INFO: Pod name my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d: Found 0 pods out of 1
Sep  4 05:57:27.781: INFO: Pod name my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d: Found 1 pods out of 1
Sep  4 05:57:27.781: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d" are running
Sep  4 05:57:27.803: INFO: Pod "my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d-hpwhf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:57:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:57:25 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:57:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-04 05:57:22 +0000 UTC Reason: Message:}])
Sep  4 05:57:27.803: INFO: Trying to dial the pod
Sep  4 05:57:32.857: INFO: Controller my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d: Got expected result from replica 1 [my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d-hpwhf]: "my-hostname-basic-c3ccb034-f54e-4e7e-a92b-f488bd6ceb8d-hpwhf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:57:32.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4416" for this suite.
Sep  4 05:57:38.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:57:39.006: INFO: namespace replication-controller-4416 deletion completed in 6.12249495s

• [SLOW TEST:16.479 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:57:39.006: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  4 05:57:39.174: INFO: PodSpec: initContainers in spec.initContainers
Sep  4 05:58:24.475: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-97226813-30fc-4475-ab49-628d40005083", GenerateName:"", Namespace:"init-container-1905", SelfLink:"/api/v1/namespaces/init-container-1905/pods/pod-init-97226813-30fc-4475-ab49-628d40005083", UID:"500f8ba8-76e0-478d-b4e4-a9966d27686b", ResourceVersion:"21357", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703173459, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"174927785"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.10.80.5/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hqxzk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003ec8700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hqxzk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hqxzk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hqxzk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00064d2c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.1.101", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023ce9c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00064d3a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00064d3c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00064d3c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00064d3cc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703173459, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703173459, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703173459, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703173459, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.101", PodIP:"10.10.80.5", StartTime:(*v1.Time)(0xc0007f25c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000aed340)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000aed3b0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://e2718051a186ed5e2ba060f8c86f9ab7325c0b0a3656adcd38b1caa89997499d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0007f2620), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0007f25e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:58:24.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1905" for this suite.
Sep  4 05:58:48.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:58:48.910: INFO: namespace init-container-1905 deletion completed in 24.427112652s

• [SLOW TEST:69.904 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:58:48.910: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  4 05:58:51.136: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:58:51.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-499" for this suite.
Sep  4 05:58:57.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:58:57.338: INFO: namespace container-runtime-499 deletion completed in 6.139824215s

• [SLOW TEST:8.428 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:58:57.339: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  4 05:58:57.503: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  4 05:58:57.521: INFO: Waiting for terminating namespaces to be deleted...
Sep  4 05:58:57.530: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.101 before test
Sep  4 05:58:57.556: INFO: calico-kube-controllers-65b8787765-j25mh from kube-system started at 2019-09-04 04:29:17 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.556: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  4 05:58:57.556: INFO: sonobuoy-e2e-job-ba0b01e0e48b4e68 from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.556: INFO: 	Container e2e ready: true, restart count 0
Sep  4 05:58:57.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  4 05:58:57.556: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-k4lpq from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.556: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:58:57.556: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  4 05:58:57.556: INFO: node-dns-bc4lx from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.556: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:58:57.556: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:58:57.556: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-04 04:30:10 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.557: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  4 05:58:57.557: INFO: calico-node-sdb87 from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.557: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:58:57.557: INFO: cluster-dns-74877f46df-96tqd from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.557: INFO: 	Container coredns ready: true, restart count 0
Sep  4 05:58:57.557: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.102 before test
Sep  4 05:58:57.580: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-7q2hh from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.581: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:58:57.581: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  4 05:58:57.581: INFO: node-dns-mvf5k from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.581: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:58:57.581: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:58:57.581: INFO: calico-node-wjlwp from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.581: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:58:57.581: INFO: 
Logging pods the kubelet thinks is on node 192.168.1.103 before test
Sep  4 05:58:57.614: INFO: calico-node-n4c7b from kube-system started at 2019-09-04 04:28:53 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.614: INFO: 	Container calico-node ready: true, restart count 0
Sep  4 05:58:57.614: INFO: cluster-dns-74877f46df-xcqpv from kube-system started at 2019-09-04 04:30:07 +0000 UTC (1 container statuses recorded)
Sep  4 05:58:57.614: INFO: 	Container coredns ready: true, restart count 0
Sep  4 05:58:57.614: INFO: node-dns-rzb6n from kube-system started at 2019-09-04 04:28:21 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.614: INFO: 	Container reload ready: true, restart count 0
Sep  4 05:58:57.614: INFO: 	Container unbound ready: true, restart count 0
Sep  4 05:58:57.614: INFO: sonobuoy-systemd-logs-daemon-set-edefd813683c49b6-fjq4x from heptio-sonobuoy started at 2019-09-04 04:30:22 +0000 UTC (2 container statuses recorded)
Sep  4 05:58:57.614: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  4 05:58:57.614: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-41bce8a5-e71c-4291-be1e-38a848c945f3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-41bce8a5-e71c-4291-be1e-38a848c945f3 off the node 192.168.1.101
STEP: verifying the node doesn't have the label kubernetes.io/e2e-41bce8a5-e71c-4291-be1e-38a848c945f3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:59:01.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7556" for this suite.
Sep  4 05:59:15.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 05:59:15.953: INFO: namespace sched-pred-7556 deletion completed in 14.118724525s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:18.615 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 05:59:15.953: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  4 05:59:20.256: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ee3b3c71-92ac-4809-abfa-baaa6cedde10,GenerateName:,Namespace:events-6284,SelfLink:/api/v1/namespaces/events-6284/pods/send-events-ee3b3c71-92ac-4809-abfa-baaa6cedde10,UID:aacfd6da-3f0a-4244-8a1d-7605c9830d6e,ResourceVersion:21553,Generation:0,CreationTimestamp:2019-09-04 05:59:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 114326583,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.80.10/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pclrq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pclrq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-pclrq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003ee9b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003ee9b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:59:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:59:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:59:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 05:59:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:10.10.80.10,StartTime:2019-09-04 05:59:16 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-04 05:59:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://870ed0dafe5d5f11349dd07fdeb3687d92d95001ff8d4febd0b50afd760c4185}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  4 05:59:22.261: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  4 05:59:24.270: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 05:59:24.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6284" for this suite.
Sep  4 06:00:02.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:00:02.923: INFO: namespace events-6284 deletion completed in 38.619554262s

• [SLOW TEST:46.970 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:00:02.937: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-c4dc0bd0-f45e-4799-8626-5d63bd7a80d4
STEP: Creating a pod to test consume secrets
Sep  4 06:00:03.203: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8" in namespace "projected-8322" to be "success or failure"
Sep  4 06:00:03.213: INFO: Pod "pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.13836ms
Sep  4 06:00:05.236: INFO: Pod "pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032895873s
Sep  4 06:00:07.247: INFO: Pod "pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044050599s
STEP: Saw pod success
Sep  4 06:00:07.247: INFO: Pod "pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8" satisfied condition "success or failure"
Sep  4 06:00:07.259: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8 container secret-volume-test: <nil>
STEP: delete the pod
Sep  4 06:00:07.298: INFO: Waiting for pod pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8 to disappear
Sep  4 06:00:07.303: INFO: Pod pod-projected-secrets-782cee29-50df-486a-93a6-5959b31908f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:00:07.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8322" for this suite.
Sep  4 06:00:13.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:00:13.492: INFO: namespace projected-8322 deletion completed in 6.184829034s

• [SLOW TEST:10.555 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:00:13.492: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  4 06:00:13.647: INFO: Waiting up to 5m0s for pod "pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef" in namespace "emptydir-7042" to be "success or failure"
Sep  4 06:00:13.650: INFO: Pod "pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.703045ms
Sep  4 06:00:15.789: INFO: Pod "pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.141724646s
Sep  4 06:00:17.801: INFO: Pod "pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.153699724s
STEP: Saw pod success
Sep  4 06:00:17.801: INFO: Pod "pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef" satisfied condition "success or failure"
Sep  4 06:00:17.805: INFO: Trying to get logs from node 192.168.1.101 pod pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef container test-container: <nil>
STEP: delete the pod
Sep  4 06:00:17.827: INFO: Waiting for pod pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef to disappear
Sep  4 06:00:17.832: INFO: Pod pod-e0b62e4f-2bc9-44c3-9223-1bbc584126ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:00:17.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7042" for this suite.
Sep  4 06:00:23.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:00:24.043: INFO: namespace emptydir-7042 deletion completed in 6.207938128s

• [SLOW TEST:10.551 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:00:24.044: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-5dee10e6-d405-4015-b885-1f0f96181dca
STEP: Creating a pod to test consume configMaps
Sep  4 06:00:24.245: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d" in namespace "projected-9095" to be "success or failure"
Sep  4 06:00:24.277: INFO: Pod "pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d": Phase="Pending", Reason="", readiness=false. Elapsed: 31.494576ms
Sep  4 06:00:26.279: INFO: Pod "pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034011892s
STEP: Saw pod success
Sep  4 06:00:26.279: INFO: Pod "pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d" satisfied condition "success or failure"
Sep  4 06:00:26.281: INFO: Trying to get logs from node 192.168.1.101 pod pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  4 06:00:26.296: INFO: Waiting for pod pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d to disappear
Sep  4 06:00:26.298: INFO: Pod pod-projected-configmaps-7cf1b8f8-cb86-4a4b-bcd3-03c5c6f1365d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:00:26.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9095" for this suite.
Sep  4 06:00:32.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:00:32.583: INFO: namespace projected-9095 deletion completed in 6.280085947s

• [SLOW TEST:8.540 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:00:32.583: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  4 06:00:35.407: INFO: Successfully updated pod "labelsupdate6dee572f-0ad6-4829-b84d-7cedf186418a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:00:37.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1236" for this suite.
Sep  4 06:00:59.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:00:59.659: INFO: namespace projected-1236 deletion completed in 22.185162039s

• [SLOW TEST:27.076 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:00:59.660: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 06:00:59.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-830'
Sep  4 06:00:59.919: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 06:00:59.920: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep  4 06:00:59.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete deployment e2e-test-nginx-deployment --namespace=kubectl-830'
Sep  4 06:01:00.035: INFO: stderr: ""
Sep  4 06:01:00.035: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:01:00.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-830" for this suite.
Sep  4 06:01:06.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:01:06.305: INFO: namespace kubectl-830 deletion completed in 6.260351051s

• [SLOW TEST:6.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:01:06.305: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 06:01:06.463: INFO: Creating deployment "test-recreate-deployment"
Sep  4 06:01:06.498: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  4 06:01:06.538: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep  4 06:01:08.551: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  4 06:01:08.555: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  4 06:01:08.566: INFO: Updating deployment test-recreate-deployment
Sep  4 06:01:08.566: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  4 06:01:08.667: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-5701,SelfLink:/apis/apps/v1/namespaces/deployment-5701/deployments/test-recreate-deployment,UID:5ebe0649-3a3c-45ab-b40f-c7777784e7ac,ResourceVersion:21935,Generation:2,CreationTimestamp:2019-09-04 06:01:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-04 06:01:08 +0000 UTC 2019-09-04 06:01:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-04 06:01:08 +0000 UTC 2019-09-04 06:01:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  4 06:01:08.671: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-5701,SelfLink:/apis/apps/v1/namespaces/deployment-5701/replicasets/test-recreate-deployment-5c8c9cc69d,UID:1c273591-2f84-45bd-916e-9e24e23c7871,ResourceVersion:21932,Generation:1,CreationTimestamp:2019-09-04 06:01:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5ebe0649-3a3c-45ab-b40f-c7777784e7ac 0xc003f713e7 0xc003f713e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 06:01:08.671: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  4 06:01:08.671: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-5701,SelfLink:/apis/apps/v1/namespaces/deployment-5701/replicasets/test-recreate-deployment-6df85df6b9,UID:db08149d-ee39-4f59-9549-929428f9615c,ResourceVersion:21922,Generation:2,CreationTimestamp:2019-09-04 06:01:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5ebe0649-3a3c-45ab-b40f-c7777784e7ac 0xc003f714b7 0xc003f714b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  4 06:01:08.676: INFO: Pod "test-recreate-deployment-5c8c9cc69d-jvthg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-jvthg,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-5701,SelfLink:/api/v1/namespaces/deployment-5701/pods/test-recreate-deployment-5c8c9cc69d-jvthg,UID:ed90dc22-72e0-48b6-94ab-d5374c4c416c,ResourceVersion:21936,Generation:0,CreationTimestamp:2019-09-04 06:01:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 1c273591-2f84-45bd-916e-9e24e23c7871 0xc0025f6d07 0xc0025f6d08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hxkdj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hxkdj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hxkdj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025f6d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025f6da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 06:01:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 06:01:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-04 06:01:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-04 06:01:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.101,PodIP:,StartTime:2019-09-04 06:01:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:01:08.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5701" for this suite.
Sep  4 06:01:14.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:01:14.857: INFO: namespace deployment-5701 deletion completed in 6.172845067s

• [SLOW TEST:8.552 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:01:14.857: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep  4 06:01:15.028: INFO: Waiting up to 5m0s for pod "client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e" in namespace "containers-5327" to be "success or failure"
Sep  4 06:01:15.040: INFO: Pod "client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918323ms
Sep  4 06:01:17.045: INFO: Pod "client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017652266s
Sep  4 06:01:19.054: INFO: Pod "client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026342781s
STEP: Saw pod success
Sep  4 06:01:19.054: INFO: Pod "client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e" satisfied condition "success or failure"
Sep  4 06:01:19.059: INFO: Trying to get logs from node 192.168.1.101 pod client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e container test-container: <nil>
STEP: delete the pod
Sep  4 06:01:19.084: INFO: Waiting for pod client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e to disappear
Sep  4 06:01:19.089: INFO: Pod client-containers-c5635a1e-bab2-4e01-9e7a-511eb3d63b7e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:01:19.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5327" for this suite.
Sep  4 06:01:25.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:01:25.461: INFO: namespace containers-5327 deletion completed in 6.367575773s

• [SLOW TEST:10.604 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:01:25.462: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  4 06:01:25.646: INFO: Waiting up to 5m0s for pod "pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6" in namespace "emptydir-7227" to be "success or failure"
Sep  4 06:01:25.651: INFO: Pod "pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.013978ms
Sep  4 06:01:27.658: INFO: Pod "pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011812251s
Sep  4 06:01:29.754: INFO: Pod "pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107665637s
STEP: Saw pod success
Sep  4 06:01:29.754: INFO: Pod "pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6" satisfied condition "success or failure"
Sep  4 06:01:29.761: INFO: Trying to get logs from node 192.168.1.101 pod pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6 container test-container: <nil>
STEP: delete the pod
Sep  4 06:01:29.796: INFO: Waiting for pod pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6 to disappear
Sep  4 06:01:29.802: INFO: Pod pod-b93ef8de-ced1-4201-a3f4-4e4ac12277e6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:01:29.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7227" for this suite.
Sep  4 06:01:35.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:01:36.011: INFO: namespace emptydir-7227 deletion completed in 6.204798504s

• [SLOW TEST:10.549 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:01:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7827
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-f1da33f4-7605-4435-b94d-eb106d1607c1
STEP: Creating configMap with name cm-test-opt-upd-9feac823-9d2a-4ba1-9668-475e16a441f8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f1da33f4-7605-4435-b94d-eb106d1607c1
STEP: Updating configmap cm-test-opt-upd-9feac823-9d2a-4ba1-9668-475e16a441f8
STEP: Creating configMap with name cm-test-opt-create-8a830af7-eb03-4a0f-86ba-dcc43a34ddab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:03:02.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7827" for this suite.
Sep  4 06:03:24.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:03:24.835: INFO: namespace projected-7827 deletion completed in 22.148088613s

• [SLOW TEST:108.823 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:03:24.837: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:03:25.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6162" for this suite.
Sep  4 06:03:31.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:03:31.255: INFO: namespace kubelet-test-6162 deletion completed in 6.117661911s

• [SLOW TEST:6.418 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:03:31.260: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  4 06:03:51.545: INFO: Container started at 2019-09-04 06:03:32 +0000 UTC, pod became ready at 2019-09-04 06:03:49 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:03:51.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3854" for this suite.
Sep  4 06:04:13.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:04:13.712: INFO: namespace container-probe-3854 deletion completed in 22.151069519s

• [SLOW TEST:42.453 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:04:13.713: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8404.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8404.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  4 06:04:18.042: INFO: Unable to read wheezy_udp@PodARecord from pod dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958: the server could not find the requested resource (get pods dns-test-d34dc631-447e-4819-9910-5fd19be92958)
Sep  4 06:04:18.068: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958: the server could not find the requested resource (get pods dns-test-d34dc631-447e-4819-9910-5fd19be92958)
Sep  4 06:04:18.096: INFO: Unable to read jessie_udp@PodARecord from pod dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958: the server could not find the requested resource (get pods dns-test-d34dc631-447e-4819-9910-5fd19be92958)
Sep  4 06:04:18.103: INFO: Unable to read jessie_tcp@PodARecord from pod dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958: the server could not find the requested resource (get pods dns-test-d34dc631-447e-4819-9910-5fd19be92958)
Sep  4 06:04:18.103: INFO: Lookups using dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Sep  4 06:04:23.170: INFO: DNS probes using dns-8404/dns-test-d34dc631-447e-4819-9910-5fd19be92958 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:04:23.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8404" for this suite.
Sep  4 06:04:29.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:04:29.446: INFO: namespace dns-8404 deletion completed in 6.22749363s

• [SLOW TEST:15.733 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:04:29.446: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4715
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-5faa37fc-c035-44df-a4b6-3167d4225df0
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:04:31.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4715" for this suite.
Sep  4 06:04:53.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:04:54.158: INFO: namespace configmap-4715 deletion completed in 22.381180515s

• [SLOW TEST:24.712 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  4 06:04:54.159: INFO: >>> kubeConfig: /tmp/kubeconfig-172565266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  4 06:04:54.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7304'
Sep  4 06:04:54.526: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  4 06:04:54.526: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  4 06:04:54.538: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-wsmw9]
Sep  4 06:04:54.538: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-wsmw9" in namespace "kubectl-7304" to be "running and ready"
Sep  4 06:04:54.544: INFO: Pod "e2e-test-nginx-rc-wsmw9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.719175ms
Sep  4 06:04:56.556: INFO: Pod "e2e-test-nginx-rc-wsmw9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017889521s
Sep  4 06:04:58.566: INFO: Pod "e2e-test-nginx-rc-wsmw9": Phase="Running", Reason="", readiness=true. Elapsed: 4.027864107s
Sep  4 06:04:58.566: INFO: Pod "e2e-test-nginx-rc-wsmw9" satisfied condition "running and ready"
Sep  4 06:04:58.566: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-wsmw9]
Sep  4 06:04:58.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 logs rc/e2e-test-nginx-rc --namespace=kubectl-7304'
Sep  4 06:04:58.778: INFO: stderr: ""
Sep  4 06:04:58.778: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep  4 06:04:58.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172565266 delete rc e2e-test-nginx-rc --namespace=kubectl-7304'
Sep  4 06:04:58.899: INFO: stderr: ""
Sep  4 06:04:58.899: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  4 06:04:58.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7304" for this suite.
Sep  4 06:05:04.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  4 06:05:05.192: INFO: namespace kubectl-7304 deletion completed in 6.284773262s

• [SLOW TEST:11.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSep  4 06:05:05.193: INFO: Running AfterSuite actions on all nodes
Sep  4 06:05:05.193: INFO: Running AfterSuite actions on node 1
Sep  4 06:05:05.193: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5639.818 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h34m0.876943358s
Test Suite Passed
